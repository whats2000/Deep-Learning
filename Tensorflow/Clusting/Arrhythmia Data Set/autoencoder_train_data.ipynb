{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-05-11T12:50:35.522250Z",
     "end_time": "2023-05-11T12:50:35.574054Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-05-11T12:50:35.526479Z",
     "end_time": "2023-05-11T12:50:35.630766Z"
    }
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('./Data/train_data.csv', header=None)\n",
    "label = pd.read_csv('./Data/train_label.csv', header=None)\n",
    "data.columns = [f'a{i}' for i in data.columns]\n",
    "label.columns = ['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-05-11T12:50:35.566338Z",
     "end_time": "2023-05-11T12:50:35.630766Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# 創建OneHotEncoder對象\n",
    "enc = OneHotEncoder()\n",
    "\n",
    "# 將訓練集和測試集的標籤都用於擬合Encoder\n",
    "enc.fit(label)\n",
    "\n",
    "# 將訓練集和測試集的標籤都轉換成One-Hot編碼\n",
    "label_enc = enc.transform(label).toarray()\n",
    "\n",
    "# 新增一個column並填入0\n",
    "unknown_col = np.zeros((label_enc.shape[0], 1))\n",
    "\n",
    "# 將unknown column插入到最後一欄\n",
    "label_enc = np.hstack((label_enc, unknown_col))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-05-11T12:50:35.570046Z",
     "end_time": "2023-05-11T12:50:35.630766Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "       0    1    2    3    4    5    6    7    8\n0    0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0\n1    0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0\n2    1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0\n3    0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0\n4    1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0\n..   ...  ...  ...  ...  ...  ...  ...  ...  ...\n288  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0\n289  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0\n290  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0\n291  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0\n292  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0\n\n[293 rows x 9 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n      <th>4</th>\n      <th>5</th>\n      <th>6</th>\n      <th>7</th>\n      <th>8</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>288</th>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>289</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>290</th>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>291</th>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>292</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>293 rows × 9 columns</p>\n</div>"
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(label_enc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-05-11T12:50:35.590796Z",
     "end_time": "2023-05-11T12:50:35.652995Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "array([[ 75. ,   0. , 190. , ...,   2.9,  23.3,  49.4],\n       [ 56. ,   1. , 165. , ...,   2.1,  20.4,  38.8],\n       [ 55. ,   0. , 175. , ...,   2.6,  34.6,  61.6],\n       ...,\n       [ 54. ,   0. , 160. , ...,  -0.8,  24.4,  18.2],\n       [ 62. ,   1. , 157. , ...,  -0.8,  35.7,  28.5],\n       [ 40. ,   0. , 170. , ...,   1.5,  24.6,  42. ]])"
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 填補缺失值\n",
    "data_no_na = np.array(pd.DataFrame(data).fillna(pd.DataFrame(data).mean()))\n",
    "data_no_na"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-05-11T12:50:35.652995Z",
     "end_time": "2023-05-11T12:50:35.655816Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 分割數據集和標籤為訓練集和測試集\n",
    "train_data, test_data, train_label, test_label = train_test_split(data_no_na, label_enc, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-05-11T12:50:35.659816Z",
     "end_time": "2023-05-11T12:50:35.664851Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "train_data_scaled = scaler.fit_transform(train_data)\n",
    "test_data_scaled = scaler.transform(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-05-11T12:50:35.664851Z",
     "end_time": "2023-05-11T12:50:35.781482Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "          0         1         2         3         4         5         6     \n0    1.279549 -1.178030 -0.057136 -0.960855 -0.690643  0.368423 -0.080128  \\\n1   -1.102007  0.848875 -0.286522 -0.666562 -0.795110  0.474074  0.138621   \n2    0.948778  0.848875 -0.188214 -0.372268 -0.690643 -0.397545  1.763616   \n3    0.221080  0.848875 -0.352061  2.040936 -0.168308  1.609819  1.669866   \n4    0.221080  0.848875 -0.352061  0.039742 -0.795110 -0.503196  0.044872   \n..        ...       ...       ...       ...       ...       ...       ...   \n229  2.073401 -1.178030  0.237788  0.922622  0.771895  0.711788 -0.267627   \n230 -1.962013 -1.178030 -0.024367 -1.137431  1.085296 -0.133418  0.201121   \n231  0.287234  0.848875 -0.352061 -0.372268 -1.212978  0.236360  0.607370   \n232  0.684160 -1.178030 -0.024367  0.275177  0.667428  0.051471  0.669870   \n233  1.478012 -1.178030  0.139480 -1.019714 -1.526379  0.051471 -1.298874   \n\n          7         8         9    ...       269       270       271   \n0    0.108400  0.666899  0.357239  ...  0.857564  0.521775 -0.138147  \\\n1   -0.452787 -0.286421 -0.590991  ...  0.638253  0.521775  0.357752   \n2   -0.845618 -0.452216  0.606774  ... -0.458305  0.521775 -0.881995   \n3    1.483310  1.122835 -0.141829  ...  0.857564  0.521775 -0.355103   \n4   -0.565025 -0.286421 -0.590991  ... -0.458305  0.521775  0.698682   \n..        ...       ...       ...  ...       ...       ...       ...   \n229 -0.536965 -0.659460 -0.391364  ... -0.896928 -2.009707  0.016821   \n230 -0.593084  0.501105  0.881262  ... -1.993485 -1.425519  2.093396   \n231 -0.508906  0.293861 -0.091922  ...  1.076876  0.521775 -1.036963   \n232 -0.144134  0.584002 -0.840526  ...  0.418941 -1.230790 -0.758020   \n233 -0.929796  0.542553 -0.166783  ...  0.199630  0.521775 -0.572058   \n\n          272       273  274       275       276       277       278  \n0    0.285652 -0.110883  0.0  0.579841  1.191817 -0.020894  0.738835  \n1    0.913283 -0.110883  0.0  1.225949  0.355921  1.901986  1.384377  \n2   -0.341978 -0.110883  0.0 -0.712376 -0.479974 -0.788321 -0.816079  \n3   -1.911055 -0.110883  0.0  0.256787 -0.403984 -0.762453 -0.664517  \n4    0.913283 -0.110883  0.0  0.579841  0.051959  0.608569  0.239242  \n..        ...       ...  ...       ...       ...       ...       ...  \n229  0.913283 -0.110883  0.0  1.225949 -1.163889  0.436114 -0.479275  \n230 -0.734247 -0.110883  0.0 -0.712376 -2.531718  1.151805 -1.394260  \n231  0.521014 -0.110883  0.0 -0.066268 -0.100022 -0.607243 -0.484888  \n232  0.913283 -0.110883  0.0  0.256787  0.811864 -0.357182  0.362736  \n233  0.913283 -0.110883  0.0 -0.389322  1.039836 -0.236463  0.592886  \n\n[234 rows x 279 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n      <th>4</th>\n      <th>5</th>\n      <th>6</th>\n      <th>7</th>\n      <th>8</th>\n      <th>9</th>\n      <th>...</th>\n      <th>269</th>\n      <th>270</th>\n      <th>271</th>\n      <th>272</th>\n      <th>273</th>\n      <th>274</th>\n      <th>275</th>\n      <th>276</th>\n      <th>277</th>\n      <th>278</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1.279549</td>\n      <td>-1.178030</td>\n      <td>-0.057136</td>\n      <td>-0.960855</td>\n      <td>-0.690643</td>\n      <td>0.368423</td>\n      <td>-0.080128</td>\n      <td>0.108400</td>\n      <td>0.666899</td>\n      <td>0.357239</td>\n      <td>...</td>\n      <td>0.857564</td>\n      <td>0.521775</td>\n      <td>-0.138147</td>\n      <td>0.285652</td>\n      <td>-0.110883</td>\n      <td>0.0</td>\n      <td>0.579841</td>\n      <td>1.191817</td>\n      <td>-0.020894</td>\n      <td>0.738835</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>-1.102007</td>\n      <td>0.848875</td>\n      <td>-0.286522</td>\n      <td>-0.666562</td>\n      <td>-0.795110</td>\n      <td>0.474074</td>\n      <td>0.138621</td>\n      <td>-0.452787</td>\n      <td>-0.286421</td>\n      <td>-0.590991</td>\n      <td>...</td>\n      <td>0.638253</td>\n      <td>0.521775</td>\n      <td>0.357752</td>\n      <td>0.913283</td>\n      <td>-0.110883</td>\n      <td>0.0</td>\n      <td>1.225949</td>\n      <td>0.355921</td>\n      <td>1.901986</td>\n      <td>1.384377</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.948778</td>\n      <td>0.848875</td>\n      <td>-0.188214</td>\n      <td>-0.372268</td>\n      <td>-0.690643</td>\n      <td>-0.397545</td>\n      <td>1.763616</td>\n      <td>-0.845618</td>\n      <td>-0.452216</td>\n      <td>0.606774</td>\n      <td>...</td>\n      <td>-0.458305</td>\n      <td>0.521775</td>\n      <td>-0.881995</td>\n      <td>-0.341978</td>\n      <td>-0.110883</td>\n      <td>0.0</td>\n      <td>-0.712376</td>\n      <td>-0.479974</td>\n      <td>-0.788321</td>\n      <td>-0.816079</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.221080</td>\n      <td>0.848875</td>\n      <td>-0.352061</td>\n      <td>2.040936</td>\n      <td>-0.168308</td>\n      <td>1.609819</td>\n      <td>1.669866</td>\n      <td>1.483310</td>\n      <td>1.122835</td>\n      <td>-0.141829</td>\n      <td>...</td>\n      <td>0.857564</td>\n      <td>0.521775</td>\n      <td>-0.355103</td>\n      <td>-1.911055</td>\n      <td>-0.110883</td>\n      <td>0.0</td>\n      <td>0.256787</td>\n      <td>-0.403984</td>\n      <td>-0.762453</td>\n      <td>-0.664517</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.221080</td>\n      <td>0.848875</td>\n      <td>-0.352061</td>\n      <td>0.039742</td>\n      <td>-0.795110</td>\n      <td>-0.503196</td>\n      <td>0.044872</td>\n      <td>-0.565025</td>\n      <td>-0.286421</td>\n      <td>-0.590991</td>\n      <td>...</td>\n      <td>-0.458305</td>\n      <td>0.521775</td>\n      <td>0.698682</td>\n      <td>0.913283</td>\n      <td>-0.110883</td>\n      <td>0.0</td>\n      <td>0.579841</td>\n      <td>0.051959</td>\n      <td>0.608569</td>\n      <td>0.239242</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>229</th>\n      <td>2.073401</td>\n      <td>-1.178030</td>\n      <td>0.237788</td>\n      <td>0.922622</td>\n      <td>0.771895</td>\n      <td>0.711788</td>\n      <td>-0.267627</td>\n      <td>-0.536965</td>\n      <td>-0.659460</td>\n      <td>-0.391364</td>\n      <td>...</td>\n      <td>-0.896928</td>\n      <td>-2.009707</td>\n      <td>0.016821</td>\n      <td>0.913283</td>\n      <td>-0.110883</td>\n      <td>0.0</td>\n      <td>1.225949</td>\n      <td>-1.163889</td>\n      <td>0.436114</td>\n      <td>-0.479275</td>\n    </tr>\n    <tr>\n      <th>230</th>\n      <td>-1.962013</td>\n      <td>-1.178030</td>\n      <td>-0.024367</td>\n      <td>-1.137431</td>\n      <td>1.085296</td>\n      <td>-0.133418</td>\n      <td>0.201121</td>\n      <td>-0.593084</td>\n      <td>0.501105</td>\n      <td>0.881262</td>\n      <td>...</td>\n      <td>-1.993485</td>\n      <td>-1.425519</td>\n      <td>2.093396</td>\n      <td>-0.734247</td>\n      <td>-0.110883</td>\n      <td>0.0</td>\n      <td>-0.712376</td>\n      <td>-2.531718</td>\n      <td>1.151805</td>\n      <td>-1.394260</td>\n    </tr>\n    <tr>\n      <th>231</th>\n      <td>0.287234</td>\n      <td>0.848875</td>\n      <td>-0.352061</td>\n      <td>-0.372268</td>\n      <td>-1.212978</td>\n      <td>0.236360</td>\n      <td>0.607370</td>\n      <td>-0.508906</td>\n      <td>0.293861</td>\n      <td>-0.091922</td>\n      <td>...</td>\n      <td>1.076876</td>\n      <td>0.521775</td>\n      <td>-1.036963</td>\n      <td>0.521014</td>\n      <td>-0.110883</td>\n      <td>0.0</td>\n      <td>-0.066268</td>\n      <td>-0.100022</td>\n      <td>-0.607243</td>\n      <td>-0.484888</td>\n    </tr>\n    <tr>\n      <th>232</th>\n      <td>0.684160</td>\n      <td>-1.178030</td>\n      <td>-0.024367</td>\n      <td>0.275177</td>\n      <td>0.667428</td>\n      <td>0.051471</td>\n      <td>0.669870</td>\n      <td>-0.144134</td>\n      <td>0.584002</td>\n      <td>-0.840526</td>\n      <td>...</td>\n      <td>0.418941</td>\n      <td>-1.230790</td>\n      <td>-0.758020</td>\n      <td>0.913283</td>\n      <td>-0.110883</td>\n      <td>0.0</td>\n      <td>0.256787</td>\n      <td>0.811864</td>\n      <td>-0.357182</td>\n      <td>0.362736</td>\n    </tr>\n    <tr>\n      <th>233</th>\n      <td>1.478012</td>\n      <td>-1.178030</td>\n      <td>0.139480</td>\n      <td>-1.019714</td>\n      <td>-1.526379</td>\n      <td>0.051471</td>\n      <td>-1.298874</td>\n      <td>-0.929796</td>\n      <td>0.542553</td>\n      <td>-0.166783</td>\n      <td>...</td>\n      <td>0.199630</td>\n      <td>0.521775</td>\n      <td>-0.572058</td>\n      <td>0.913283</td>\n      <td>-0.110883</td>\n      <td>0.0</td>\n      <td>-0.389322</td>\n      <td>1.039836</td>\n      <td>-0.236463</td>\n      <td>0.592886</td>\n    </tr>\n  </tbody>\n</table>\n<p>234 rows × 279 columns</p>\n</div>"
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(train_data_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-05-11T12:50:35.696918Z",
     "end_time": "2023-05-11T12:50:35.781482Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "(234, 279)"
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data_scaled.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-05-11T12:50:35.703337Z",
     "end_time": "2023-05-11T12:50:35.797849Z"
    }
   },
   "outputs": [],
   "source": [
    "train_data_3d = np.reshape(train_data_scaled, (train_data_scaled.shape[0], train_data_scaled.shape[1], 1))\n",
    "test_data_3d = np.reshape(test_data_scaled, (test_data_scaled.shape[0], test_data_scaled.shape[1], 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-05-11T12:50:35.711080Z",
     "end_time": "2023-05-11T12:50:35.797849Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "array([[[ 1.27954927],\n        [-1.17803018],\n        [-0.05713642],\n        ...,\n        [ 1.19181677],\n        [-0.02089366],\n        [ 0.73883476]],\n\n       [[-1.10200686],\n        [ 0.84887469],\n        [-0.28652235],\n        ...,\n        [ 0.3559213 ],\n        [ 1.90198642],\n        [ 1.38437661]],\n\n       [[ 0.94877758],\n        [ 0.84887469],\n        [-0.1882141 ],\n        ...,\n        [-0.47997417],\n        [-0.78832113],\n        [-0.81607909]],\n\n       ...,\n\n       [[ 0.28723422],\n        [ 0.84887469],\n        [-0.35206119],\n        ...,\n        [-0.10002168],\n        [-0.60724274],\n        [-0.48488805]],\n\n       [[ 0.68416024],\n        [-1.17803018],\n        [-0.024367  ],\n        ...,\n        [ 0.81186429],\n        [-0.3571821 ],\n        [ 0.36273647]],\n\n       [[ 1.47801228],\n        [-1.17803018],\n        [ 0.13948009],\n        ...,\n        [ 1.03983578],\n        [-0.23646318],\n        [ 0.59288617]]])"
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data_3d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-05-11T12:50:35.719220Z",
     "end_time": "2023-05-11T12:50:35.797849Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": "(234, 279, 1)"
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data_3d.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-05-11T12:50:35.727104Z",
     "end_time": "2023-05-11T12:50:35.797849Z"
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-05-11T12:50:35.730977Z",
     "end_time": "2023-05-11T12:50:35.797849Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "[PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU')]"
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.config.list_physical_devices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-05-11T12:50:35.739428Z",
     "end_time": "2023-05-11T12:50:35.797849Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  0\n"
     ]
    }
   ],
   "source": [
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('gpu')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-05-11T12:50:35.747280Z",
     "end_time": "2023-05-11T12:50:35.797849Z"
    }
   },
   "outputs": [],
   "source": [
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "  # Create 2 virtual GPUs with 1GB memory each\n",
    "  try:\n",
    "    tf.config.set_logical_device_configuration(\n",
    "        gpus[0],\n",
    "        [tf.config.LogicalDeviceConfiguration(memory_limit=1024),\n",
    "         tf.config.LogicalDeviceConfiguration(memory_limit=1024)])\n",
    "    logical_gpus = tf.config.list_logical_devices('GPU')\n",
    "    print(len(gpus), \"Physical GPU,\", len(logical_gpus), \"Logical GPUs\")\n",
    "  except RuntimeError as e:\n",
    "    # Virtual devices must be set before GPUs have been initialized\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-05-11T12:50:35.761001Z",
     "end_time": "2023-05-11T12:50:36.055347Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_4 (LSTM)               (None, 48)                9600      \n",
      "                                                                 \n",
      " dropout_10 (Dropout)        (None, 48)                0         \n",
      "                                                                 \n",
      " batch_normalization_10 (Bat  (None, 48)               192       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dense_10 (Dense)            (None, 36)                1764      \n",
      "                                                                 \n",
      " dropout_11 (Dropout)        (None, 36)                0         \n",
      "                                                                 \n",
      " batch_normalization_11 (Bat  (None, 36)               144       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dense_11 (Dense)            (None, 24)                888       \n",
      "                                                                 \n",
      " dropout_12 (Dropout)        (None, 24)                0         \n",
      "                                                                 \n",
      " batch_normalization_12 (Bat  (None, 24)               96        \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dense_12 (Dense)            (None, 18)                450       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 13,134\n",
      "Trainable params: 12,918\n",
      "Non-trainable params: 216\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras import regularizers\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.layers import BatchNormalization\n",
    "# 建立編碼模型\n",
    "encoder = keras.models.Sequential([\n",
    "    keras.layers.LSTM(48, activation='tanh', return_sequences=False, input_shape=(train_data_3d.shape[1], train_data_3d.shape[2]), kernel_regularizer=regularizers.l2(0.001)),\n",
    "    Dropout(0.1),\n",
    "    BatchNormalization(),\n",
    "    Dense(36, activation='relu', kernel_regularizer=regularizers.l2(0.001)),\n",
    "    Dropout(0.1),\n",
    "    BatchNormalization(),\n",
    "    Dense(24, activation='relu', kernel_regularizer=regularizers.l2(0.001)),\n",
    "    Dropout(0.1),\n",
    "    BatchNormalization(),\n",
    "    Dense(18, activation='relu', kernel_regularizer=regularizers.l2(0.001))\n",
    "])\n",
    "\n",
    "encoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-05-11T12:50:36.071464Z",
     "end_time": "2023-05-11T12:50:36.542273Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_13 (Dense)            (None, 24)                456       \n",
      "                                                                 \n",
      " dropout_13 (Dropout)        (None, 24)                0         \n",
      "                                                                 \n",
      " batch_normalization_13 (Bat  (None, 24)               96        \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dense_14 (Dense)            (None, 36)                900       \n",
      "                                                                 \n",
      " dropout_14 (Dropout)        (None, 36)                0         \n",
      "                                                                 \n",
      " batch_normalization_14 (Bat  (None, 36)               144       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dense_15 (Dense)            (None, 48)                1776      \n",
      "                                                                 \n",
      " dropout_15 (Dropout)        (None, 48)                0         \n",
      "                                                                 \n",
      " batch_normalization_15 (Bat  (None, 48)               192       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " repeat_vector_2 (RepeatVect  (None, 279, 48)          0         \n",
      " or)                                                             \n",
      "                                                                 \n",
      " lstm_5 (LSTM)               (None, 279, 48)           18624     \n",
      "                                                                 \n",
      " time_distributed_4 (TimeDis  (None, 279, 1)           49        \n",
      " tributed)                                                       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 22,237\n",
      "Trainable params: 22,021\n",
      "Non-trainable params: 216\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# 建立解碼模型\n",
    "decoder = keras.models.Sequential([\n",
    "    keras.layers.Dense(24, activation='relu', input_shape=(18,), kernel_regularizer=regularizers.l2(0.001)),\n",
    "    Dropout(0.1),\n",
    "    BatchNormalization(),\n",
    "    keras.layers.Dense(36, activation='relu', kernel_regularizer=regularizers.l2(0.001)),\n",
    "    Dropout(0.1),\n",
    "    BatchNormalization(),\n",
    "    keras.layers.Dense(48, activation='relu', kernel_regularizer=regularizers.l2(0.001)),\n",
    "    Dropout(0.1),\n",
    "    BatchNormalization(),\n",
    "    keras.layers.RepeatVector(train_data_3d.shape[1]),\n",
    "    keras.layers.LSTM(48, activation='tanh', return_sequences=True, kernel_regularizer=regularizers.l2(0.001)),\n",
    "    keras.layers.TimeDistributed(keras.layers.Dense(train_data_3d.shape[2], activation='linear'))\n",
    "])\n",
    "\n",
    "decoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_8\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " sequential_6 (Sequential)   (None, 18)                13134     \n",
      "                                                                 \n",
      " sequential_7 (Sequential)   (None, 279, 1)            22237     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 35,371\n",
      "Trainable params: 34,939\n",
      "Non-trainable params: 432\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Autoencoder\n",
    "autoencoder = keras.models.Sequential([encoder, decoder])\n",
    "optimizer = keras.optimizers.Adam(learning_rate=0.01)\n",
    "\n",
    "autoencoder.summary()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-11T12:50:36.477022Z",
     "end_time": "2023-05-11T12:50:37.041279Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "\n",
    "# 定義交叉驗證參數\n",
    "n_splits = 5 # 設置5折交叉驗證\n",
    "fold = KFold(n_splits=n_splits, shuffle=True, random_state=42)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-11T12:50:36.985930Z",
     "end_time": "2023-05-11T12:50:37.041279Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2000\n",
      "4/4 [==============================] - 7s 494ms/step - loss: 1.2363 - MSE: 0.9759 - val_loss: 1.2480 - val_MSE: 0.9880\n",
      "Epoch 2/2000\n",
      "4/4 [==============================] - 1s 184ms/step - loss: 1.1644 - MSE: 0.9051 - val_loss: 1.2461 - val_MSE: 0.9886\n",
      "Epoch 3/2000\n",
      "4/4 [==============================] - 1s 193ms/step - loss: 1.1476 - MSE: 0.8913 - val_loss: 1.2439 - val_MSE: 0.9903\n",
      "Epoch 4/2000\n",
      "4/4 [==============================] - 1s 181ms/step - loss: 1.1297 - MSE: 0.8779 - val_loss: 1.2402 - val_MSE: 0.9922\n",
      "Epoch 5/2000\n",
      "4/4 [==============================] - 1s 187ms/step - loss: 1.1198 - MSE: 0.8742 - val_loss: 1.2291 - val_MSE: 0.9884\n",
      "Epoch 6/2000\n",
      "4/4 [==============================] - 1s 189ms/step - loss: 1.1084 - MSE: 0.8705 - val_loss: 1.2198 - val_MSE: 0.9874\n",
      "Epoch 7/2000\n",
      "4/4 [==============================] - 1s 188ms/step - loss: 1.0992 - MSE: 0.8698 - val_loss: 1.2114 - val_MSE: 0.9879\n",
      "Epoch 8/2000\n",
      "4/4 [==============================] - 1s 189ms/step - loss: 1.0883 - MSE: 0.8679 - val_loss: 1.2026 - val_MSE: 0.9883\n",
      "Epoch 9/2000\n",
      "4/4 [==============================] - 1s 194ms/step - loss: 1.0768 - MSE: 0.8657 - val_loss: 1.1926 - val_MSE: 0.9876\n",
      "Epoch 10/2000\n",
      "4/4 [==============================] - 1s 196ms/step - loss: 1.0681 - MSE: 0.8662 - val_loss: 1.1834 - val_MSE: 0.9876\n",
      "Epoch 11/2000\n",
      "4/4 [==============================] - 1s 184ms/step - loss: 1.0583 - MSE: 0.8655 - val_loss: 1.1748 - val_MSE: 0.9879\n",
      "Epoch 12/2000\n",
      "4/4 [==============================] - 1s 187ms/step - loss: 1.0507 - MSE: 0.8667 - val_loss: 1.1663 - val_MSE: 0.9879\n",
      "Epoch 13/2000\n",
      "4/4 [==============================] - 1s 193ms/step - loss: 1.0412 - MSE: 0.8656 - val_loss: 1.1581 - val_MSE: 0.9879\n",
      "Epoch 14/2000\n",
      "4/4 [==============================] - 1s 205ms/step - loss: 1.0320 - MSE: 0.8645 - val_loss: 1.1501 - val_MSE: 0.9878\n",
      "Epoch 15/2000\n",
      "4/4 [==============================] - 1s 193ms/step - loss: 1.0261 - MSE: 0.8664 - val_loss: 1.1434 - val_MSE: 0.9887\n",
      "Epoch 16/2000\n",
      "4/4 [==============================] - 1s 189ms/step - loss: 1.0183 - MSE: 0.8661 - val_loss: 1.1351 - val_MSE: 0.9876\n",
      "Epoch 17/2000\n",
      "4/4 [==============================] - 1s 183ms/step - loss: 1.0093 - MSE: 0.8642 - val_loss: 1.1280 - val_MSE: 0.9875\n",
      "Epoch 18/2000\n",
      "4/4 [==============================] - 1s 211ms/step - loss: 1.0029 - MSE: 0.8646 - val_loss: 1.1218 - val_MSE: 0.9878\n",
      "Epoch 19/2000\n",
      "4/4 [==============================] - 1s 199ms/step - loss: 0.9967 - MSE: 0.8648 - val_loss: 1.1159 - val_MSE: 0.9881\n",
      "Epoch 20/2000\n",
      "4/4 [==============================] - 1s 184ms/step - loss: 0.9903 - MSE: 0.8645 - val_loss: 1.1096 - val_MSE: 0.9878\n",
      "Epoch 21/2000\n",
      "4/4 [==============================] - 1s 193ms/step - loss: 0.9847 - MSE: 0.8648 - val_loss: 1.1038 - val_MSE: 0.9875\n",
      "Epoch 22/2000\n",
      "4/4 [==============================] - 1s 181ms/step - loss: 0.9792 - MSE: 0.8648 - val_loss: 1.0992 - val_MSE: 0.9883\n",
      "Epoch 23/2000\n",
      "4/4 [==============================] - 1s 182ms/step - loss: 0.9744 - MSE: 0.8653 - val_loss: 1.0942 - val_MSE: 0.9884\n",
      "Epoch 24/2000\n",
      "4/4 [==============================] - 1s 196ms/step - loss: 0.9696 - MSE: 0.8655 - val_loss: 1.0884 - val_MSE: 0.9875\n",
      "Epoch 25/2000\n",
      "4/4 [==============================] - 1s 188ms/step - loss: 0.9657 - MSE: 0.8664 - val_loss: 1.0836 - val_MSE: 0.9874\n",
      "Epoch 26/2000\n",
      "4/4 [==============================] - 1s 201ms/step - loss: 0.9596 - MSE: 0.8650 - val_loss: 1.0808 - val_MSE: 0.9890\n",
      "Epoch 27/2000\n",
      "4/4 [==============================] - 1s 198ms/step - loss: 0.9542 - MSE: 0.8638 - val_loss: 1.0776 - val_MSE: 0.9899\n",
      "Epoch 28/2000\n",
      "4/4 [==============================] - 1s 186ms/step - loss: 0.9518 - MSE: 0.8655 - val_loss: 1.0714 - val_MSE: 0.9877\n",
      "Epoch 29/2000\n",
      "4/4 [==============================] - 1s 207ms/step - loss: 0.9463 - MSE: 0.8640 - val_loss: 1.0672 - val_MSE: 0.9875\n",
      "Epoch 30/2000\n",
      "4/4 [==============================] - 1s 178ms/step - loss: 0.9416 - MSE: 0.8631 - val_loss: 1.0637 - val_MSE: 0.9876\n",
      "Epoch 31/2000\n",
      "4/4 [==============================] - 1s 186ms/step - loss: 0.9391 - MSE: 0.8642 - val_loss: 1.0606 - val_MSE: 0.9880\n",
      "Epoch 32/2000\n",
      "4/4 [==============================] - 1s 208ms/step - loss: 0.9355 - MSE: 0.8641 - val_loss: 1.0571 - val_MSE: 0.9880\n",
      "Epoch 33/2000\n",
      "4/4 [==============================] - 1s 188ms/step - loss: 0.9323 - MSE: 0.8642 - val_loss: 1.0538 - val_MSE: 0.9878\n",
      "Epoch 34/2000\n",
      "4/4 [==============================] - 1s 194ms/step - loss: 0.9293 - MSE: 0.8643 - val_loss: 1.0508 - val_MSE: 0.9878\n",
      "Epoch 35/2000\n",
      "4/4 [==============================] - 1s 190ms/step - loss: 0.9262 - MSE: 0.8641 - val_loss: 1.0483 - val_MSE: 0.9881\n",
      "Epoch 36/2000\n",
      "4/4 [==============================] - 1s 211ms/step - loss: 0.9226 - MSE: 0.8633 - val_loss: 1.0458 - val_MSE: 0.9883\n",
      "Epoch 37/2000\n",
      "4/4 [==============================] - 1s 205ms/step - loss: 0.9197 - MSE: 0.8631 - val_loss: 1.0427 - val_MSE: 0.9878\n",
      "Epoch 38/2000\n",
      "4/4 [==============================] - 1s 174ms/step - loss: 0.9176 - MSE: 0.8635 - val_loss: 1.0403 - val_MSE: 0.9878\n",
      "Epoch 39/2000\n",
      "4/4 [==============================] - 1s 195ms/step - loss: 0.9149 - MSE: 0.8632 - val_loss: 1.0387 - val_MSE: 0.9885\n",
      "Epoch 40/2000\n",
      "4/4 [==============================] - 1s 209ms/step - loss: 0.9133 - MSE: 0.8639 - val_loss: 1.0366 - val_MSE: 0.9886\n",
      "Epoch 41/2000\n",
      "4/4 [==============================] - 1s 190ms/step - loss: 0.9110 - MSE: 0.8637 - val_loss: 1.0340 - val_MSE: 0.9880\n",
      "Epoch 42/2000\n",
      "4/4 [==============================] - 1s 186ms/step - loss: 0.9084 - MSE: 0.8632 - val_loss: 1.0318 - val_MSE: 0.9878\n",
      "Epoch 43/2000\n",
      "4/4 [==============================] - 1s 181ms/step - loss: 0.9071 - MSE: 0.8637 - val_loss: 1.0299 - val_MSE: 0.9878\n",
      "Epoch 44/2000\n",
      "4/4 [==============================] - 1s 185ms/step - loss: 0.9049 - MSE: 0.8634 - val_loss: 1.0287 - val_MSE: 0.9884\n",
      "Epoch 45/2000\n",
      "4/4 [==============================] - 1s 193ms/step - loss: 0.9027 - MSE: 0.8630 - val_loss: 1.0276 - val_MSE: 0.9891\n",
      "Epoch 46/2000\n",
      "4/4 [==============================] - 1s 197ms/step - loss: 0.9013 - MSE: 0.8633 - val_loss: 1.0251 - val_MSE: 0.9883\n",
      "Epoch 47/2000\n",
      "4/4 [==============================] - 1s 195ms/step - loss: 0.8986 - MSE: 0.8623 - val_loss: 1.0231 - val_MSE: 0.9879\n",
      "Epoch 48/2000\n",
      "4/4 [==============================] - 1s 199ms/step - loss: 0.8976 - MSE: 0.8628 - val_loss: 1.0215 - val_MSE: 0.9878\n",
      "Epoch 49/2000\n",
      "4/4 [==============================] - 1s 183ms/step - loss: 0.8969 - MSE: 0.8637 - val_loss: 1.0203 - val_MSE: 0.9880\n",
      "Epoch 50/2000\n",
      "4/4 [==============================] - 1s 184ms/step - loss: 0.8956 - MSE: 0.8638 - val_loss: 1.0196 - val_MSE: 0.9886\n",
      "Epoch 51/2000\n",
      "4/4 [==============================] - 1s 183ms/step - loss: 0.8941 - MSE: 0.8636 - val_loss: 1.0182 - val_MSE: 0.9886\n",
      "Epoch 52/2000\n",
      "4/4 [==============================] - 1s 195ms/step - loss: 0.8918 - MSE: 0.8626 - val_loss: 1.0169 - val_MSE: 0.9885\n",
      "Epoch 53/2000\n",
      "4/4 [==============================] - 1s 183ms/step - loss: 0.8909 - MSE: 0.8630 - val_loss: 1.0162 - val_MSE: 0.9890\n",
      "Epoch 54/2000\n",
      "4/4 [==============================] - 1s 242ms/step - loss: 0.8893 - MSE: 0.8625 - val_loss: 1.0148 - val_MSE: 0.9887\n",
      "Epoch 55/2000\n",
      "4/4 [==============================] - 1s 228ms/step - loss: 0.8887 - MSE: 0.8630 - val_loss: 1.0130 - val_MSE: 0.9880\n",
      "Epoch 56/2000\n",
      "4/4 [==============================] - 1s 208ms/step - loss: 0.8877 - MSE: 0.8630 - val_loss: 1.0118 - val_MSE: 0.9879\n",
      "Epoch 57/2000\n",
      "4/4 [==============================] - 1s 198ms/step - loss: 0.8868 - MSE: 0.8632 - val_loss: 1.0107 - val_MSE: 0.9877\n",
      "Epoch 58/2000\n",
      "4/4 [==============================] - 1s 218ms/step - loss: 0.8848 - MSE: 0.8622 - val_loss: 1.0100 - val_MSE: 0.9880\n",
      "Epoch 59/2000\n",
      "4/4 [==============================] - 1s 185ms/step - loss: 0.8838 - MSE: 0.8621 - val_loss: 1.0099 - val_MSE: 0.9889\n",
      "Epoch 60/2000\n",
      "4/4 [==============================] - 1s 189ms/step - loss: 0.8833 - MSE: 0.8625 - val_loss: 1.0093 - val_MSE: 0.9890\n",
      "Epoch 61/2000\n",
      "4/4 [==============================] - 1s 206ms/step - loss: 0.8824 - MSE: 0.8624 - val_loss: 1.0072 - val_MSE: 0.9877\n",
      "Epoch 62/2000\n",
      "4/4 [==============================] - 1s 229ms/step - loss: 0.8813 - MSE: 0.8621 - val_loss: 1.0063 - val_MSE: 0.9875\n",
      "Epoch 63/2000\n",
      "4/4 [==============================] - 1s 221ms/step - loss: 0.8810 - MSE: 0.8625 - val_loss: 1.0060 - val_MSE: 0.9880\n",
      "Epoch 64/2000\n",
      "4/4 [==============================] - 1s 233ms/step - loss: 0.8795 - MSE: 0.8617 - val_loss: 1.0054 - val_MSE: 0.9880\n",
      "Epoch 65/2000\n",
      "4/4 [==============================] - 1s 203ms/step - loss: 0.8792 - MSE: 0.8620 - val_loss: 1.0050 - val_MSE: 0.9883\n",
      "Epoch 66/2000\n",
      "4/4 [==============================] - 1s 193ms/step - loss: 0.8787 - MSE: 0.8622 - val_loss: 1.0045 - val_MSE: 0.9884\n",
      "Epoch 67/2000\n",
      "4/4 [==============================] - 1s 203ms/step - loss: 0.8773 - MSE: 0.8615 - val_loss: 1.0036 - val_MSE: 0.9881\n",
      "Epoch 68/2000\n",
      "4/4 [==============================] - 1s 207ms/step - loss: 0.8779 - MSE: 0.8627 - val_loss: 1.0028 - val_MSE: 0.9879\n",
      "Epoch 69/2000\n",
      "4/4 [==============================] - 1s 196ms/step - loss: 0.8755 - MSE: 0.8608 - val_loss: 1.0021 - val_MSE: 0.9877\n",
      "Epoch 70/2000\n",
      "4/4 [==============================] - 1s 201ms/step - loss: 0.8775 - MSE: 0.8634 - val_loss: 1.0017 - val_MSE: 0.9879\n",
      "Epoch 71/2000\n",
      "4/4 [==============================] - 1s 193ms/step - loss: 0.8763 - MSE: 0.8626 - val_loss: 1.0014 - val_MSE: 0.9881\n",
      "Epoch 72/2000\n",
      "4/4 [==============================] - 1s 193ms/step - loss: 0.8753 - MSE: 0.8621 - val_loss: 1.0014 - val_MSE: 0.9885\n",
      "Epoch 73/2000\n",
      "4/4 [==============================] - 1s 196ms/step - loss: 0.8745 - MSE: 0.8618 - val_loss: 1.0014 - val_MSE: 0.9890\n",
      "Epoch 74/2000\n",
      "4/4 [==============================] - 1s 197ms/step - loss: 0.8748 - MSE: 0.8625 - val_loss: 1.0008 - val_MSE: 0.9889\n",
      "Epoch 75/2000\n",
      "4/4 [==============================] - 1s 205ms/step - loss: 0.8744 - MSE: 0.8626 - val_loss: 0.9997 - val_MSE: 0.9882\n",
      "Epoch 76/2000\n",
      "4/4 [==============================] - 1s 190ms/step - loss: 0.8739 - MSE: 0.8625 - val_loss: 0.9989 - val_MSE: 0.9878\n",
      "Epoch 77/2000\n",
      "4/4 [==============================] - 1s 195ms/step - loss: 0.8732 - MSE: 0.8622 - val_loss: 0.9991 - val_MSE: 0.9883\n",
      "Epoch 78/2000\n",
      "4/4 [==============================] - 1s 193ms/step - loss: 0.8723 - MSE: 0.8617 - val_loss: 0.9989 - val_MSE: 0.9885\n",
      "Epoch 79/2000\n",
      "4/4 [==============================] - 1s 197ms/step - loss: 0.8723 - MSE: 0.8620 - val_loss: 0.9988 - val_MSE: 0.9888\n",
      "Epoch 80/2000\n",
      "4/4 [==============================] - 1s 188ms/step - loss: 0.8729 - MSE: 0.8630 - val_loss: 0.9976 - val_MSE: 0.9879\n",
      "Epoch 81/2000\n",
      "4/4 [==============================] - 1s 194ms/step - loss: 0.8711 - MSE: 0.8615 - val_loss: 0.9972 - val_MSE: 0.9878\n",
      "Epoch 82/2000\n",
      "4/4 [==============================] - 1s 193ms/step - loss: 0.8707 - MSE: 0.8615 - val_loss: 0.9971 - val_MSE: 0.9881\n",
      "Epoch 83/2000\n",
      "4/4 [==============================] - 1s 205ms/step - loss: 0.8698 - MSE: 0.8609 - val_loss: 0.9968 - val_MSE: 0.9881\n",
      "Epoch 84/2000\n",
      "4/4 [==============================] - 1s 176ms/step - loss: 0.8701 - MSE: 0.8615 - val_loss: 0.9964 - val_MSE: 0.9880\n",
      "Epoch 85/2000\n",
      "4/4 [==============================] - 1s 179ms/step - loss: 0.8692 - MSE: 0.8609 - val_loss: 0.9961 - val_MSE: 0.9880\n",
      "Epoch 86/2000\n",
      "4/4 [==============================] - 1s 184ms/step - loss: 0.8683 - MSE: 0.8603 - val_loss: 0.9955 - val_MSE: 0.9877\n",
      "Epoch 87/2000\n",
      "4/4 [==============================] - 1s 185ms/step - loss: 0.8680 - MSE: 0.8602 - val_loss: 0.9953 - val_MSE: 0.9877\n",
      "Epoch 88/2000\n",
      "4/4 [==============================] - 1s 189ms/step - loss: 0.8682 - MSE: 0.8607 - val_loss: 0.9951 - val_MSE: 0.9878\n",
      "Epoch 89/2000\n",
      "4/4 [==============================] - 1s 196ms/step - loss: 0.8684 - MSE: 0.8612 - val_loss: 0.9948 - val_MSE: 0.9878\n",
      "Epoch 90/2000\n",
      "4/4 [==============================] - 1s 188ms/step - loss: 0.8694 - MSE: 0.8624 - val_loss: 0.9946 - val_MSE: 0.9878\n",
      "Epoch 91/2000\n",
      "4/4 [==============================] - 1s 180ms/step - loss: 0.8678 - MSE: 0.8610 - val_loss: 0.9948 - val_MSE: 0.9882\n",
      "Epoch 92/2000\n",
      "4/4 [==============================] - 1s 205ms/step - loss: 0.8669 - MSE: 0.8604 - val_loss: 0.9944 - val_MSE: 0.9880\n",
      "Epoch 93/2000\n",
      "4/4 [==============================] - 1s 180ms/step - loss: 0.8674 - MSE: 0.8610 - val_loss: 0.9941 - val_MSE: 0.9879\n",
      "Epoch 94/2000\n",
      "4/4 [==============================] - 1s 197ms/step - loss: 0.8694 - MSE: 0.8633 - val_loss: 0.9937 - val_MSE: 0.9877\n",
      "Epoch 95/2000\n",
      "4/4 [==============================] - 1s 217ms/step - loss: 0.8683 - MSE: 0.8623 - val_loss: 0.9937 - val_MSE: 0.9878\n",
      "Epoch 96/2000\n",
      "4/4 [==============================] - 1s 195ms/step - loss: 0.8661 - MSE: 0.8602 - val_loss: 0.9941 - val_MSE: 0.9882\n",
      "Epoch 97/2000\n",
      "4/4 [==============================] - 1s 229ms/step - loss: 0.8659 - MSE: 0.8601 - val_loss: 0.9934 - val_MSE: 0.9877\n",
      "Epoch 98/2000\n",
      "4/4 [==============================] - 1s 178ms/step - loss: 0.8655 - MSE: 0.8598 - val_loss: 0.9929 - val_MSE: 0.9873\n",
      "Epoch 99/2000\n",
      "4/4 [==============================] - 1s 199ms/step - loss: 0.8644 - MSE: 0.8587 - val_loss: 0.9927 - val_MSE: 0.9872\n",
      "Epoch 100/2000\n",
      "4/4 [==============================] - 1s 192ms/step - loss: 0.8643 - MSE: 0.8588 - val_loss: 0.9930 - val_MSE: 0.9876\n",
      "Epoch 101/2000\n",
      "4/4 [==============================] - 1s 203ms/step - loss: 0.8686 - MSE: 0.8633 - val_loss: 0.9926 - val_MSE: 0.9874\n",
      "Epoch 102/2000\n",
      "4/4 [==============================] - 1s 182ms/step - loss: 0.8680 - MSE: 0.8629 - val_loss: 0.9926 - val_MSE: 0.9876\n",
      "Epoch 103/2000\n",
      "4/4 [==============================] - 1s 186ms/step - loss: 0.8669 - MSE: 0.8619 - val_loss: 0.9927 - val_MSE: 0.9878\n",
      "Epoch 104/2000\n",
      "4/4 [==============================] - 1s 202ms/step - loss: 0.8650 - MSE: 0.8602 - val_loss: 0.9921 - val_MSE: 0.9874\n",
      "Epoch 105/2000\n",
      "4/4 [==============================] - 1s 181ms/step - loss: 0.8647 - MSE: 0.8600 - val_loss: 0.9917 - val_MSE: 0.9870\n",
      "Epoch 106/2000\n",
      "4/4 [==============================] - 1s 190ms/step - loss: 0.8648 - MSE: 0.8601 - val_loss: 0.9924 - val_MSE: 0.9878\n",
      "Epoch 107/2000\n",
      "4/4 [==============================] - 1s 183ms/step - loss: 0.8663 - MSE: 0.8618 - val_loss: 0.9924 - val_MSE: 0.9879\n",
      "Epoch 108/2000\n",
      "4/4 [==============================] - 1s 174ms/step - loss: 0.8656 - MSE: 0.8611 - val_loss: 0.9917 - val_MSE: 0.9873\n",
      "Epoch 109/2000\n",
      "4/4 [==============================] - 1s 187ms/step - loss: 0.8639 - MSE: 0.8595 - val_loss: 0.9912 - val_MSE: 0.9869\n",
      "Epoch 110/2000\n",
      "4/4 [==============================] - 1s 193ms/step - loss: 0.8627 - MSE: 0.8584 - val_loss: 0.9912 - val_MSE: 0.9870\n",
      "Epoch 111/2000\n",
      "4/4 [==============================] - 1s 190ms/step - loss: 0.8604 - MSE: 0.8562 - val_loss: 0.9908 - val_MSE: 0.9866\n",
      "Epoch 112/2000\n",
      "4/4 [==============================] - 1s 186ms/step - loss: 0.8593 - MSE: 0.8551 - val_loss: 0.9903 - val_MSE: 0.9861\n",
      "Epoch 113/2000\n",
      "4/4 [==============================] - 1s 186ms/step - loss: 0.8584 - MSE: 0.8543 - val_loss: 0.9903 - val_MSE: 0.9863\n",
      "Epoch 114/2000\n",
      "4/4 [==============================] - 1s 187ms/step - loss: 0.8581 - MSE: 0.8541 - val_loss: 0.9908 - val_MSE: 0.9869\n",
      "Epoch 115/2000\n",
      "4/4 [==============================] - 1s 197ms/step - loss: 0.8586 - MSE: 0.8548 - val_loss: 0.9898 - val_MSE: 0.9861\n",
      "Epoch 116/2000\n",
      "4/4 [==============================] - 1s 185ms/step - loss: 0.8586 - MSE: 0.8549 - val_loss: 0.9902 - val_MSE: 0.9866\n",
      "Epoch 117/2000\n",
      "4/4 [==============================] - 1s 198ms/step - loss: 0.8724 - MSE: 0.8689 - val_loss: 0.9911 - val_MSE: 0.9877\n",
      "Epoch 118/2000\n",
      "4/4 [==============================] - 1s 188ms/step - loss: 0.8673 - MSE: 0.8637 - val_loss: 0.9919 - val_MSE: 0.9881\n",
      "Epoch 119/2000\n",
      "4/4 [==============================] - 1s 179ms/step - loss: 0.8678 - MSE: 0.8640 - val_loss: 0.9913 - val_MSE: 0.9873\n",
      "Epoch 120/2000\n",
      "4/4 [==============================] - 1s 180ms/step - loss: 0.8665 - MSE: 0.8625 - val_loss: 0.9915 - val_MSE: 0.9874\n",
      "Epoch 121/2000\n",
      "4/4 [==============================] - 1s 190ms/step - loss: 0.8661 - MSE: 0.8620 - val_loss: 0.9915 - val_MSE: 0.9874\n",
      "Epoch 122/2000\n",
      "4/4 [==============================] - 1s 193ms/step - loss: 0.8658 - MSE: 0.8617 - val_loss: 0.9917 - val_MSE: 0.9877\n",
      "Epoch 123/2000\n",
      "4/4 [==============================] - 1s 178ms/step - loss: 0.8659 - MSE: 0.8618 - val_loss: 0.9915 - val_MSE: 0.9876\n",
      "Epoch 124/2000\n",
      "4/4 [==============================] - 1s 191ms/step - loss: 0.8645 - MSE: 0.8606 - val_loss: 0.9911 - val_MSE: 0.9873\n",
      "Epoch 125/2000\n",
      "4/4 [==============================] - 1s 198ms/step - loss: 0.8632 - MSE: 0.8594 - val_loss: 0.9908 - val_MSE: 0.9871\n",
      "Epoch 126/2000\n",
      "4/4 [==============================] - 1s 181ms/step - loss: 0.8675 - MSE: 0.8639 - val_loss: 0.9914 - val_MSE: 0.9879\n",
      "Epoch 127/2000\n",
      "4/4 [==============================] - 1s 202ms/step - loss: 0.8682 - MSE: 0.8647 - val_loss: 0.9919 - val_MSE: 0.9884\n",
      "Epoch 128/2000\n",
      "4/4 [==============================] - 1s 187ms/step - loss: 0.8674 - MSE: 0.8639 - val_loss: 0.9916 - val_MSE: 0.9881\n",
      "Epoch 129/2000\n",
      "4/4 [==============================] - 1s 190ms/step - loss: 0.8689 - MSE: 0.8655 - val_loss: 0.9910 - val_MSE: 0.9876\n",
      "Epoch 130/2000\n",
      "4/4 [==============================] - 1s 179ms/step - loss: 0.8673 - MSE: 0.8640 - val_loss: 0.9907 - val_MSE: 0.9875\n",
      "Epoch 131/2000\n",
      "4/4 [==============================] - 1s 179ms/step - loss: 0.8673 - MSE: 0.8641 - val_loss: 0.9911 - val_MSE: 0.9880\n",
      "Epoch 132/2000\n",
      "4/4 [==============================] - 1s 189ms/step - loss: 0.8666 - MSE: 0.8636 - val_loss: 0.9909 - val_MSE: 0.9880\n",
      "Epoch 133/2000\n",
      "4/4 [==============================] - 1s 183ms/step - loss: 0.8659 - MSE: 0.8630 - val_loss: 0.9904 - val_MSE: 0.9876\n",
      "Epoch 134/2000\n",
      "4/4 [==============================] - 1s 205ms/step - loss: 0.8650 - MSE: 0.8622 - val_loss: 0.9903 - val_MSE: 0.9875\n",
      "Epoch 135/2000\n",
      "4/4 [==============================] - 1s 177ms/step - loss: 0.8632 - MSE: 0.8605 - val_loss: 0.9898 - val_MSE: 0.9870\n",
      "Epoch 136/2000\n",
      "4/4 [==============================] - 1s 192ms/step - loss: 0.8690 - MSE: 0.8662 - val_loss: 0.9920 - val_MSE: 0.9891\n",
      "Epoch 137/2000\n",
      "4/4 [==============================] - 1s 190ms/step - loss: 0.8666 - MSE: 0.8636 - val_loss: 0.9919 - val_MSE: 0.9884\n",
      "Epoch 138/2000\n",
      "4/4 [==============================] - 1s 194ms/step - loss: 0.8659 - MSE: 0.8621 - val_loss: 0.9926 - val_MSE: 0.9883\n",
      "Epoch 139/2000\n",
      "4/4 [==============================] - 1s 203ms/step - loss: 0.8643 - MSE: 0.8598 - val_loss: 0.9918 - val_MSE: 0.9870\n",
      "Epoch 140/2000\n",
      "4/4 [==============================] - 1s 184ms/step - loss: 0.8630 - MSE: 0.8581 - val_loss: 0.9912 - val_MSE: 0.9863\n",
      "Epoch 141/2000\n",
      "4/4 [==============================] - 1s 205ms/step - loss: 0.8644 - MSE: 0.8595 - val_loss: 0.9879 - val_MSE: 0.9830\n",
      "Epoch 142/2000\n",
      "4/4 [==============================] - 1s 212ms/step - loss: 0.8623 - MSE: 0.8575 - val_loss: 0.9874 - val_MSE: 0.9828\n",
      "Epoch 143/2000\n",
      "4/4 [==============================] - 1s 213ms/step - loss: 0.8621 - MSE: 0.8576 - val_loss: 0.9886 - val_MSE: 0.9844\n",
      "Epoch 144/2000\n",
      "4/4 [==============================] - 1s 185ms/step - loss: 0.8635 - MSE: 0.8594 - val_loss: 0.9970 - val_MSE: 0.9931\n",
      "Epoch 145/2000\n",
      "4/4 [==============================] - 1s 183ms/step - loss: 0.8688 - MSE: 0.8652 - val_loss: 0.9931 - val_MSE: 0.9897\n",
      "Epoch 146/2000\n",
      "4/4 [==============================] - 1s 181ms/step - loss: 0.8677 - MSE: 0.8643 - val_loss: 0.9924 - val_MSE: 0.9892\n",
      "Epoch 147/2000\n",
      "4/4 [==============================] - 1s 185ms/step - loss: 0.8663 - MSE: 0.8632 - val_loss: 0.9932 - val_MSE: 0.9901\n",
      "Epoch 148/2000\n",
      "4/4 [==============================] - 1s 190ms/step - loss: 0.8609 - MSE: 0.8579 - val_loss: 0.9916 - val_MSE: 0.9885\n",
      "Epoch 149/2000\n",
      "4/4 [==============================] - 1s 185ms/step - loss: 0.8677 - MSE: 0.8645 - val_loss: 0.9908 - val_MSE: 0.9878\n",
      "Epoch 150/2000\n",
      "4/4 [==============================] - 1s 203ms/step - loss: 0.8672 - MSE: 0.8641 - val_loss: 0.9910 - val_MSE: 0.9877\n",
      "Epoch 151/2000\n",
      "4/4 [==============================] - 1s 191ms/step - loss: 0.8656 - MSE: 0.8621 - val_loss: 0.9906 - val_MSE: 0.9870\n",
      "Epoch 152/2000\n",
      "4/4 [==============================] - 1s 223ms/step - loss: 0.8614 - MSE: 0.8577 - val_loss: 0.9866 - val_MSE: 0.9828\n",
      "Epoch 153/2000\n",
      "4/4 [==============================] - 1s 187ms/step - loss: 0.8598 - MSE: 0.8561 - val_loss: 0.9905 - val_MSE: 0.9869\n",
      "Epoch 154/2000\n",
      "4/4 [==============================] - 1s 182ms/step - loss: 0.8638 - MSE: 0.8602 - val_loss: 0.9915 - val_MSE: 0.9880\n",
      "Epoch 155/2000\n",
      "4/4 [==============================] - 1s 184ms/step - loss: 0.8676 - MSE: 0.8642 - val_loss: 0.9891 - val_MSE: 0.9854\n",
      "Epoch 156/2000\n",
      "4/4 [==============================] - 1s 174ms/step - loss: 0.8635 - MSE: 0.8596 - val_loss: 1.0045 - val_MSE: 1.0002\n",
      "Epoch 157/2000\n",
      "4/4 [==============================] - 1s 194ms/step - loss: 0.8699 - MSE: 0.8655 - val_loss: 0.9934 - val_MSE: 0.9888\n",
      "Epoch 158/2000\n",
      "4/4 [==============================] - 1s 180ms/step - loss: 0.8730 - MSE: 0.8680 - val_loss: 0.9886 - val_MSE: 0.9830\n",
      "Epoch 159/2000\n",
      "4/4 [==============================] - 1s 194ms/step - loss: 0.8693 - MSE: 0.8633 - val_loss: 0.9976 - val_MSE: 0.9909\n",
      "Epoch 160/2000\n",
      "4/4 [==============================] - 1s 184ms/step - loss: 0.8721 - MSE: 0.8652 - val_loss: 1.0010 - val_MSE: 0.9940\n",
      "Epoch 161/2000\n",
      "4/4 [==============================] - 1s 211ms/step - loss: 0.8708 - MSE: 0.8638 - val_loss: 0.9932 - val_MSE: 0.9865\n",
      "Epoch 162/2000\n",
      "4/4 [==============================] - 1s 193ms/step - loss: 0.8713 - MSE: 0.8647 - val_loss: 0.9930 - val_MSE: 0.9867\n",
      "Epoch 163/2000\n",
      "4/4 [==============================] - 1s 206ms/step - loss: 0.8700 - MSE: 0.8639 - val_loss: 0.9942 - val_MSE: 0.9885\n",
      "Epoch 164/2000\n",
      "4/4 [==============================] - 1s 175ms/step - loss: 0.8688 - MSE: 0.8633 - val_loss: 0.9899 - val_MSE: 0.9849\n",
      "Epoch 165/2000\n",
      "4/4 [==============================] - 1s 176ms/step - loss: 0.8669 - MSE: 0.8620 - val_loss: 0.9946 - val_MSE: 0.9900\n",
      "Epoch 166/2000\n",
      "4/4 [==============================] - 1s 206ms/step - loss: 0.8647 - MSE: 0.8603 - val_loss: 1.0079 - val_MSE: 1.0036\n",
      "Epoch 167/2000\n",
      "4/4 [==============================] - 1s 196ms/step - loss: 0.8617 - MSE: 0.8575 - val_loss: 1.0773 - val_MSE: 1.0732\n",
      "Epoch 168/2000\n",
      "4/4 [==============================] - 1s 207ms/step - loss: 0.8688 - MSE: 0.8648 - val_loss: 1.0160 - val_MSE: 1.0123\n",
      "Epoch 169/2000\n",
      "4/4 [==============================] - 1s 206ms/step - loss: 0.8727 - MSE: 0.8690 - val_loss: 0.9942 - val_MSE: 0.9902\n",
      "Epoch 170/2000\n",
      "4/4 [==============================] - 1s 188ms/step - loss: 0.8689 - MSE: 0.8647 - val_loss: 0.9886 - val_MSE: 0.9841\n",
      "Epoch 171/2000\n",
      "4/4 [==============================] - 1s 200ms/step - loss: 0.8648 - MSE: 0.8602 - val_loss: 0.9947 - val_MSE: 0.9901\n",
      "Epoch 172/2000\n",
      "4/4 [==============================] - 1s 204ms/step - loss: 0.8613 - MSE: 0.8567 - val_loss: 0.9973 - val_MSE: 0.9930\n",
      "Epoch 173/2000\n",
      "4/4 [==============================] - 1s 202ms/step - loss: 0.8601 - MSE: 0.8559 - val_loss: 1.0024 - val_MSE: 0.9986\n",
      "Epoch 174/2000\n",
      "4/4 [==============================] - 1s 191ms/step - loss: 0.8597 - MSE: 0.8559 - val_loss: 0.9827 - val_MSE: 0.9792\n",
      "Epoch 175/2000\n",
      "4/4 [==============================] - 1s 232ms/step - loss: 0.8582 - MSE: 0.8548 - val_loss: 0.9863 - val_MSE: 0.9830\n",
      "Epoch 176/2000\n",
      "4/4 [==============================] - 1s 202ms/step - loss: 0.8583 - MSE: 0.8551 - val_loss: 0.9824 - val_MSE: 0.9794\n",
      "Epoch 177/2000\n",
      "4/4 [==============================] - 1s 191ms/step - loss: 0.8573 - MSE: 0.8544 - val_loss: 0.9828 - val_MSE: 0.9800\n",
      "Epoch 178/2000\n",
      "4/4 [==============================] - 1s 206ms/step - loss: 0.8570 - MSE: 0.8543 - val_loss: 0.9800 - val_MSE: 0.9775\n",
      "Epoch 179/2000\n",
      "4/4 [==============================] - 1s 195ms/step - loss: 0.8576 - MSE: 0.8552 - val_loss: 0.9850 - val_MSE: 0.9827\n",
      "Epoch 180/2000\n",
      "4/4 [==============================] - 1s 210ms/step - loss: 0.8569 - MSE: 0.8548 - val_loss: 0.9880 - val_MSE: 0.9859\n",
      "Epoch 181/2000\n",
      "4/4 [==============================] - 1s 236ms/step - loss: 0.8564 - MSE: 0.8544 - val_loss: 0.9848 - val_MSE: 0.9829\n",
      "Epoch 182/2000\n",
      "4/4 [==============================] - 1s 220ms/step - loss: 0.8570 - MSE: 0.8551 - val_loss: 0.9840 - val_MSE: 0.9822\n",
      "Epoch 183/2000\n",
      "4/4 [==============================] - 1s 189ms/step - loss: 0.8560 - MSE: 0.8543 - val_loss: 0.9858 - val_MSE: 0.9842\n",
      "Epoch 184/2000\n",
      "4/4 [==============================] - 1s 193ms/step - loss: 0.8562 - MSE: 0.8546 - val_loss: 0.9892 - val_MSE: 0.9876\n",
      "Epoch 185/2000\n",
      "4/4 [==============================] - 1s 190ms/step - loss: 0.8557 - MSE: 0.8542 - val_loss: 0.9851 - val_MSE: 0.9837\n",
      "Epoch 186/2000\n",
      "4/4 [==============================] - 1s 211ms/step - loss: 0.8558 - MSE: 0.8543 - val_loss: 0.9870 - val_MSE: 0.9856\n",
      "Epoch 187/2000\n",
      "4/4 [==============================] - 1s 189ms/step - loss: 0.8551 - MSE: 0.8538 - val_loss: 0.9881 - val_MSE: 0.9868\n",
      "Epoch 188/2000\n",
      "4/4 [==============================] - 1s 195ms/step - loss: 0.8555 - MSE: 0.8542 - val_loss: 0.9875 - val_MSE: 0.9863\n",
      "Epoch 189/2000\n",
      "4/4 [==============================] - 1s 206ms/step - loss: 0.8555 - MSE: 0.8543 - val_loss: 0.9892 - val_MSE: 0.9880\n",
      "Epoch 190/2000\n",
      "4/4 [==============================] - 1s 201ms/step - loss: 0.8553 - MSE: 0.8541 - val_loss: 0.9872 - val_MSE: 0.9860\n",
      "Epoch 191/2000\n",
      "4/4 [==============================] - 1s 190ms/step - loss: 0.8553 - MSE: 0.8542 - val_loss: 0.9862 - val_MSE: 0.9851\n",
      "Epoch 192/2000\n",
      "4/4 [==============================] - 1s 187ms/step - loss: 0.8555 - MSE: 0.8544 - val_loss: 0.9872 - val_MSE: 0.9860\n",
      "Epoch 193/2000\n",
      "4/4 [==============================] - 1s 200ms/step - loss: 0.8553 - MSE: 0.8542 - val_loss: 0.9867 - val_MSE: 0.9856\n",
      "Epoch 194/2000\n",
      "4/4 [==============================] - 1s 208ms/step - loss: 0.8554 - MSE: 0.8543 - val_loss: 0.9861 - val_MSE: 0.9851\n",
      "Epoch 195/2000\n",
      "4/4 [==============================] - 1s 207ms/step - loss: 0.8550 - MSE: 0.8540 - val_loss: 0.9863 - val_MSE: 0.9853\n",
      "Epoch 196/2000\n",
      "4/4 [==============================] - 1s 186ms/step - loss: 0.8553 - MSE: 0.8543 - val_loss: 0.9886 - val_MSE: 0.9876\n",
      "Epoch 197/2000\n",
      "4/4 [==============================] - 1s 207ms/step - loss: 0.8552 - MSE: 0.8542 - val_loss: 0.9868 - val_MSE: 0.9858\n",
      "Epoch 198/2000\n",
      "4/4 [==============================] - 1s 170ms/step - loss: 0.8558 - MSE: 0.8548 - val_loss: 0.9892 - val_MSE: 0.9882\n",
      "Epoch 199/2000\n",
      "4/4 [==============================] - 1s 197ms/step - loss: 0.8558 - MSE: 0.8548 - val_loss: 0.9870 - val_MSE: 0.9861\n",
      "Epoch 200/2000\n",
      "4/4 [==============================] - 1s 189ms/step - loss: 0.8555 - MSE: 0.8545 - val_loss: 0.9847 - val_MSE: 0.9836\n",
      "Epoch 201/2000\n",
      "4/4 [==============================] - 1s 194ms/step - loss: 0.8550 - MSE: 0.8540 - val_loss: 0.9841 - val_MSE: 0.9830\n",
      "Epoch 202/2000\n",
      "4/4 [==============================] - 1s 191ms/step - loss: 0.8557 - MSE: 0.8546 - val_loss: 0.9831 - val_MSE: 0.9820\n",
      "Epoch 203/2000\n",
      "4/4 [==============================] - 1s 186ms/step - loss: 0.8553 - MSE: 0.8543 - val_loss: 0.9877 - val_MSE: 0.9867\n",
      "Epoch 204/2000\n",
      "4/4 [==============================] - 1s 197ms/step - loss: 0.8550 - MSE: 0.8539 - val_loss: 0.9846 - val_MSE: 0.9836\n",
      "Epoch 205/2000\n",
      "4/4 [==============================] - 1s 190ms/step - loss: 0.8548 - MSE: 0.8537 - val_loss: 0.9848 - val_MSE: 0.9838\n",
      "Epoch 206/2000\n",
      "4/4 [==============================] - 1s 192ms/step - loss: 0.8552 - MSE: 0.8542 - val_loss: 0.9862 - val_MSE: 0.9852\n",
      "Epoch 207/2000\n",
      "4/4 [==============================] - 1s 180ms/step - loss: 0.8550 - MSE: 0.8540 - val_loss: 0.9845 - val_MSE: 0.9835\n",
      "Epoch 208/2000\n",
      "4/4 [==============================] - 1s 179ms/step - loss: 0.8553 - MSE: 0.8543 - val_loss: 0.9841 - val_MSE: 0.9832\n",
      "Epoch 209/2000\n",
      "4/4 [==============================] - 1s 185ms/step - loss: 0.8554 - MSE: 0.8545 - val_loss: 0.9850 - val_MSE: 0.9841\n",
      "Epoch 210/2000\n",
      "4/4 [==============================] - 1s 187ms/step - loss: 0.8549 - MSE: 0.8540 - val_loss: 0.9864 - val_MSE: 0.9855\n",
      "Epoch 211/2000\n",
      "4/4 [==============================] - 1s 193ms/step - loss: 0.8551 - MSE: 0.8542 - val_loss: 0.9861 - val_MSE: 0.9853\n",
      "Epoch 212/2000\n",
      "4/4 [==============================] - 1s 178ms/step - loss: 0.8547 - MSE: 0.8539 - val_loss: 0.9872 - val_MSE: 0.9864\n",
      "Epoch 213/2000\n",
      "4/4 [==============================] - 1s 189ms/step - loss: 0.8550 - MSE: 0.8541 - val_loss: 0.9854 - val_MSE: 0.9845\n",
      "Epoch 214/2000\n",
      "4/4 [==============================] - 1s 212ms/step - loss: 0.8549 - MSE: 0.8540 - val_loss: 0.9821 - val_MSE: 0.9812\n",
      "Epoch 215/2000\n",
      "4/4 [==============================] - 1s 211ms/step - loss: 0.8550 - MSE: 0.8541 - val_loss: 0.9880 - val_MSE: 0.9871\n",
      "Epoch 216/2000\n",
      "4/4 [==============================] - 1s 187ms/step - loss: 0.8550 - MSE: 0.8541 - val_loss: 0.9829 - val_MSE: 0.9820\n",
      "Epoch 217/2000\n",
      "4/4 [==============================] - 1s 200ms/step - loss: 0.8549 - MSE: 0.8540 - val_loss: 0.9823 - val_MSE: 0.9814\n",
      "Epoch 218/2000\n",
      "4/4 [==============================] - 1s 176ms/step - loss: 0.8549 - MSE: 0.8540 - val_loss: 0.9814 - val_MSE: 0.9805\n",
      "Epoch 219/2000\n",
      "4/4 [==============================] - 1s 190ms/step - loss: 0.8550 - MSE: 0.8541 - val_loss: 0.9822 - val_MSE: 0.9813\n",
      "Epoch 220/2000\n",
      "4/4 [==============================] - 1s 185ms/step - loss: 0.8548 - MSE: 0.8539 - val_loss: 0.9823 - val_MSE: 0.9815\n",
      "Epoch 221/2000\n",
      "4/4 [==============================] - 1s 186ms/step - loss: 0.8545 - MSE: 0.8537 - val_loss: 0.9833 - val_MSE: 0.9825\n",
      "Epoch 222/2000\n",
      "4/4 [==============================] - 1s 198ms/step - loss: 0.8548 - MSE: 0.8540 - val_loss: 0.9845 - val_MSE: 0.9837\n",
      "Epoch 223/2000\n",
      "4/4 [==============================] - 1s 207ms/step - loss: 0.8544 - MSE: 0.8537 - val_loss: 0.9828 - val_MSE: 0.9820\n",
      "Epoch 224/2000\n",
      "4/4 [==============================] - 1s 199ms/step - loss: 0.8548 - MSE: 0.8540 - val_loss: 0.9817 - val_MSE: 0.9809\n",
      "Epoch 225/2000\n",
      "4/4 [==============================] - 1s 183ms/step - loss: 0.8548 - MSE: 0.8540 - val_loss: 0.9819 - val_MSE: 0.9811\n",
      "Epoch 226/2000\n",
      "4/4 [==============================] - 1s 180ms/step - loss: 0.8551 - MSE: 0.8543 - val_loss: 0.9815 - val_MSE: 0.9807\n",
      "Epoch 227/2000\n",
      "4/4 [==============================] - 1s 198ms/step - loss: 0.8547 - MSE: 0.8540 - val_loss: 0.9808 - val_MSE: 0.9800\n",
      "Epoch 228/2000\n",
      "4/4 [==============================] - 1s 195ms/step - loss: 0.8550 - MSE: 0.8542 - val_loss: 0.9826 - val_MSE: 0.9818\n",
      "Epoch 1/2000\n",
      "4/4 [==============================] - 7s 509ms/step - loss: 0.8537 - MSE: 0.8512 - val_loss: 1.0125 - val_MSE: 1.0101\n",
      "Epoch 2/2000\n",
      "4/4 [==============================] - 1s 201ms/step - loss: 0.8538 - MSE: 0.8514 - val_loss: 1.0117 - val_MSE: 1.0095\n",
      "Epoch 3/2000\n",
      "4/4 [==============================] - 1s 211ms/step - loss: 0.8535 - MSE: 0.8513 - val_loss: 1.0069 - val_MSE: 1.0048\n",
      "Epoch 4/2000\n",
      "4/4 [==============================] - 1s 194ms/step - loss: 0.8530 - MSE: 0.8510 - val_loss: 1.0077 - val_MSE: 1.0058\n",
      "Epoch 5/2000\n",
      "4/4 [==============================] - 1s 221ms/step - loss: 0.8527 - MSE: 0.8509 - val_loss: 1.0094 - val_MSE: 1.0076\n",
      "Epoch 6/2000\n",
      "4/4 [==============================] - 1s 196ms/step - loss: 0.8529 - MSE: 0.8511 - val_loss: 1.0090 - val_MSE: 1.0074\n",
      "Epoch 7/2000\n",
      "4/4 [==============================] - 1s 215ms/step - loss: 0.8528 - MSE: 0.8512 - val_loss: 1.0093 - val_MSE: 1.0078\n",
      "Epoch 8/2000\n",
      "4/4 [==============================] - 1s 220ms/step - loss: 0.8526 - MSE: 0.8511 - val_loss: 1.0090 - val_MSE: 1.0076\n",
      "Epoch 9/2000\n",
      "4/4 [==============================] - 1s 184ms/step - loss: 0.8526 - MSE: 0.8512 - val_loss: 1.0101 - val_MSE: 1.0088\n",
      "Epoch 10/2000\n",
      "4/4 [==============================] - 1s 195ms/step - loss: 0.8525 - MSE: 0.8512 - val_loss: 1.0096 - val_MSE: 1.0084\n",
      "Epoch 11/2000\n",
      "4/4 [==============================] - 1s 191ms/step - loss: 0.8521 - MSE: 0.8508 - val_loss: 1.0091 - val_MSE: 1.0079\n",
      "Epoch 12/2000\n",
      "4/4 [==============================] - 1s 207ms/step - loss: 0.8522 - MSE: 0.8510 - val_loss: 1.0089 - val_MSE: 1.0077\n",
      "Epoch 13/2000\n",
      "4/4 [==============================] - 1s 200ms/step - loss: 0.8519 - MSE: 0.8507 - val_loss: 1.0106 - val_MSE: 1.0095\n",
      "Epoch 14/2000\n",
      "4/4 [==============================] - 1s 195ms/step - loss: 0.8522 - MSE: 0.8510 - val_loss: 1.0085 - val_MSE: 1.0074\n",
      "Epoch 15/2000\n",
      "4/4 [==============================] - 1s 231ms/step - loss: 0.8519 - MSE: 0.8507 - val_loss: 1.0090 - val_MSE: 1.0079\n",
      "Epoch 16/2000\n",
      "4/4 [==============================] - 1s 219ms/step - loss: 0.8518 - MSE: 0.8508 - val_loss: 1.0094 - val_MSE: 1.0084\n",
      "Epoch 17/2000\n",
      "4/4 [==============================] - 1s 194ms/step - loss: 0.8518 - MSE: 0.8508 - val_loss: 1.0093 - val_MSE: 1.0083\n",
      "Epoch 18/2000\n",
      "4/4 [==============================] - 1s 190ms/step - loss: 0.8519 - MSE: 0.8509 - val_loss: 1.0097 - val_MSE: 1.0087\n",
      "Epoch 19/2000\n",
      "4/4 [==============================] - 1s 202ms/step - loss: 0.8522 - MSE: 0.8513 - val_loss: 1.0084 - val_MSE: 1.0075\n",
      "Epoch 20/2000\n",
      "4/4 [==============================] - 1s 195ms/step - loss: 0.8514 - MSE: 0.8504 - val_loss: 1.0098 - val_MSE: 1.0089\n",
      "Epoch 21/2000\n",
      "4/4 [==============================] - 1s 191ms/step - loss: 0.8515 - MSE: 0.8505 - val_loss: 1.0081 - val_MSE: 1.0072\n",
      "Epoch 22/2000\n",
      "4/4 [==============================] - 1s 210ms/step - loss: 0.8521 - MSE: 0.8512 - val_loss: 1.0090 - val_MSE: 1.0081\n",
      "Epoch 23/2000\n",
      "4/4 [==============================] - 1s 192ms/step - loss: 0.8521 - MSE: 0.8512 - val_loss: 1.0074 - val_MSE: 1.0065\n",
      "Epoch 24/2000\n",
      "4/4 [==============================] - 1s 193ms/step - loss: 0.8521 - MSE: 0.8512 - val_loss: 1.0083 - val_MSE: 1.0074\n",
      "Epoch 25/2000\n",
      "4/4 [==============================] - 1s 191ms/step - loss: 0.8523 - MSE: 0.8514 - val_loss: 1.0065 - val_MSE: 1.0056\n",
      "Epoch 26/2000\n",
      "4/4 [==============================] - 1s 205ms/step - loss: 0.8521 - MSE: 0.8512 - val_loss: 1.0067 - val_MSE: 1.0058\n",
      "Epoch 27/2000\n",
      "4/4 [==============================] - 1s 205ms/step - loss: 0.8519 - MSE: 0.8509 - val_loss: 1.0065 - val_MSE: 1.0056\n",
      "Epoch 28/2000\n",
      "4/4 [==============================] - 1s 200ms/step - loss: 0.8519 - MSE: 0.8510 - val_loss: 1.0060 - val_MSE: 1.0051\n",
      "Epoch 29/2000\n",
      "4/4 [==============================] - 1s 210ms/step - loss: 0.8520 - MSE: 0.8512 - val_loss: 1.0101 - val_MSE: 1.0092\n",
      "Epoch 30/2000\n",
      "4/4 [==============================] - 1s 207ms/step - loss: 0.8516 - MSE: 0.8507 - val_loss: 1.0062 - val_MSE: 1.0053\n",
      "Epoch 31/2000\n",
      "4/4 [==============================] - 1s 199ms/step - loss: 0.8519 - MSE: 0.8510 - val_loss: 1.0072 - val_MSE: 1.0064\n",
      "Epoch 32/2000\n",
      "4/4 [==============================] - 1s 190ms/step - loss: 0.8515 - MSE: 0.8507 - val_loss: 1.0071 - val_MSE: 1.0063\n",
      "Epoch 33/2000\n",
      "4/4 [==============================] - 1s 197ms/step - loss: 0.8518 - MSE: 0.8509 - val_loss: 1.0089 - val_MSE: 1.0080\n",
      "Epoch 34/2000\n",
      "4/4 [==============================] - 1s 203ms/step - loss: 0.8516 - MSE: 0.8507 - val_loss: 1.0062 - val_MSE: 1.0053\n",
      "Epoch 35/2000\n",
      "4/4 [==============================] - 1s 198ms/step - loss: 0.8518 - MSE: 0.8509 - val_loss: 1.0126 - val_MSE: 1.0117\n",
      "Epoch 36/2000\n",
      "4/4 [==============================] - 1s 208ms/step - loss: 0.8518 - MSE: 0.8509 - val_loss: 1.0178 - val_MSE: 1.0169\n",
      "Epoch 37/2000\n",
      "4/4 [==============================] - 1s 192ms/step - loss: 0.8521 - MSE: 0.8513 - val_loss: 1.0086 - val_MSE: 1.0078\n",
      "Epoch 38/2000\n",
      "4/4 [==============================] - 1s 191ms/step - loss: 0.8524 - MSE: 0.8515 - val_loss: 1.0052 - val_MSE: 1.0043\n",
      "Epoch 39/2000\n",
      "4/4 [==============================] - 1s 215ms/step - loss: 0.8518 - MSE: 0.8509 - val_loss: 1.0049 - val_MSE: 1.0040\n",
      "Epoch 40/2000\n",
      "4/4 [==============================] - 1s 192ms/step - loss: 0.8516 - MSE: 0.8507 - val_loss: 1.0056 - val_MSE: 1.0047\n",
      "Epoch 41/2000\n",
      "4/4 [==============================] - 1s 202ms/step - loss: 0.8515 - MSE: 0.8507 - val_loss: 1.0063 - val_MSE: 1.0054\n",
      "Epoch 42/2000\n",
      "4/4 [==============================] - 1s 202ms/step - loss: 0.8516 - MSE: 0.8507 - val_loss: 1.0066 - val_MSE: 1.0057\n",
      "Epoch 43/2000\n",
      "4/4 [==============================] - 1s 207ms/step - loss: 0.8513 - MSE: 0.8505 - val_loss: 1.0081 - val_MSE: 1.0072\n",
      "Epoch 44/2000\n",
      "4/4 [==============================] - 1s 211ms/step - loss: 0.8513 - MSE: 0.8505 - val_loss: 1.0059 - val_MSE: 1.0051\n",
      "Epoch 45/2000\n",
      "4/4 [==============================] - 1s 236ms/step - loss: 0.8516 - MSE: 0.8508 - val_loss: 1.0107 - val_MSE: 1.0099\n",
      "Epoch 46/2000\n",
      "4/4 [==============================] - 1s 192ms/step - loss: 0.8514 - MSE: 0.8506 - val_loss: 1.0059 - val_MSE: 1.0051\n",
      "Epoch 47/2000\n",
      "4/4 [==============================] - 1s 205ms/step - loss: 0.8514 - MSE: 0.8506 - val_loss: 1.0050 - val_MSE: 1.0042\n",
      "Epoch 48/2000\n",
      "4/4 [==============================] - 1s 199ms/step - loss: 0.8516 - MSE: 0.8508 - val_loss: 1.0060 - val_MSE: 1.0052\n",
      "Epoch 49/2000\n",
      "4/4 [==============================] - 1s 224ms/step - loss: 0.8519 - MSE: 0.8511 - val_loss: 1.0054 - val_MSE: 1.0046\n",
      "Epoch 50/2000\n",
      "4/4 [==============================] - 1s 196ms/step - loss: 0.8515 - MSE: 0.8507 - val_loss: 1.0082 - val_MSE: 1.0074\n",
      "Epoch 51/2000\n",
      "4/4 [==============================] - 1s 216ms/step - loss: 0.8512 - MSE: 0.8504 - val_loss: 1.0082 - val_MSE: 1.0074\n",
      "Epoch 52/2000\n",
      "4/4 [==============================] - 1s 183ms/step - loss: 0.8514 - MSE: 0.8506 - val_loss: 1.0057 - val_MSE: 1.0049\n",
      "Epoch 53/2000\n",
      "4/4 [==============================] - 1s 195ms/step - loss: 0.8516 - MSE: 0.8508 - val_loss: 1.0043 - val_MSE: 1.0035\n",
      "Epoch 54/2000\n",
      "4/4 [==============================] - 1s 221ms/step - loss: 0.8515 - MSE: 0.8507 - val_loss: 1.0047 - val_MSE: 1.0039\n",
      "Epoch 55/2000\n",
      "4/4 [==============================] - 1s 202ms/step - loss: 0.8516 - MSE: 0.8508 - val_loss: 1.0048 - val_MSE: 1.0040\n",
      "Epoch 56/2000\n",
      "4/4 [==============================] - 1s 195ms/step - loss: 0.8524 - MSE: 0.8517 - val_loss: 1.0059 - val_MSE: 1.0051\n",
      "Epoch 57/2000\n",
      "4/4 [==============================] - 1s 217ms/step - loss: 0.8515 - MSE: 0.8508 - val_loss: 1.0059 - val_MSE: 1.0052\n",
      "Epoch 58/2000\n",
      "4/4 [==============================] - 1s 196ms/step - loss: 0.8515 - MSE: 0.8507 - val_loss: 1.0029 - val_MSE: 1.0021\n",
      "Epoch 59/2000\n",
      "4/4 [==============================] - 1s 188ms/step - loss: 0.8515 - MSE: 0.8507 - val_loss: 1.0044 - val_MSE: 1.0037\n",
      "Epoch 60/2000\n",
      "4/4 [==============================] - 1s 192ms/step - loss: 0.8513 - MSE: 0.8505 - val_loss: 1.0039 - val_MSE: 1.0031\n",
      "Epoch 61/2000\n",
      "4/4 [==============================] - 1s 192ms/step - loss: 0.8513 - MSE: 0.8505 - val_loss: 1.0044 - val_MSE: 1.0036\n",
      "Epoch 62/2000\n",
      "4/4 [==============================] - 1s 199ms/step - loss: 0.8517 - MSE: 0.8509 - val_loss: 1.0069 - val_MSE: 1.0061\n",
      "Epoch 63/2000\n",
      "4/4 [==============================] - 1s 214ms/step - loss: 0.8517 - MSE: 0.8509 - val_loss: 1.0044 - val_MSE: 1.0036\n",
      "Epoch 64/2000\n",
      "4/4 [==============================] - 1s 203ms/step - loss: 0.8511 - MSE: 0.8503 - val_loss: 1.0118 - val_MSE: 1.0110\n",
      "Epoch 65/2000\n",
      "4/4 [==============================] - 1s 204ms/step - loss: 0.8515 - MSE: 0.8507 - val_loss: 1.0054 - val_MSE: 1.0047\n",
      "Epoch 66/2000\n",
      "4/4 [==============================] - 1s 188ms/step - loss: 0.8514 - MSE: 0.8507 - val_loss: 1.0072 - val_MSE: 1.0064\n",
      "Epoch 67/2000\n",
      "4/4 [==============================] - 1s 184ms/step - loss: 0.8520 - MSE: 0.8513 - val_loss: 1.0091 - val_MSE: 1.0084\n",
      "Epoch 68/2000\n",
      "4/4 [==============================] - 1s 193ms/step - loss: 0.8517 - MSE: 0.8510 - val_loss: 1.0263 - val_MSE: 1.0256\n",
      "Epoch 69/2000\n",
      "4/4 [==============================] - 1s 189ms/step - loss: 0.8518 - MSE: 0.8511 - val_loss: 1.0216 - val_MSE: 1.0209\n",
      "Epoch 70/2000\n",
      "4/4 [==============================] - 1s 191ms/step - loss: 0.8524 - MSE: 0.8517 - val_loss: 1.0453 - val_MSE: 1.0445\n",
      "Epoch 71/2000\n",
      "4/4 [==============================] - 1s 203ms/step - loss: 0.8602 - MSE: 0.8594 - val_loss: 1.0118 - val_MSE: 1.0107\n",
      "Epoch 72/2000\n",
      "4/4 [==============================] - 1s 213ms/step - loss: 0.8626 - MSE: 0.8607 - val_loss: 1.0605 - val_MSE: 1.0568\n",
      "Epoch 73/2000\n",
      "4/4 [==============================] - 1s 195ms/step - loss: 0.8652 - MSE: 0.8605 - val_loss: 1.0157 - val_MSE: 1.0091\n",
      "Epoch 74/2000\n",
      "4/4 [==============================] - 1s 204ms/step - loss: 0.8672 - MSE: 0.8598 - val_loss: 1.0196 - val_MSE: 1.0110\n",
      "Epoch 75/2000\n",
      "4/4 [==============================] - 1s 201ms/step - loss: 0.8694 - MSE: 0.8604 - val_loss: 1.0524 - val_MSE: 1.0428\n",
      "Epoch 76/2000\n",
      "4/4 [==============================] - 1s 196ms/step - loss: 0.8699 - MSE: 0.8602 - val_loss: 1.0678 - val_MSE: 1.0581\n",
      "Epoch 77/2000\n",
      "4/4 [==============================] - 1s 297ms/step - loss: 0.8693 - MSE: 0.8597 - val_loss: 1.0218 - val_MSE: 1.0126\n",
      "Epoch 78/2000\n",
      "4/4 [==============================] - 1s 201ms/step - loss: 0.8701 - MSE: 0.8611 - val_loss: 1.0201 - val_MSE: 1.0117\n",
      "Epoch 79/2000\n",
      "4/4 [==============================] - 1s 252ms/step - loss: 0.8682 - MSE: 0.8601 - val_loss: 1.0185 - val_MSE: 1.0110\n",
      "Epoch 80/2000\n",
      "4/4 [==============================] - 1s 217ms/step - loss: 0.8670 - MSE: 0.8597 - val_loss: 1.0172 - val_MSE: 1.0105\n",
      "Epoch 81/2000\n",
      "4/4 [==============================] - 1s 199ms/step - loss: 0.8662 - MSE: 0.8598 - val_loss: 1.0211 - val_MSE: 1.0152\n",
      "Epoch 82/2000\n",
      "4/4 [==============================] - 1s 257ms/step - loss: 0.8656 - MSE: 0.8600 - val_loss: 1.0285 - val_MSE: 1.0233\n",
      "Epoch 83/2000\n",
      "4/4 [==============================] - 1s 214ms/step - loss: 0.8644 - MSE: 0.8596 - val_loss: 1.0547 - val_MSE: 1.0503\n",
      "Epoch 84/2000\n",
      "4/4 [==============================] - 1s 202ms/step - loss: 0.8627 - MSE: 0.8586 - val_loss: 1.0148 - val_MSE: 1.0110\n",
      "Epoch 85/2000\n",
      "4/4 [==============================] - 1s 211ms/step - loss: 0.8633 - MSE: 0.8596 - val_loss: 1.1403 - val_MSE: 1.1369\n",
      "Epoch 86/2000\n",
      "4/4 [==============================] - 1s 224ms/step - loss: 0.8651 - MSE: 0.8619 - val_loss: 1.0147 - val_MSE: 1.0118\n",
      "Epoch 87/2000\n",
      "4/4 [==============================] - 1s 204ms/step - loss: 0.8632 - MSE: 0.8603 - val_loss: 1.0140 - val_MSE: 1.0112\n",
      "Epoch 88/2000\n",
      "4/4 [==============================] - 1s 416ms/step - loss: 0.8630 - MSE: 0.8603 - val_loss: 1.0135 - val_MSE: 1.0110\n",
      "Epoch 89/2000\n",
      "4/4 [==============================] - 3s 657ms/step - loss: 0.8627 - MSE: 0.8603 - val_loss: 1.0132 - val_MSE: 1.0110\n",
      "Epoch 90/2000\n",
      "4/4 [==============================] - 3s 656ms/step - loss: 0.8623 - MSE: 0.8602 - val_loss: 1.0130 - val_MSE: 1.0111\n",
      "Epoch 91/2000\n",
      "4/4 [==============================] - 3s 653ms/step - loss: 0.8620 - MSE: 0.8602 - val_loss: 1.0128 - val_MSE: 1.0112\n",
      "Epoch 92/2000\n",
      "4/4 [==============================] - 3s 669ms/step - loss: 0.8618 - MSE: 0.8603 - val_loss: 1.0126 - val_MSE: 1.0112\n",
      "Epoch 93/2000\n",
      "4/4 [==============================] - 3s 646ms/step - loss: 0.8614 - MSE: 0.8601 - val_loss: 1.0122 - val_MSE: 1.0110\n",
      "Epoch 94/2000\n",
      "4/4 [==============================] - 2s 409ms/step - loss: 0.8614 - MSE: 0.8603 - val_loss: 1.0120 - val_MSE: 1.0110\n",
      "Epoch 95/2000\n",
      "4/4 [==============================] - 1s 257ms/step - loss: 0.8609 - MSE: 0.8599 - val_loss: 1.0118 - val_MSE: 1.0109\n",
      "Epoch 96/2000\n",
      "4/4 [==============================] - 2s 378ms/step - loss: 0.8607 - MSE: 0.8598 - val_loss: 1.0117 - val_MSE: 1.0109\n",
      "Epoch 97/2000\n",
      "4/4 [==============================] - 1s 313ms/step - loss: 0.8606 - MSE: 0.8598 - val_loss: 1.0117 - val_MSE: 1.0108\n",
      "Epoch 98/2000\n",
      "4/4 [==============================] - 3s 648ms/step - loss: 0.8601 - MSE: 0.8593 - val_loss: 1.0115 - val_MSE: 1.0106\n",
      "Epoch 99/2000\n",
      "4/4 [==============================] - 3s 664ms/step - loss: 0.8599 - MSE: 0.8590 - val_loss: 1.0114 - val_MSE: 1.0104\n",
      "Epoch 100/2000\n",
      "4/4 [==============================] - 3s 636ms/step - loss: 0.8597 - MSE: 0.8587 - val_loss: 1.0119 - val_MSE: 1.0108\n",
      "Epoch 101/2000\n",
      "4/4 [==============================] - 3s 696ms/step - loss: 0.8601 - MSE: 0.8589 - val_loss: 1.0109 - val_MSE: 1.0097\n",
      "Epoch 102/2000\n",
      "4/4 [==============================] - 3s 654ms/step - loss: 0.8595 - MSE: 0.8583 - val_loss: 1.0100 - val_MSE: 1.0088\n",
      "Epoch 103/2000\n",
      "4/4 [==============================] - 3s 646ms/step - loss: 0.8596 - MSE: 0.8584 - val_loss: 1.0101 - val_MSE: 1.0089\n",
      "Epoch 104/2000\n",
      "4/4 [==============================] - 3s 655ms/step - loss: 0.8598 - MSE: 0.8586 - val_loss: 1.0115 - val_MSE: 1.0103\n",
      "Epoch 105/2000\n",
      "4/4 [==============================] - 3s 658ms/step - loss: 0.8598 - MSE: 0.8585 - val_loss: 1.0129 - val_MSE: 1.0116\n",
      "Epoch 106/2000\n",
      "4/4 [==============================] - 3s 638ms/step - loss: 0.8596 - MSE: 0.8584 - val_loss: 1.0095 - val_MSE: 1.0083\n",
      "Epoch 107/2000\n",
      "4/4 [==============================] - 2s 640ms/step - loss: 0.8597 - MSE: 0.8585 - val_loss: 1.0097 - val_MSE: 1.0086\n",
      "Epoch 108/2000\n",
      "4/4 [==============================] - 2s 622ms/step - loss: 0.8605 - MSE: 0.8594 - val_loss: 1.0116 - val_MSE: 1.0106\n",
      "Epoch 1/2000\n",
      "4/4 [==============================] - 16s 595ms/step - loss: 0.8736 - MSE: 0.8728 - val_loss: 0.6574 - val_MSE: 0.6567\n",
      "Epoch 2/2000\n",
      "4/4 [==============================] - 2s 612ms/step - loss: 0.8738 - MSE: 0.8730 - val_loss: 0.6578 - val_MSE: 0.6570\n",
      "Epoch 3/2000\n",
      "4/4 [==============================] - 2s 457ms/step - loss: 0.8735 - MSE: 0.8727 - val_loss: 0.6615 - val_MSE: 0.6607\n",
      "Epoch 4/2000\n",
      "4/4 [==============================] - 1s 224ms/step - loss: 0.8739 - MSE: 0.8731 - val_loss: 0.6568 - val_MSE: 0.6560\n",
      "Epoch 5/2000\n",
      "4/4 [==============================] - 1s 212ms/step - loss: 0.8739 - MSE: 0.8730 - val_loss: 0.6547 - val_MSE: 0.6539\n",
      "Epoch 6/2000\n",
      "4/4 [==============================] - 1s 218ms/step - loss: 0.8733 - MSE: 0.8724 - val_loss: 0.6545 - val_MSE: 0.6537\n",
      "Epoch 7/2000\n",
      "4/4 [==============================] - 1s 206ms/step - loss: 0.8735 - MSE: 0.8726 - val_loss: 0.6540 - val_MSE: 0.6531\n",
      "Epoch 8/2000\n",
      "4/4 [==============================] - 1s 236ms/step - loss: 0.8732 - MSE: 0.8723 - val_loss: 0.6545 - val_MSE: 0.6537\n",
      "Epoch 9/2000\n",
      "4/4 [==============================] - 1s 199ms/step - loss: 0.8734 - MSE: 0.8726 - val_loss: 0.6536 - val_MSE: 0.6527\n",
      "Epoch 10/2000\n",
      "4/4 [==============================] - 1s 189ms/step - loss: 0.8731 - MSE: 0.8722 - val_loss: 0.6545 - val_MSE: 0.6537\n",
      "Epoch 11/2000\n",
      "4/4 [==============================] - 1s 197ms/step - loss: 0.8732 - MSE: 0.8723 - val_loss: 0.6567 - val_MSE: 0.6559\n",
      "Epoch 12/2000\n",
      "4/4 [==============================] - 1s 213ms/step - loss: 0.8739 - MSE: 0.8731 - val_loss: 0.6547 - val_MSE: 0.6539\n",
      "Epoch 13/2000\n",
      "4/4 [==============================] - 1s 193ms/step - loss: 0.8736 - MSE: 0.8728 - val_loss: 0.6553 - val_MSE: 0.6545\n",
      "Epoch 14/2000\n",
      "4/4 [==============================] - 1s 197ms/step - loss: 0.8733 - MSE: 0.8725 - val_loss: 0.6563 - val_MSE: 0.6555\n",
      "Epoch 15/2000\n",
      "4/4 [==============================] - 1s 213ms/step - loss: 0.8737 - MSE: 0.8729 - val_loss: 0.6695 - val_MSE: 0.6687\n",
      "Epoch 16/2000\n",
      "4/4 [==============================] - 1s 200ms/step - loss: 0.8734 - MSE: 0.8726 - val_loss: 0.6577 - val_MSE: 0.6569\n",
      "Epoch 17/2000\n",
      "4/4 [==============================] - 1s 212ms/step - loss: 0.8731 - MSE: 0.8722 - val_loss: 0.6673 - val_MSE: 0.6665\n",
      "Epoch 18/2000\n",
      "4/4 [==============================] - 1s 206ms/step - loss: 0.8734 - MSE: 0.8726 - val_loss: 0.6558 - val_MSE: 0.6549\n",
      "Epoch 19/2000\n",
      "4/4 [==============================] - 1s 191ms/step - loss: 0.8733 - MSE: 0.8725 - val_loss: 0.6538 - val_MSE: 0.6530\n",
      "Epoch 20/2000\n",
      "4/4 [==============================] - 1s 203ms/step - loss: 0.8733 - MSE: 0.8725 - val_loss: 0.6573 - val_MSE: 0.6565\n",
      "Epoch 21/2000\n",
      "4/4 [==============================] - 1s 183ms/step - loss: 0.8732 - MSE: 0.8724 - val_loss: 0.6550 - val_MSE: 0.6543\n",
      "Epoch 22/2000\n",
      "4/4 [==============================] - 1s 199ms/step - loss: 0.8737 - MSE: 0.8729 - val_loss: 0.6759 - val_MSE: 0.6752\n",
      "Epoch 23/2000\n",
      "4/4 [==============================] - 1s 182ms/step - loss: 0.8732 - MSE: 0.8725 - val_loss: 0.6606 - val_MSE: 0.6599\n",
      "Epoch 24/2000\n",
      "4/4 [==============================] - 1s 215ms/step - loss: 0.8739 - MSE: 0.8731 - val_loss: 0.6545 - val_MSE: 0.6537\n",
      "Epoch 25/2000\n",
      "4/4 [==============================] - 1s 195ms/step - loss: 0.8732 - MSE: 0.8724 - val_loss: 0.6571 - val_MSE: 0.6563\n",
      "Epoch 26/2000\n",
      "4/4 [==============================] - 1s 210ms/step - loss: 0.8730 - MSE: 0.8722 - val_loss: 0.6621 - val_MSE: 0.6613\n",
      "Epoch 27/2000\n",
      "4/4 [==============================] - 1s 203ms/step - loss: 0.8733 - MSE: 0.8726 - val_loss: 0.6623 - val_MSE: 0.6615\n",
      "Epoch 28/2000\n",
      "4/4 [==============================] - 1s 186ms/step - loss: 0.8734 - MSE: 0.8726 - val_loss: 0.6566 - val_MSE: 0.6558\n",
      "Epoch 29/2000\n",
      "4/4 [==============================] - 1s 197ms/step - loss: 0.8732 - MSE: 0.8725 - val_loss: 0.6631 - val_MSE: 0.6623\n",
      "Epoch 30/2000\n",
      "4/4 [==============================] - 1s 199ms/step - loss: 0.8731 - MSE: 0.8723 - val_loss: 0.6574 - val_MSE: 0.6566\n",
      "Epoch 31/2000\n",
      "4/4 [==============================] - 1s 194ms/step - loss: 0.8732 - MSE: 0.8725 - val_loss: 0.6555 - val_MSE: 0.6548\n",
      "Epoch 32/2000\n",
      "4/4 [==============================] - 1s 198ms/step - loss: 0.8730 - MSE: 0.8722 - val_loss: 0.6556 - val_MSE: 0.6549\n",
      "Epoch 33/2000\n",
      "4/4 [==============================] - 1s 198ms/step - loss: 0.8730 - MSE: 0.8723 - val_loss: 0.6563 - val_MSE: 0.6556\n",
      "Epoch 34/2000\n",
      "4/4 [==============================] - 1s 189ms/step - loss: 0.8731 - MSE: 0.8724 - val_loss: 0.6572 - val_MSE: 0.6566\n",
      "Epoch 35/2000\n",
      "4/4 [==============================] - 1s 200ms/step - loss: 0.8731 - MSE: 0.8724 - val_loss: 0.6554 - val_MSE: 0.6547\n",
      "Epoch 36/2000\n",
      "4/4 [==============================] - 1s 196ms/step - loss: 0.8733 - MSE: 0.8726 - val_loss: 0.6540 - val_MSE: 0.6533\n",
      "Epoch 37/2000\n",
      "4/4 [==============================] - 1s 216ms/step - loss: 0.8733 - MSE: 0.8726 - val_loss: 0.6544 - val_MSE: 0.6537\n",
      "Epoch 38/2000\n",
      "4/4 [==============================] - 1s 200ms/step - loss: 0.8731 - MSE: 0.8724 - val_loss: 0.6556 - val_MSE: 0.6549\n",
      "Epoch 39/2000\n",
      "4/4 [==============================] - 1s 195ms/step - loss: 0.8734 - MSE: 0.8726 - val_loss: 0.6548 - val_MSE: 0.6541\n",
      "Epoch 40/2000\n",
      "4/4 [==============================] - 1s 204ms/step - loss: 0.8729 - MSE: 0.8722 - val_loss: 0.6570 - val_MSE: 0.6563\n",
      "Epoch 41/2000\n",
      "4/4 [==============================] - 1s 192ms/step - loss: 0.8731 - MSE: 0.8724 - val_loss: 0.6542 - val_MSE: 0.6535\n",
      "Epoch 42/2000\n",
      "4/4 [==============================] - 1s 234ms/step - loss: 0.8734 - MSE: 0.8727 - val_loss: 0.6551 - val_MSE: 0.6544\n",
      "Epoch 43/2000\n",
      "4/4 [==============================] - 1s 205ms/step - loss: 0.8730 - MSE: 0.8723 - val_loss: 0.6552 - val_MSE: 0.6545\n",
      "Epoch 44/2000\n",
      "4/4 [==============================] - 1s 218ms/step - loss: 0.8737 - MSE: 0.8731 - val_loss: 0.6553 - val_MSE: 0.6547\n",
      "Epoch 45/2000\n",
      "4/4 [==============================] - 1s 196ms/step - loss: 0.8734 - MSE: 0.8727 - val_loss: 0.6540 - val_MSE: 0.6533\n",
      "Epoch 46/2000\n",
      "4/4 [==============================] - 1s 213ms/step - loss: 0.8736 - MSE: 0.8729 - val_loss: 0.6553 - val_MSE: 0.6546\n",
      "Epoch 47/2000\n",
      "4/4 [==============================] - 1s 186ms/step - loss: 0.8744 - MSE: 0.8737 - val_loss: 0.6641 - val_MSE: 0.6634\n",
      "Epoch 48/2000\n",
      "4/4 [==============================] - 1s 224ms/step - loss: 0.8745 - MSE: 0.8738 - val_loss: 0.6553 - val_MSE: 0.6546\n",
      "Epoch 49/2000\n",
      "4/4 [==============================] - 1s 199ms/step - loss: 0.8742 - MSE: 0.8735 - val_loss: 0.6556 - val_MSE: 0.6547\n",
      "Epoch 50/2000\n",
      "4/4 [==============================] - 1s 192ms/step - loss: 0.8741 - MSE: 0.8732 - val_loss: 0.6999 - val_MSE: 0.6990\n",
      "Epoch 51/2000\n",
      "4/4 [==============================] - 1s 199ms/step - loss: 0.8743 - MSE: 0.8733 - val_loss: 0.6548 - val_MSE: 0.6539\n",
      "Epoch 52/2000\n",
      "4/4 [==============================] - 1s 195ms/step - loss: 0.8739 - MSE: 0.8729 - val_loss: 0.6592 - val_MSE: 0.6582\n",
      "Epoch 53/2000\n",
      "4/4 [==============================] - 1s 198ms/step - loss: 0.8737 - MSE: 0.8727 - val_loss: 0.6647 - val_MSE: 0.6637\n",
      "Epoch 54/2000\n",
      "4/4 [==============================] - 1s 204ms/step - loss: 0.8738 - MSE: 0.8729 - val_loss: 0.6676 - val_MSE: 0.6666\n",
      "Epoch 55/2000\n",
      "4/4 [==============================] - 1s 201ms/step - loss: 0.8739 - MSE: 0.8729 - val_loss: 0.6553 - val_MSE: 0.6543\n",
      "Epoch 56/2000\n",
      "4/4 [==============================] - 1s 203ms/step - loss: 0.8740 - MSE: 0.8730 - val_loss: 0.6621 - val_MSE: 0.6612\n",
      "Epoch 57/2000\n",
      "4/4 [==============================] - 1s 197ms/step - loss: 0.8739 - MSE: 0.8730 - val_loss: 0.7133 - val_MSE: 0.7124\n",
      "Epoch 58/2000\n",
      "4/4 [==============================] - 1s 143ms/step - loss: 0.8739 - MSE: 0.8729 - val_loss: 0.6593 - val_MSE: 0.6583\n",
      "Epoch 59/2000\n",
      "4/4 [==============================] - 1s 132ms/step - loss: 0.8737 - MSE: 0.8727 - val_loss: 0.6946 - val_MSE: 0.6936\n",
      "Epoch 1/2000\n",
      "4/4 [==============================] - 5s 308ms/step - loss: 0.8556 - MSE: 0.8547 - val_loss: 0.9911 - val_MSE: 0.9902\n",
      "Epoch 2/2000\n",
      "4/4 [==============================] - 0s 122ms/step - loss: 0.8560 - MSE: 0.8551 - val_loss: 0.9935 - val_MSE: 0.9926\n",
      "Epoch 3/2000\n",
      "4/4 [==============================] - 0s 123ms/step - loss: 0.8557 - MSE: 0.8548 - val_loss: 0.9929 - val_MSE: 0.9921\n",
      "Epoch 4/2000\n",
      "4/4 [==============================] - 0s 121ms/step - loss: 0.8555 - MSE: 0.8546 - val_loss: 0.9924 - val_MSE: 0.9915\n",
      "Epoch 5/2000\n",
      "4/4 [==============================] - 0s 123ms/step - loss: 0.8557 - MSE: 0.8548 - val_loss: 0.9921 - val_MSE: 0.9912\n",
      "Epoch 6/2000\n",
      "4/4 [==============================] - 0s 125ms/step - loss: 0.8552 - MSE: 0.8544 - val_loss: 0.9910 - val_MSE: 0.9901\n",
      "Epoch 7/2000\n",
      "4/4 [==============================] - 0s 124ms/step - loss: 0.8553 - MSE: 0.8545 - val_loss: 0.9912 - val_MSE: 0.9904\n",
      "Epoch 8/2000\n",
      "4/4 [==============================] - 0s 124ms/step - loss: 0.8553 - MSE: 0.8545 - val_loss: 0.9901 - val_MSE: 0.9892\n",
      "Epoch 9/2000\n",
      "4/4 [==============================] - 0s 125ms/step - loss: 0.8558 - MSE: 0.8548 - val_loss: 0.9914 - val_MSE: 0.9905\n",
      "Epoch 10/2000\n",
      "4/4 [==============================] - 0s 123ms/step - loss: 0.8554 - MSE: 0.8545 - val_loss: 0.9964 - val_MSE: 0.9955\n",
      "Epoch 11/2000\n",
      "4/4 [==============================] - 0s 125ms/step - loss: 0.8557 - MSE: 0.8548 - val_loss: 0.9927 - val_MSE: 0.9918\n",
      "Epoch 12/2000\n",
      "4/4 [==============================] - 0s 124ms/step - loss: 0.8557 - MSE: 0.8548 - val_loss: 0.9972 - val_MSE: 0.9962\n",
      "Epoch 13/2000\n",
      "4/4 [==============================] - 0s 125ms/step - loss: 0.8556 - MSE: 0.8547 - val_loss: 0.9898 - val_MSE: 0.9889\n",
      "Epoch 14/2000\n",
      "4/4 [==============================] - 0s 123ms/step - loss: 0.8552 - MSE: 0.8543 - val_loss: 1.0010 - val_MSE: 1.0001\n",
      "Epoch 15/2000\n",
      "4/4 [==============================] - 0s 121ms/step - loss: 0.8555 - MSE: 0.8546 - val_loss: 1.0079 - val_MSE: 1.0069\n",
      "Epoch 16/2000\n",
      "4/4 [==============================] - 0s 123ms/step - loss: 0.8559 - MSE: 0.8549 - val_loss: 0.9949 - val_MSE: 0.9939\n",
      "Epoch 17/2000\n",
      "4/4 [==============================] - 0s 124ms/step - loss: 0.8556 - MSE: 0.8546 - val_loss: 0.9904 - val_MSE: 0.9895\n",
      "Epoch 18/2000\n",
      "4/4 [==============================] - 0s 122ms/step - loss: 0.8556 - MSE: 0.8547 - val_loss: 1.0001 - val_MSE: 0.9992\n",
      "Epoch 19/2000\n",
      "4/4 [==============================] - 0s 124ms/step - loss: 0.8555 - MSE: 0.8547 - val_loss: 0.9943 - val_MSE: 0.9935\n",
      "Epoch 20/2000\n",
      "4/4 [==============================] - 0s 121ms/step - loss: 0.8554 - MSE: 0.8546 - val_loss: 0.9909 - val_MSE: 0.9901\n",
      "Epoch 21/2000\n",
      "4/4 [==============================] - 0s 126ms/step - loss: 0.8551 - MSE: 0.8543 - val_loss: 0.9949 - val_MSE: 0.9941\n",
      "Epoch 22/2000\n",
      "4/4 [==============================] - 0s 125ms/step - loss: 0.8555 - MSE: 0.8547 - val_loss: 0.9917 - val_MSE: 0.9909\n",
      "Epoch 23/2000\n",
      "4/4 [==============================] - 0s 126ms/step - loss: 0.8550 - MSE: 0.8543 - val_loss: 0.9925 - val_MSE: 0.9918\n",
      "Epoch 24/2000\n",
      "4/4 [==============================] - 0s 122ms/step - loss: 0.8555 - MSE: 0.8548 - val_loss: 0.9922 - val_MSE: 0.9915\n",
      "Epoch 25/2000\n",
      "4/4 [==============================] - 0s 122ms/step - loss: 0.8552 - MSE: 0.8545 - val_loss: 0.9944 - val_MSE: 0.9937\n",
      "Epoch 26/2000\n",
      "4/4 [==============================] - 0s 124ms/step - loss: 0.8553 - MSE: 0.8546 - val_loss: 0.9968 - val_MSE: 0.9961\n",
      "Epoch 27/2000\n",
      "4/4 [==============================] - 0s 124ms/step - loss: 0.8562 - MSE: 0.8555 - val_loss: 1.0092 - val_MSE: 1.0084\n",
      "Epoch 28/2000\n",
      "4/4 [==============================] - 0s 130ms/step - loss: 0.8551 - MSE: 0.8544 - val_loss: 0.9947 - val_MSE: 0.9939\n",
      "Epoch 29/2000\n",
      "4/4 [==============================] - 0s 122ms/step - loss: 0.8557 - MSE: 0.8549 - val_loss: 0.9919 - val_MSE: 0.9910\n",
      "Epoch 30/2000\n",
      "4/4 [==============================] - 0s 123ms/step - loss: 0.8551 - MSE: 0.8542 - val_loss: 0.9949 - val_MSE: 0.9940\n",
      "Epoch 31/2000\n",
      "4/4 [==============================] - 0s 124ms/step - loss: 0.8555 - MSE: 0.8546 - val_loss: 0.9907 - val_MSE: 0.9898\n",
      "Epoch 32/2000\n",
      "4/4 [==============================] - 0s 125ms/step - loss: 0.8555 - MSE: 0.8547 - val_loss: 0.9908 - val_MSE: 0.9900\n",
      "Epoch 33/2000\n",
      "4/4 [==============================] - 0s 122ms/step - loss: 0.8551 - MSE: 0.8543 - val_loss: 0.9960 - val_MSE: 0.9953\n",
      "Epoch 34/2000\n",
      "4/4 [==============================] - 0s 122ms/step - loss: 0.8555 - MSE: 0.8548 - val_loss: 0.9937 - val_MSE: 0.9930\n",
      "Epoch 35/2000\n",
      "4/4 [==============================] - 0s 123ms/step - loss: 0.8550 - MSE: 0.8543 - val_loss: 0.9905 - val_MSE: 0.9898\n",
      "Epoch 36/2000\n",
      "4/4 [==============================] - 0s 121ms/step - loss: 0.8552 - MSE: 0.8545 - val_loss: 0.9904 - val_MSE: 0.9897\n",
      "Epoch 37/2000\n",
      "4/4 [==============================] - 0s 121ms/step - loss: 0.8556 - MSE: 0.8549 - val_loss: 0.9926 - val_MSE: 0.9919\n",
      "Epoch 38/2000\n",
      "4/4 [==============================] - 0s 123ms/step - loss: 0.8552 - MSE: 0.8545 - val_loss: 0.9937 - val_MSE: 0.9931\n",
      "Epoch 39/2000\n",
      "4/4 [==============================] - 0s 123ms/step - loss: 0.8555 - MSE: 0.8548 - val_loss: 0.9992 - val_MSE: 0.9985\n",
      "Epoch 40/2000\n",
      "4/4 [==============================] - 0s 123ms/step - loss: 0.8551 - MSE: 0.8545 - val_loss: 1.0114 - val_MSE: 1.0107\n",
      "Epoch 41/2000\n",
      "4/4 [==============================] - 0s 123ms/step - loss: 0.8552 - MSE: 0.8545 - val_loss: 1.0072 - val_MSE: 1.0065\n",
      "Epoch 42/2000\n",
      "4/4 [==============================] - 0s 123ms/step - loss: 0.8558 - MSE: 0.8551 - val_loss: 1.0068 - val_MSE: 1.0061\n",
      "Epoch 43/2000\n",
      "4/4 [==============================] - 0s 124ms/step - loss: 0.8552 - MSE: 0.8545 - val_loss: 1.0130 - val_MSE: 1.0123\n",
      "Epoch 44/2000\n",
      "4/4 [==============================] - 0s 123ms/step - loss: 0.8552 - MSE: 0.8545 - val_loss: 1.0120 - val_MSE: 1.0113\n",
      "Epoch 45/2000\n",
      "4/4 [==============================] - 0s 125ms/step - loss: 0.8549 - MSE: 0.8541 - val_loss: 0.9902 - val_MSE: 0.9894\n",
      "Epoch 46/2000\n",
      "4/4 [==============================] - 0s 125ms/step - loss: 0.8552 - MSE: 0.8544 - val_loss: 1.0000 - val_MSE: 0.9992\n",
      "Epoch 47/2000\n",
      "4/4 [==============================] - 0s 123ms/step - loss: 0.8551 - MSE: 0.8543 - val_loss: 0.9934 - val_MSE: 0.9926\n",
      "Epoch 48/2000\n",
      "4/4 [==============================] - 0s 122ms/step - loss: 0.8554 - MSE: 0.8546 - val_loss: 1.0121 - val_MSE: 1.0113\n",
      "Epoch 49/2000\n",
      "4/4 [==============================] - 0s 123ms/step - loss: 0.8557 - MSE: 0.8550 - val_loss: 0.9948 - val_MSE: 0.9940\n",
      "Epoch 50/2000\n",
      "4/4 [==============================] - 0s 123ms/step - loss: 0.8554 - MSE: 0.8546 - val_loss: 0.9904 - val_MSE: 0.9897\n",
      "Epoch 51/2000\n",
      "4/4 [==============================] - 0s 123ms/step - loss: 0.8552 - MSE: 0.8544 - val_loss: 1.0032 - val_MSE: 1.0024\n",
      "Epoch 52/2000\n",
      "4/4 [==============================] - 0s 120ms/step - loss: 0.8556 - MSE: 0.8548 - val_loss: 0.9908 - val_MSE: 0.9900\n",
      "Epoch 53/2000\n",
      "4/4 [==============================] - 0s 124ms/step - loss: 0.8553 - MSE: 0.8545 - val_loss: 0.9943 - val_MSE: 0.9936\n",
      "Epoch 54/2000\n",
      "4/4 [==============================] - 0s 124ms/step - loss: 0.8552 - MSE: 0.8545 - val_loss: 0.9976 - val_MSE: 0.9968\n",
      "Epoch 55/2000\n",
      "4/4 [==============================] - 0s 123ms/step - loss: 0.8557 - MSE: 0.8549 - val_loss: 0.9897 - val_MSE: 0.9888\n",
      "Epoch 56/2000\n",
      "4/4 [==============================] - 0s 121ms/step - loss: 0.8552 - MSE: 0.8544 - val_loss: 0.9931 - val_MSE: 0.9923\n",
      "Epoch 57/2000\n",
      "4/4 [==============================] - 0s 122ms/step - loss: 0.8553 - MSE: 0.8545 - val_loss: 1.0012 - val_MSE: 1.0003\n",
      "Epoch 58/2000\n",
      "4/4 [==============================] - 0s 125ms/step - loss: 0.8555 - MSE: 0.8547 - val_loss: 0.9904 - val_MSE: 0.9896\n",
      "Epoch 59/2000\n",
      "4/4 [==============================] - 0s 125ms/step - loss: 0.8551 - MSE: 0.8543 - val_loss: 0.9896 - val_MSE: 0.9889\n",
      "Epoch 60/2000\n",
      "4/4 [==============================] - 0s 125ms/step - loss: 0.8551 - MSE: 0.8544 - val_loss: 0.9901 - val_MSE: 0.9893\n",
      "Epoch 61/2000\n",
      "4/4 [==============================] - 0s 123ms/step - loss: 0.8554 - MSE: 0.8547 - val_loss: 0.9914 - val_MSE: 0.9908\n",
      "Epoch 62/2000\n",
      "4/4 [==============================] - 0s 124ms/step - loss: 0.8550 - MSE: 0.8543 - val_loss: 0.9921 - val_MSE: 0.9914\n",
      "Epoch 63/2000\n",
      "4/4 [==============================] - 0s 122ms/step - loss: 0.8553 - MSE: 0.8547 - val_loss: 0.9918 - val_MSE: 0.9912\n",
      "Epoch 64/2000\n",
      "4/4 [==============================] - 0s 122ms/step - loss: 0.8549 - MSE: 0.8542 - val_loss: 0.9965 - val_MSE: 0.9959\n",
      "Epoch 65/2000\n",
      "4/4 [==============================] - 0s 123ms/step - loss: 0.8555 - MSE: 0.8548 - val_loss: 0.9983 - val_MSE: 0.9977\n",
      "Epoch 66/2000\n",
      "4/4 [==============================] - 0s 121ms/step - loss: 0.8552 - MSE: 0.8546 - val_loss: 0.9910 - val_MSE: 0.9904\n",
      "Epoch 67/2000\n",
      "4/4 [==============================] - 0s 123ms/step - loss: 0.8557 - MSE: 0.8550 - val_loss: 0.9919 - val_MSE: 0.9912\n",
      "Epoch 68/2000\n",
      "4/4 [==============================] - 0s 124ms/step - loss: 0.8559 - MSE: 0.8552 - val_loss: 0.9962 - val_MSE: 0.9955\n",
      "Epoch 69/2000\n",
      "4/4 [==============================] - 0s 124ms/step - loss: 0.8554 - MSE: 0.8546 - val_loss: 1.0135 - val_MSE: 1.0126\n",
      "Epoch 70/2000\n",
      "4/4 [==============================] - 0s 124ms/step - loss: 0.8562 - MSE: 0.8553 - val_loss: 1.0158 - val_MSE: 1.0148\n",
      "Epoch 71/2000\n",
      "4/4 [==============================] - 0s 126ms/step - loss: 0.8561 - MSE: 0.8551 - val_loss: 0.9932 - val_MSE: 0.9922\n",
      "Epoch 72/2000\n",
      "4/4 [==============================] - 0s 121ms/step - loss: 0.8556 - MSE: 0.8546 - val_loss: 0.9942 - val_MSE: 0.9931\n",
      "Epoch 73/2000\n",
      "4/4 [==============================] - 0s 123ms/step - loss: 0.8559 - MSE: 0.8549 - val_loss: 1.0145 - val_MSE: 1.0134\n",
      "Epoch 74/2000\n",
      "4/4 [==============================] - 0s 124ms/step - loss: 0.8558 - MSE: 0.8547 - val_loss: 1.0217 - val_MSE: 1.0207\n",
      "Epoch 75/2000\n",
      "4/4 [==============================] - 0s 122ms/step - loss: 0.8559 - MSE: 0.8549 - val_loss: 0.9984 - val_MSE: 0.9974\n",
      "Epoch 76/2000\n",
      "4/4 [==============================] - 0s 123ms/step - loss: 0.8555 - MSE: 0.8546 - val_loss: 0.9900 - val_MSE: 0.9891\n",
      "Epoch 77/2000\n",
      "4/4 [==============================] - 0s 125ms/step - loss: 0.8555 - MSE: 0.8546 - val_loss: 1.0168 - val_MSE: 1.0159\n",
      "Epoch 78/2000\n",
      "4/4 [==============================] - 0s 124ms/step - loss: 0.8555 - MSE: 0.8547 - val_loss: 1.0005 - val_MSE: 0.9997\n",
      "Epoch 79/2000\n",
      "4/4 [==============================] - 0s 123ms/step - loss: 0.8555 - MSE: 0.8547 - val_loss: 1.0031 - val_MSE: 1.0024\n",
      "Epoch 80/2000\n",
      "4/4 [==============================] - 0s 124ms/step - loss: 0.8552 - MSE: 0.8545 - val_loss: 1.0121 - val_MSE: 1.0114\n",
      "Epoch 81/2000\n",
      "4/4 [==============================] - 0s 122ms/step - loss: 0.8549 - MSE: 0.8542 - val_loss: 0.9960 - val_MSE: 0.9953\n",
      "Epoch 82/2000\n",
      "4/4 [==============================] - 0s 124ms/step - loss: 0.8554 - MSE: 0.8546 - val_loss: 1.0155 - val_MSE: 1.0148\n",
      "Epoch 83/2000\n",
      "4/4 [==============================] - 0s 123ms/step - loss: 0.8552 - MSE: 0.8544 - val_loss: 0.9901 - val_MSE: 0.9893\n",
      "Epoch 84/2000\n",
      "4/4 [==============================] - 0s 124ms/step - loss: 0.8552 - MSE: 0.8544 - val_loss: 0.9915 - val_MSE: 0.9907\n",
      "Epoch 85/2000\n",
      "4/4 [==============================] - 0s 121ms/step - loss: 0.8557 - MSE: 0.8549 - val_loss: 1.0006 - val_MSE: 0.9998\n",
      "Epoch 86/2000\n",
      "4/4 [==============================] - 0s 122ms/step - loss: 0.8555 - MSE: 0.8547 - val_loss: 0.9968 - val_MSE: 0.9960\n",
      "Epoch 87/2000\n",
      "4/4 [==============================] - 0s 123ms/step - loss: 0.8555 - MSE: 0.8547 - val_loss: 0.9908 - val_MSE: 0.9900\n",
      "Epoch 88/2000\n",
      "4/4 [==============================] - 0s 123ms/step - loss: 0.8552 - MSE: 0.8544 - val_loss: 0.9911 - val_MSE: 0.9904\n",
      "Epoch 89/2000\n",
      "4/4 [==============================] - 0s 121ms/step - loss: 0.8555 - MSE: 0.8548 - val_loss: 0.9900 - val_MSE: 0.9893\n",
      "Epoch 90/2000\n",
      "4/4 [==============================] - 0s 125ms/step - loss: 0.8551 - MSE: 0.8544 - val_loss: 0.9908 - val_MSE: 0.9902\n",
      "Epoch 91/2000\n",
      "4/4 [==============================] - 0s 121ms/step - loss: 0.8552 - MSE: 0.8546 - val_loss: 0.9909 - val_MSE: 0.9903\n",
      "Epoch 92/2000\n",
      "4/4 [==============================] - 0s 122ms/step - loss: 0.8550 - MSE: 0.8543 - val_loss: 0.9914 - val_MSE: 0.9907\n",
      "Epoch 93/2000\n",
      "4/4 [==============================] - 0s 122ms/step - loss: 0.8555 - MSE: 0.8548 - val_loss: 0.9914 - val_MSE: 0.9907\n",
      "Epoch 94/2000\n",
      "4/4 [==============================] - 0s 122ms/step - loss: 0.8561 - MSE: 0.8555 - val_loss: 0.9916 - val_MSE: 0.9909\n",
      "Epoch 95/2000\n",
      "4/4 [==============================] - 0s 123ms/step - loss: 0.8554 - MSE: 0.8547 - val_loss: 0.9933 - val_MSE: 0.9926\n",
      "Epoch 96/2000\n",
      "4/4 [==============================] - 0s 125ms/step - loss: 0.8563 - MSE: 0.8556 - val_loss: 0.9943 - val_MSE: 0.9936\n",
      "Epoch 97/2000\n",
      "4/4 [==============================] - 0s 122ms/step - loss: 0.8554 - MSE: 0.8547 - val_loss: 0.9925 - val_MSE: 0.9918\n",
      "Epoch 98/2000\n",
      "4/4 [==============================] - 0s 124ms/step - loss: 0.8557 - MSE: 0.8550 - val_loss: 0.9963 - val_MSE: 0.9956\n",
      "Epoch 99/2000\n",
      "4/4 [==============================] - 0s 122ms/step - loss: 0.8555 - MSE: 0.8547 - val_loss: 0.9965 - val_MSE: 0.9957\n",
      "Epoch 100/2000\n",
      "4/4 [==============================] - 0s 123ms/step - loss: 0.8557 - MSE: 0.8549 - val_loss: 1.0261 - val_MSE: 1.0251\n",
      "Epoch 101/2000\n",
      "4/4 [==============================] - 0s 124ms/step - loss: 0.8556 - MSE: 0.8546 - val_loss: 0.9906 - val_MSE: 0.9896\n",
      "Epoch 102/2000\n",
      "4/4 [==============================] - 0s 124ms/step - loss: 0.8561 - MSE: 0.8551 - val_loss: 1.0231 - val_MSE: 1.0221\n",
      "Epoch 103/2000\n",
      "4/4 [==============================] - 0s 124ms/step - loss: 0.8558 - MSE: 0.8548 - val_loss: 0.9910 - val_MSE: 0.9899\n",
      "Epoch 104/2000\n",
      "4/4 [==============================] - 0s 123ms/step - loss: 0.8554 - MSE: 0.8543 - val_loss: 1.0008 - val_MSE: 0.9998\n",
      "Epoch 105/2000\n",
      "4/4 [==============================] - 0s 122ms/step - loss: 0.8562 - MSE: 0.8552 - val_loss: 0.9910 - val_MSE: 0.9901\n",
      "Epoch 106/2000\n",
      "4/4 [==============================] - 0s 124ms/step - loss: 0.8565 - MSE: 0.8555 - val_loss: 1.0040 - val_MSE: 1.0030\n",
      "Epoch 107/2000\n",
      "4/4 [==============================] - 0s 122ms/step - loss: 0.8560 - MSE: 0.8550 - val_loss: 1.0112 - val_MSE: 1.0102\n",
      "Epoch 108/2000\n",
      "4/4 [==============================] - 0s 124ms/step - loss: 0.8555 - MSE: 0.8546 - val_loss: 0.9938 - val_MSE: 0.9928\n",
      "Epoch 109/2000\n",
      "4/4 [==============================] - 0s 123ms/step - loss: 0.8556 - MSE: 0.8547 - val_loss: 1.0159 - val_MSE: 1.0150\n",
      "Epoch 1/2000\n",
      "4/4 [==============================] - 5s 304ms/step - loss: 0.8624 - MSE: 0.8616 - val_loss: 1.4331 - val_MSE: 1.4323\n",
      "Epoch 2/2000\n",
      "4/4 [==============================] - 0s 123ms/step - loss: 0.8629 - MSE: 0.8622 - val_loss: 1.4355 - val_MSE: 1.4347\n",
      "Epoch 3/2000\n",
      "4/4 [==============================] - 0s 121ms/step - loss: 0.8625 - MSE: 0.8618 - val_loss: 1.4433 - val_MSE: 1.4426\n",
      "Epoch 4/2000\n",
      "4/4 [==============================] - 0s 122ms/step - loss: 0.8627 - MSE: 0.8620 - val_loss: 1.4373 - val_MSE: 1.4365\n",
      "Epoch 5/2000\n",
      "4/4 [==============================] - 0s 124ms/step - loss: 0.8628 - MSE: 0.8621 - val_loss: 1.4329 - val_MSE: 1.4321\n",
      "Epoch 6/2000\n",
      "4/4 [==============================] - 0s 122ms/step - loss: 0.8627 - MSE: 0.8619 - val_loss: 1.4330 - val_MSE: 1.4322\n",
      "Epoch 7/2000\n",
      "4/4 [==============================] - 0s 122ms/step - loss: 0.8626 - MSE: 0.8619 - val_loss: 1.4383 - val_MSE: 1.4376\n",
      "Epoch 8/2000\n",
      "4/4 [==============================] - 0s 120ms/step - loss: 0.8626 - MSE: 0.8619 - val_loss: 1.4473 - val_MSE: 1.4466\n",
      "Epoch 9/2000\n",
      "4/4 [==============================] - 0s 123ms/step - loss: 0.8630 - MSE: 0.8622 - val_loss: 1.4489 - val_MSE: 1.4482\n",
      "Epoch 10/2000\n",
      "4/4 [==============================] - 0s 121ms/step - loss: 0.8627 - MSE: 0.8620 - val_loss: 1.4361 - val_MSE: 1.4354\n",
      "Epoch 11/2000\n",
      "4/4 [==============================] - 0s 120ms/step - loss: 0.8626 - MSE: 0.8618 - val_loss: 1.4329 - val_MSE: 1.4321\n",
      "Epoch 12/2000\n",
      "4/4 [==============================] - 0s 121ms/step - loss: 0.8633 - MSE: 0.8625 - val_loss: 1.4410 - val_MSE: 1.4401\n",
      "Epoch 13/2000\n",
      "4/4 [==============================] - 0s 123ms/step - loss: 0.8630 - MSE: 0.8621 - val_loss: 1.4361 - val_MSE: 1.4353\n",
      "Epoch 14/2000\n",
      "4/4 [==============================] - 0s 121ms/step - loss: 0.8629 - MSE: 0.8620 - val_loss: 1.4420 - val_MSE: 1.4412\n",
      "Epoch 15/2000\n",
      "4/4 [==============================] - 0s 122ms/step - loss: 0.8630 - MSE: 0.8622 - val_loss: 1.4483 - val_MSE: 1.4474\n",
      "Epoch 16/2000\n",
      "4/4 [==============================] - 0s 121ms/step - loss: 0.8630 - MSE: 0.8621 - val_loss: 1.4605 - val_MSE: 1.4596\n",
      "Epoch 17/2000\n",
      "4/4 [==============================] - 0s 122ms/step - loss: 0.8630 - MSE: 0.8621 - val_loss: 1.4584 - val_MSE: 1.4576\n",
      "Epoch 18/2000\n",
      "4/4 [==============================] - 0s 122ms/step - loss: 0.8628 - MSE: 0.8619 - val_loss: 1.4508 - val_MSE: 1.4500\n",
      "Epoch 19/2000\n",
      "4/4 [==============================] - 0s 122ms/step - loss: 0.8627 - MSE: 0.8619 - val_loss: 1.4316 - val_MSE: 1.4308\n",
      "Epoch 20/2000\n",
      "4/4 [==============================] - 0s 123ms/step - loss: 0.8630 - MSE: 0.8622 - val_loss: 1.4354 - val_MSE: 1.4346\n",
      "Epoch 21/2000\n",
      "4/4 [==============================] - 0s 122ms/step - loss: 0.8626 - MSE: 0.8618 - val_loss: 1.4434 - val_MSE: 1.4427\n",
      "Epoch 22/2000\n",
      "4/4 [==============================] - 0s 121ms/step - loss: 0.8625 - MSE: 0.8618 - val_loss: 1.4480 - val_MSE: 1.4473\n",
      "Epoch 23/2000\n",
      "4/4 [==============================] - 0s 124ms/step - loss: 0.8624 - MSE: 0.8617 - val_loss: 1.4418 - val_MSE: 1.4412\n",
      "Epoch 24/2000\n",
      "4/4 [==============================] - 0s 123ms/step - loss: 0.8630 - MSE: 0.8623 - val_loss: 1.4411 - val_MSE: 1.4404\n",
      "Epoch 25/2000\n",
      "4/4 [==============================] - 0s 122ms/step - loss: 0.8629 - MSE: 0.8622 - val_loss: 1.4507 - val_MSE: 1.4500\n",
      "Epoch 26/2000\n",
      "4/4 [==============================] - 0s 122ms/step - loss: 0.8629 - MSE: 0.8622 - val_loss: 1.4332 - val_MSE: 1.4324\n",
      "Epoch 27/2000\n",
      "4/4 [==============================] - 0s 121ms/step - loss: 0.8629 - MSE: 0.8621 - val_loss: 1.4336 - val_MSE: 1.4327\n",
      "Epoch 28/2000\n",
      "4/4 [==============================] - 0s 121ms/step - loss: 0.8626 - MSE: 0.8617 - val_loss: 1.4342 - val_MSE: 1.4333\n",
      "Epoch 29/2000\n",
      "4/4 [==============================] - 0s 123ms/step - loss: 0.8624 - MSE: 0.8615 - val_loss: 1.4365 - val_MSE: 1.4356\n",
      "Epoch 30/2000\n",
      "4/4 [==============================] - 0s 121ms/step - loss: 0.8626 - MSE: 0.8617 - val_loss: 1.4337 - val_MSE: 1.4329\n",
      "Epoch 31/2000\n",
      "4/4 [==============================] - 0s 125ms/step - loss: 0.8624 - MSE: 0.8616 - val_loss: 1.4456 - val_MSE: 1.4448\n",
      "Epoch 32/2000\n",
      "4/4 [==============================] - 0s 123ms/step - loss: 0.8624 - MSE: 0.8616 - val_loss: 1.4367 - val_MSE: 1.4360\n",
      "Epoch 33/2000\n",
      "4/4 [==============================] - 0s 121ms/step - loss: 0.8630 - MSE: 0.8623 - val_loss: 1.4338 - val_MSE: 1.4332\n",
      "Epoch 34/2000\n",
      "4/4 [==============================] - 0s 122ms/step - loss: 0.8625 - MSE: 0.8619 - val_loss: 1.4345 - val_MSE: 1.4339\n",
      "Epoch 35/2000\n",
      "4/4 [==============================] - 0s 122ms/step - loss: 0.8624 - MSE: 0.8618 - val_loss: 1.4368 - val_MSE: 1.4361\n",
      "Epoch 36/2000\n",
      "4/4 [==============================] - 0s 125ms/step - loss: 0.8628 - MSE: 0.8621 - val_loss: 1.4537 - val_MSE: 1.4530\n",
      "Epoch 37/2000\n",
      "4/4 [==============================] - 0s 123ms/step - loss: 0.8627 - MSE: 0.8620 - val_loss: 1.4354 - val_MSE: 1.4347\n",
      "Epoch 38/2000\n",
      "4/4 [==============================] - 0s 122ms/step - loss: 0.8626 - MSE: 0.8619 - val_loss: 1.4359 - val_MSE: 1.4352\n",
      "Epoch 39/2000\n",
      "4/4 [==============================] - 0s 123ms/step - loss: 0.8625 - MSE: 0.8618 - val_loss: 1.4320 - val_MSE: 1.4312\n",
      "Epoch 40/2000\n",
      "4/4 [==============================] - 0s 122ms/step - loss: 0.8625 - MSE: 0.8618 - val_loss: 1.4334 - val_MSE: 1.4327\n",
      "Epoch 41/2000\n",
      "4/4 [==============================] - 0s 122ms/step - loss: 0.8629 - MSE: 0.8621 - val_loss: 1.4472 - val_MSE: 1.4464\n",
      "Epoch 42/2000\n",
      "4/4 [==============================] - 0s 121ms/step - loss: 0.8624 - MSE: 0.8617 - val_loss: 1.4435 - val_MSE: 1.4428\n",
      "Epoch 43/2000\n",
      "4/4 [==============================] - 0s 123ms/step - loss: 0.8626 - MSE: 0.8619 - val_loss: 1.4392 - val_MSE: 1.4385\n",
      "Epoch 44/2000\n",
      "4/4 [==============================] - 0s 123ms/step - loss: 0.8627 - MSE: 0.8620 - val_loss: 1.4368 - val_MSE: 1.4361\n",
      "Epoch 45/2000\n",
      "4/4 [==============================] - 0s 123ms/step - loss: 0.8631 - MSE: 0.8624 - val_loss: 1.4367 - val_MSE: 1.4360\n",
      "Epoch 46/2000\n",
      "4/4 [==============================] - 0s 123ms/step - loss: 0.8628 - MSE: 0.8621 - val_loss: 1.4409 - val_MSE: 1.4402\n",
      "Epoch 47/2000\n",
      "4/4 [==============================] - 0s 121ms/step - loss: 0.8625 - MSE: 0.8618 - val_loss: 1.4317 - val_MSE: 1.4310\n",
      "Epoch 48/2000\n",
      "4/4 [==============================] - 0s 123ms/step - loss: 0.8625 - MSE: 0.8618 - val_loss: 1.4334 - val_MSE: 1.4327\n",
      "Epoch 49/2000\n",
      "4/4 [==============================] - 0s 121ms/step - loss: 0.8623 - MSE: 0.8617 - val_loss: 1.4367 - val_MSE: 1.4361\n",
      "Epoch 50/2000\n",
      "4/4 [==============================] - 0s 120ms/step - loss: 0.8627 - MSE: 0.8620 - val_loss: 1.4343 - val_MSE: 1.4337\n",
      "Epoch 51/2000\n",
      "4/4 [==============================] - 0s 123ms/step - loss: 0.8625 - MSE: 0.8619 - val_loss: 1.4610 - val_MSE: 1.4603\n",
      "Epoch 52/2000\n",
      "4/4 [==============================] - 0s 121ms/step - loss: 0.8623 - MSE: 0.8615 - val_loss: 1.4330 - val_MSE: 1.4322\n",
      "Epoch 53/2000\n",
      "4/4 [==============================] - 0s 122ms/step - loss: 0.8626 - MSE: 0.8618 - val_loss: 1.4583 - val_MSE: 1.4575\n",
      "Epoch 54/2000\n",
      "4/4 [==============================] - 0s 124ms/step - loss: 0.8627 - MSE: 0.8619 - val_loss: 1.4394 - val_MSE: 1.4385\n",
      "Epoch 55/2000\n",
      "4/4 [==============================] - 0s 124ms/step - loss: 0.8631 - MSE: 0.8622 - val_loss: 1.4641 - val_MSE: 1.4632\n",
      "Epoch 56/2000\n",
      "4/4 [==============================] - 0s 122ms/step - loss: 0.8633 - MSE: 0.8624 - val_loss: 1.4323 - val_MSE: 1.4314\n",
      "Epoch 57/2000\n",
      "4/4 [==============================] - 0s 125ms/step - loss: 0.8624 - MSE: 0.8616 - val_loss: 1.4525 - val_MSE: 1.4517\n",
      "Epoch 58/2000\n",
      "4/4 [==============================] - 0s 123ms/step - loss: 0.8630 - MSE: 0.8622 - val_loss: 1.4345 - val_MSE: 1.4336\n",
      "Epoch 59/2000\n",
      "4/4 [==============================] - 0s 123ms/step - loss: 0.8629 - MSE: 0.8621 - val_loss: 1.4345 - val_MSE: 1.4337\n",
      "Epoch 60/2000\n",
      "4/4 [==============================] - 0s 124ms/step - loss: 0.8626 - MSE: 0.8618 - val_loss: 1.4314 - val_MSE: 1.4306\n",
      "Epoch 61/2000\n",
      "4/4 [==============================] - 0s 122ms/step - loss: 0.8624 - MSE: 0.8617 - val_loss: 1.4517 - val_MSE: 1.4510\n",
      "Epoch 62/2000\n",
      "4/4 [==============================] - 0s 121ms/step - loss: 0.8630 - MSE: 0.8623 - val_loss: 1.4393 - val_MSE: 1.4387\n",
      "Epoch 63/2000\n",
      "4/4 [==============================] - 0s 121ms/step - loss: 0.8646 - MSE: 0.8640 - val_loss: 1.5113 - val_MSE: 1.5106\n",
      "Epoch 64/2000\n",
      "4/4 [==============================] - 0s 121ms/step - loss: 0.8687 - MSE: 0.8675 - val_loss: 1.4561 - val_MSE: 1.4538\n",
      "Epoch 65/2000\n",
      "4/4 [==============================] - 0s 122ms/step - loss: 0.8749 - MSE: 0.8719 - val_loss: 1.4506 - val_MSE: 1.4462\n",
      "Epoch 66/2000\n",
      "4/4 [==============================] - 0s 122ms/step - loss: 0.8764 - MSE: 0.8712 - val_loss: 1.4603 - val_MSE: 1.4540\n",
      "Epoch 67/2000\n",
      "4/4 [==============================] - 0s 122ms/step - loss: 0.8775 - MSE: 0.8708 - val_loss: 1.4604 - val_MSE: 1.4533\n",
      "Epoch 68/2000\n",
      "4/4 [==============================] - 0s 125ms/step - loss: 0.8785 - MSE: 0.8714 - val_loss: 1.4552 - val_MSE: 1.4482\n",
      "Epoch 69/2000\n",
      "4/4 [==============================] - 0s 122ms/step - loss: 0.8780 - MSE: 0.8711 - val_loss: 1.4530 - val_MSE: 1.4467\n",
      "Epoch 70/2000\n",
      "4/4 [==============================] - 0s 122ms/step - loss: 0.8770 - MSE: 0.8710 - val_loss: 1.4526 - val_MSE: 1.4472\n",
      "Epoch 71/2000\n",
      "4/4 [==============================] - 0s 120ms/step - loss: 0.8756 - MSE: 0.8705 - val_loss: 1.4523 - val_MSE: 1.4478\n",
      "Epoch 72/2000\n",
      "4/4 [==============================] - 0s 122ms/step - loss: 0.8744 - MSE: 0.8702 - val_loss: 1.4591 - val_MSE: 1.4555\n",
      "Epoch 73/2000\n",
      "4/4 [==============================] - 0s 121ms/step - loss: 0.8752 - MSE: 0.8718 - val_loss: 1.4501 - val_MSE: 1.4472\n",
      "Epoch 74/2000\n",
      "4/4 [==============================] - 0s 120ms/step - loss: 0.8739 - MSE: 0.8711 - val_loss: 1.4494 - val_MSE: 1.4468\n",
      "Epoch 75/2000\n",
      "4/4 [==============================] - 0s 122ms/step - loss: 0.8733 - MSE: 0.8709 - val_loss: 1.4513 - val_MSE: 1.4491\n",
      "Epoch 76/2000\n",
      "4/4 [==============================] - 0s 123ms/step - loss: 0.8731 - MSE: 0.8710 - val_loss: 1.4536 - val_MSE: 1.4517\n",
      "Epoch 77/2000\n",
      "4/4 [==============================] - 0s 122ms/step - loss: 0.8715 - MSE: 0.8697 - val_loss: 1.4578 - val_MSE: 1.4560\n",
      "Epoch 78/2000\n",
      "4/4 [==============================] - 0s 122ms/step - loss: 0.8740 - MSE: 0.8722 - val_loss: 1.4507 - val_MSE: 1.4489\n",
      "Epoch 79/2000\n",
      "4/4 [==============================] - 0s 122ms/step - loss: 0.8727 - MSE: 0.8708 - val_loss: 1.4506 - val_MSE: 1.4486\n",
      "Epoch 80/2000\n",
      "4/4 [==============================] - 0s 123ms/step - loss: 0.8731 - MSE: 0.8710 - val_loss: 1.4492 - val_MSE: 1.4472\n",
      "Epoch 81/2000\n",
      "4/4 [==============================] - 0s 123ms/step - loss: 0.8730 - MSE: 0.8709 - val_loss: 1.4497 - val_MSE: 1.4477\n",
      "Epoch 82/2000\n",
      "4/4 [==============================] - 0s 123ms/step - loss: 0.8728 - MSE: 0.8709 - val_loss: 1.4486 - val_MSE: 1.4468\n",
      "Epoch 83/2000\n",
      "4/4 [==============================] - 0s 122ms/step - loss: 0.8720 - MSE: 0.8703 - val_loss: 1.4482 - val_MSE: 1.4465\n",
      "Epoch 84/2000\n",
      "4/4 [==============================] - 0s 122ms/step - loss: 0.8698 - MSE: 0.8682 - val_loss: 1.4862 - val_MSE: 1.4846\n",
      "Epoch 85/2000\n",
      "4/4 [==============================] - 0s 121ms/step - loss: 0.8665 - MSE: 0.8647 - val_loss: 1.4785 - val_MSE: 1.4766\n",
      "Epoch 86/2000\n",
      "4/4 [==============================] - 0s 120ms/step - loss: 0.8655 - MSE: 0.8637 - val_loss: 1.4460 - val_MSE: 1.4441\n",
      "Epoch 87/2000\n",
      "4/4 [==============================] - 0s 122ms/step - loss: 0.8655 - MSE: 0.8636 - val_loss: 1.4900 - val_MSE: 1.4879\n",
      "Epoch 88/2000\n",
      "4/4 [==============================] - 0s 122ms/step - loss: 0.8657 - MSE: 0.8636 - val_loss: 1.4398 - val_MSE: 1.4375\n",
      "Epoch 89/2000\n",
      "4/4 [==============================] - 0s 125ms/step - loss: 0.8654 - MSE: 0.8631 - val_loss: 1.4376 - val_MSE: 1.4353\n",
      "Epoch 90/2000\n",
      "4/4 [==============================] - 0s 123ms/step - loss: 0.8653 - MSE: 0.8630 - val_loss: 1.4746 - val_MSE: 1.4723\n",
      "Epoch 91/2000\n",
      "4/4 [==============================] - 0s 123ms/step - loss: 0.8656 - MSE: 0.8634 - val_loss: 1.4486 - val_MSE: 1.4464\n",
      "Epoch 92/2000\n",
      "4/4 [==============================] - 0s 122ms/step - loss: 0.8649 - MSE: 0.8627 - val_loss: 1.4483 - val_MSE: 1.4463\n",
      "Epoch 93/2000\n",
      "4/4 [==============================] - 0s 122ms/step - loss: 0.8645 - MSE: 0.8626 - val_loss: 1.4495 - val_MSE: 1.4477\n",
      "Epoch 94/2000\n",
      "4/4 [==============================] - 0s 122ms/step - loss: 0.8643 - MSE: 0.8626 - val_loss: 1.4387 - val_MSE: 1.4371\n",
      "Epoch 95/2000\n",
      "4/4 [==============================] - 0s 122ms/step - loss: 0.8743 - MSE: 0.8728 - val_loss: 1.4490 - val_MSE: 1.4475\n",
      "Epoch 96/2000\n",
      "4/4 [==============================] - 0s 120ms/step - loss: 0.8726 - MSE: 0.8711 - val_loss: 1.4498 - val_MSE: 1.4480\n",
      "Epoch 97/2000\n",
      "4/4 [==============================] - 0s 120ms/step - loss: 0.8711 - MSE: 0.8692 - val_loss: 1.4491 - val_MSE: 1.4471\n",
      "Epoch 98/2000\n",
      "4/4 [==============================] - 0s 119ms/step - loss: 0.8684 - MSE: 0.8664 - val_loss: 1.4526 - val_MSE: 1.4505\n",
      "Epoch 99/2000\n",
      "4/4 [==============================] - 0s 121ms/step - loss: 0.8674 - MSE: 0.8653 - val_loss: 1.5125 - val_MSE: 1.5104\n",
      "Epoch 100/2000\n",
      "4/4 [==============================] - 0s 122ms/step - loss: 0.8762 - MSE: 0.8741 - val_loss: 1.4475 - val_MSE: 1.4453\n",
      "Epoch 101/2000\n",
      "4/4 [==============================] - 0s 119ms/step - loss: 0.8732 - MSE: 0.8709 - val_loss: 1.4493 - val_MSE: 1.4469\n",
      "Epoch 102/2000\n",
      "4/4 [==============================] - 0s 124ms/step - loss: 0.8737 - MSE: 0.8712 - val_loss: 1.4497 - val_MSE: 1.4472\n",
      "Epoch 103/2000\n",
      "4/4 [==============================] - 0s 120ms/step - loss: 0.8736 - MSE: 0.8711 - val_loss: 1.4498 - val_MSE: 1.4474\n",
      "Epoch 104/2000\n",
      "4/4 [==============================] - 0s 122ms/step - loss: 0.8735 - MSE: 0.8711 - val_loss: 1.4496 - val_MSE: 1.4474\n",
      "Epoch 105/2000\n",
      "4/4 [==============================] - 0s 129ms/step - loss: 0.8727 - MSE: 0.8706 - val_loss: 1.4467 - val_MSE: 1.4448\n",
      "Epoch 106/2000\n",
      "4/4 [==============================] - 0s 124ms/step - loss: 0.8733 - MSE: 0.8715 - val_loss: 1.4454 - val_MSE: 1.4438\n",
      "Epoch 107/2000\n",
      "4/4 [==============================] - 0s 121ms/step - loss: 0.8709 - MSE: 0.8694 - val_loss: 1.4470 - val_MSE: 1.4456\n",
      "Epoch 108/2000\n",
      "4/4 [==============================] - 0s 120ms/step - loss: 0.8726 - MSE: 0.8713 - val_loss: 1.4445 - val_MSE: 1.4431\n",
      "Epoch 109/2000\n",
      "4/4 [==============================] - 0s 122ms/step - loss: 0.8720 - MSE: 0.8706 - val_loss: 1.4473 - val_MSE: 1.4460\n",
      "Epoch 110/2000\n",
      "4/4 [==============================] - 0s 124ms/step - loss: 0.8719 - MSE: 0.8705 - val_loss: 1.4488 - val_MSE: 1.4473\n",
      "Cross-validation MSE: 1.0109 (+/- 0.2474)\n"
     ]
    }
   ],
   "source": [
    "# 增加 callbacks\n",
    "early_stopping = keras.callbacks.EarlyStopping(monitor='val_loss', patience=50, restore_best_weights=True)\n",
    "\n",
    "# 進行交叉驗證\n",
    "scores = []\n",
    "for train_index, test_index in fold.split(data):\n",
    "    # 將數據分為訓練集和測試集\n",
    "    X_train, X_test = data_no_na[train_index], data_no_na[test_index]\n",
    "\n",
    "    # 標準化\n",
    "    scaler = StandardScaler()\n",
    "    train_data_scaled = scaler.fit_transform(X_train)\n",
    "    test_data_scaled = scaler.transform(X_test)\n",
    "\n",
    "    # 訓練自動編碼器\n",
    "    autoencoder.compile(loss='mse', optimizer=optimizer, metrics=['MSE'])\n",
    "    autoencoder.fit(train_data_scaled, train_data_scaled,\n",
    "                    epochs=2000, batch_size=64,\n",
    "                    validation_data=(test_data_scaled, test_data_scaled),\n",
    "                    callbacks=[early_stopping])\n",
    "\n",
    "    # 評估模型\n",
    "    score = autoencoder.evaluate(test_data_scaled, test_data_scaled, verbose=0)\n",
    "    scores.append(score)\n",
    "\n",
    "# 輸出交叉驗證結果\n",
    "print(\"Cross-validation MSE: %.4f (+/- %.4f)\" % (np.mean(scores), np.std(scores)))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-11T12:50:36.998266Z",
     "end_time": "2023-05-11T12:58:36.949640Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-05-11T12:58:36.950637Z",
     "end_time": "2023-05-11T12:58:36.953627Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": "[[0.9799818992614746, 0.9774671792984009],\n [1.0028879642486572, 1.0020718574523926],\n [0.6535766124725342, 0.652717113494873],\n [0.9896494150161743, 0.9888978600502014],\n [1.4313597679138184, 1.430630087852478]]"
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "import datetime\n",
    "\n",
    "# 獲取當前日期和時間\n",
    "now = datetime.datetime.now()\n",
    "\n",
    "# 格式化日期和時間，並作為模型名稱\n",
    "model_name = f\"Arrhythmia_AutoEncoder_{now.strftime('%Y-%m-%d_%H-%M-%S')}\"\n",
    "\n",
    "# 儲存模型\n",
    "autoencoder.save(f\"{model_name}.h5\")"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
