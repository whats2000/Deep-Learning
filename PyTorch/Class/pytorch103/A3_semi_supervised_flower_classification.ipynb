{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MIS 583 Assignment 3: Semi-supervised Flower Classfication"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we start, please put your name and SID in following format: <br>\n",
    ": LASTNAME Firstname, ?00000000   //   e.g.) 李晨愷 M114020035"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Your Answer:**    \n",
    "Hi I'm 鄔仁迪, B104020009."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Semi-supervised Flower Classfication\n",
    "\n",
    "In this approach, you have a dataset that includes both labeled and unlabeled examples.\n",
    "\n",
    "The goal is to use the labeled data to train the model while also leveraging the unlabeled\n",
    "data to improve the model's performance.\n",
    "\n",
    "In this assignment, you’ll explore a self-training mechanism for this task.\n",
    "\n",
    "\n",
    "**Please note that you’re not allowed to use pre-constructed models or pre-trained weights.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kaggle Competition\n",
    "Kaggle is an online community of data scientists and machine learning practitioners. Kaggle allows users to find and publish datasets, explore and build models in a web-based data-science environment, work with other data scientists and machine learning engineers, and enter competitions to solve data science challenges.\n",
    "\n",
    "This assignment use kaggle to calculate your grade.  \n",
    "Please use this [**LINK**](https://www.kaggle.com/t/e304bb12c8a84e5c9c1b27a6c3bd4026) to join the competition.\n",
    "\n",
    "**Again, Use your SID as your team's name!!!**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Google Colab Setup\n",
    "Next we need to run a few commands to set up our environment on Google Colab. If you are running this notebook on a local machine you can skip this section.\n",
    "\n",
    "Run the following cell to mount your Google Drive. Follow the link, sign in to your Google account (the same account you used to store this notebook!) and copy the authorization code into the text box that appears below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Versions of used packages\n",
    "\n",
    "We will check PyTorch version to make sure everything work properly.\n",
    "\n",
    "We use `python==3.10.12`, `torch==2.0.1+cu118` and `torchvision==0.15.2+cu118`. This is the default version in Google Colab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-03T10:51:54.359653800Z",
     "start_time": "2023-11-03T10:51:54.351309600Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python 3.11.2 (tags/v3.11.2:878ead1, Feb  7 2023, 16:38:35) [MSC v.1934 64 bit (AMD64)]\n",
      "torch 2.1.0+cu118\n",
      "torchvision 0.16.0+cu118\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import torch\n",
    "import torchvision\n",
    "from torch.nn import Sequential\n",
    "\n",
    "print('python', sys.version.split('\\n')[0])\n",
    "print('torch', torch.__version__)\n",
    "print('torchvision', torchvision.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use [Flowers Recognition](https://www.kaggle.com/alxmamaev/flowers-recognition) dataset.\n",
    "This is collected by Alexander Mamaev.\n",
    "\n",
    "**Abstrct**  \n",
    "\n",
    "We clean the dataset,this dataset contains 4262 flower images.   \n",
    "**IMPORTANT: you CANNOT use any extra images.**\n",
    "\n",
    "The data collection is grabed from the data flicr, google images, yandex images.\n",
    "You can use this datastet to recognize plants from the photo.\n",
    "\n",
    "The pictures are divided into five classes: \n",
    "+ daisy\n",
    "+ tulip\n",
    "+ rose\n",
    "+ sunflower\n",
    "+ dandelion\n",
    "\n",
    "For each class there are about 800 photos. Photos are not high resolution, about 320x240 pixels. Photos are not reduced to a single size, they have different proportions!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How to Get Data\n",
    "\n",
    "請先到共用雲端硬碟將檔案 `A3_data_flower_2023.zip`，建立捷徑到自己的雲端硬碟中。\n",
    "\n",
    "> 操作步驟\n",
    "1. 點開雲端[連結](https://drive.google.com/file/d/1eme754s_uI5dI5SnNUH2ZuvJ5QT-kmaZ/view?usp=sharing)\n",
    "2. 點選右上角「新增雲端硬碟捷徑」\n",
    "3. 點選「我的雲端硬碟」\n",
    "4. 點選「新增捷徑」\n",
    "\n",
    "完成以上流程會在你的雲端硬碟中建立一個檔案的捷徑，接著我們在colab中取得權限即可使用。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unzip Data\n",
    "\n",
    "Unzip `A3_data_flower_2023.zip`, there are 2 folders and 4 csvs.\n",
    "\n",
    "- `train/`: contains 5 folders for 5 categories of flowers. Images of flowers inside them.\n",
    "- `test/`: unclassified images of testing set.\n",
    "- `train_labeled_dataset.csv`: file path and true label of training set.\n",
    "- `train_unlabeled_dataset.csv`: file path and without label of training set.\n",
    "- `val.csv`: file path and true label of validation set.\n",
    "- `test.csv`: file paht of testing set.\n",
    "\n",
    "There are **843 images in labeled_dataset_train.**  \n",
    "\n",
    "There are **1713 images in unlabeled_dataset_train.** \n",
    "\n",
    "There are **853 images in dataset_test.**  \n",
    "\n",
    "There are **853 images in dataset_val.**  \n",
    "\n",
    "---\n",
    "\n",
    "解壓縮 `A3_data_flower_2023.zip` 後可以發現裡面有兩個資料夾和四個csv檔。\n",
    "\n",
    "+ `train` : 存有五個資料夾分別是五個種類的花，資料夾內為花的照片。\n",
    "+ `test` : 資料夾中為未分類之測試集照片。\n",
    "+ `train_labeled_dataset.csv` : 讀取 train data 的順序、路徑與圖片所屬花別。\n",
    "+ `train_unlabeled_dataset.csv` : 讀取 train data 的順序、路徑與圖片但沒有所屬花別標籤。\n",
    "+ `val.csv` : 讀取 validate data 的順序、路徑與圖片所屬花別。\n",
    "+ `test.csv` : 讀取 test data 的順序、路徑。\n",
    "\n",
    "其中`train_labeled`的圖片 843 張，`train_unlabeled`的圖片 1713 張，`val` 的圖片 853 張，`test` 的圖片 853 張。\n",
    "\n",
    "注意: 若有另外設定存放在雲端硬碟中的路徑，請記得本處路徑也須做更動。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-03T10:51:58.111969600Z",
     "start_time": "2023-11-03T10:51:58.075959200Z"
    }
   },
   "outputs": [],
   "source": [
    "# !unzip -qq ./drive/MyDrive/A3_data_flower_2023.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-03T10:51:59.016501900Z",
     "start_time": "2023-11-03T10:51:59.008988900Z"
    }
   },
   "outputs": [],
   "source": [
    "data_folder = 'A3_data_flower_2023'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Custom dataset\n",
    "\n",
    "Build a classs inherit `torch.utils.data.Dataset`.  \n",
    "Implement `__init__`, `__getitem__` and `__len__` 3 functions.  \n",
    "\n",
    "Some operations could be there: setting location of dataset, the method of reading data, label of dataset or transform of dataset.\n",
    "\n",
    "See [torch.utils.data.Dataset](https://pytorch.org/docs/stable/data.html#torch.utils.data.Dataset) for more details\n",
    "\n",
    "---\n",
    "\n",
    "繼承自定義資料集的框架 `torch.utils.data.Dataset`，主要實現 `__getitem__()` 和 `__len__()` 這兩個方法。\n",
    "\n",
    "常使用來做到設定資料位址、設定讀取方式、子資料集的標籤和轉換條件...等。\n",
    "\n",
    "See [torch.utils.data.Dataset](https://pytorch.org/docs/stable/data.html#torch.utils.data.Dataset) for more details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-03T10:52:01.195632400Z",
     "start_time": "2023-11-03T10:52:01.040621900Z"
    }
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import torch\n",
    "\n",
    "class FlowerData(torch.utils.data.Dataset):\n",
    "    def __init__(self, csv_file, mode='train', transform=None):\n",
    "        self.mode = mode # 'train', 'unlabeled_train', 'val' or 'test'\n",
    "        self.data_list = []\n",
    "        self.labels = []\n",
    "        self.transform = transform\n",
    "        \n",
    "        with open(f'{data_folder}/{csv_file}', newline='') as csvfile:\n",
    "            reader = csv.DictReader(csvfile)\n",
    "            for row in reader:\n",
    "                self.data_list.append(f\"{data_folder}/{row['file_path']}\")\n",
    "                if mode != 'test' and mode != 'unlabeled_train':\n",
    "                    self.labels.append(row['label'])\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        data = Image.open(self.data_list[index])\n",
    "        if self.transform is not None:\n",
    "            data = self.transform(data)\n",
    "        if self.mode == 'test':\n",
    "            return data\n",
    "        if self.mode == 'unlabeled_train':\n",
    "            return self.data_list[index]\n",
    "        label = int(self.labels[index])\n",
    "\n",
    "        return data, label\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data augmentation \n",
    "\n",
    "Data augmentation are techniques used to increase the amount of data by adding slightly modified copies of already existing data or newly created synthetic data from existing data.\n",
    "\n",
    "PyTorch use `torchvision.transforms` to do data augmentation.\n",
    "[You can see all function here.](https://pytorch.org/vision/stable/transforms.html)\n",
    "\n",
    "**NOTICE**: There are some operations may not be necessary for predict, so we should write one for train and one for others."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "from torchvision import transforms\n",
    "\n",
    "# Define transforms_train with the necessary transformations.\n",
    "transforms_train = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),  # Resize the image to 224x224 for consistency.\n",
    "    transforms.ToTensor()  # Convert the image to a PyTorch tensor.\n",
    "])\n",
    "\n",
    "def calculate_mean_std(dataset):\n",
    "    loader = torch.utils.data.DataLoader(dataset, batch_size=10, shuffle=False, num_workers=0, pin_memory=True)\n",
    "\n",
    "    mean = 0.\n",
    "    std = 0.\n",
    "    nb_samples = 0.\n",
    "    for data, _ in loader:\n",
    "        batch_samples = data.size(0)\n",
    "        data = data.view(batch_samples, data.size(1), -1)\n",
    "        mean += data.mean(2).sum(0)\n",
    "        std += data.std(2).sum(0)\n",
    "        nb_samples += batch_samples\n",
    "\n",
    "    mean /= nb_samples\n",
    "    std /= nb_samples\n",
    "    return mean, std\n",
    "\n",
    "# Train set\n",
    "train_set = FlowerData('train_labeled_dataset.csv', mode='train', transform=transforms_train)\n",
    "\n",
    "# Calculate the mean and standard deviation\n",
    "train_mean, train_std = calculate_mean_std(train_set)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-03T10:55:20.421253500Z",
     "start_time": "2023-11-03T10:55:10.748692Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "data": {
      "text/plain": "(tensor([0.4603, 0.4217, 0.2971]), tensor([0.2422, 0.2153, 0.2188]))"
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_mean, train_std"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-03T10:55:22.600811100Z",
     "start_time": "2023-11-03T10:55:22.579396900Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-01T09:09:55.913103200Z",
     "start_time": "2023-11-01T09:09:55.858149600Z"
    }
   },
   "outputs": [],
   "source": [
    "from torchvision.transforms import AutoAugmentPolicy, AutoAugment\n",
    "from torchvision import transforms\n",
    "# For TRAIN\n",
    "########################################################################\n",
    "#  TODO: use transforms.xxx method to do some data augmentation        #\n",
    "#  This one is for training, find the composition to get better result #\n",
    "########################################################################\n",
    "# These calculate from data eval\n",
    "transforms_train = transforms.Compose([\n",
    "    transforms.RandomResizedCrop(224),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomVerticalFlip(),\n",
    "    transforms.RandomRotation(30),\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=train_mean, std=train_std)\n",
    "])\n",
    "############################################################\n",
    "#                           End of your code                           #\n",
    "########################################################################\n",
    "\n",
    "# For VAL, TEST\n",
    "########################################################################\n",
    "#  TODO: use transforms.xxx method to do some data augmentation        #\n",
    "#  This one is for validate and test,                                  #\n",
    "#  NOTICE some operation we usually not use in this part               #\n",
    "########################################################################\n",
    "transforms_test = transforms.Compose([\n",
    "    transforms.Resize(256),                               # Resize to a fixed size\n",
    "    transforms.CenterCrop(224),                           # Center crop\n",
    "    transforms.ToTensor(),                                # Convert to tensor\n",
    "    transforms.Normalize(mean=train_mean, std=train_std)  # Normalize\n",
    "])\n",
    "########################################################################\n",
    "#                           End of your code                           #\n",
    "########################################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instantiate dataset\n",
    "\n",
    "Let's instantiate three `FlowerData` class.\n",
    "+ train_set: for labeled_training.\n",
    "+ unlabeled_set: for unlabeled_training.\n",
    "+ dataset_val: for validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-01T09:09:55.913103200Z",
     "start_time": "2023-11-01T09:09:55.864490800Z"
    }
   },
   "outputs": [],
   "source": [
    "train_set = FlowerData('train_labeled_dataset.csv', mode='train', transform=transforms_train)\n",
    "unlabeled_set = FlowerData('train_unlabeled_dataset.csv', mode='test', transform=transforms_train)\n",
    "valid_set = FlowerData('val.csv', mode='val', transform=transforms_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-01T09:09:55.922029200Z",
     "start_time": "2023-11-01T09:09:55.882113200Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The first image's shape in dataset_train : torch.Size([3, 224, 224])\n",
      "There are 843 images in labeled_dataset_train.\n",
      "There are 1713 images in unlabeled_dataset_train.\n",
      "There are 853 images in dataset_val.\n"
     ]
    }
   ],
   "source": [
    "print(\"The first image's shape in dataset_train :\", train_set[0][0].size())\n",
    "print(\"There are\", len(train_set), \"images in labeled_dataset_train.\")\n",
    "print(\"There are\", len(unlabeled_set), \"images in unlabeled_dataset_train.\")\n",
    "print(\"There are\", len(valid_set), \"images in dataset_val.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `DataLoader`\n",
    "\n",
    "`torch.utils.data.DataLoader` define how to sample from `dataset` and some other function like:\n",
    "+ `shuffle` : set to `True` to have the data reshuffled at every epoch\n",
    "+ `batch_size` : how many samples per batch to load\n",
    "\n",
    "See [torch.utils.data.DataLoader](https://pytorch.org/docs/stable/data.html#torch.utils.data.DataLoader) for more details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-01T09:09:55.927251500Z",
     "start_time": "2023-11-01T09:09:55.923033900Z"
    }
   },
   "outputs": [],
   "source": [
    "#####################################################\n",
    "#            You can adjust batch_size              #\n",
    "#####################################################\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "batch_size = 32\n",
    "num_workers = 0\n",
    "train_loader = DataLoader(train_set, batch_size=batch_size, num_workers=num_workers, shuffle=True)\n",
    "valid_loader = DataLoader(valid_set, batch_size=batch_size, num_workers=num_workers, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally! We have made all data prepared.  \n",
    "Let's go develop our model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Self-training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Supervised training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implement CNN using PyTorch \n",
    "\n",
    "Try to use labeled data design and train a deep convolutional network from scratch to predict the class label of a flower image. \n",
    "\n",
    "**Again, the goal of this assignment is for you to test different convolutional structures. You cannot directly use the blocks/architectures of pre-trained models.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "from torch.nn.modules.conv import Conv2d\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class YourCNNModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        ########################################################################\n",
    "        #     TODO: use nn.xxx method to generate a CNN model part             #\n",
    "        ########################################################################\n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv2d(3, 32, kernel_size=7, stride=2, padding=3),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.SELU()\n",
    "        )\n",
    "\n",
    "        # Inverted Bottleneck Convolution Blocks\n",
    "        self.blocks = nn.Sequential(\n",
    "            # in, out, k, p, s, layer, expansion, use_se = True, ues_residual = True, use_shortcut = True\n",
    "            self.inverted_bottleneck_conv_block(32, 16, 3, 1, 1, 1, 1, True, True, False),  # Block 1\n",
    "            self.inverted_bottleneck_conv_block(16, 24, 3, 1, 2, 1, 6, True, True, False),  # Block 2\n",
    "            self.inverted_bottleneck_conv_block(24, 24, 3, 1, 1, 1, 6, True, True, False),  # Repeated Block 2\n",
    "            self.inverted_bottleneck_conv_block(24, 40, 5, 2, 2, 1, 6, True, True, False),  # Block 3\n",
    "            self.inverted_bottleneck_conv_block(40, 40, 5, 2, 1, 1, 6, True, True, False),  # Repeated Block 3\n",
    "            self.inverted_bottleneck_conv_block(40, 80, 3, 1, 2, 1, 6, True, True, False),  # Block 4\n",
    "            self.inverted_bottleneck_conv_block(80, 80, 3, 1, 1, 1, 6, True, True, False),  # Repeated Block 4 (x2)\n",
    "            self.inverted_bottleneck_conv_block(80, 80, 3, 1, 1, 1, 6, True, True, False),  # Repeated Block 4\n",
    "        )\n",
    "\n",
    "        # Final Convolution\n",
    "        self.conv_last = nn.Sequential(\n",
    "            nn.Conv2d(80, 1280, kernel_size=1, stride=1),\n",
    "            nn.BatchNorm2d(1280),\n",
    "            nn.SELU()\n",
    "        )\n",
    "\n",
    "        # Fully connected layers\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(1280, 512),\n",
    "            nn.SELU(),\n",
    "            nn.BatchNorm1d(512),\n",
    "        )\n",
    "        self.out = nn.Linear(512, 5)\n",
    "\n",
    "    def inverted_bottleneck_conv_block(self,\n",
    "                     in_channels: int,\n",
    "                     out_channels: int,\n",
    "                     kernel_size: int,\n",
    "                     padding: int,\n",
    "                     stride: int,\n",
    "                     num_layers: int,\n",
    "                     expansion: int = 6,\n",
    "                     use_se: bool = True,\n",
    "                     use_residual: bool = True,\n",
    "                     use_shortcut: bool = True):\n",
    "        \"\"\"\n",
    "        Create an Inverted Bottleneck Convolution (IBConv) block with optional Squeeze-and-Excitation (SE) block and residual connections.\n",
    "\n",
    "        Parameters:\n",
    "            in_channels (int): Number of input channels.\n",
    "            out_channels (int): Number of output channels.\n",
    "            kernel_size (int): Size of the convolutional kernel.\n",
    "            padding (int): Padding for the convolutional layer.\n",
    "            stride (int): Stride for the convolutional layer.\n",
    "            num_layers (int): Number of depth-wise separable layers.\n",
    "            expansion (int, optional): Expansion factor for the hidden dimension. Default is 6.\n",
    "            use_se (bool, optional): Whether to include the SE block. Default is True.\n",
    "            use_residual (bool, optional): Whether to include the residual connection when in_channels == out_channels. Default is True.\n",
    "            use_shortcut (bool, optional): Whether to include the shortcut connection when in_channels != out_channels. Default is False.\n",
    "\n",
    "        Returns:\n",
    "            nn.Module: A PyTorch module containing the layers forming the IBConv block.\n",
    "        \"\"\"\n",
    "        class IBConvWithSE(nn.Module):\n",
    "            def __init__(self):\n",
    "                class Swish(nn.Module):\n",
    "                    def forward(self, x):\n",
    "                        return x * torch.sigmoid(x)\n",
    "\n",
    "                super(IBConvWithSE, self).__init__()\n",
    "\n",
    "                # Initial Convolution\n",
    "                self.initial_conv = nn.Sequential(\n",
    "                    nn.Conv2d(in_channels, in_channels * expansion, kernel_size=1, stride=1, padding=0, bias=False),\n",
    "                    nn.BatchNorm2d(in_channels * expansion),\n",
    "                    nn.SELU()\n",
    "                )\n",
    "\n",
    "                # Short-cut point-wise convolution\n",
    "                if use_shortcut:\n",
    "                    self.shortcut = nn.Sequential(\n",
    "                        nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=stride, padding=0, bias=False),\n",
    "                        nn.BatchNorm2d(out_channels)\n",
    "                    )\n",
    "\n",
    "                # Depth-wise separable convolutions with multiple layers\n",
    "                self.depthwise_layers = nn.ModuleList()\n",
    "                for _ in range(num_layers):\n",
    "                    self.depthwise_layers.append(nn.Sequential(\n",
    "                        nn.Conv2d(in_channels * expansion, in_channels * expansion, kernel_size=kernel_size, stride=stride, padding=padding, groups=in_channels * expansion, bias=False),\n",
    "                        nn.BatchNorm2d(in_channels * expansion),\n",
    "                        nn.SELU()\n",
    "                    ))\n",
    "\n",
    "                # SE block\n",
    "                self.se_block = nn.Sequential(\n",
    "                    nn.AdaptiveAvgPool2d(1),\n",
    "                    nn.Conv2d(in_channels * expansion, in_channels * expansion // 16, kernel_size=1),\n",
    "                    Swish(),\n",
    "                    nn.Conv2d(in_channels * expansion // 16, in_channels * expansion, kernel_size=1),\n",
    "                    nn.Sigmoid()\n",
    "                )\n",
    "\n",
    "                # Point-wise convolution\n",
    "                self.pointwise_conv = nn.Sequential(\n",
    "                    nn.Conv2d(in_channels * expansion, out_channels, kernel_size=1, stride=1, padding=0, bias=False),\n",
    "                    nn.BatchNorm2d(out_channels),\n",
    "                    nn.SELU()\n",
    "                )\n",
    "\n",
    "                # Dropout layer\n",
    "                self.dropout = nn.Dropout(0.2)\n",
    "\n",
    "            def forward(self, x):\n",
    "                # Store x for residual\n",
    "                identity = x\n",
    "\n",
    "                x = self.initial_conv(x)\n",
    "                for layer in self.depthwise_layers:\n",
    "                    x = layer(x)\n",
    "\n",
    "                if use_se:\n",
    "                    se = self.se_block(x)\n",
    "                    x = x * se\n",
    "\n",
    "                x = self.pointwise_conv(x)\n",
    "\n",
    "                # Add residual connection if in_channels == out_channels\n",
    "                if in_channels == out_channels and use_residual:\n",
    "                    x += identity  # Element-wise addition\n",
    "                    x = self.dropout(x)  # Apply dropout\n",
    "\n",
    "                # Add shortcut connection if in_channels != out_channels\n",
    "                if in_channels != out_channels and use_shortcut:\n",
    "                    x += self.shortcut(identity)\n",
    "\n",
    "                return x\n",
    "\n",
    "        return IBConvWithSE()\n",
    "        ########################################################################\n",
    "        #                           End of your code                           #\n",
    "        ########################################################################\n",
    "\n",
    "    def forward(self, x):\n",
    "        if not isinstance(x, torch.Tensor):\n",
    "          x = torch.Tensor(x)\n",
    "        ########################################################################\n",
    "        #     TODO: forward your model and get output                          #\n",
    "        ########################################################################\n",
    "        # Forward pass through convolutional layers\n",
    "        x = self.conv1(x)\n",
    "        x = self.blocks(x)\n",
    "        x = self.conv_last(x)\n",
    "        x = nn.AdaptiveAvgPool2d((1, 1))(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc(x)\n",
    "        out = self.out(x)\n",
    "        ########################################################################\n",
    "        #                           End of your code                           #\n",
    "        ########################################################################\n",
    "        return out"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-01T09:09:56.008695600Z",
     "start_time": "2023-11-01T09:09:55.927251500Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "device = torch.device('cuda')\n",
    "# or\n",
    "# device = torch.device('cpu')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-01T09:09:56.022688700Z",
     "start_time": "2023-11-01T09:09:55.949198700Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-01T09:09:57.414177Z",
     "start_time": "2023-11-01T09:09:55.963689800Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "YourCNNModel(\n  (conv1): Sequential(\n    (0): Conv2d(3, 32, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3))\n    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (2): SELU()\n  )\n  (blocks): Sequential(\n    (0): IBConvWithSE(\n      (initial_conv): Sequential(\n        (0): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (2): SELU()\n      )\n      (depthwise_layers): ModuleList(\n        (0): Sequential(\n          (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n          (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (2): SELU()\n        )\n      )\n      (se_block): Sequential(\n        (0): AdaptiveAvgPool2d(output_size=1)\n        (1): Conv2d(32, 2, kernel_size=(1, 1), stride=(1, 1))\n        (2): Swish()\n        (3): Conv2d(2, 32, kernel_size=(1, 1), stride=(1, 1))\n        (4): Sigmoid()\n      )\n      (pointwise_conv): Sequential(\n        (0): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (2): SELU()\n      )\n      (dropout): Dropout(p=0.2, inplace=False)\n    )\n    (1): IBConvWithSE(\n      (initial_conv): Sequential(\n        (0): Conv2d(16, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (2): SELU()\n      )\n      (depthwise_layers): ModuleList(\n        (0): Sequential(\n          (0): Conv2d(96, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=96, bias=False)\n          (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (2): SELU()\n        )\n      )\n      (se_block): Sequential(\n        (0): AdaptiveAvgPool2d(output_size=1)\n        (1): Conv2d(96, 6, kernel_size=(1, 1), stride=(1, 1))\n        (2): Swish()\n        (3): Conv2d(6, 96, kernel_size=(1, 1), stride=(1, 1))\n        (4): Sigmoid()\n      )\n      (pointwise_conv): Sequential(\n        (0): Conv2d(96, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (2): SELU()\n      )\n      (dropout): Dropout(p=0.2, inplace=False)\n    )\n    (2): IBConvWithSE(\n      (initial_conv): Sequential(\n        (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (2): SELU()\n      )\n      (depthwise_layers): ModuleList(\n        (0): Sequential(\n          (0): Conv2d(144, 144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=144, bias=False)\n          (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (2): SELU()\n        )\n      )\n      (se_block): Sequential(\n        (0): AdaptiveAvgPool2d(output_size=1)\n        (1): Conv2d(144, 9, kernel_size=(1, 1), stride=(1, 1))\n        (2): Swish()\n        (3): Conv2d(9, 144, kernel_size=(1, 1), stride=(1, 1))\n        (4): Sigmoid()\n      )\n      (pointwise_conv): Sequential(\n        (0): Conv2d(144, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (2): SELU()\n      )\n      (dropout): Dropout(p=0.2, inplace=False)\n    )\n    (3): IBConvWithSE(\n      (initial_conv): Sequential(\n        (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (2): SELU()\n      )\n      (depthwise_layers): ModuleList(\n        (0): Sequential(\n          (0): Conv2d(144, 144, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=144, bias=False)\n          (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (2): SELU()\n        )\n      )\n      (se_block): Sequential(\n        (0): AdaptiveAvgPool2d(output_size=1)\n        (1): Conv2d(144, 9, kernel_size=(1, 1), stride=(1, 1))\n        (2): Swish()\n        (3): Conv2d(9, 144, kernel_size=(1, 1), stride=(1, 1))\n        (4): Sigmoid()\n      )\n      (pointwise_conv): Sequential(\n        (0): Conv2d(144, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (1): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (2): SELU()\n      )\n      (dropout): Dropout(p=0.2, inplace=False)\n    )\n    (4): IBConvWithSE(\n      (initial_conv): Sequential(\n        (0): Conv2d(40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (1): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (2): SELU()\n      )\n      (depthwise_layers): ModuleList(\n        (0): Sequential(\n          (0): Conv2d(240, 240, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=240, bias=False)\n          (1): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (2): SELU()\n        )\n      )\n      (se_block): Sequential(\n        (0): AdaptiveAvgPool2d(output_size=1)\n        (1): Conv2d(240, 15, kernel_size=(1, 1), stride=(1, 1))\n        (2): Swish()\n        (3): Conv2d(15, 240, kernel_size=(1, 1), stride=(1, 1))\n        (4): Sigmoid()\n      )\n      (pointwise_conv): Sequential(\n        (0): Conv2d(240, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (1): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (2): SELU()\n      )\n      (dropout): Dropout(p=0.2, inplace=False)\n    )\n    (5): IBConvWithSE(\n      (initial_conv): Sequential(\n        (0): Conv2d(40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (1): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (2): SELU()\n      )\n      (depthwise_layers): ModuleList(\n        (0): Sequential(\n          (0): Conv2d(240, 240, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=240, bias=False)\n          (1): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (2): SELU()\n        )\n      )\n      (se_block): Sequential(\n        (0): AdaptiveAvgPool2d(output_size=1)\n        (1): Conv2d(240, 15, kernel_size=(1, 1), stride=(1, 1))\n        (2): Swish()\n        (3): Conv2d(15, 240, kernel_size=(1, 1), stride=(1, 1))\n        (4): Sigmoid()\n      )\n      (pointwise_conv): Sequential(\n        (0): Conv2d(240, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (1): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (2): SELU()\n      )\n      (dropout): Dropout(p=0.2, inplace=False)\n    )\n    (6): IBConvWithSE(\n      (initial_conv): Sequential(\n        (0): Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (2): SELU()\n      )\n      (depthwise_layers): ModuleList(\n        (0): Sequential(\n          (0): Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=480, bias=False)\n          (1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (2): SELU()\n        )\n      )\n      (se_block): Sequential(\n        (0): AdaptiveAvgPool2d(output_size=1)\n        (1): Conv2d(480, 30, kernel_size=(1, 1), stride=(1, 1))\n        (2): Swish()\n        (3): Conv2d(30, 480, kernel_size=(1, 1), stride=(1, 1))\n        (4): Sigmoid()\n      )\n      (pointwise_conv): Sequential(\n        (0): Conv2d(480, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (1): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (2): SELU()\n      )\n      (dropout): Dropout(p=0.2, inplace=False)\n    )\n    (7): IBConvWithSE(\n      (initial_conv): Sequential(\n        (0): Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (2): SELU()\n      )\n      (depthwise_layers): ModuleList(\n        (0): Sequential(\n          (0): Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=480, bias=False)\n          (1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (2): SELU()\n        )\n      )\n      (se_block): Sequential(\n        (0): AdaptiveAvgPool2d(output_size=1)\n        (1): Conv2d(480, 30, kernel_size=(1, 1), stride=(1, 1))\n        (2): Swish()\n        (3): Conv2d(30, 480, kernel_size=(1, 1), stride=(1, 1))\n        (4): Sigmoid()\n      )\n      (pointwise_conv): Sequential(\n        (0): Conv2d(480, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (1): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (2): SELU()\n      )\n      (dropout): Dropout(p=0.2, inplace=False)\n    )\n  )\n  (conv_last): Sequential(\n    (0): Conv2d(80, 1280, kernel_size=(1, 1), stride=(1, 1))\n    (1): BatchNorm2d(1280, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (2): SELU()\n  )\n  (fc): Sequential(\n    (0): Linear(in_features=1280, out_features=512, bias=True)\n    (1): SELU()\n    (2): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  )\n  (out): Linear(in_features=512, out_features=5, bias=True)\n)"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = YourCNNModel()\n",
    "model.to(device)\n",
    "#print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have made our model!  \n",
    "Next, PyTorch also provide many utility function(loss, optmizer...etc).  \n",
    "You can define them in one-line."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define loss and optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-01T09:10:12.328079Z",
     "start_time": "2023-11-01T09:10:12.325069600Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "################################################################################\n",
    "# TODO: Define loss and optmizer functions                                     #\n",
    "# Try any loss or optimizer function and learning rate to get better result    #\n",
    "# hint: torch.nn and torch.optim                                               #\n",
    "################################################################################\n",
    "# CrossEntropyLoss for classification tasks\n",
    "class CrossEntropyLossWithTemperature(nn.CrossEntropyLoss):\n",
    "    def __init__(self, temperature=1.0, *args, **kwargs):\n",
    "        super(CrossEntropyLossWithTemperature, self).__init__(*args, **kwargs)\n",
    "        self.temperature = temperature\n",
    "\n",
    "    def forward(self, input, target):\n",
    "        input_temperature = input / self.temperature\n",
    "        return super(CrossEntropyLossWithTemperature, self).forward(input_temperature, target)\n",
    "\n",
    "criterion = CrossEntropyLossWithTemperature(temperature=2)\n",
    "\n",
    "# Adam optimizer\n",
    "learning_rate = 0.003\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate, weight_decay=1e-5)\n",
    "\n",
    "# Reduce learning rate\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', patience=20, factor=0.5)\n",
    "################################################################################\n",
    "#                               End of your code                               #\n",
    "################################################################################\n",
    "criterion = criterion.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train function\n",
    "Let's define train function.  \n",
    "It will iterate input data 1 epoch and update model with optmizer.  \n",
    "Finally, calculate mean loss and total accuracy.\n",
    "\n",
    "Hint: [torch.max()](https://pytorch.org/docs/stable/generated/torch.max.html#torch-max) or [torch.argmax()](https://pytorch.org/docs/stable/generated/torch.argmax.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-01T09:10:15.921589400Z",
     "start_time": "2023-11-01T09:10:15.892035600Z"
    }
   },
   "outputs": [],
   "source": [
    "def train(input_data, model, criterion, optimizer):\n",
    "    '''\n",
    "    Argement:\n",
    "    input_data -- iterable data, typr torch.utils.data.Dataloader is prefer\n",
    "    model -- nn.Module, model contain forward to predict output\n",
    "    criterion -- loss function, used to evaluate goodness of model\n",
    "    optimizer -- optmizer function, method for weight updating\n",
    "    '''\n",
    "    model.train()\n",
    "    loss_list = []\n",
    "    total_count = 0\n",
    "    acc_count = 0\n",
    "    for images, labels in input_data:\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        ########################################################################\n",
    "        # TODO: Forward, backward and optimize                                 #\n",
    "        # 1. zero the parameter gradients                                      #\n",
    "        # 2. process input through the network                                 #\n",
    "        # 3. compute the loss                                                  #\n",
    "        # 4. propagate gradients back into the network’s parameters            #\n",
    "        # 5. Update the weights of the network                                 #\n",
    "        ########################################################################\n",
    "        # Zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward, backward, and optimize\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        ########################################################################\n",
    "        #                           End of your code                           #\n",
    "        ########################################################################\n",
    "\n",
    "\n",
    "        ########################################################################\n",
    "        # TODO: Get the counts of correctly classified images                  #\n",
    "        # 1. get the model predicted result                                    #\n",
    "        # 2. sum the nuIber of this batch predicted images                     #\n",
    "        # 3. sum the nuIber of correctly classified                            #\n",
    "        # 4. save this batch's loss into loss_list                             #\n",
    "        # dimension of outputs: [batch_size, nuIber of classes]                #\n",
    "        # Hint 1: use outputs.data to get no auto_grad                         #\n",
    "        # Hint 2: use torch.max()                                              #\n",
    "        ########################################################################\n",
    "        # Get the counts of correctly classified images\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total_count += labels.size(0)\n",
    "        acc_count += (predicted == labels).sum().item()\n",
    "        loss_list.append(loss.item())\n",
    "        ########################################################################\n",
    "        #                           End of your code                           #\n",
    "        ########################################################################\n",
    "\n",
    "    # Compute this epoch accuracy and loss\n",
    "    acc = acc_count / total_count\n",
    "    loss = sum(loss_list) / len(loss_list)\n",
    "    return acc, loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Validate function\n",
    "Next part is validate function.  \n",
    "It works as training function without optmizer and weight-updating part."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-01T09:10:16.914058800Z",
     "start_time": "2023-11-01T09:10:16.901317Z"
    }
   },
   "outputs": [],
   "source": [
    "def val(input_data, model, criterion):\n",
    "    model.eval()\n",
    "\n",
    "    loss_list = []\n",
    "    total_count = 0\n",
    "    acc_count = 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in input_data:\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            ####################################################################\n",
    "            # TODO: Get the predicted result and loss                          #\n",
    "            # 1. process input through the network                             #\n",
    "            # 2. compute the loss                                              #\n",
    "            # 3. get the model predicted result                                #\n",
    "            # 4. get the counts of correctly classified images                 #\n",
    "            # 5. save this batch's loss into loss_list                         #\n",
    "            ####################################################################\n",
    "            # Get the predicted result and loss\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            # Get the counts of correctly classified images\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total_count += labels.size(0)\n",
    "            acc_count += (predicted == labels).sum().item()\n",
    "            loss_list.append(loss.item())\n",
    "            ####################################################################\n",
    "            #                         End of your code                         #\n",
    "            ####################################################################\n",
    "\n",
    "    acc = acc_count / total_count\n",
    "    loss = sum(loss_list) / len(loss_list)\n",
    "    return acc, loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training in a loop\n",
    "Call train and test function in a loop.  \n",
    "Take a break and wait."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-01T09:52:09.695773600Z",
     "start_time": "2023-11-01T09:10:18.092745200Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================== Epoch 1 ====================\n",
      "Train Acc: 0.274021 Train Loss: 1.785806\n",
      "  Val Acc: 0.311841   Val Loss: 1.526222\n",
      "==================== Epoch 2 ====================\n",
      "Train Acc: 0.355872 Train Loss: 1.463021\n",
      "  Val Acc: 0.354045   Val Loss: 1.503368\n",
      "==================== Epoch 3 ====================\n",
      "Train Acc: 0.354686 Train Loss: 1.420032\n",
      "  Val Acc: 0.391559   Val Loss: 1.384266\n",
      "==================== Epoch 4 ====================\n",
      "Train Acc: 0.399763 Train Loss: 1.369688\n",
      "  Val Acc: 0.459555   Val Loss: 1.288241\n",
      "==================== Epoch 5 ====================\n",
      "Train Acc: 0.402135 Train Loss: 1.361240\n",
      "  Val Acc: 0.427902   Val Loss: 1.263490\n",
      "==================== Epoch 6 ====================\n",
      "Train Acc: 0.435350 Train Loss: 1.313373\n",
      "  Val Acc: 0.441970   Val Loss: 1.249452\n",
      "==================== Epoch 7 ====================\n",
      "Train Acc: 0.437722 Train Loss: 1.308499\n",
      "  Val Acc: 0.389215   Val Loss: 1.480458\n",
      "==================== Epoch 8 ====================\n",
      "Train Acc: 0.406880 Train Loss: 1.342743\n",
      "  Val Acc: 0.431419   Val Loss: 1.330934\n",
      "==================== Epoch 9 ====================\n",
      "Train Acc: 0.465006 Train Loss: 1.255922\n",
      "  Val Acc: 0.492380   Val Loss: 1.253478\n",
      "==================== Epoch 10 ====================\n",
      "Train Acc: 0.437722 Train Loss: 1.344024\n",
      "  Val Acc: 0.498242   Val Loss: 1.246964\n",
      "==================== Epoch 11 ====================\n",
      "Train Acc: 0.442467 Train Loss: 1.299794\n",
      "  Val Acc: 0.495897   Val Loss: 1.201419\n",
      "==================== Epoch 12 ====================\n",
      "Train Acc: 0.511269 Train Loss: 1.199954\n",
      "  Val Acc: 0.467761   Val Loss: 1.192443\n",
      "==================== Epoch 13 ====================\n",
      "Train Acc: 0.511269 Train Loss: 1.172638\n",
      "  Val Acc: 0.485346   Val Loss: 1.200687\n",
      "==================== Epoch 14 ====================\n",
      "Train Acc: 0.492289 Train Loss: 1.205114\n",
      "  Val Acc: 0.542790   Val Loss: 1.107078\n",
      "==================== Epoch 15 ====================\n",
      "Train Acc: 0.510083 Train Loss: 1.172433\n",
      "  Val Acc: 0.520516   Val Loss: 1.138532\n",
      "==================== Epoch 16 ====================\n",
      "Train Acc: 0.512456 Train Loss: 1.165178\n",
      "  Val Acc: 0.572098   Val Loss: 1.096755\n",
      "==================== Epoch 17 ====================\n",
      "Train Acc: 0.558719 Train Loss: 1.102260\n",
      "  Val Acc: 0.565064   Val Loss: 1.118123\n",
      "==================== Epoch 18 ====================\n",
      "Train Acc: 0.524318 Train Loss: 1.147109\n",
      "  Val Acc: 0.574443   Val Loss: 1.188529\n",
      "==================== Epoch 19 ====================\n",
      "Train Acc: 0.552788 Train Loss: 1.142726\n",
      "  Val Acc: 0.572098   Val Loss: 1.160639\n",
      "==================== Epoch 20 ====================\n",
      "Train Acc: 0.523132 Train Loss: 1.150052\n",
      "  Val Acc: 0.506448   Val Loss: 1.147980\n",
      "==================== Epoch 21 ====================\n",
      "Train Acc: 0.542112 Train Loss: 1.138751\n",
      "  Val Acc: 0.602579   Val Loss: 1.018571\n",
      "==================== Epoch 22 ====================\n",
      "Train Acc: 0.542112 Train Loss: 1.140714\n",
      "  Val Acc: 0.533411   Val Loss: 1.162373\n",
      "==================== Epoch 23 ====================\n",
      "Train Acc: 0.561091 Train Loss: 1.080354\n",
      "  Val Acc: 0.583822   Val Loss: 1.062616\n",
      "==================== Epoch 24 ====================\n",
      "Train Acc: 0.575326 Train Loss: 1.091174\n",
      "  Val Acc: 0.548652   Val Loss: 1.114457\n",
      "==================== Epoch 25 ====================\n",
      "Train Acc: 0.571767 Train Loss: 1.116509\n",
      "  Val Acc: 0.565064   Val Loss: 1.038305\n",
      "==================== Epoch 26 ====================\n",
      "Train Acc: 0.555160 Train Loss: 1.103357\n",
      "  Val Acc: 0.572098   Val Loss: 1.041358\n",
      "==================== Epoch 27 ====================\n",
      "Train Acc: 0.576512 Train Loss: 1.128792\n",
      "  Val Acc: 0.583822   Val Loss: 1.056996\n",
      "==================== Epoch 28 ====================\n",
      "Train Acc: 0.580071 Train Loss: 1.077362\n",
      "  Val Acc: 0.627198   Val Loss: 0.985193\n",
      "==================== Epoch 29 ====================\n",
      "Train Acc: 0.591934 Train Loss: 1.053164\n",
      "  Val Acc: 0.629543   Val Loss: 0.955724\n",
      "==================== Epoch 30 ====================\n",
      "Train Acc: 0.588375 Train Loss: 1.071499\n",
      "  Val Acc: 0.552169   Val Loss: 1.263112\n",
      "==================== Epoch 31 ====================\n",
      "Train Acc: 0.588375 Train Loss: 1.071432\n",
      "  Val Acc: 0.594373   Val Loss: 1.090720\n",
      "==================== Epoch 32 ====================\n",
      "Train Acc: 0.610913 Train Loss: 1.023066\n",
      "  Val Acc: 0.627198   Val Loss: 0.979059\n",
      "==================== Epoch 33 ====================\n",
      "Train Acc: 0.580071 Train Loss: 1.080784\n",
      "  Val Acc: 0.623681   Val Loss: 1.003068\n",
      "==================== Epoch 34 ====================\n",
      "Train Acc: 0.588375 Train Loss: 1.043030\n",
      "  Val Acc: 0.637749   Val Loss: 0.970639\n",
      "==================== Epoch 35 ====================\n",
      "Train Acc: 0.595492 Train Loss: 1.056216\n",
      "  Val Acc: 0.604924   Val Loss: 0.982792\n",
      "==================== Epoch 36 ====================\n",
      "Train Acc: 0.597865 Train Loss: 1.054537\n",
      "  Val Acc: 0.574443   Val Loss: 1.035091\n",
      "==================== Epoch 37 ====================\n",
      "Train Acc: 0.603796 Train Loss: 1.058908\n",
      "  Val Acc: 0.642438   Val Loss: 0.988734\n",
      "==================== Epoch 38 ====================\n",
      "Train Acc: 0.558719 Train Loss: 1.093505\n",
      "  Val Acc: 0.558030   Val Loss: 1.209696\n",
      "==================== Epoch 39 ====================\n",
      "Train Acc: 0.580071 Train Loss: 1.073551\n",
      "  Val Acc: 0.540445   Val Loss: 1.043271\n",
      "==================== Epoch 40 ====================\n",
      "Train Acc: 0.591934 Train Loss: 1.051756\n",
      "  Val Acc: 0.650645   Val Loss: 0.930443\n",
      "==================== Epoch 41 ====================\n",
      "Train Acc: 0.612100 Train Loss: 1.005468\n",
      "  Val Acc: 0.640094   Val Loss: 0.917602\n",
      "==================== Epoch 42 ====================\n",
      "Train Acc: 0.602610 Train Loss: 1.023163\n",
      "  Val Acc: 0.576788   Val Loss: 1.048687\n",
      "==================== Epoch 43 ====================\n",
      "Train Acc: 0.616845 Train Loss: 1.003122\n",
      "  Val Acc: 0.644783   Val Loss: 0.999655\n",
      "==================== Epoch 44 ====================\n",
      "Train Acc: 0.603796 Train Loss: 1.047975\n",
      "  Val Acc: 0.613130   Val Loss: 1.000414\n",
      "==================== Epoch 45 ====================\n",
      "Train Acc: 0.639383 Train Loss: 0.998998\n",
      "  Val Acc: 0.603751   Val Loss: 1.184972\n",
      "==================== Epoch 46 ====================\n",
      "Train Acc: 0.619217 Train Loss: 1.017130\n",
      "  Val Acc: 0.642438   Val Loss: 0.902560\n",
      "==================== Epoch 47 ====================\n",
      "Train Acc: 0.631079 Train Loss: 0.943584\n",
      "  Val Acc: 0.552169   Val Loss: 1.230125\n",
      "==================== Epoch 48 ====================\n",
      "Train Acc: 0.647687 Train Loss: 0.971562\n",
      "  Val Acc: 0.670574   Val Loss: 0.895065\n",
      "==================== Epoch 49 ====================\n",
      "Train Acc: 0.653618 Train Loss: 0.964894\n",
      "  Val Acc: 0.621336   Val Loss: 0.962166\n",
      "==================== Epoch 50 ====================\n",
      "Train Acc: 0.623962 Train Loss: 1.007907\n",
      "  Val Acc: 0.635404   Val Loss: 0.939483\n",
      "==================== Epoch 51 ====================\n",
      "Train Acc: 0.606168 Train Loss: 1.028388\n",
      "  Val Acc: 0.609613   Val Loss: 0.994323\n",
      "==================== Epoch 52 ====================\n",
      "Train Acc: 0.623962 Train Loss: 0.989845\n",
      "  Val Acc: 0.607268   Val Loss: 0.993239\n",
      "==================== Epoch 53 ====================\n",
      "Train Acc: 0.616845 Train Loss: 0.993885\n",
      "  Val Acc: 0.649472   Val Loss: 0.931577\n",
      "==================== Epoch 54 ====================\n",
      "Train Acc: 0.646501 Train Loss: 0.937305\n",
      "  Val Acc: 0.569754   Val Loss: 1.105220\n",
      "==================== Epoch 55 ====================\n",
      "Train Acc: 0.650059 Train Loss: 0.910346\n",
      "  Val Acc: 0.681125   Val Loss: 0.901215\n",
      "==================== Epoch 56 ====================\n",
      "Train Acc: 0.661922 Train Loss: 0.937946\n",
      "  Val Acc: 0.674091   Val Loss: 0.906220\n",
      "==================== Epoch 57 ====================\n",
      "Train Acc: 0.657177 Train Loss: 0.911415\n",
      "  Val Acc: 0.676436   Val Loss: 0.865194\n",
      "==================== Epoch 58 ====================\n",
      "Train Acc: 0.667853 Train Loss: 0.932738\n",
      "  Val Acc: 0.629543   Val Loss: 1.024918\n",
      "==================== Epoch 59 ====================\n",
      "Train Acc: 0.644128 Train Loss: 0.965074\n",
      "  Val Acc: 0.644783   Val Loss: 0.960126\n",
      "==================== Epoch 60 ====================\n",
      "Train Acc: 0.629893 Train Loss: 0.970995\n",
      "  Val Acc: 0.661196   Val Loss: 0.883540\n",
      "==================== Epoch 61 ====================\n",
      "Train Acc: 0.664294 Train Loss: 0.909440\n",
      "  Val Acc: 0.656506   Val Loss: 0.936226\n",
      "==================== Epoch 62 ====================\n",
      "Train Acc: 0.673784 Train Loss: 0.879169\n",
      "  Val Acc: 0.608441   Val Loss: 1.044573\n",
      "==================== Epoch 63 ====================\n",
      "Train Acc: 0.659549 Train Loss: 0.893352\n",
      "  Val Acc: 0.683470   Val Loss: 0.895582\n",
      "==================== Epoch 64 ====================\n",
      "Train Acc: 0.672598 Train Loss: 0.874706\n",
      "  Val Acc: 0.691676   Val Loss: 0.841201\n",
      "==================== Epoch 65 ====================\n",
      "Train Acc: 0.666667 Train Loss: 0.857119\n",
      "  Val Acc: 0.689332   Val Loss: 0.850852\n",
      "==================== Epoch 66 ====================\n",
      "Train Acc: 0.655991 Train Loss: 0.867393\n",
      "  Val Acc: 0.651817   Val Loss: 0.941318\n",
      "==================== Epoch 67 ====================\n",
      "Train Acc: 0.683274 Train Loss: 0.911223\n",
      "  Val Acc: 0.686987   Val Loss: 0.844243\n",
      "==================== Epoch 68 ====================\n",
      "Train Acc: 0.685647 Train Loss: 0.854774\n",
      "  Val Acc: 0.670574   Val Loss: 0.912154\n",
      "==================== Epoch 69 ====================\n",
      "Train Acc: 0.665480 Train Loss: 0.887691\n",
      "  Val Acc: 0.621336   Val Loss: 0.971252\n",
      "==================== Epoch 70 ====================\n",
      "Train Acc: 0.644128 Train Loss: 0.935793\n",
      "  Val Acc: 0.703400   Val Loss: 0.807519\n",
      "==================== Epoch 71 ====================\n",
      "Train Acc: 0.682088 Train Loss: 0.873568\n",
      "  Val Acc: 0.637749   Val Loss: 0.963418\n",
      "==================== Epoch 72 ====================\n",
      "Train Acc: 0.682088 Train Loss: 0.851187\n",
      "  Val Acc: 0.723329   Val Loss: 0.756705\n",
      "==================== Epoch 73 ====================\n",
      "Train Acc: 0.669039 Train Loss: 0.876109\n",
      "  Val Acc: 0.722157   Val Loss: 0.790380\n",
      "==================== Epoch 74 ====================\n",
      "Train Acc: 0.701068 Train Loss: 0.832510\n",
      "  Val Acc: 0.716295   Val Loss: 0.778141\n",
      "==================== Epoch 75 ====================\n",
      "Train Acc: 0.708185 Train Loss: 0.814642\n",
      "  Val Acc: 0.608441   Val Loss: 1.042206\n",
      "==================== Epoch 76 ====================\n",
      "Train Acc: 0.706999 Train Loss: 0.792484\n",
      "  Val Acc: 0.726846   Val Loss: 0.789025\n",
      "==================== Epoch 77 ====================\n",
      "Train Acc: 0.680902 Train Loss: 0.845746\n",
      "  Val Acc: 0.709261   Val Loss: 0.810448\n",
      "==================== Epoch 78 ====================\n",
      "Train Acc: 0.695136 Train Loss: 0.854734\n",
      "  Val Acc: 0.661196   Val Loss: 0.860284\n",
      "==================== Epoch 79 ====================\n",
      "Train Acc: 0.692764 Train Loss: 0.830499\n",
      "  Val Acc: 0.708089   Val Loss: 0.761119\n",
      "==================== Epoch 80 ====================\n",
      "Train Acc: 0.706999 Train Loss: 0.756961\n",
      "  Val Acc: 0.690504   Val Loss: 0.878875\n",
      "==================== Epoch 81 ====================\n",
      "Train Acc: 0.692764 Train Loss: 0.815912\n",
      "  Val Acc: 0.724502   Val Loss: 0.776740\n",
      "==================== Epoch 82 ====================\n",
      "Train Acc: 0.711744 Train Loss: 0.804394\n",
      "  Val Acc: 0.697538   Val Loss: 0.829270\n",
      "==================== Epoch 83 ====================\n",
      "Train Acc: 0.716489 Train Loss: 0.776671\n",
      "  Val Acc: 0.681125   Val Loss: 0.821749\n",
      "==================== Epoch 84 ====================\n",
      "Train Acc: 0.697509 Train Loss: 0.807237\n",
      "  Val Acc: 0.717468   Val Loss: 0.778444\n",
      "==================== Epoch 85 ====================\n",
      "Train Acc: 0.703440 Train Loss: 0.765941\n",
      "  Val Acc: 0.664713   Val Loss: 0.887159\n",
      "==================== Epoch 86 ====================\n",
      "Train Acc: 0.693950 Train Loss: 0.791457\n",
      "  Val Acc: 0.739742   Val Loss: 0.734245\n",
      "==================== Epoch 87 ====================\n",
      "Train Acc: 0.728351 Train Loss: 0.762089\n",
      "  Val Acc: 0.713951   Val Loss: 0.767024\n",
      "==================== Epoch 88 ====================\n",
      "Train Acc: 0.690391 Train Loss: 0.783628\n",
      "  Val Acc: 0.743259   Val Loss: 0.716708\n",
      "==================== Epoch 89 ====================\n",
      "Train Acc: 0.721234 Train Loss: 0.769146\n",
      "  Val Acc: 0.702227   Val Loss: 0.801119\n",
      "==================== Epoch 90 ====================\n",
      "Train Acc: 0.724792 Train Loss: 0.734946\n",
      "  Val Acc: 0.737397   Val Loss: 0.758406\n",
      "==================== Epoch 91 ====================\n",
      "Train Acc: 0.718861 Train Loss: 0.742425\n",
      "  Val Acc: 0.750293   Val Loss: 0.674237\n",
      "==================== Epoch 92 ====================\n",
      "Train Acc: 0.716489 Train Loss: 0.744035\n",
      "  Val Acc: 0.709261   Val Loss: 0.845182\n",
      "==================== Epoch 93 ====================\n",
      "Train Acc: 0.727165 Train Loss: 0.751547\n",
      "  Val Acc: 0.718640   Val Loss: 0.781318\n",
      "==================== Epoch 94 ====================\n",
      "Train Acc: 0.725979 Train Loss: 0.729672\n",
      "  Val Acc: 0.640094   Val Loss: 1.016496\n",
      "==================== Epoch 95 ====================\n",
      "Train Acc: 0.729537 Train Loss: 0.756648\n",
      "  Val Acc: 0.724502   Val Loss: 0.788879\n",
      "==================== Epoch 96 ====================\n",
      "Train Acc: 0.721234 Train Loss: 0.745357\n",
      "  Val Acc: 0.743259   Val Loss: 0.698345\n",
      "==================== Epoch 97 ====================\n",
      "Train Acc: 0.716489 Train Loss: 0.750730\n",
      "  Val Acc: 0.744431   Val Loss: 0.736005\n",
      "==================== Epoch 98 ====================\n",
      "Train Acc: 0.733096 Train Loss: 0.725136\n",
      "  Val Acc: 0.744431   Val Loss: 0.702952\n",
      "==================== Epoch 99 ====================\n",
      "Train Acc: 0.720047 Train Loss: 0.750625\n",
      "  Val Acc: 0.719812   Val Loss: 0.756133\n",
      "==================== Epoch 100 ====================\n",
      "Train Acc: 0.723606 Train Loss: 0.747554\n",
      "  Val Acc: 0.729191   Val Loss: 0.776537\n",
      "==================== Epoch 101 ====================\n",
      "Train Acc: 0.742586 Train Loss: 0.691246\n",
      "  Val Acc: 0.703400   Val Loss: 0.817776\n",
      "==================== Epoch 102 ====================\n",
      "Train Acc: 0.758007 Train Loss: 0.691255\n",
      "  Val Acc: 0.657679   Val Loss: 0.953568\n",
      "==================== Epoch 103 ====================\n",
      "Train Acc: 0.718861 Train Loss: 0.736845\n",
      "  Val Acc: 0.711606   Val Loss: 0.754262\n",
      "==================== Epoch 104 ====================\n",
      "Train Acc: 0.746145 Train Loss: 0.677935\n",
      "  Val Acc: 0.688159   Val Loss: 0.850173\n",
      "==================== Epoch 105 ====================\n",
      "Train Acc: 0.740214 Train Loss: 0.685068\n",
      "  Val Acc: 0.758499   Val Loss: 0.658763\n",
      "==================== Epoch 106 ====================\n",
      "Train Acc: 0.733096 Train Loss: 0.706017\n",
      "  Val Acc: 0.733880   Val Loss: 0.729048\n",
      "==================== Epoch 107 ====================\n",
      "Train Acc: 0.755635 Train Loss: 0.652296\n",
      "  Val Acc: 0.726846   Val Loss: 0.803389\n",
      "==================== Epoch 108 ====================\n",
      "Train Acc: 0.746145 Train Loss: 0.735948\n",
      "  Val Acc: 0.760844   Val Loss: 0.743224\n",
      "==================== Epoch 109 ====================\n",
      "Train Acc: 0.708185 Train Loss: 0.748201\n",
      "  Val Acc: 0.744431   Val Loss: 0.775128\n",
      "==================== Epoch 110 ====================\n",
      "Train Acc: 0.760380 Train Loss: 0.670382\n",
      "  Val Acc: 0.764361   Val Loss: 0.715597\n",
      "==================== Epoch 111 ====================\n",
      "Train Acc: 0.754448 Train Loss: 0.696969\n",
      "  Val Acc: 0.699883   Val Loss: 0.828426\n",
      "==================== Epoch 112 ====================\n",
      "Train Acc: 0.750890 Train Loss: 0.690259\n",
      "  Val Acc: 0.756155   Val Loss: 0.680982\n",
      "==================== Epoch 113 ====================\n",
      "Train Acc: 0.727165 Train Loss: 0.753122\n",
      "  Val Acc: 0.733880   Val Loss: 0.710709\n",
      "==================== Epoch 114 ====================\n",
      "Train Acc: 0.739027 Train Loss: 0.707894\n",
      "  Val Acc: 0.764361   Val Loss: 0.662619\n",
      "==================== Epoch 115 ====================\n",
      "Train Acc: 0.749703 Train Loss: 0.665298\n",
      "  Val Acc: 0.762016   Val Loss: 0.680049\n",
      "==================== Epoch 116 ====================\n",
      "Train Acc: 0.756821 Train Loss: 0.634756\n",
      "  Val Acc: 0.765533   Val Loss: 0.664869\n",
      "==================== Epoch 117 ====================\n",
      "Train Acc: 0.774614 Train Loss: 0.603958\n",
      "  Val Acc: 0.772567   Val Loss: 0.672116\n",
      "==================== Epoch 118 ====================\n",
      "Train Acc: 0.756821 Train Loss: 0.649324\n",
      "  Val Acc: 0.723329   Val Loss: 0.717224\n",
      "==================== Epoch 119 ====================\n",
      "Train Acc: 0.749703 Train Loss: 0.674099\n",
      "  Val Acc: 0.732708   Val Loss: 0.751869\n",
      "==================== Epoch 120 ====================\n",
      "Train Acc: 0.743772 Train Loss: 0.707254\n",
      "  Val Acc: 0.746776   Val Loss: 0.697028\n",
      "==================== Epoch 121 ====================\n",
      "Train Acc: 0.760380 Train Loss: 0.634467\n",
      "  Val Acc: 0.786635   Val Loss: 0.636489\n",
      "==================== Epoch 122 ====================\n",
      "Train Acc: 0.762752 Train Loss: 0.627011\n",
      "  Val Acc: 0.750293   Val Loss: 0.728068\n",
      "==================== Epoch 123 ====================\n",
      "Train Acc: 0.776987 Train Loss: 0.600218\n",
      "  Val Acc: 0.765533   Val Loss: 0.685911\n",
      "==================== Epoch 124 ====================\n",
      "Train Acc: 0.768683 Train Loss: 0.608310\n",
      "  Val Acc: 0.751465   Val Loss: 0.741415\n",
      "==================== Epoch 125 ====================\n",
      "Train Acc: 0.750890 Train Loss: 0.690128\n",
      "  Val Acc: 0.729191   Val Loss: 0.828065\n",
      "==================== Epoch 126 ====================\n",
      "Train Acc: 0.734282 Train Loss: 0.677544\n",
      "  Val Acc: 0.753810   Val Loss: 0.711777\n",
      "==================== Epoch 127 ====================\n",
      "Train Acc: 0.754448 Train Loss: 0.641608\n",
      "  Val Acc: 0.758499   Val Loss: 0.701117\n",
      "==================== Epoch 128 ====================\n",
      "Train Acc: 0.781732 Train Loss: 0.602840\n",
      "  Val Acc: 0.739742   Val Loss: 0.745574\n",
      "==================== Epoch 129 ====================\n",
      "Train Acc: 0.778173 Train Loss: 0.597896\n",
      "  Val Acc: 0.757327   Val Loss: 0.725428\n",
      "==================== Epoch 130 ====================\n",
      "Train Acc: 0.756821 Train Loss: 0.661869\n",
      "  Val Acc: 0.736225   Val Loss: 0.731389\n",
      "==================== Epoch 131 ====================\n",
      "Train Acc: 0.772242 Train Loss: 0.631305\n",
      "  Val Acc: 0.774912   Val Loss: 0.636688\n",
      "==================== Epoch 132 ====================\n",
      "Train Acc: 0.768683 Train Loss: 0.607292\n",
      "  Val Acc: 0.772567   Val Loss: 0.644424\n",
      "==================== Epoch 133 ====================\n",
      "Train Acc: 0.740214 Train Loss: 0.673237\n",
      "  Val Acc: 0.753810   Val Loss: 0.694769\n",
      "==================== Epoch 134 ====================\n",
      "Train Acc: 0.762752 Train Loss: 0.606652\n",
      "  Val Acc: 0.773740   Val Loss: 0.636588\n",
      "==================== Epoch 135 ====================\n",
      "Train Acc: 0.781732 Train Loss: 0.649167\n",
      "  Val Acc: 0.765533   Val Loss: 0.712414\n",
      "==================== Epoch 136 ====================\n",
      "Train Acc: 0.768683 Train Loss: 0.615064\n",
      "  Val Acc: 0.772567   Val Loss: 0.646674\n",
      "==================== Epoch 137 ====================\n",
      "Train Acc: 0.775801 Train Loss: 0.599911\n",
      "  Val Acc: 0.751465   Val Loss: 0.701839\n",
      "==================== Epoch 138 ====================\n",
      "Train Acc: 0.762752 Train Loss: 0.624349\n",
      "  Val Acc: 0.756155   Val Loss: 0.655780\n",
      "==================== Epoch 139 ====================\n",
      "Train Acc: 0.793594 Train Loss: 0.532741\n",
      "  Val Acc: 0.751465   Val Loss: 0.732660\n",
      "==================== Epoch 140 ====================\n",
      "Train Acc: 0.768683 Train Loss: 0.598012\n",
      "  Val Acc: 0.774912   Val Loss: 0.663491\n",
      "==================== Epoch 141 ====================\n",
      "Train Acc: 0.772242 Train Loss: 0.634655\n",
      "  Val Acc: 0.766706   Val Loss: 0.678195\n",
      "==================== Epoch 142 ====================\n",
      "Train Acc: 0.786477 Train Loss: 0.570179\n",
      "  Val Acc: 0.777257   Val Loss: 0.666228\n",
      "==================== Epoch 143 ====================\n",
      "Train Acc: 0.778173 Train Loss: 0.589290\n",
      "  Val Acc: 0.791325   Val Loss: 0.591112\n",
      "==================== Epoch 144 ====================\n",
      "Train Acc: 0.806643 Train Loss: 0.526596\n",
      "  Val Acc: 0.796014   Val Loss: 0.576415\n",
      "==================== Epoch 145 ====================\n",
      "Train Acc: 0.799526 Train Loss: 0.544980\n",
      "  Val Acc: 0.801876   Val Loss: 0.599212\n",
      "==================== Epoch 146 ====================\n",
      "Train Acc: 0.799526 Train Loss: 0.542708\n",
      "  Val Acc: 0.788980   Val Loss: 0.611618\n",
      "==================== Epoch 147 ====================\n",
      "Train Acc: 0.806643 Train Loss: 0.520934\n",
      "  Val Acc: 0.781946   Val Loss: 0.605746\n",
      "==================== Epoch 148 ====================\n",
      "Train Acc: 0.814947 Train Loss: 0.513235\n",
      "  Val Acc: 0.787808   Val Loss: 0.628740\n",
      "==================== Epoch 149 ====================\n",
      "Train Acc: 0.794781 Train Loss: 0.530669\n",
      "  Val Acc: 0.798359   Val Loss: 0.595926\n",
      "==================== Epoch 150 ====================\n",
      "Train Acc: 0.812574 Train Loss: 0.553672\n",
      "  Val Acc: 0.796014   Val Loss: 0.637611\n",
      "==================== Epoch 151 ====================\n",
      "Train Acc: 0.768683 Train Loss: 0.620848\n",
      "  Val Acc: 0.791325   Val Loss: 0.613614\n",
      "==================== Epoch 152 ====================\n",
      "Train Acc: 0.823250 Train Loss: 0.531593\n",
      "  Val Acc: 0.790152   Val Loss: 0.605263\n",
      "==================== Epoch 153 ====================\n",
      "Train Acc: 0.836299 Train Loss: 0.457582\n",
      "  Val Acc: 0.799531   Val Loss: 0.589617\n",
      "==================== Epoch 154 ====================\n",
      "Train Acc: 0.816133 Train Loss: 0.485394\n",
      "  Val Acc: 0.781946   Val Loss: 0.635590\n",
      "==================== Epoch 155 ====================\n",
      "Train Acc: 0.819692 Train Loss: 0.495995\n",
      "  Val Acc: 0.786635   Val Loss: 0.642795\n",
      "==================== Epoch 156 ====================\n",
      "Train Acc: 0.810202 Train Loss: 0.546048\n",
      "  Val Acc: 0.778429   Val Loss: 0.627412\n",
      "==================== Epoch 157 ====================\n",
      "Train Acc: 0.823250 Train Loss: 0.493755\n",
      "  Val Acc: 0.786635   Val Loss: 0.590190\n",
      "==================== Epoch 158 ====================\n",
      "Train Acc: 0.816133 Train Loss: 0.496870\n",
      "  Val Acc: 0.797186   Val Loss: 0.605838\n",
      "==================== Epoch 159 ====================\n",
      "Train Acc: 0.838671 Train Loss: 0.446001\n",
      "  Val Acc: 0.807737   Val Loss: 0.605869\n",
      "==================== Epoch 160 ====================\n",
      "Train Acc: 0.811388 Train Loss: 0.513329\n",
      "  Val Acc: 0.784291   Val Loss: 0.670426\n",
      "==================== Epoch 161 ====================\n",
      "Train Acc: 0.820878 Train Loss: 0.483069\n",
      "  Val Acc: 0.779601   Val Loss: 0.674486\n",
      "==================== Epoch 162 ====================\n",
      "Train Acc: 0.838671 Train Loss: 0.470852\n",
      "  Val Acc: 0.793669   Val Loss: 0.632422\n",
      "==================== Epoch 163 ====================\n",
      "Train Acc: 0.810202 Train Loss: 0.495643\n",
      "  Val Acc: 0.766706   Val Loss: 0.705736\n",
      "==================== Epoch 164 ====================\n",
      "Train Acc: 0.830368 Train Loss: 0.469124\n",
      "  Val Acc: 0.799531   Val Loss: 0.599382\n",
      "==================== Epoch 165 ====================\n",
      "Train Acc: 0.820878 Train Loss: 0.491187\n",
      "  Val Acc: 0.791325   Val Loss: 0.626931\n",
      "==================== Epoch 166 ====================\n",
      "Train Acc: 0.820878 Train Loss: 0.472637\n",
      "  Val Acc: 0.799531   Val Loss: 0.595181\n",
      "==================== Epoch 167 ====================\n",
      "Train Acc: 0.839858 Train Loss: 0.431275\n",
      "  Val Acc: 0.808910   Val Loss: 0.575836\n",
      "==================== Epoch 168 ====================\n",
      "Train Acc: 0.857651 Train Loss: 0.396566\n",
      "  Val Acc: 0.787808   Val Loss: 0.605265\n",
      "==================== Epoch 169 ====================\n",
      "Train Acc: 0.851720 Train Loss: 0.436456\n",
      "  Val Acc: 0.814771   Val Loss: 0.578305\n",
      "==================== Epoch 170 ====================\n",
      "Train Acc: 0.857651 Train Loss: 0.412118\n",
      "  Val Acc: 0.803048   Val Loss: 0.621345\n",
      "==================== Epoch 171 ====================\n",
      "Train Acc: 0.842230 Train Loss: 0.442858\n",
      "  Val Acc: 0.819461   Val Loss: 0.576794\n",
      "==================== Epoch 172 ====================\n",
      "Train Acc: 0.869514 Train Loss: 0.414961\n",
      "  Val Acc: 0.804220   Val Loss: 0.599384\n",
      "==================== Epoch 173 ====================\n",
      "Train Acc: 0.850534 Train Loss: 0.425447\n",
      "  Val Acc: 0.805393   Val Loss: 0.590965\n",
      "==================== Epoch 174 ====================\n",
      "Train Acc: 0.844603 Train Loss: 0.441455\n",
      "  Val Acc: 0.790152   Val Loss: 0.600918\n",
      "==================== Epoch 175 ====================\n",
      "Train Acc: 0.858837 Train Loss: 0.398798\n",
      "  Val Acc: 0.807737   Val Loss: 0.588983\n",
      "==================== Epoch 176 ====================\n",
      "Train Acc: 0.839858 Train Loss: 0.426194\n",
      "  Val Acc: 0.797186   Val Loss: 0.618032\n",
      "==================== Epoch 177 ====================\n",
      "Train Acc: 0.858837 Train Loss: 0.392209\n",
      "  Val Acc: 0.800703   Val Loss: 0.611540\n",
      "==================== Epoch 178 ====================\n",
      "Train Acc: 0.838671 Train Loss: 0.455040\n",
      "  Val Acc: 0.813599   Val Loss: 0.571597\n",
      "==================== Epoch 179 ====================\n",
      "Train Acc: 0.852906 Train Loss: 0.408621\n",
      "  Val Acc: 0.788980   Val Loss: 0.636997\n",
      "==================== Epoch 180 ====================\n",
      "Train Acc: 0.841044 Train Loss: 0.425778\n",
      "  Val Acc: 0.807737   Val Loss: 0.580860\n",
      "==================== Epoch 181 ====================\n",
      "Train Acc: 0.831554 Train Loss: 0.432976\n",
      "  Val Acc: 0.815944   Val Loss: 0.570001\n",
      "==================== Epoch 182 ====================\n",
      "Train Acc: 0.856465 Train Loss: 0.410241\n",
      "  Val Acc: 0.793669   Val Loss: 0.630393\n",
      "==================== Epoch 183 ====================\n",
      "Train Acc: 0.841044 Train Loss: 0.424976\n",
      "  Val Acc: 0.812427   Val Loss: 0.581747\n",
      "==================== Epoch 184 ====================\n",
      "Train Acc: 0.864769 Train Loss: 0.391906\n",
      "  Val Acc: 0.792497   Val Loss: 0.622348\n",
      "==================== Epoch 185 ====================\n",
      "Train Acc: 0.852906 Train Loss: 0.405141\n",
      "  Val Acc: 0.801876   Val Loss: 0.614008\n",
      "==================== Epoch 186 ====================\n",
      "Train Acc: 0.857651 Train Loss: 0.417277\n",
      "  Val Acc: 0.803048   Val Loss: 0.587175\n",
      "==================== Epoch 187 ====================\n",
      "Train Acc: 0.848161 Train Loss: 0.402773\n",
      "  Val Acc: 0.824150   Val Loss: 0.562325\n",
      "==================== Epoch 188 ====================\n",
      "Train Acc: 0.862396 Train Loss: 0.380034\n",
      "  Val Acc: 0.815944   Val Loss: 0.576480\n",
      "==================== Epoch 189 ====================\n",
      "Train Acc: 0.886121 Train Loss: 0.351350\n",
      "  Val Acc: 0.799531   Val Loss: 0.630241\n",
      "==================== Epoch 190 ====================\n",
      "Train Acc: 0.851720 Train Loss: 0.381412\n",
      "  Val Acc: 0.806565   Val Loss: 0.596713\n",
      "==================== Epoch 191 ====================\n",
      "Train Acc: 0.860024 Train Loss: 0.388731\n",
      "  Val Acc: 0.796014   Val Loss: 0.593358\n",
      "==================== Epoch 192 ====================\n",
      "Train Acc: 0.844603 Train Loss: 0.418719\n",
      "  Val Acc: 0.786635   Val Loss: 0.613592\n",
      "==================== Epoch 193 ====================\n",
      "Train Acc: 0.842230 Train Loss: 0.420922\n",
      "  Val Acc: 0.791325   Val Loss: 0.632230\n",
      "==================== Epoch 194 ====================\n",
      "Train Acc: 0.852906 Train Loss: 0.409154\n",
      "  Val Acc: 0.791325   Val Loss: 0.609716\n",
      "==================== Epoch 195 ====================\n",
      "Train Acc: 0.846975 Train Loss: 0.428766\n",
      "  Val Acc: 0.813599   Val Loss: 0.594423\n",
      "==================== Epoch 196 ====================\n",
      "Train Acc: 0.857651 Train Loss: 0.403284\n",
      "  Val Acc: 0.812427   Val Loss: 0.586198\n",
      "==================== Epoch 197 ====================\n",
      "Train Acc: 0.845789 Train Loss: 0.396430\n",
      "  Val Acc: 0.801876   Val Loss: 0.607312\n",
      "==================== Epoch 198 ====================\n",
      "Train Acc: 0.876631 Train Loss: 0.358138\n",
      "  Val Acc: 0.810082   Val Loss: 0.619072\n",
      "==================== Epoch 199 ====================\n",
      "Train Acc: 0.845789 Train Loss: 0.387104\n",
      "  Val Acc: 0.810082   Val Loss: 0.604010\n",
      "==================== Epoch 200 ====================\n",
      "Train Acc: 0.836299 Train Loss: 0.412743\n",
      "  Val Acc: 0.798359   Val Loss: 0.606806\n",
      "==================== Epoch 201 ====================\n",
      "Train Acc: 0.865955 Train Loss: 0.393424\n",
      "  Val Acc: 0.799531   Val Loss: 0.598480\n",
      "==================== Epoch 202 ====================\n",
      "Train Acc: 0.861210 Train Loss: 0.373751\n",
      "  Val Acc: 0.815944   Val Loss: 0.593198\n",
      "==================== Epoch 203 ====================\n",
      "Train Acc: 0.855279 Train Loss: 0.409167\n",
      "  Val Acc: 0.807737   Val Loss: 0.603949\n",
      "==================== Epoch 204 ====================\n",
      "Train Acc: 0.846975 Train Loss: 0.434047\n",
      "  Val Acc: 0.804220   Val Loss: 0.622447\n",
      "==================== Epoch 205 ====================\n",
      "Train Acc: 0.863582 Train Loss: 0.382220\n",
      "  Val Acc: 0.813599   Val Loss: 0.591093\n",
      "==================== Epoch 206 ====================\n",
      "Train Acc: 0.856465 Train Loss: 0.387286\n",
      "  Val Acc: 0.812427   Val Loss: 0.588604\n",
      "==================== Epoch 207 ====================\n",
      "Train Acc: 0.867141 Train Loss: 0.366177\n",
      "  Val Acc: 0.801876   Val Loss: 0.594795\n",
      "==================== Epoch 208 ====================\n",
      "Train Acc: 0.869514 Train Loss: 0.374676\n",
      "  Val Acc: 0.813599   Val Loss: 0.571985\n",
      "==================== Epoch 209 ====================\n",
      "Train Acc: 0.882562 Train Loss: 0.343975\n",
      "  Val Acc: 0.810082   Val Loss: 0.582201\n",
      "==================== Epoch 210 ====================\n",
      "Train Acc: 0.888493 Train Loss: 0.317159\n",
      "  Val Acc: 0.808910   Val Loss: 0.593959\n",
      "==================== Epoch 211 ====================\n",
      "Train Acc: 0.884935 Train Loss: 0.312937\n",
      "  Val Acc: 0.817116   Val Loss: 0.578880\n",
      "==================== Epoch 212 ====================\n",
      "Train Acc: 0.884935 Train Loss: 0.352942\n",
      "  Val Acc: 0.804220   Val Loss: 0.604646\n",
      "==================== Epoch 213 ====================\n",
      "Train Acc: 0.869514 Train Loss: 0.366749\n",
      "  Val Acc: 0.803048   Val Loss: 0.598079\n",
      "==================== Epoch 214 ====================\n",
      "Train Acc: 0.874259 Train Loss: 0.349908\n",
      "  Val Acc: 0.806565   Val Loss: 0.595466\n",
      "==================== Epoch 215 ====================\n",
      "Train Acc: 0.884935 Train Loss: 0.329731\n",
      "  Val Acc: 0.806565   Val Loss: 0.603276\n",
      "==================== Epoch 216 ====================\n",
      "Train Acc: 0.870700 Train Loss: 0.345368\n",
      "  Val Acc: 0.803048   Val Loss: 0.616160\n",
      "==================== Epoch 217 ====================\n",
      "Train Acc: 0.863582 Train Loss: 0.371231\n",
      "  Val Acc: 0.801876   Val Loss: 0.606243\n",
      "Early stopping at epoch 217 due to no improvement in validation loss.\n"
     ]
    }
   ],
   "source": [
    "################################################################################\n",
    "#     You can adjust those hyper parameters to loop for max_epochs times       #\n",
    "################################################################################\n",
    "max_epochs = 5000\n",
    "log_interval = 1\n",
    "early_stopping_patience = 30    # NuIber of epochs to wait for improvement\n",
    "\n",
    "train_acc_list = []\n",
    "train_loss_list = []\n",
    "val_acc_list = []\n",
    "val_loss_list = []\n",
    "\n",
    "best_acc = 0       # Initialize with a small value\n",
    "no_improvement_count = 0\n",
    "\n",
    "best_model_state_dict = None    # To store the state_dict of the best model\n",
    "\n",
    "for epoch in range(1, max_epochs + 1):\n",
    "    train_acc, train_loss = train(train_loader, model, criterion, optimizer)\n",
    "    val_acc, val_loss = val(valid_loader, model, criterion)\n",
    "\n",
    "    scheduler.step(val_loss)\n",
    "\n",
    "    train_acc_list.append(train_acc)\n",
    "    train_loss_list.append(train_loss)\n",
    "    val_acc_list.append(val_acc)\n",
    "    val_loss_list.append(val_loss)\n",
    "\n",
    "    if epoch % log_interval == 0:\n",
    "        print('=' * 20, 'Epoch', epoch, '=' * 20)\n",
    "        print('Train Acc: {:.6f} Train Loss: {:.6f}'.format(train_acc, train_loss))\n",
    "        print('  Val Acc: {:.6f}   Val Loss: {:.6f}'.format(val_acc, val_loss))\n",
    "\n",
    "    # Check for early stopping based on validation loss\n",
    "    if  val_acc > best_acc:\n",
    "        best_acc = val_acc\n",
    "        no_improvement_count = 0\n",
    "\n",
    "        # Save a copy of the model's state_dict when the best validation loss is seen\n",
    "        best_model_state_dict = model.state_dict()\n",
    "    else:\n",
    "        no_improvement_count += 1\n",
    "\n",
    "    if no_improvement_count >= early_stopping_patience:\n",
    "        print(f'Early stopping at epoch {epoch} due to no improvement in validation loss.')\n",
    "\n",
    "        # Restore the best model weights\n",
    "        if best_model_state_dict is not None:\n",
    "            model.load_state_dict(best_model_state_dict)\n",
    "        break\n",
    "################################################################################\n",
    "#                               End of your code                               #\n",
    "################################################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualize accuracy and loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-01T09:52:45.173035400Z",
     "start_time": "2023-11-01T09:52:43.211538600Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 1200x400 with 1 Axes>",
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<Figure size 1200x400 with 1 Axes>",
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "plt.figure(figsize=(12, 4))\n",
    "plt.plot(range(len(train_loss_list)), train_loss_list)\n",
    "plt.plot(range(len(val_loss_list)), val_loss_list, c='r')\n",
    "plt.legend(['train', 'val'])\n",
    "plt.title('Loss')\n",
    "plt.show()\n",
    "plt.figure(figsize=(12, 4))\n",
    "plt.plot(range(len(train_acc_list)), train_acc_list)\n",
    "plt.plot(range(len(val_acc_list)), val_acc_list, c='r')\n",
    "plt.legend(['train', 'val'])\n",
    "plt.title('Acc')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-01T09:53:18.359751900Z",
     "start_time": "2023-11-01T09:53:18.306748200Z"
    }
   },
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "# save your well-trained state_dict of model\n",
    "# Get the current timestamp\n",
    "timestamp = datetime.now().strftime(\"%Y-%m-%d-%H-%M\")\n",
    "torch.save(model.state_dict(), f'IB-CONV_{timestamp}.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "finish training your classifier, next you should use this classifer to predict unlabel images with pseduo label."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step2: Use unlabeled data to enhance model performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-01T05:31:52.499040700Z",
     "start_time": "2023-11-01T05:31:52.462837600Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "<All keys matched successfully>"
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load the trained classifier weights\n",
    "ckpt = torch.load('IB-CONV_Self_Train_2023-11-01-00-33.pt')\n",
    "model.load_state_dict(ckpt) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-01T05:56:27.980292600Z",
     "start_time": "2023-11-01T05:56:20.138399900Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1713\n"
     ]
    }
   ],
   "source": [
    "# create a unlabeled data set list, we will use it later\n",
    "unlabeled_set_list = []\n",
    "train_set = FlowerData('train_labeled_dataset.csv', mode='train', transform=transforms_train)\n",
    "train_loader = DataLoader(train_set, batch_size=batch_size, num_workers=num_workers, shuffle=True)\n",
    "\n",
    "for img in unlabeled_set:\n",
    "    unlabeled_set_list.append(img)\n",
    "    \n",
    "print(len(unlabeled_set_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define loss and optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-01T05:56:31.016437600Z",
     "start_time": "2023-11-01T05:56:30.993499Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "################################################################################\n",
    "# TODO: Define loss and optmizer functions                                     #\n",
    "# Try any loss or optimizer function and learning rate to get better result    #\n",
    "# hint: torch.nn and torch.optim                                               #\n",
    "################################################################################\n",
    "# CrossEntropyLoss for classification tasks\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "import copy\n",
    "# EMA copy\n",
    "ema_model = copy.deepcopy(model)\n",
    "\n",
    "# Adam optimizer\n",
    "learning_rate = 0.0001\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate, weight_decay=1e-3)\n",
    "\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', patience=5, factor=0.5)\n",
    "################################################################################\n",
    "#                               End of your code                               #\n",
    "################################################################################\n",
    "criterion = criterion.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use the trained classifier to generates pseudo-labels of a dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-01T05:56:33.817444500Z",
     "start_time": "2023-11-01T05:56:33.814009200Z"
    }
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import ConcatDataset, DataLoader, Subset\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "###########################################################\n",
    "#   You can adjust the threshold to get better result !   #                                  \n",
    "###########################################################\n",
    "def get_pseudo_labels(model, threshold=0.5):\n",
    "    \n",
    "    global unlabeled_set_list, train_set\n",
    "\n",
    "    remove_index, index = [], 0\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    softmax = nn.Softmax(dim=-1)\n",
    "\n",
    "    # Iterate over the dataset by batches.\n",
    "    for img in tqdm(unlabeled_set_list):\n",
    "\n",
    "        #####################################################################################\n",
    "        #     TODO:                                                                         #\n",
    "        #     1. Foward the data, Using torch.no_grad() accelerates the forward process     #\n",
    "        #     2. obtain the probability distributions by applying softmax on logits         #\n",
    "        #     3. Filter the data with threshold                                             #\n",
    "        #     4. CoIbine the labeled training data with the pseudo-labeled data             #\n",
    "        #        to construct a new training set. then removed                              #\n",
    "        #     5. the unlabeled data from unlabeled_set_list                                 #\n",
    "        #     hint: ConcatDataset                                                           #\n",
    "        #####################################################################################\n",
    "        with torch.no_grad():\n",
    "            img = img.to(device)  # Move the image to the device (e.g., GPU)\n",
    "\n",
    "            # 1. Forward the data\n",
    "            outputs = model(img.unsqueeze(0))  # Unsqueeze to add batch dimension\n",
    "\n",
    "            # 2. Obtain the probability distributions by applying softmax on logits\n",
    "            probs = softmax(outputs)\n",
    "\n",
    "            # 3. Filter the data with the threshold\n",
    "            max_prob, predicted_label = torch.max(probs, 1)\n",
    "\n",
    "            if max_prob.item() >= threshold:\n",
    "                # 4. Add the pseudo-label and image for the train set.\n",
    "                train_set.data_list.append(unlabeled_set.data_list[index])\n",
    "                train_set.labels.append(predicted_label.item())\n",
    "\n",
    "                # 5. Remove the unlabeled data from unlabeled_set_list\n",
    "                remove_index.append(index)\n",
    "\n",
    "            index += 1\n",
    "        #####################################################################################\n",
    "        #                           End of your code                                        #\n",
    "        #####################################################################################\n",
    "\n",
    "\n",
    "    remove_index.reverse()\n",
    "    for i in remove_index:\n",
    "        del unlabeled_set_list[i]\n",
    "\n",
    "    print(f\"[{len(train_set)-843}/1713] images have been labeled.\")\n",
    "    \n",
    "    # # Turn off the eval mode.\n",
    "    model.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's define train function.  \n",
    "\n",
    "Use the **get_pseudo_labels** function to get the new training set, then construct a new data loader for training.\n",
    "\n",
    "It will iterate input data 1 epoch and update model with optmizer.  \n",
    "\n",
    "Finally, calculate mean loss and total accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-01T05:59:20.383014Z",
     "start_time": "2023-11-01T05:56:41.625997Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "  0%|          | 0/1713 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "34abe180e8794947bc1e6ea2237ba2d9"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[746/1713] images have been labeled.\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/50 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "ed1508b6cca44454b40ff72b964c9f3a"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ Train | 001/010 ] loss = 0.40877, acc = 0.86339\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/27 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "57f9746fbb5a4dbebe70372b89013246"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ Valid | 001/010 ] loss = 0.57149, acc = 0.83317\n",
      "[ EMA Valid | 001/010 ] loss = 0.59612, acc = 0.81757\n",
      "[001/010] saving model with acc 0.833\n",
      "New best validation accuracy: 0.8332. Lowering threshold to 0.9250\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/1713 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "1b9ed124e57741c690b91b672091d71c"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[859/1713] images have been labeled.\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/54 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "4fe05990b9ee477095a5a991a949073c"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ Train | 002/010 ] loss = 0.38400, acc = 0.87249\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/27 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "59765e29e7594687a9833ff39129a45d"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ Valid | 002/010 ] loss = 0.57346, acc = 0.82275\n",
      "[ EMA Valid | 002/010 ] loss = 0.59496, acc = 0.81641\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/1713 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "2a4fd53566f24c18a79135a32f5d60dc"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[838/1713] images have been labeled.\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/53 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "598b29d0517d441fa379261c550dbe2e"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ Train | 003/010 ] loss = 0.38597, acc = 0.86342\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/27 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "7b8de9257c18421f8b4960fd9507a411"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ Valid | 003/010 ] loss = 0.56637, acc = 0.82622\n",
      "[ EMA Valid | 003/010 ] loss = 0.59314, acc = 0.81410\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/1713 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "c5c969b546ee4afb839d861c46a3ec60"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[839/1713] images have been labeled.\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/53 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "0e05a7854a964dd185e8110cb2ff8fb3"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ Train | 004/010 ] loss = 0.34550, acc = 0.87317\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/27 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "2394864cb7a8438b85ec1d39d92eb762"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ Valid | 004/010 ] loss = 0.56304, acc = 0.82738\n",
      "[ EMA Valid | 004/010 ] loss = 0.59057, acc = 0.81294\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/1713 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "0953c737650b4bb0a62a734ccb4ed016"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[838/1713] images have been labeled.\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/53 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "3db3b5a12a2c46dd99d6db6841b1c99d"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ Train | 005/010 ] loss = 0.36092, acc = 0.87417\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/27 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "cd5f157b83e74bd2a52fe7e0c6c86a6f"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ Valid | 005/010 ] loss = 0.54964, acc = 0.82330\n",
      "[ EMA Valid | 005/010 ] loss = 0.58773, acc = 0.81063\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/1713 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "8176585965284d73a9234186baae7513"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[809/1713] images have been labeled.\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/52 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "3ac400036cab4a169f82b729f09d14b7"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ Train | 006/010 ] loss = 0.32289, acc = 0.89627\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/27 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "0fbca89b6f33400ba0b2077fdfaab742"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ Valid | 006/010 ] loss = 0.56540, acc = 0.82330\n",
      "[ EMA Valid | 006/010 ] loss = 0.58405, acc = 0.81178\n",
      "Early stopping.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.setrecursionlimit(1000000)\n",
    "#########################################################################################################\n",
    "#         You can adjust those hyper parameters like epochs or threshlod for training                   #\n",
    "#########################################################################################################\n",
    "n_epochs = 10               # Number of epochs for training\n",
    "best_acc = 0                # Initialize with a small value\n",
    "early_stopping_counter = 0  # Counter for early stopping\n",
    "early_stopping_limit = 5    # Number of epochs to wait for improvement\n",
    "threshold = 0.95            # Threshold for pseudo-labeling\n",
    "threshold_decay = 0.025     # Decay rate for the threshold\n",
    "min_threshold = 0.8         # Minimum threshold for pseudo-labeling\n",
    "ema_decay = 0.999           # Decay rate for the EMA\n",
    "\n",
    "\n",
    "train_set = FlowerData('train_labeled_dataset.csv', mode='train', transform=transforms_train)\n",
    "get_pseudo_labels(ema_model, threshold=threshold)\n",
    "\n",
    "def update_ema_weights(model, ema_model, ema_decay):\n",
    "    \"\"\"\n",
    "    Update the weights of the ema_model based on the weights of the main model.\n",
    "\n",
    "    Parameters:\n",
    "    - model (torch.nn.Module): Main model whose weights are used for the update.\n",
    "    - ema_model (torch.nn.Module): Model to be updated.\n",
    "    - ema_decay (float): Decay rate for the EMA.\n",
    "    \"\"\"\n",
    "    for model_params, ema_params in zip(model.parameters(), ema_model.parameters()):\n",
    "        ema_params.data.mul_(ema_decay).add_(model_params.data, alpha=1 - ema_decay)\n",
    "\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    #########################################################################################################\n",
    "    #    TODO:                                                                                              #\n",
    "    #    In each epoch, relabel the unlabeled dataset for semi-supervised learning.                         #\n",
    "    #    1. Obtain pseudo-labels for unlabeled data using trained model.(use get_pseudo_labels function)    #\n",
    "    #    2. Construct a new dataset and a data loader for training.                                         #\n",
    "    #    You can try different way to use the get_pseudo_label function maybe will get the better result.   #                                  #\n",
    "    #########################################################################################################\n",
    "    global train_set, threshold\n",
    "\n",
    "    # Create a new data loader for training\n",
    "    train_loader = DataLoader(train_set, batch_size=batch_size, num_workers=num_workers, shuffle=True)\n",
    "    #########################################################################################################  \n",
    "    #                                          End of your code                                             #\n",
    "    #########################################################################################################\n",
    "\n",
    "    # ---------- Training ----------\n",
    "    model.train()\n",
    "    \n",
    "    train_loss = []\n",
    "    train_accs = []\n",
    "\n",
    "    for batch in tqdm(train_loader):\n",
    "        imgs, labels = batch\n",
    "\n",
    "        # Forward propagation\n",
    "        logits = model(imgs.to(device))\n",
    "\n",
    "        # Get loss\n",
    "        loss = criterion(logits, labels.to(device))\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "\n",
    "        # Gradient clipping\n",
    "        grad_norm = nn.utils.clip_grad_norm_(model.parameters(), max_norm=10)\n",
    "        optimizer.step()\n",
    "\n",
    "        # Update EMA weights\n",
    "        update_ema_weights(model, ema_model, ema_decay)\n",
    "\n",
    "        # Evaluation\n",
    "        acc = (logits.argmax(dim=-1) == labels.to(device)).float().mean()\n",
    "\n",
    "        train_loss.append(loss.item())\n",
    "        train_accs.append(acc)\n",
    "\n",
    "    train_loss = sum(train_loss) / len(train_loss)\n",
    "    train_acc = sum(train_accs) / len(train_accs)\n",
    "\n",
    "    print(f\"[ Train | {epoch + 1:03d}/{n_epochs:03d} ] loss = {train_loss:.5f}, acc = {train_acc:.5f}\")\n",
    "\n",
    "    # ---------- Validation ----------\n",
    "    model.eval()\n",
    "    ema_model.eval()\n",
    "\n",
    "    valid_loss = []\n",
    "    valid_accs = []\n",
    "    valid_loss_ema = []\n",
    "    valid_accs_ema = []\n",
    "\n",
    "    for batch in tqdm(valid_loader):\n",
    "\n",
    "        imgs, labels = batch\n",
    "\n",
    "        with torch.no_grad():\n",
    "            logits = model(imgs.to(device))\n",
    "            logits_ema = ema_model(imgs.to(device))\n",
    "\n",
    "        loss = criterion(logits, labels.to(device))\n",
    "        loss_ema = criterion(logits_ema, labels.to(device))\n",
    "\n",
    "        acc = (logits.argmax(dim=-1) == labels.to(device)).float().mean()\n",
    "        acc_ema = (logits_ema.argmax(dim=-1) == labels.to(device)).float().mean()\n",
    "\n",
    "        valid_loss.append(loss.item())\n",
    "        valid_accs.append(acc)\n",
    "\n",
    "        valid_loss_ema.append(loss_ema.item())\n",
    "        valid_accs_ema.append(acc_ema)\n",
    "\n",
    "    valid_loss = sum(valid_loss) / len(valid_loss)\n",
    "    valid_acc = sum(valid_accs) / len(valid_accs)\n",
    "\n",
    "    valid_loss_ema = sum(valid_loss_ema) / len(valid_loss_ema)\n",
    "    valid_acc_ema = sum(valid_accs_ema) / len(valid_accs_ema)\n",
    "\n",
    "    scheduler.step(valid_loss)\n",
    "\n",
    "    print(f\"[ Valid | {epoch + 1:03d}/{n_epochs:03d} ] loss = {valid_loss:.5f}, acc = {valid_acc:.5f}\")\n",
    "    print(f\"[ EMA Valid | {epoch + 1:03d}/{n_epochs:03d} ] loss = {valid_loss_ema:.5f}, acc = {valid_acc_ema:.5f}\")\n",
    "\n",
    "    # Save the best model\n",
    "    if valid_acc > best_acc:\n",
    "        best_acc = valid_acc\n",
    "        torch.save(model.state_dict(), 'NAME_OF_SELF_TRAINING_EXPERIMENT.pt')\n",
    "        print('[{:03d}/{:03d}] saving model with acc {:.3f}'.format(epoch + 1, n_epochs, best_acc))\n",
    "        # Lower the threshold if the model improves on the validation set\n",
    "        early_stopping_counter = 0\n",
    "        threshold = max(min_threshold, threshold - threshold_decay)\n",
    "        print(f\"New best validation accuracy: {best_acc:.4f}. Lowering threshold to {threshold:.4f}\")\n",
    "\n",
    "    # Early stopping\n",
    "    if valid_acc < best_acc:\n",
    "        early_stopping_counter += 1\n",
    "\n",
    "        if early_stopping_counter >= early_stopping_limit:\n",
    "            print(\"Early stopping.\")\n",
    "            break\n",
    "\n",
    "    train_set = FlowerData('train_labeled_dataset.csv', mode='train', transform=transforms_train)\n",
    "    get_pseudo_labels(ema_model if valid_acc_ema > valid_acc else model, threshold=threshold)\n",
    "#########################################################################################################\n",
    "#                               End of your code                                                        #\n",
    "#########################################################################################################\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "data": {
      "text/plain": "  0%|          | 0/53 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "c0d24a8f0434488195bceb0c5a76e003"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ Train | 001/1000 ] loss = 0.44115\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/27 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "b30f6930845945b091470d0f9a246f71"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ Valid | 001/1000 ] loss = 0.59418, acc = 0.82507\n",
      "[ EMA Valid | 001/1000 ] loss = 0.57916, acc = 0.82622\n",
      "[001/1000] saving model with acc 0.825\n",
      "New best validation accuracy: 0.8251. Lowering threshold to 0.8500\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/53 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "a8f1221c67c041deb75d677061f08409"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ Train | 002/1000 ] loss = 0.40705\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/27 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "1c435c5b4a7b43a1a8860626aa9d72cd"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ Valid | 002/1000 ] loss = 0.60248, acc = 0.82446\n",
      "[ EMA Valid | 002/1000 ] loss = 0.57916, acc = 0.82622\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/53 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "ffe5dc7db3294092919b9045058d8933"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ Train | 003/1000 ] loss = 0.43744\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/27 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "9445b10c2f98400ca69e1d0bb45e0356"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ Valid | 003/1000 ] loss = 0.60178, acc = 0.83025\n",
      "[ EMA Valid | 003/1000 ] loss = 0.57916, acc = 0.82622\n",
      "[003/1000] saving model with acc 0.830\n",
      "New best validation accuracy: 0.8302. Lowering threshold to 0.8000\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/53 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "215fa747c4ee41ab91130db7ba8fd113"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ Train | 004/1000 ] loss = 0.47824\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/27 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "b83fbdfb6aef480f99896c0a53666d20"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ Valid | 004/1000 ] loss = 0.58395, acc = 0.82391\n",
      "[ EMA Valid | 004/1000 ] loss = 0.57916, acc = 0.82622\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/53 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "90958ad794bc4c38a20b908120c5bfe4"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ Train | 005/1000 ] loss = 0.46011\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/27 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "5f3726df69ae4775ab28287be3dd9103"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ Valid | 005/1000 ] loss = 0.58906, acc = 0.82970\n",
      "[ EMA Valid | 005/1000 ] loss = 0.57916, acc = 0.82622\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/53 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "fb9abc148ee74b48b27724b9ddf0e4f6"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ Train | 006/1000 ] loss = 0.47130\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/27 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "8764cdba68264591822eeaaf0bfb4862"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ Valid | 006/1000 ] loss = 0.59655, acc = 0.82738\n",
      "[ EMA Valid | 006/1000 ] loss = 0.57916, acc = 0.82622\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/53 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "02c2b8c368fb4dabb6042831c0a91e23"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ Train | 007/1000 ] loss = 0.45779\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/27 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "ef3c53dc9a5643afb4d1efb74b5737bb"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ Valid | 007/1000 ] loss = 0.58950, acc = 0.82738\n",
      "[ EMA Valid | 007/1000 ] loss = 0.57916, acc = 0.82622\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/53 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "59822672d6e04afbb48a6803bfda4f89"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ Train | 008/1000 ] loss = 0.46247\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/27 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "be5317a3395643ef825c2ccc0238ef16"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ Valid | 008/1000 ] loss = 0.60865, acc = 0.82622\n",
      "[ EMA Valid | 008/1000 ] loss = 0.57916, acc = 0.82622\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/53 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "29d23c1bc1bc49048be2ec659fb8a9df"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ Train | 009/1000 ] loss = 0.49506\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/27 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "2289c6db79f54911b77f1867d1bbad86"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ Valid | 009/1000 ] loss = 0.61255, acc = 0.82159\n",
      "[ EMA Valid | 009/1000 ] loss = 0.57916, acc = 0.82622\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/53 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "85b2f4269b164b21aefa74b20c8258a5"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ Train | 010/1000 ] loss = 0.50873\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/27 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "3e672f2801c341ffa288f97107533275"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ Valid | 010/1000 ] loss = 0.60349, acc = 0.82391\n",
      "[ EMA Valid | 010/1000 ] loss = 0.57916, acc = 0.82622\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/53 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "f15ef2ffcd214b7a8bbfb59d1e7a80ba"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ Train | 011/1000 ] loss = 0.58341\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/27 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "ab60df7d2d394fa2964314c36192fae7"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ Valid | 011/1000 ] loss = 0.58912, acc = 0.82275\n",
      "[ EMA Valid | 011/1000 ] loss = 0.57916, acc = 0.82622\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/53 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "1b8a9fba29b74a299ac67b11bea77c8e"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ Train | 012/1000 ] loss = 0.54053\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/27 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "6d38545bc55d43fba3683e5e3682050c"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ Valid | 012/1000 ] loss = 0.59733, acc = 0.82275\n",
      "[ EMA Valid | 012/1000 ] loss = 0.57916, acc = 0.82622\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/53 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "47ebb93f1ccc4b87864f62af052b9214"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ Train | 013/1000 ] loss = 0.55028\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/27 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "9668b2f013d74cecb61c045fa6e3b2c7"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ Valid | 013/1000 ] loss = 0.59702, acc = 0.82099\n",
      "[ EMA Valid | 013/1000 ] loss = 0.57916, acc = 0.82622\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/53 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "0c8e0bdf2e3445b7b54dae0d7d97d081"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ Train | 014/1000 ] loss = 0.45461\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/27 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "9c587fe6dd684b938aa361a9e9e0d4a2"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ Valid | 014/1000 ] loss = 0.59152, acc = 0.82622\n",
      "[ EMA Valid | 014/1000 ] loss = 0.57916, acc = 0.82622\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/53 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "b0f4ddbd547d4bb283c6a2e6a6f76807"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ Train | 015/1000 ] loss = 0.53695\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/27 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "cf4b87ad4fc74c76bd10cf34a4474fd7"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ Valid | 015/1000 ] loss = 0.58888, acc = 0.83085\n",
      "[ EMA Valid | 015/1000 ] loss = 0.57916, acc = 0.82622\n",
      "[015/1000] saving model with acc 0.831\n",
      "New best validation accuracy: 0.8309. Lowering threshold to 0.7500\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/53 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "06ca31531e0c424da2e6575102bfde98"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ Train | 016/1000 ] loss = 0.56302\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/27 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "4826746e418f4c17b23f6f4576c04cbe"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ Valid | 016/1000 ] loss = 0.59206, acc = 0.82622\n",
      "[ EMA Valid | 016/1000 ] loss = 0.57916, acc = 0.82622\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/53 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "db7680a60c8d4e06973ac0493d95bee2"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ Train | 017/1000 ] loss = 0.63184\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/27 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "4fd51f6981c0447383136d53df3e6bed"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ Valid | 017/1000 ] loss = 0.59883, acc = 0.82622\n",
      "[ EMA Valid | 017/1000 ] loss = 0.57916, acc = 0.82622\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/53 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "e362b8843ff3480792715fb77b303309"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ Train | 018/1000 ] loss = 0.64537\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/27 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "b5bd139e2c5b48f49b75ea7f090ded9a"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ Valid | 018/1000 ] loss = 0.58897, acc = 0.83085\n",
      "[ EMA Valid | 018/1000 ] loss = 0.57916, acc = 0.82622\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/53 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "0cd8b423217948539fe35b4ba428da84"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ Train | 019/1000 ] loss = 0.54922\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/27 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "cb1aef8758d74368ad98715e75d20fae"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ Valid | 019/1000 ] loss = 0.59272, acc = 0.82507\n",
      "[ EMA Valid | 019/1000 ] loss = 0.57916, acc = 0.82622\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/53 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "9fa26df24f6f488fb83f1a21b4b428a9"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ Train | 020/1000 ] loss = 0.60369\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/27 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "ddbd9a52400b405482880ebeb75081ef"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ Valid | 020/1000 ] loss = 0.59302, acc = 0.82507\n",
      "[ EMA Valid | 020/1000 ] loss = 0.57916, acc = 0.82622\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/53 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "d51dba16929c49d1b12e1e73a7743f79"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ Train | 021/1000 ] loss = 0.58982\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/27 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "ea279897389b415ebae605d664b013e8"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ Valid | 021/1000 ] loss = 0.58828, acc = 0.82970\n",
      "[ EMA Valid | 021/1000 ] loss = 0.57916, acc = 0.82622\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/53 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "764bdd1b8e14478482d42924eb31252a"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ Train | 022/1000 ] loss = 0.57523\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/27 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "273602bdf5f34ef494470a93d5596d86"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ Valid | 022/1000 ] loss = 0.59214, acc = 0.82507\n",
      "[ EMA Valid | 022/1000 ] loss = 0.57916, acc = 0.82622\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/53 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "e703c2ebf95f458aad5398e683719d2d"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ Train | 023/1000 ] loss = 0.55964\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/27 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "360215ba6c034d6aba9d9aa400a6534f"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ Valid | 023/1000 ] loss = 0.60999, acc = 0.81812\n",
      "[ EMA Valid | 023/1000 ] loss = 0.57916, acc = 0.82622\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/53 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "89e51893b21149a5a889f324cca66165"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ Train | 024/1000 ] loss = 0.60690\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/27 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "636e2f4005a84b90ac586d9e2480a4f8"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ Valid | 024/1000 ] loss = 0.60379, acc = 0.82507\n",
      "[ EMA Valid | 024/1000 ] loss = 0.57916, acc = 0.82622\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/53 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "c1022f46add14258b6acebeebe0946ac"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ Train | 025/1000 ] loss = 0.58192\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/27 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "a6525325d29348bd9b8be23c97bc4ed1"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ Valid | 025/1000 ] loss = 0.60210, acc = 0.82738\n",
      "[ EMA Valid | 025/1000 ] loss = 0.57916, acc = 0.82622\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/53 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "256e71fb85ce473dbca2ecdeed26c628"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ Train | 026/1000 ] loss = 0.59592\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/27 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "4fb1109afeda44679b8532d370ad3d15"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ Valid | 026/1000 ] loss = 0.60321, acc = 0.82622\n",
      "[ EMA Valid | 026/1000 ] loss = 0.57916, acc = 0.82622\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/53 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "dd441ca92edd4b01abb66a199892a4f6"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ Train | 027/1000 ] loss = 0.58033\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/27 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "3a38a40f638443b4bfafe1ad708e3aad"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ Valid | 027/1000 ] loss = 0.59841, acc = 0.82330\n",
      "[ EMA Valid | 027/1000 ] loss = 0.57916, acc = 0.82622\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/53 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "5feddb53ef8548a9bb2adf8705d2fb7e"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ Train | 028/1000 ] loss = 0.56584\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/27 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "f2a6e12198354f70a0dc8d2b3d7fb900"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ Valid | 028/1000 ] loss = 0.58993, acc = 0.83317\n",
      "[ EMA Valid | 028/1000 ] loss = 0.57916, acc = 0.82622\n",
      "[028/1000] saving model with acc 0.833\n",
      "New best validation accuracy: 0.8332. Lowering threshold to 0.7000\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/53 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "1b7c93f7c0d148019f18a57e30c5d985"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ Train | 029/1000 ] loss = 0.61991\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/27 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "7ae325fb8bb64f17845c2b3afcbe5f94"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ Valid | 029/1000 ] loss = 0.61370, acc = 0.82159\n",
      "[ EMA Valid | 029/1000 ] loss = 0.57916, acc = 0.82622\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/53 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "6c5f0ff971c2499587808c023d02a659"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ Train | 030/1000 ] loss = 0.60494\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/27 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "032f05ab619b49b5a88c90001ae5c2b9"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ Valid | 030/1000 ] loss = 0.59940, acc = 0.82507\n",
      "[ EMA Valid | 030/1000 ] loss = 0.57916, acc = 0.82622\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/53 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "251108cfb2cc4ea8b0324528a240544e"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ Train | 031/1000 ] loss = 0.56870\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/27 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "d98da5e7b3c04006a8b9e7037c6f5803"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ Valid | 031/1000 ] loss = 0.60028, acc = 0.82622\n",
      "[ EMA Valid | 031/1000 ] loss = 0.57916, acc = 0.82622\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/53 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "f5338f93fb8c4251a939870af25649a7"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ Train | 032/1000 ] loss = 0.61323\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/27 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "598e01ee99eb488192f561897a99406f"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ Valid | 032/1000 ] loss = 0.60072, acc = 0.82275\n",
      "[ EMA Valid | 032/1000 ] loss = 0.57916, acc = 0.82622\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/53 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "2a8f5df09a644f2189c63305cc24fc58"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ Train | 033/1000 ] loss = 0.59614\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/27 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "126830444d6d4a1789b3b019c5167355"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ Valid | 033/1000 ] loss = 0.58878, acc = 0.82562\n",
      "[ EMA Valid | 033/1000 ] loss = 0.57916, acc = 0.82622\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/53 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "302adcb6d0244631bbfb26cb6bc79ef2"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ Train | 034/1000 ] loss = 0.57044\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/27 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "984262ab0bbc4d9a99fb013b4d45bee6"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ Valid | 034/1000 ] loss = 0.60394, acc = 0.82507\n",
      "[ EMA Valid | 034/1000 ] loss = 0.57916, acc = 0.82622\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/53 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "576dc45ec8a0465883f2e9069c3ee4cb"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ Train | 035/1000 ] loss = 0.60874\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/27 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "442a2620d940456580b0feae5ba177da"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ Valid | 035/1000 ] loss = 0.59328, acc = 0.83201\n",
      "[ EMA Valid | 035/1000 ] loss = 0.57916, acc = 0.82622\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/53 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "66f810e9bb0d4c2aab3ba3af139a00d7"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ Train | 036/1000 ] loss = 0.61046\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/27 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "b25a5776c214465f8e356982ee291ab7"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ Valid | 036/1000 ] loss = 0.59968, acc = 0.82391\n",
      "[ EMA Valid | 036/1000 ] loss = 0.57916, acc = 0.82622\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/53 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "89ae418bf4da4891803112bcace29a83"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ Train | 037/1000 ] loss = 0.60256\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/27 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "15d7972b65d144ecbc3b3937889b87e3"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ Valid | 037/1000 ] loss = 0.58548, acc = 0.82391\n",
      "[ EMA Valid | 037/1000 ] loss = 0.57916, acc = 0.82622\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/53 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "2004fe3d576e4a10b5bf54418264e55d"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ Train | 038/1000 ] loss = 0.57958\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/27 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "3a7532e59ad649ea9b5c1f63c7f86190"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ Valid | 038/1000 ] loss = 0.60366, acc = 0.81812\n",
      "[ EMA Valid | 038/1000 ] loss = 0.57916, acc = 0.82622\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/53 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "2a8f7084c84e422ea7d36ed6e14342a9"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ Train | 039/1000 ] loss = 0.65347\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/27 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "219cb14938b148c5a897e3e177a674de"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ Valid | 039/1000 ] loss = 0.58668, acc = 0.83085\n",
      "[ EMA Valid | 039/1000 ] loss = 0.57916, acc = 0.82622\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/53 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "af6d61a3ca644e75b5c43df35dc54ba4"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ Train | 040/1000 ] loss = 0.63289\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/27 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "6e7067abbf5346a3839584e1362a9953"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ Valid | 040/1000 ] loss = 0.59472, acc = 0.82622\n",
      "[ EMA Valid | 040/1000 ] loss = 0.57916, acc = 0.82622\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/53 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "020489544856467a9f1bf2366b89cea4"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ Train | 041/1000 ] loss = 0.55046\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/27 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "30a2d5c25440447cb0dc2d316c1633c8"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ Valid | 041/1000 ] loss = 0.59391, acc = 0.82330\n",
      "[ EMA Valid | 041/1000 ] loss = 0.57916, acc = 0.82622\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/53 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "3852a4597b3045db985ae1cd5026b1f8"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ Train | 042/1000 ] loss = 0.62640\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/27 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "3e7ead8134e34d2d932f9087cc4f6592"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ Valid | 042/1000 ] loss = 0.59472, acc = 0.82970\n",
      "[ EMA Valid | 042/1000 ] loss = 0.57916, acc = 0.82622\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/53 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "354fdfc59b6a44afa1e6397035051789"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ Train | 043/1000 ] loss = 0.56278\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/27 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "ac8524d7dfa64c34ab6af7058d874ca4"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ Valid | 043/1000 ] loss = 0.59367, acc = 0.82391\n",
      "[ EMA Valid | 043/1000 ] loss = 0.57916, acc = 0.82622\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/53 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "48c886eb662b49568207127c162fc5bc"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ Train | 044/1000 ] loss = 0.59289\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/27 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "038e08a6c4274faaa479c03ca0cd7226"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ Valid | 044/1000 ] loss = 0.59117, acc = 0.82507\n",
      "[ EMA Valid | 044/1000 ] loss = 0.57916, acc = 0.82622\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/53 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "0b2ff6856670407199c4424963cbe62d"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ Train | 045/1000 ] loss = 0.67270\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/27 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "787370206ee54a4c90282932f22176fe"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ Valid | 045/1000 ] loss = 0.60321, acc = 0.82275\n",
      "[ EMA Valid | 045/1000 ] loss = 0.57916, acc = 0.82622\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/53 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "04cdf0afff3443d1b5439eda4c8cfe1b"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ Train | 046/1000 ] loss = 0.63608\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/27 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "8f71081139ac483aa4032e1eb39ee2b1"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ Valid | 046/1000 ] loss = 0.60606, acc = 0.82044\n",
      "[ EMA Valid | 046/1000 ] loss = 0.57916, acc = 0.82622\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/53 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "3867462c975c4930a035eb6a8e1e76c2"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ Train | 047/1000 ] loss = 0.61274\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/27 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "f7bce46e754740aca4b2dd0891dab606"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ Valid | 047/1000 ] loss = 0.61225, acc = 0.82159\n",
      "[ EMA Valid | 047/1000 ] loss = 0.57916, acc = 0.82622\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/53 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "70dd0726356b464cab0ebef27b6f96d1"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ Train | 048/1000 ] loss = 0.57823\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/27 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "d05104712d1b4713bd728ff0d57f4183"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ Valid | 048/1000 ] loss = 0.59650, acc = 0.82391\n",
      "[ EMA Valid | 048/1000 ] loss = 0.57916, acc = 0.82622\n",
      "Early stopping.\n"
     ]
    }
   ],
   "source": [
    "import copy\n",
    "import sys\n",
    "from tqdm.auto import tqdm\n",
    "sys.setrecursionlimit(1000000)\n",
    "#########################################################################################################\n",
    "#         You can adjust those hyper parameters like epochs or threshlod for training                   #\n",
    "#########################################################################################################\n",
    "# FixMatch Semi-Supervise\n",
    "# https://arxiv.org/ftp/arxiv/papers/2001/2001.07685.pdf\n",
    "alpha = 0.9                 # Mix-up parameter\n",
    "initial_weight = 0.1        # Initial weight for the EMA model\n",
    "step = 0.1                  # Step size for the EMA model\n",
    "n_epochs = 1000             # Number of epochs to train for\n",
    "temperature = 2             # Temperature for sharpening the pseudo-labels\n",
    "threshold = 0.9             # Threshold for the pseudo-labels\n",
    "threshold_decay = 0.05      # Decay rate for the threshold\n",
    "min_threshold = 0.7         # Minimum threshold for the pseudo-labels\n",
    "early_stopping_limit = 20   # Number of epochs to wait for improvement in validation loss\n",
    "\n",
    "# ckpt = torch.load('IB-CONV_Self_Train_2023-11-01-14-58.pt')\n",
    "# model.load_state_dict(ckpt)\n",
    "\n",
    "# Copy the model\n",
    "teacher_model = copy.deepcopy(model)\n",
    "student_model = copy.deepcopy(model)\n",
    "\n",
    "# CrossEntropyLoss for classification tasks different from FixMatch\n",
    "criterion_label = nn.CrossEntropyLoss(reduction='mean').to(device)\n",
    "criterion_unlabeled = nn.CrossEntropyLoss(reduction='none').to(device)\n",
    "\n",
    "# Reset the counter\n",
    "global_step = 0\n",
    "best_acc = 0\n",
    "early_stopping_counter = 0\n",
    "\n",
    "def update_ema_weights(student_model, teacher_model, ema_decay, global_step):\n",
    "    \"\"\"\n",
    "    Update the weights of the teacher_model based on the weights of the student_model.\n",
    "\n",
    "    Parameters:\n",
    "    - student_model (torch.nn.Module): Main model (student) whose weights are used for the update.\n",
    "    - teacher_model (torch.nn.Module): Model (teacher) to be updated.\n",
    "    - ema_decay (float): Decay rate for the EMA.\n",
    "    - global_step (int): Current step in the training loop.\n",
    "\n",
    "    Returns:\n",
    "    - None\n",
    "    \"\"\"\n",
    "    # Calculate decay rate for this specific step\n",
    "    decay = min(ema_decay, (1.0 + global_step) / (10.0 + global_step))\n",
    "\n",
    "    # Update the EMA model\n",
    "    with torch.no_grad():\n",
    "        for ema_params, params in zip(teacher_model.parameters(), student_model.parameters()):\n",
    "            ema_params.data.mul_(decay).add_(params.data, alpha=1 - decay)\n",
    "\n",
    "\n",
    "# Define two different sets of transforms\n",
    "transforms_less = transforms.Compose([\n",
    "    transforms.Resize(256),                               # Resize to a fixed size\n",
    "    transforms.CenterCrop(224),                           # Center crop\n",
    "    transforms.ToTensor(),                                # Convert to tensor\n",
    "    transforms.Normalize(mean=train_mean, std=train_std)  # Normalize\n",
    "])\n",
    "transforms_more = transforms.Compose([\n",
    "    transforms.RandomResizedCrop(224),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomVerticalFlip(),\n",
    "    transforms.RandomRotation(30),\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=train_mean, std=train_std)\n",
    "])\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(n_epochs):\n",
    "     #########################################################################################################\n",
    "    #    TODO:                                                                                              #\n",
    "    #    In each epoch, relabel the unlabeled dataset for semi-supervised learning.                         #\n",
    "    #    1. Obtain pseudo-labels for unlabeled data using trained model.(use get_pseudo_labels function)    #\n",
    "    #    2. Construct a new dataset and a data loader for training.                                         #\n",
    "    #    You can try different way to use the get_pseudo_label function maybe will get the better result.   #                                  #\n",
    "    #########################################################################################################\n",
    "    # Create data loaders for labeled and unlabeled data\n",
    "    labeled_loader = DataLoader(train_set, batch_size=batch_size//2, shuffle=True)\n",
    "    unlabeled_set = FlowerData('train_unlabeled_dataset.csv', mode='unlabeled_train', transform=None)\n",
    "    unlabeled_loader = DataLoader(unlabeled_set, batch_size=batch_size//2, shuffle=True, drop_last=True)\n",
    "     #########################################################################################################\n",
    "    #                                          End of your code                                             #\n",
    "    #########################################################################################################\n",
    "\n",
    "    # ---------- Training ----------\n",
    "\n",
    "    train_loss = []\n",
    "    student_model.train()\n",
    "\n",
    "    # Create tqdm object based on the data loader\n",
    "    pbar = tqdm(zip(labeled_loader, unlabeled_loader), total=len(labeled_loader))\n",
    "\n",
    "    for (labeled_batch, unlabeled_batch) in pbar:\n",
    "        # Apply the less aggressive transform to unlabeled_batch for the teacher model\n",
    "        teacher_images = [transforms_less(Image.open(img)) for img in unlabeled_batch]\n",
    "        teacher_images = torch.stack(teacher_images).to(device)\n",
    "\n",
    "        # Apply the more aggressive transform to unlabeled_batch for the student model\n",
    "        student_images = [transforms_more(Image.open(img)) for img in unlabeled_batch]\n",
    "        student_images = torch.stack(student_images).to(device)\n",
    "\n",
    "        # Prepare mixed batch\n",
    "        mixed_images = torch.cat([labeled_batch[0].to(device), student_images], dim=0)\n",
    "        labels = labeled_batch[1]  # Only the labeled part has labels\n",
    "\n",
    "        # Forward pass through a student\n",
    "        logits_student = student_model(mixed_images)\n",
    "\n",
    "        # Calculate Loss for labeled data\n",
    "        loss_labeled = criterion_label(logits_student[:len(labeled_batch[0])], labels.to(device))\n",
    "\n",
    "        with torch.no_grad():\n",
    "            # Add noise to teacher's logits\n",
    "            logits_teacher = teacher_model(teacher_images)\n",
    "\n",
    "        # Apply softmax and get the most confident predictions\n",
    "        probs = torch.softmax(logits_teacher.detach() / temperature, dim=-1)\n",
    "        max_prob, predicted_label = torch.max(probs, 1)\n",
    "        mask = max_prob.ge(threshold).float()\n",
    "\n",
    "        # Calculate Loss for unlabeled data\n",
    "        loss_unlabeled = (criterion_unlabeled(logits_student[len(labeled_batch[0]):], predicted_label) * mask).mean()\n",
    "\n",
    "        # Combine the two losses, backpropagation, and update student model\n",
    "        unlabeled_loss_weight = min(1, initial_weight + step * epoch)\n",
    "        loss = loss_labeled + unlabeled_loss_weight * loss_unlabeled\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Update the EMA model\n",
    "        update_ema_weights(student_model, teacher_model, alpha, global_step)\n",
    "\n",
    "        train_loss.append(loss.item())\n",
    "\n",
    "        global_step += 1\n",
    "\n",
    "    train_loss = sum(train_loss) / len(train_loss)\n",
    "\n",
    "    print(f\"[ Train | {epoch + 1:03d}/{n_epochs:03d} ] loss = {train_loss:.5f}\")\n",
    "\n",
    "    # ---------- Validation ----------\n",
    "    student_model.eval()\n",
    "    teacher_model.eval()\n",
    "\n",
    "    valid_loss = []\n",
    "    valid_accs = []\n",
    "    valid_loss_ema = []\n",
    "    valid_accs_ema = []\n",
    "\n",
    "    # Create tqdm object based on the valid loader\n",
    "    for batch in tqdm(valid_loader):\n",
    "        imgs, labels = batch\n",
    "\n",
    "        # Forward propagation\n",
    "        with torch.no_grad():\n",
    "            logits = student_model(imgs.to(device))\n",
    "            logits_ema = teacher_model(imgs.to(device))\n",
    "\n",
    "        # Calculate loss\n",
    "        loss = criterion_label(logits, labels.to(device))\n",
    "        loss_ema = criterion_label(logits_ema, labels.to(device))\n",
    "\n",
    "        # Calculate accuracy\n",
    "        acc = (logits.argmax(dim=-1) == labels.to(device)).float().mean()\n",
    "        acc_ema = (logits_ema.argmax(dim=-1) == labels.to(device)).float().mean()\n",
    "\n",
    "        # Save the loss and accuracy\n",
    "        valid_loss.append(loss.item())\n",
    "        valid_accs.append(acc)\n",
    "\n",
    "        valid_loss_ema.append(loss_ema.item())\n",
    "        valid_accs_ema.append(acc_ema)\n",
    "\n",
    "    valid_loss = sum(valid_loss) / len(valid_loss)\n",
    "    valid_acc = sum(valid_accs) / len(valid_accs)\n",
    "\n",
    "    valid_loss_ema = sum(valid_loss_ema) / len(valid_loss_ema)\n",
    "    valid_acc_ema = sum(valid_accs_ema) / len(valid_accs_ema)\n",
    "\n",
    "    scheduler.step(valid_loss)\n",
    "\n",
    "    print(f\"[ Valid | {epoch + 1:03d}/{n_epochs:03d} ] loss = {valid_loss:.5f}, acc = {valid_acc:.5f}\")\n",
    "    print(f\"[ EMA Valid | {epoch + 1:03d}/{n_epochs:03d} ] loss = {valid_loss_ema:.5f}, acc = {valid_acc_ema:.5f}\")\n",
    "\n",
    "    # Save the model with the best validation accuracy\n",
    "    if valid_acc > best_acc:\n",
    "        best_acc = valid_acc\n",
    "        torch.save(model.state_dict(), 'FixMatchModel.pt')\n",
    "        print('[{:03d}/{:03d}] saving model with acc {:.3f}'.format(epoch + 1, n_epochs, best_acc))\n",
    "        # Lower the threshold if the model improves on the validation set\n",
    "        early_stopping_counter = 0\n",
    "        threshold = max(min_threshold, threshold - threshold_decay)\n",
    "        print(f\"New best validation accuracy: {best_acc:.4f}. Lowering threshold to {threshold:.4f}\")\n",
    "\n",
    "    # Stop training if the model does not improve for a while\n",
    "    if valid_acc < best_acc:\n",
    "        early_stopping_counter += 1\n",
    "\n",
    "        if early_stopping_counter >= early_stopping_limit:\n",
    "            print(\"Early stopping.\")\n",
    "            break\n",
    "#########################################################################################################\n",
    "#                               End of your code                                                        #\n",
    "#########################################################################################################"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-01T10:15:05.755509900Z",
     "start_time": "2023-11-01T09:57:29.821070700Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "outputs": [],
   "source": [
    "# save your well-trained state_dict of model\n",
    "from datetime import datetime\n",
    "\n",
    "# Get the current timestamp\n",
    "timestamp = datetime.now().strftime(\"%Y-%m-%d-%H-%M\")\n",
    "torch.save(model.state_dict(), f'IB-CONV_Self_Train_{timestamp}.pt')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-01T07:58:40.778341400Z",
     "start_time": "2023-11-01T07:58:40.720892500Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Predict Result\n",
    "\n",
    "Predict the labesl based on testing set. Upload to [Kaggle](https://www.kaggle.com/t/e304bb12c8a84e5c9c1b27a6c3bd4026).\n",
    "\n",
    "**How to upload**\n",
    "\n",
    "1. Click the folder icon in the left hand side of Colab.\n",
    "2. Right click \"result.csv\". Select \"Download\"\n",
    "3. To kaggle. Click \"Submit Predictions\"\n",
    "4. Upload the result.csv\n",
    "5. System will automaticlaly calculate the accuracy of 50% dataset and publish this result to leaderboard.\n",
    "\n",
    "---\n",
    "\n",
    "預測`test`並將結果上傳至Kaggle。[**連結**](https://www.kaggle.com/t/e304bb12c8a84e5c9c1b27a6c3bd4026)\n",
    "\n",
    "執行完畢此區的程式碼後，會將`test`預測完的結果存下來。\n",
    "\n",
    "上傳流程\n",
    "1. 點選左側選單最下方的資料夾圖示\n",
    "2. 右鍵「result.csv」\n",
    "3. 點選「Download」\n",
    "4. 至連結網頁點選「Submit Predictions」\n",
    "5. 將剛剛下載的檔案上傳\n",
    "6. 系統會計算並公布其中50%資料的正確率"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "data": {
      "text/plain": "<All keys matched successfully>"
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# if you wanna load previous best model\n",
    "ckpt = torch.load('FixMatchModel.pt')\n",
    "model.load_state_dict(ckpt)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-01T11:12:36.184372600Z",
     "start_time": "2023-11-01T11:12:36.108809600Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [],
   "source": [
    "test_set = FlowerData('test.csv', mode='test', transform=transforms_test)\n",
    "test_loader = DataLoader(test_set, batch_size=batch_size, num_workers=num_workers, shuffle=False)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-01T11:12:44.744282700Z",
     "start_time": "2023-11-01T11:12:44.697002700Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [],
   "source": [
    "def predict(input_data, model):\n",
    "    model.eval()\n",
    "    output_list = []\n",
    "    with torch.no_grad():\n",
    "        for images in input_data:\n",
    "            images = images.to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            output_list.extend(predicted.to('cpu').numpy().tolist())\n",
    "    return output_list"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-01T11:12:44.751272800Z",
     "start_time": "2023-11-01T11:12:44.745279Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-01T11:12:57.278320900Z",
     "start_time": "2023-11-01T11:12:44.745279Z"
    }
   },
   "outputs": [],
   "source": [
    "idx = 0\n",
    "output_csv = predict(test_loader, model)\n",
    "with open('result.csv', 'w', newline='') as csvFile:\n",
    "    writer = csv.DictWriter(csvFile, fieldnames=['file_path', 'label'])\n",
    "    writer.writeheader()\n",
    "    for result in output_csv:\n",
    "        file_path = test_set.data_list[idx].replace(data_folder + '/', '')\n",
    "        writer.writerow({'file_path':file_path, 'label':result})\n",
    "        idx += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "(dot.exe:24916): Pango-WARNING **: couldn't load font \"Linux libertine Not-Rotated 10\", falling back to \"Sans Not-Rotated 10\", expect ugly output.\n"
     ]
    },
    {
     "data": {
      "image/svg+xml": "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<!-- Generated by graphviz version 9.0.0 (20230911.1827)\n -->\n<!-- Title: model Pages: 1 -->\n<svg width=\"218pt\" height=\"3694pt\"\n viewBox=\"0.00 0.00 218.11 3694.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n<g id=\"graph0\" class=\"graph\" transform=\"scale(0.73192 0.73192) rotate(0) translate(4 5043)\">\n<title>model</title>\n<polygon fill=\"white\" stroke=\"none\" points=\"-4,4 -4,-5043 294,-5043 294,4 -4,4\"/>\n<g id=\"clust2\" class=\"cluster\">\n<title>cluster_3</title>\n<polygon fill=\"none\" stroke=\"black\" stroke-dasharray=\"5,2\" points=\"8,-794.5 8,-4746.75 282,-4746.75 282,-794.5 8,-794.5\"/>\n<text text-anchor=\"middle\" x=\"39.25\" y=\"-4731.35\" font-family=\"Times New Roman,serif\" font-size=\"12.00\">Sequential</text>\n</g>\n<g id=\"clust5\" class=\"cluster\">\n<title>cluster_6</title>\n<polygon fill=\"none\" stroke=\"black\" stroke-dasharray=\"5,2\" points=\"16,-3333.75 16,-3896 262,-3896 262,-3333.75 16,-3333.75\"/>\n<text text-anchor=\"middle\" x=\"59.62\" y=\"-3880.6\" font-family=\"Times New Roman,serif\" font-size=\"12.00\">IBConvWithSE</text>\n</g>\n<g id=\"clust3\" class=\"cluster\">\n<title>cluster_4</title>\n<polygon fill=\"none\" stroke=\"black\" stroke-dasharray=\"5,2\" points=\"22,-4314.25 22,-4716.5 268,-4716.5 268,-4314.25 22,-4314.25\"/>\n<text text-anchor=\"middle\" x=\"65.62\" y=\"-4701.1\" font-family=\"Times New Roman,serif\" font-size=\"12.00\">IBConvWithSE</text>\n</g>\n<g id=\"clust4\" class=\"cluster\">\n<title>cluster_5</title>\n<polygon fill=\"none\" stroke=\"black\" stroke-dasharray=\"5,2\" points=\"38,-3904 38,-4306.25 274,-4306.25 274,-3904 38,-3904\"/>\n<text text-anchor=\"middle\" x=\"81.62\" y=\"-4290.85\" font-family=\"Times New Roman,serif\" font-size=\"12.00\">IBConvWithSE</text>\n</g>\n<g id=\"clust7\" class=\"cluster\">\n<title>cluster_8</title>\n<polygon fill=\"none\" stroke=\"black\" stroke-dasharray=\"5,2\" points=\"16,-2353.25 16,-2915.5 262,-2915.5 262,-2353.25 16,-2353.25\"/>\n<text text-anchor=\"middle\" x=\"59.62\" y=\"-2900.1\" font-family=\"Times New Roman,serif\" font-size=\"12.00\">IBConvWithSE</text>\n</g>\n<g id=\"clust9\" class=\"cluster\">\n<title>cluster_10</title>\n<polygon fill=\"none\" stroke=\"black\" stroke-dasharray=\"5,2\" points=\"16,-1372.75 16,-1935 262,-1935 262,-1372.75 16,-1372.75\"/>\n<text text-anchor=\"middle\" x=\"59.62\" y=\"-1919.6\" font-family=\"Times New Roman,serif\" font-size=\"12.00\">IBConvWithSE</text>\n</g>\n<g id=\"clust8\" class=\"cluster\">\n<title>cluster_9</title>\n<polygon fill=\"none\" stroke=\"black\" stroke-dasharray=\"5,2\" points=\"28,-1943 28,-2345.25 274,-2345.25 274,-1943 28,-1943\"/>\n<text text-anchor=\"middle\" x=\"71.62\" y=\"-2329.85\" font-family=\"Times New Roman,serif\" font-size=\"12.00\">IBConvWithSE</text>\n</g>\n<g id=\"clust6\" class=\"cluster\">\n<title>cluster_7</title>\n<polygon fill=\"none\" stroke=\"black\" stroke-dasharray=\"5,2\" points=\"28,-2923.5 28,-3325.75 274,-3325.75 274,-2923.5 28,-2923.5\"/>\n<text text-anchor=\"middle\" x=\"71.62\" y=\"-3310.35\" font-family=\"Times New Roman,serif\" font-size=\"12.00\">IBConvWithSE</text>\n</g>\n<g id=\"clust10\" class=\"cluster\">\n<title>cluster_11</title>\n<polygon fill=\"none\" stroke=\"black\" stroke-dasharray=\"5,2\" points=\"16,-802.5 16,-1364.75 262,-1364.75 262,-802.5 16,-802.5\"/>\n<text text-anchor=\"middle\" x=\"59.62\" y=\"-1349.35\" font-family=\"Times New Roman,serif\" font-size=\"12.00\">IBConvWithSE</text>\n</g>\n<g id=\"clust1\" class=\"cluster\">\n<title>cluster_2</title>\n<polygon fill=\"none\" stroke=\"black\" stroke-dasharray=\"5,2\" points=\"27,-4754.75 27,-4997 239,-4997 239,-4754.75 27,-4754.75\"/>\n<text text-anchor=\"middle\" x=\"58.25\" y=\"-4981.6\" font-family=\"Times New Roman,serif\" font-size=\"12.00\">Sequential</text>\n</g>\n<g id=\"clust12\" class=\"cluster\">\n<title>cluster_13</title>\n<polygon fill=\"none\" stroke=\"black\" stroke-dasharray=\"5,2\" points=\"71,-142 71,-384.25 245,-384.25 245,-142 71,-142\"/>\n<text text-anchor=\"middle\" x=\"102.25\" y=\"-368.85\" font-family=\"Times New Roman,serif\" font-size=\"12.00\">Sequential</text>\n</g>\n<g id=\"clust11\" class=\"cluster\">\n<title>cluster_12</title>\n<polygon fill=\"none\" stroke=\"black\" stroke-dasharray=\"5,2\" points=\"52,-544.25 52,-786.5 264,-786.5 264,-544.25 52,-544.25\"/>\n<text text-anchor=\"middle\" x=\"83.25\" y=\"-771.1\" font-family=\"Times New Roman,serif\" font-size=\"12.00\">Sequential</text>\n</g>\n<!-- 0 -->\n<g id=\"node1\" class=\"node\">\n<title>0</title>\n<polygon fill=\"lightyellow\" stroke=\"none\" points=\"202.62,-5039 63.38,-5039 63.38,-5005 202.62,-5005 202.62,-5039\"/>\n<polygon fill=\"none\" stroke=\"black\" points=\"63.38,-5005 63.38,-5039 125.12,-5039 125.12,-5005 63.38,-5005\"/>\n<text text-anchor=\"start\" x=\"68.38\" y=\"-5024.5\" font-family=\"Linux libertine\" font-size=\"10.00\">input&#45;tensor</text>\n<text text-anchor=\"start\" x=\"77.75\" y=\"-5012.5\" font-family=\"Linux libertine\" font-size=\"10.00\">depth:0</text>\n<polygon fill=\"none\" stroke=\"black\" points=\"125.12,-5005 125.12,-5039 202.62,-5039 202.62,-5005 125.12,-5005\"/>\n<text text-anchor=\"start\" x=\"130.12\" y=\"-5018.5\" font-family=\"Linux libertine\" font-size=\"10.00\">(1, 3, 224, 224)</text>\n</g>\n<!-- 1 -->\n<g id=\"node2\" class=\"node\">\n<title>1</title>\n<polygon fill=\"#c1ffc1\" stroke=\"none\" points=\"218.5,-4966.75 47.5,-4966.75 47.5,-4922.75 218.5,-4922.75 218.5,-4966.75\"/>\n<polygon fill=\"none\" stroke=\"black\" points=\"47.5,-4922.75 47.5,-4966.75 90.5,-4966.75 90.5,-4922.75 47.5,-4922.75\"/>\n<text text-anchor=\"start\" x=\"53.25\" y=\"-4947.25\" font-family=\"Linux libertine\" font-size=\"10.00\">Conv2d</text>\n<text text-anchor=\"start\" x=\"52.5\" y=\"-4935.25\" font-family=\"Linux libertine\" font-size=\"10.00\">depth:2</text>\n<polygon fill=\"none\" stroke=\"black\" points=\"90.5,-4944.75 90.5,-4966.75 133.5,-4966.75 133.5,-4944.75 90.5,-4944.75\"/>\n<text text-anchor=\"start\" x=\"99.62\" y=\"-4952.25\" font-family=\"Linux libertine\" font-size=\"10.00\">input:</text>\n<polygon fill=\"none\" stroke=\"black\" points=\"133.5,-4944.75 133.5,-4966.75 218.5,-4966.75 218.5,-4944.75 133.5,-4944.75\"/>\n<text text-anchor=\"start\" x=\"140.75\" y=\"-4952.25\" font-family=\"Linux libertine\" font-size=\"10.00\">(1, 3, 224, 224) </text>\n<polygon fill=\"none\" stroke=\"black\" points=\"90.5,-4922.75 90.5,-4944.75 133.5,-4944.75 133.5,-4922.75 90.5,-4922.75\"/>\n<text text-anchor=\"start\" x=\"95.12\" y=\"-4930.25\" font-family=\"Linux libertine\" font-size=\"10.00\">output: </text>\n<polygon fill=\"none\" stroke=\"black\" points=\"133.5,-4922.75 133.5,-4944.75 218.5,-4944.75 218.5,-4922.75 133.5,-4922.75\"/>\n<text text-anchor=\"start\" x=\"138.12\" y=\"-4930.25\" font-family=\"Linux libertine\" font-size=\"10.00\">(1, 32, 112, 112) </text>\n</g>\n<!-- 0&#45;&gt;1 -->\n<g id=\"edge1\" class=\"edge\">\n<title>0&#45;&gt;1</title>\n<path fill=\"none\" stroke=\"black\" d=\"M133,-5005.04C133,-4997.15 133,-4987.34 133,-4977.98\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"136.5,-4978.06 133,-4968.06 129.5,-4978.06 136.5,-4978.06\"/>\n</g>\n<!-- 2 -->\n<g id=\"node3\" class=\"node\">\n<title>2</title>\n<polygon fill=\"#c1ffc1\" stroke=\"none\" points=\"230.5,-4886.75 35.5,-4886.75 35.5,-4842.75 230.5,-4842.75 230.5,-4886.75\"/>\n<polygon fill=\"none\" stroke=\"black\" points=\"35.5,-4842.75 35.5,-4886.75 102.5,-4886.75 102.5,-4842.75 35.5,-4842.75\"/>\n<text text-anchor=\"start\" x=\"40.5\" y=\"-4867.25\" font-family=\"Linux libertine\" font-size=\"10.00\">BatchNorm2d</text>\n<text text-anchor=\"start\" x=\"52.5\" y=\"-4855.25\" font-family=\"Linux libertine\" font-size=\"10.00\">depth:2</text>\n<polygon fill=\"none\" stroke=\"black\" points=\"102.5,-4864.75 102.5,-4886.75 145.5,-4886.75 145.5,-4864.75 102.5,-4864.75\"/>\n<text text-anchor=\"start\" x=\"111.62\" y=\"-4872.25\" font-family=\"Linux libertine\" font-size=\"10.00\">input:</text>\n<polygon fill=\"none\" stroke=\"black\" points=\"145.5,-4864.75 145.5,-4886.75 230.5,-4886.75 230.5,-4864.75 145.5,-4864.75\"/>\n<text text-anchor=\"start\" x=\"150.12\" y=\"-4872.25\" font-family=\"Linux libertine\" font-size=\"10.00\">(1, 32, 112, 112) </text>\n<polygon fill=\"none\" stroke=\"black\" points=\"102.5,-4842.75 102.5,-4864.75 145.5,-4864.75 145.5,-4842.75 102.5,-4842.75\"/>\n<text text-anchor=\"start\" x=\"107.12\" y=\"-4850.25\" font-family=\"Linux libertine\" font-size=\"10.00\">output: </text>\n<polygon fill=\"none\" stroke=\"black\" points=\"145.5,-4842.75 145.5,-4864.75 230.5,-4864.75 230.5,-4842.75 145.5,-4842.75\"/>\n<text text-anchor=\"start\" x=\"150.12\" y=\"-4850.25\" font-family=\"Linux libertine\" font-size=\"10.00\">(1, 32, 112, 112) </text>\n</g>\n<!-- 1&#45;&gt;2 -->\n<g id=\"edge2\" class=\"edge\">\n<title>1&#45;&gt;2</title>\n<path fill=\"none\" stroke=\"black\" d=\"M133,-4922.85C133,-4915.24 133,-4906.45 133,-4898.09\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"136.5,-4898.22 133,-4888.22 129.5,-4898.22 136.5,-4898.22\"/>\n</g>\n<!-- 3 -->\n<g id=\"node4\" class=\"node\">\n<title>3</title>\n<polygon fill=\"#c1ffc1\" stroke=\"none\" points=\"218.5,-4806.75 47.5,-4806.75 47.5,-4762.75 218.5,-4762.75 218.5,-4806.75\"/>\n<polygon fill=\"none\" stroke=\"black\" points=\"47.5,-4762.75 47.5,-4806.75 90.5,-4806.75 90.5,-4762.75 47.5,-4762.75\"/>\n<text text-anchor=\"start\" x=\"58.12\" y=\"-4787.25\" font-family=\"Linux libertine\" font-size=\"10.00\">SELU</text>\n<text text-anchor=\"start\" x=\"52.5\" y=\"-4775.25\" font-family=\"Linux libertine\" font-size=\"10.00\">depth:2</text>\n<polygon fill=\"none\" stroke=\"black\" points=\"90.5,-4784.75 90.5,-4806.75 133.5,-4806.75 133.5,-4784.75 90.5,-4784.75\"/>\n<text text-anchor=\"start\" x=\"99.62\" y=\"-4792.25\" font-family=\"Linux libertine\" font-size=\"10.00\">input:</text>\n<polygon fill=\"none\" stroke=\"black\" points=\"133.5,-4784.75 133.5,-4806.75 218.5,-4806.75 218.5,-4784.75 133.5,-4784.75\"/>\n<text text-anchor=\"start\" x=\"138.12\" y=\"-4792.25\" font-family=\"Linux libertine\" font-size=\"10.00\">(1, 32, 112, 112) </text>\n<polygon fill=\"none\" stroke=\"black\" points=\"90.5,-4762.75 90.5,-4784.75 133.5,-4784.75 133.5,-4762.75 90.5,-4762.75\"/>\n<text text-anchor=\"start\" x=\"95.12\" y=\"-4770.25\" font-family=\"Linux libertine\" font-size=\"10.00\">output: </text>\n<polygon fill=\"none\" stroke=\"black\" points=\"133.5,-4762.75 133.5,-4784.75 218.5,-4784.75 218.5,-4762.75 133.5,-4762.75\"/>\n<text text-anchor=\"start\" x=\"138.12\" y=\"-4770.25\" font-family=\"Linux libertine\" font-size=\"10.00\">(1, 32, 112, 112) </text>\n</g>\n<!-- 2&#45;&gt;3 -->\n<g id=\"edge3\" class=\"edge\">\n<title>2&#45;&gt;3</title>\n<path fill=\"none\" stroke=\"black\" d=\"M133,-4842.85C133,-4835.24 133,-4826.45 133,-4818.09\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"136.5,-4818.22 133,-4808.22 129.5,-4818.22 136.5,-4818.22\"/>\n</g>\n<!-- 4 -->\n<g id=\"node5\" class=\"node\">\n<title>4</title>\n<polygon fill=\"#c1ffc1\" stroke=\"none\" points=\"224.5,-4686.25 41.5,-4686.25 41.5,-4642.25 224.5,-4642.25 224.5,-4686.25\"/>\n<polygon fill=\"none\" stroke=\"black\" points=\"41.5,-4642.25 41.5,-4686.25 96.5,-4686.25 96.5,-4642.25 41.5,-4642.25\"/>\n<text text-anchor=\"start\" x=\"46.5\" y=\"-4666.75\" font-family=\"Linux libertine\" font-size=\"10.00\">Sequential</text>\n<text text-anchor=\"start\" x=\"52.5\" y=\"-4654.75\" font-family=\"Linux libertine\" font-size=\"10.00\">depth:3</text>\n<polygon fill=\"none\" stroke=\"black\" points=\"96.5,-4664.25 96.5,-4686.25 139.5,-4686.25 139.5,-4664.25 96.5,-4664.25\"/>\n<text text-anchor=\"start\" x=\"105.62\" y=\"-4671.75\" font-family=\"Linux libertine\" font-size=\"10.00\">input:</text>\n<polygon fill=\"none\" stroke=\"black\" points=\"139.5,-4664.25 139.5,-4686.25 224.5,-4686.25 224.5,-4664.25 139.5,-4664.25\"/>\n<text text-anchor=\"start\" x=\"144.12\" y=\"-4671.75\" font-family=\"Linux libertine\" font-size=\"10.00\">(1, 32, 112, 112) </text>\n<polygon fill=\"none\" stroke=\"black\" points=\"96.5,-4642.25 96.5,-4664.25 139.5,-4664.25 139.5,-4642.25 96.5,-4642.25\"/>\n<text text-anchor=\"start\" x=\"101.12\" y=\"-4649.75\" font-family=\"Linux libertine\" font-size=\"10.00\">output: </text>\n<polygon fill=\"none\" stroke=\"black\" points=\"139.5,-4642.25 139.5,-4664.25 224.5,-4664.25 224.5,-4642.25 139.5,-4642.25\"/>\n<text text-anchor=\"start\" x=\"144.12\" y=\"-4649.75\" font-family=\"Linux libertine\" font-size=\"10.00\">(1, 32, 112, 112) </text>\n</g>\n<!-- 3&#45;&gt;4 -->\n<g id=\"edge4\" class=\"edge\">\n<title>3&#45;&gt;4</title>\n<path fill=\"none\" stroke=\"black\" d=\"M133,-4762.84C133,-4744.73 133,-4718.25 133,-4697.44\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"136.5,-4697.47 133,-4687.47 129.5,-4697.47 136.5,-4697.47\"/>\n</g>\n<!-- 5 -->\n<g id=\"node6\" class=\"node\">\n<title>5</title>\n<polygon fill=\"#c1ffc1\" stroke=\"none\" points=\"224.5,-4606.25 41.5,-4606.25 41.5,-4562.25 224.5,-4562.25 224.5,-4606.25\"/>\n<polygon fill=\"none\" stroke=\"black\" points=\"41.5,-4562.25 41.5,-4606.25 96.5,-4606.25 96.5,-4562.25 41.5,-4562.25\"/>\n<text text-anchor=\"start\" x=\"46.5\" y=\"-4586.75\" font-family=\"Linux libertine\" font-size=\"10.00\">Sequential</text>\n<text text-anchor=\"start\" x=\"52.5\" y=\"-4574.75\" font-family=\"Linux libertine\" font-size=\"10.00\">depth:3</text>\n<polygon fill=\"none\" stroke=\"black\" points=\"96.5,-4584.25 96.5,-4606.25 139.5,-4606.25 139.5,-4584.25 96.5,-4584.25\"/>\n<text text-anchor=\"start\" x=\"105.62\" y=\"-4591.75\" font-family=\"Linux libertine\" font-size=\"10.00\">input:</text>\n<polygon fill=\"none\" stroke=\"black\" points=\"139.5,-4584.25 139.5,-4606.25 224.5,-4606.25 224.5,-4584.25 139.5,-4584.25\"/>\n<text text-anchor=\"start\" x=\"144.12\" y=\"-4591.75\" font-family=\"Linux libertine\" font-size=\"10.00\">(1, 32, 112, 112) </text>\n<polygon fill=\"none\" stroke=\"black\" points=\"96.5,-4562.25 96.5,-4584.25 139.5,-4584.25 139.5,-4562.25 96.5,-4562.25\"/>\n<text text-anchor=\"start\" x=\"101.12\" y=\"-4569.75\" font-family=\"Linux libertine\" font-size=\"10.00\">output: </text>\n<polygon fill=\"none\" stroke=\"black\" points=\"139.5,-4562.25 139.5,-4584.25 224.5,-4584.25 224.5,-4562.25 139.5,-4562.25\"/>\n<text text-anchor=\"start\" x=\"144.12\" y=\"-4569.75\" font-family=\"Linux libertine\" font-size=\"10.00\">(1, 32, 112, 112) </text>\n</g>\n<!-- 4&#45;&gt;5 -->\n<g id=\"edge5\" class=\"edge\">\n<title>4&#45;&gt;5</title>\n<path fill=\"none\" stroke=\"black\" d=\"M133,-4642.35C133,-4634.74 133,-4625.95 133,-4617.59\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"136.5,-4617.72 133,-4607.72 129.5,-4617.72 136.5,-4617.72\"/>\n</g>\n<!-- 6 -->\n<g id=\"node7\" class=\"node\">\n<title>6</title>\n<polygon fill=\"#c1ffc1\" stroke=\"none\" points=\"247.5,-4526.25 64.5,-4526.25 64.5,-4482.25 247.5,-4482.25 247.5,-4526.25\"/>\n<polygon fill=\"none\" stroke=\"black\" points=\"64.5,-4482.25 64.5,-4526.25 119.5,-4526.25 119.5,-4482.25 64.5,-4482.25\"/>\n<text text-anchor=\"start\" x=\"69.5\" y=\"-4506.75\" font-family=\"Linux libertine\" font-size=\"10.00\">Sequential</text>\n<text text-anchor=\"start\" x=\"75.5\" y=\"-4494.75\" font-family=\"Linux libertine\" font-size=\"10.00\">depth:3</text>\n<polygon fill=\"none\" stroke=\"black\" points=\"119.5,-4504.25 119.5,-4526.25 162.5,-4526.25 162.5,-4504.25 119.5,-4504.25\"/>\n<text text-anchor=\"start\" x=\"128.62\" y=\"-4511.75\" font-family=\"Linux libertine\" font-size=\"10.00\">input:</text>\n<polygon fill=\"none\" stroke=\"black\" points=\"162.5,-4504.25 162.5,-4526.25 247.5,-4526.25 247.5,-4504.25 162.5,-4504.25\"/>\n<text text-anchor=\"start\" x=\"167.12\" y=\"-4511.75\" font-family=\"Linux libertine\" font-size=\"10.00\">(1, 32, 112, 112) </text>\n<polygon fill=\"none\" stroke=\"black\" points=\"119.5,-4482.25 119.5,-4504.25 162.5,-4504.25 162.5,-4482.25 119.5,-4482.25\"/>\n<text text-anchor=\"start\" x=\"124.12\" y=\"-4489.75\" font-family=\"Linux libertine\" font-size=\"10.00\">output: </text>\n<polygon fill=\"none\" stroke=\"black\" points=\"162.5,-4482.25 162.5,-4504.25 247.5,-4504.25 247.5,-4482.25 162.5,-4482.25\"/>\n<text text-anchor=\"start\" x=\"177.62\" y=\"-4489.75\" font-family=\"Linux libertine\" font-size=\"10.00\">(1, 32, 1, 1) </text>\n</g>\n<!-- 5&#45;&gt;6 -->\n<g id=\"edge6\" class=\"edge\">\n<title>5&#45;&gt;6</title>\n<path fill=\"none\" stroke=\"black\" d=\"M139.16,-4562.35C141.46,-4554.57 144.12,-4545.55 146.63,-4537.01\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"149.92,-4538.24 149.39,-4527.66 143.21,-4536.26 149.92,-4538.24\"/>\n</g>\n<!-- 7 -->\n<g id=\"node8\" class=\"node\">\n<title>7</title>\n<polygon fill=\"aliceblue\" stroke=\"none\" points=\"259.5,-4446.25 30.5,-4446.25 30.5,-4402.25 259.5,-4402.25 259.5,-4446.25\"/>\n<polygon fill=\"none\" stroke=\"black\" points=\"30.5,-4402.25 30.5,-4446.25 73.5,-4446.25 73.5,-4402.25 30.5,-4402.25\"/>\n<text text-anchor=\"start\" x=\"44.12\" y=\"-4426.75\" font-family=\"Linux libertine\" font-size=\"10.00\">mul</text>\n<text text-anchor=\"start\" x=\"35.5\" y=\"-4414.75\" font-family=\"Linux libertine\" font-size=\"10.00\">depth:3</text>\n<polygon fill=\"none\" stroke=\"black\" points=\"73.5,-4424.25 73.5,-4446.25 116.5,-4446.25 116.5,-4424.25 73.5,-4424.25\"/>\n<text text-anchor=\"start\" x=\"82.62\" y=\"-4431.75\" font-family=\"Linux libertine\" font-size=\"10.00\">input:</text>\n<polygon fill=\"none\" stroke=\"black\" points=\"116.5,-4424.25 116.5,-4446.25 259.5,-4446.25 259.5,-4424.25 116.5,-4424.25\"/>\n<text text-anchor=\"start\" x=\"121.25\" y=\"-4431.75\" font-family=\"Linux libertine\" font-size=\"10.00\">(1, 32, 112, 112), (1, 32, 1, 1) </text>\n<polygon fill=\"none\" stroke=\"black\" points=\"73.5,-4402.25 73.5,-4424.25 116.5,-4424.25 116.5,-4402.25 73.5,-4402.25\"/>\n<text text-anchor=\"start\" x=\"78.12\" y=\"-4409.75\" font-family=\"Linux libertine\" font-size=\"10.00\">output: </text>\n<polygon fill=\"none\" stroke=\"black\" points=\"116.5,-4402.25 116.5,-4424.25 259.5,-4424.25 259.5,-4402.25 116.5,-4402.25\"/>\n<text text-anchor=\"start\" x=\"150.12\" y=\"-4409.75\" font-family=\"Linux libertine\" font-size=\"10.00\">(1, 32, 112, 112) </text>\n</g>\n<!-- 5&#45;&gt;7 -->\n<g id=\"edge7\" class=\"edge\">\n<title>5&#45;&gt;7</title>\n<path fill=\"none\" stroke=\"black\" d=\"M90.28,-4562.48C76.43,-4553.41 62.67,-4541.35 55,-4526.25 46.15,-4508.81 45.57,-4499.38 55,-4482.25 61.76,-4469.98 72.39,-4459.98 84.02,-4451.98\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"85.64,-4455.09 92.23,-4446.79 81.91,-4449.17 85.64,-4455.09\"/>\n</g>\n<!-- 6&#45;&gt;7 -->\n<g id=\"edge8\" class=\"edge\">\n<title>6&#45;&gt;7</title>\n<path fill=\"none\" stroke=\"black\" d=\"M153.05,-4482.35C151.98,-4474.74 150.74,-4465.95 149.56,-4457.59\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"153.03,-4457.12 148.17,-4447.71 146.1,-4458.1 153.03,-4457.12\"/>\n</g>\n<!-- 8 -->\n<g id=\"node9\" class=\"node\">\n<title>8</title>\n<polygon fill=\"#c1ffc1\" stroke=\"none\" points=\"236.5,-4366.25 53.5,-4366.25 53.5,-4322.25 236.5,-4322.25 236.5,-4366.25\"/>\n<polygon fill=\"none\" stroke=\"black\" points=\"53.5,-4322.25 53.5,-4366.25 108.5,-4366.25 108.5,-4322.25 53.5,-4322.25\"/>\n<text text-anchor=\"start\" x=\"58.5\" y=\"-4346.75\" font-family=\"Linux libertine\" font-size=\"10.00\">Sequential</text>\n<text text-anchor=\"start\" x=\"64.5\" y=\"-4334.75\" font-family=\"Linux libertine\" font-size=\"10.00\">depth:3</text>\n<polygon fill=\"none\" stroke=\"black\" points=\"108.5,-4344.25 108.5,-4366.25 151.5,-4366.25 151.5,-4344.25 108.5,-4344.25\"/>\n<text text-anchor=\"start\" x=\"117.62\" y=\"-4351.75\" font-family=\"Linux libertine\" font-size=\"10.00\">input:</text>\n<polygon fill=\"none\" stroke=\"black\" points=\"151.5,-4344.25 151.5,-4366.25 236.5,-4366.25 236.5,-4344.25 151.5,-4344.25\"/>\n<text text-anchor=\"start\" x=\"156.12\" y=\"-4351.75\" font-family=\"Linux libertine\" font-size=\"10.00\">(1, 32, 112, 112) </text>\n<polygon fill=\"none\" stroke=\"black\" points=\"108.5,-4322.25 108.5,-4344.25 151.5,-4344.25 151.5,-4322.25 108.5,-4322.25\"/>\n<text text-anchor=\"start\" x=\"113.12\" y=\"-4329.75\" font-family=\"Linux libertine\" font-size=\"10.00\">output: </text>\n<polygon fill=\"none\" stroke=\"black\" points=\"151.5,-4322.25 151.5,-4344.25 236.5,-4344.25 236.5,-4322.25 151.5,-4322.25\"/>\n<text text-anchor=\"start\" x=\"156.12\" y=\"-4329.75\" font-family=\"Linux libertine\" font-size=\"10.00\">(1, 16, 112, 112) </text>\n</g>\n<!-- 7&#45;&gt;8 -->\n<g id=\"edge9\" class=\"edge\">\n<title>7&#45;&gt;8</title>\n<path fill=\"none\" stroke=\"black\" d=\"M145,-4402.35C145,-4394.74 145,-4385.95 145,-4377.59\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"148.5,-4377.72 145,-4367.72 141.5,-4377.72 148.5,-4377.72\"/>\n</g>\n<!-- 9 -->\n<g id=\"node10\" class=\"node\">\n<title>9</title>\n<polygon fill=\"#c1ffc1\" stroke=\"none\" points=\"236.5,-4276 53.5,-4276 53.5,-4232 236.5,-4232 236.5,-4276\"/>\n<polygon fill=\"none\" stroke=\"black\" points=\"53.5,-4232 53.5,-4276 108.5,-4276 108.5,-4232 53.5,-4232\"/>\n<text text-anchor=\"start\" x=\"58.5\" y=\"-4256.5\" font-family=\"Linux libertine\" font-size=\"10.00\">Sequential</text>\n<text text-anchor=\"start\" x=\"64.5\" y=\"-4244.5\" font-family=\"Linux libertine\" font-size=\"10.00\">depth:3</text>\n<polygon fill=\"none\" stroke=\"black\" points=\"108.5,-4254 108.5,-4276 151.5,-4276 151.5,-4254 108.5,-4254\"/>\n<text text-anchor=\"start\" x=\"117.62\" y=\"-4261.5\" font-family=\"Linux libertine\" font-size=\"10.00\">input:</text>\n<polygon fill=\"none\" stroke=\"black\" points=\"151.5,-4254 151.5,-4276 236.5,-4276 236.5,-4254 151.5,-4254\"/>\n<text text-anchor=\"start\" x=\"156.12\" y=\"-4261.5\" font-family=\"Linux libertine\" font-size=\"10.00\">(1, 16, 112, 112) </text>\n<polygon fill=\"none\" stroke=\"black\" points=\"108.5,-4232 108.5,-4254 151.5,-4254 151.5,-4232 108.5,-4232\"/>\n<text text-anchor=\"start\" x=\"113.12\" y=\"-4239.5\" font-family=\"Linux libertine\" font-size=\"10.00\">output: </text>\n<polygon fill=\"none\" stroke=\"black\" points=\"151.5,-4232 151.5,-4254 236.5,-4254 236.5,-4232 151.5,-4232\"/>\n<text text-anchor=\"start\" x=\"156.12\" y=\"-4239.5\" font-family=\"Linux libertine\" font-size=\"10.00\">(1, 96, 112, 112) </text>\n</g>\n<!-- 8&#45;&gt;9 -->\n<g id=\"edge10\" class=\"edge\">\n<title>8&#45;&gt;9</title>\n<path fill=\"none\" stroke=\"black\" d=\"M145,-4322.34C145,-4311.79 145,-4298.76 145,-4286.98\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"148.5,-4287.28 145,-4277.28 141.5,-4287.28 148.5,-4287.28\"/>\n</g>\n<!-- 10 -->\n<g id=\"node11\" class=\"node\">\n<title>10</title>\n<polygon fill=\"#c1ffc1\" stroke=\"none\" points=\"236.5,-4196 53.5,-4196 53.5,-4152 236.5,-4152 236.5,-4196\"/>\n<polygon fill=\"none\" stroke=\"black\" points=\"53.5,-4152 53.5,-4196 108.5,-4196 108.5,-4152 53.5,-4152\"/>\n<text text-anchor=\"start\" x=\"58.5\" y=\"-4176.5\" font-family=\"Linux libertine\" font-size=\"10.00\">Sequential</text>\n<text text-anchor=\"start\" x=\"64.5\" y=\"-4164.5\" font-family=\"Linux libertine\" font-size=\"10.00\">depth:3</text>\n<polygon fill=\"none\" stroke=\"black\" points=\"108.5,-4174 108.5,-4196 151.5,-4196 151.5,-4174 108.5,-4174\"/>\n<text text-anchor=\"start\" x=\"117.62\" y=\"-4181.5\" font-family=\"Linux libertine\" font-size=\"10.00\">input:</text>\n<polygon fill=\"none\" stroke=\"black\" points=\"151.5,-4174 151.5,-4196 236.5,-4196 236.5,-4174 151.5,-4174\"/>\n<text text-anchor=\"start\" x=\"156.12\" y=\"-4181.5\" font-family=\"Linux libertine\" font-size=\"10.00\">(1, 96, 112, 112) </text>\n<polygon fill=\"none\" stroke=\"black\" points=\"108.5,-4152 108.5,-4174 151.5,-4174 151.5,-4152 108.5,-4152\"/>\n<text text-anchor=\"start\" x=\"113.12\" y=\"-4159.5\" font-family=\"Linux libertine\" font-size=\"10.00\">output: </text>\n<polygon fill=\"none\" stroke=\"black\" points=\"151.5,-4152 151.5,-4174 236.5,-4174 236.5,-4152 151.5,-4152\"/>\n<text text-anchor=\"start\" x=\"161.38\" y=\"-4159.5\" font-family=\"Linux libertine\" font-size=\"10.00\">(1, 96, 56, 56) </text>\n</g>\n<!-- 9&#45;&gt;10 -->\n<g id=\"edge11\" class=\"edge\">\n<title>9&#45;&gt;10</title>\n<path fill=\"none\" stroke=\"black\" d=\"M145,-4232.1C145,-4224.49 145,-4215.7 145,-4207.34\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"148.5,-4207.47 145,-4197.47 141.5,-4207.47 148.5,-4207.47\"/>\n</g>\n<!-- 11 -->\n<g id=\"node12\" class=\"node\">\n<title>11</title>\n<polygon fill=\"#c1ffc1\" stroke=\"none\" points=\"253.5,-4116 80.5,-4116 80.5,-4072 253.5,-4072 253.5,-4116\"/>\n<polygon fill=\"none\" stroke=\"black\" points=\"80.5,-4072 80.5,-4116 135.5,-4116 135.5,-4072 80.5,-4072\"/>\n<text text-anchor=\"start\" x=\"85.5\" y=\"-4096.5\" font-family=\"Linux libertine\" font-size=\"10.00\">Sequential</text>\n<text text-anchor=\"start\" x=\"91.5\" y=\"-4084.5\" font-family=\"Linux libertine\" font-size=\"10.00\">depth:3</text>\n<polygon fill=\"none\" stroke=\"black\" points=\"135.5,-4094 135.5,-4116 178.5,-4116 178.5,-4094 135.5,-4094\"/>\n<text text-anchor=\"start\" x=\"144.62\" y=\"-4101.5\" font-family=\"Linux libertine\" font-size=\"10.00\">input:</text>\n<polygon fill=\"none\" stroke=\"black\" points=\"178.5,-4094 178.5,-4116 253.5,-4116 253.5,-4094 178.5,-4094\"/>\n<text text-anchor=\"start\" x=\"183.38\" y=\"-4101.5\" font-family=\"Linux libertine\" font-size=\"10.00\">(1, 96, 56, 56) </text>\n<polygon fill=\"none\" stroke=\"black\" points=\"135.5,-4072 135.5,-4094 178.5,-4094 178.5,-4072 135.5,-4072\"/>\n<text text-anchor=\"start\" x=\"140.12\" y=\"-4079.5\" font-family=\"Linux libertine\" font-size=\"10.00\">output: </text>\n<polygon fill=\"none\" stroke=\"black\" points=\"178.5,-4072 178.5,-4094 253.5,-4094 253.5,-4072 178.5,-4072\"/>\n<text text-anchor=\"start\" x=\"188.62\" y=\"-4079.5\" font-family=\"Linux libertine\" font-size=\"10.00\">(1, 96, 1, 1) </text>\n</g>\n<!-- 10&#45;&gt;11 -->\n<g id=\"edge12\" class=\"edge\">\n<title>10&#45;&gt;11</title>\n<path fill=\"none\" stroke=\"black\" d=\"M150.9,-4152.1C153.09,-4144.32 155.63,-4135.3 158.04,-4126.76\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"161.33,-4127.99 160.68,-4117.42 154.59,-4126.09 161.33,-4127.99\"/>\n</g>\n<!-- 12 -->\n<g id=\"node13\" class=\"node\">\n<title>12</title>\n<polygon fill=\"aliceblue\" stroke=\"none\" points=\"265.5,-4036 46.5,-4036 46.5,-3992 265.5,-3992 265.5,-4036\"/>\n<polygon fill=\"none\" stroke=\"black\" points=\"46.5,-3992 46.5,-4036 89.5,-4036 89.5,-3992 46.5,-3992\"/>\n<text text-anchor=\"start\" x=\"60.12\" y=\"-4016.5\" font-family=\"Linux libertine\" font-size=\"10.00\">mul</text>\n<text text-anchor=\"start\" x=\"51.5\" y=\"-4004.5\" font-family=\"Linux libertine\" font-size=\"10.00\">depth:3</text>\n<polygon fill=\"none\" stroke=\"black\" points=\"89.5,-4014 89.5,-4036 132.5,-4036 132.5,-4014 89.5,-4014\"/>\n<text text-anchor=\"start\" x=\"98.62\" y=\"-4021.5\" font-family=\"Linux libertine\" font-size=\"10.00\">input:</text>\n<polygon fill=\"none\" stroke=\"black\" points=\"132.5,-4014 132.5,-4036 265.5,-4036 265.5,-4014 132.5,-4014\"/>\n<text text-anchor=\"start\" x=\"137.5\" y=\"-4021.5\" font-family=\"Linux libertine\" font-size=\"10.00\">(1, 96, 56, 56), (1, 96, 1, 1) </text>\n<polygon fill=\"none\" stroke=\"black\" points=\"89.5,-3992 89.5,-4014 132.5,-4014 132.5,-3992 89.5,-3992\"/>\n<text text-anchor=\"start\" x=\"94.12\" y=\"-3999.5\" font-family=\"Linux libertine\" font-size=\"10.00\">output: </text>\n<polygon fill=\"none\" stroke=\"black\" points=\"132.5,-3992 132.5,-4014 265.5,-4014 265.5,-3992 132.5,-3992\"/>\n<text text-anchor=\"start\" x=\"166.38\" y=\"-3999.5\" font-family=\"Linux libertine\" font-size=\"10.00\">(1, 96, 56, 56) </text>\n</g>\n<!-- 10&#45;&gt;12 -->\n<g id=\"edge13\" class=\"edge\">\n<title>10&#45;&gt;12</title>\n<path fill=\"none\" stroke=\"black\" d=\"M104.81,-4152.05C91.53,-4142.91 78.3,-4130.84 71,-4116 62.37,-4098.45 61.8,-4089.25 71,-4072 77.4,-4060 87.58,-4050.08 98.7,-4042.06\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"100.53,-4045.05 106.94,-4036.61 96.66,-4039.21 100.53,-4045.05\"/>\n</g>\n<!-- 11&#45;&gt;12 -->\n<g id=\"edge14\" class=\"edge\">\n<title>11&#45;&gt;12</title>\n<path fill=\"none\" stroke=\"black\" d=\"M164.05,-4072.1C162.98,-4064.49 161.74,-4055.7 160.56,-4047.34\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"164.03,-4046.87 159.17,-4037.46 157.1,-4047.85 164.03,-4046.87\"/>\n</g>\n<!-- 13 -->\n<g id=\"node14\" class=\"node\">\n<title>13</title>\n<polygon fill=\"#c1ffc1\" stroke=\"none\" points=\"244.5,-3956 71.5,-3956 71.5,-3912 244.5,-3912 244.5,-3956\"/>\n<polygon fill=\"none\" stroke=\"black\" points=\"71.5,-3912 71.5,-3956 126.5,-3956 126.5,-3912 71.5,-3912\"/>\n<text text-anchor=\"start\" x=\"76.5\" y=\"-3936.5\" font-family=\"Linux libertine\" font-size=\"10.00\">Sequential</text>\n<text text-anchor=\"start\" x=\"82.5\" y=\"-3924.5\" font-family=\"Linux libertine\" font-size=\"10.00\">depth:3</text>\n<polygon fill=\"none\" stroke=\"black\" points=\"126.5,-3934 126.5,-3956 169.5,-3956 169.5,-3934 126.5,-3934\"/>\n<text text-anchor=\"start\" x=\"135.62\" y=\"-3941.5\" font-family=\"Linux libertine\" font-size=\"10.00\">input:</text>\n<polygon fill=\"none\" stroke=\"black\" points=\"169.5,-3934 169.5,-3956 244.5,-3956 244.5,-3934 169.5,-3934\"/>\n<text text-anchor=\"start\" x=\"174.38\" y=\"-3941.5\" font-family=\"Linux libertine\" font-size=\"10.00\">(1, 96, 56, 56) </text>\n<polygon fill=\"none\" stroke=\"black\" points=\"126.5,-3912 126.5,-3934 169.5,-3934 169.5,-3912 126.5,-3912\"/>\n<text text-anchor=\"start\" x=\"131.12\" y=\"-3919.5\" font-family=\"Linux libertine\" font-size=\"10.00\">output: </text>\n<polygon fill=\"none\" stroke=\"black\" points=\"169.5,-3912 169.5,-3934 244.5,-3934 244.5,-3912 169.5,-3912\"/>\n<text text-anchor=\"start\" x=\"174.38\" y=\"-3919.5\" font-family=\"Linux libertine\" font-size=\"10.00\">(1, 24, 56, 56) </text>\n</g>\n<!-- 12&#45;&gt;13 -->\n<g id=\"edge15\" class=\"edge\">\n<title>12&#45;&gt;13</title>\n<path fill=\"none\" stroke=\"black\" d=\"M156.54,-3992.1C156.73,-3984.49 156.96,-3975.7 157.17,-3967.34\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"160.67,-3967.56 157.42,-3957.47 153.67,-3967.38 160.67,-3967.56\"/>\n</g>\n<!-- 14 -->\n<g id=\"node15\" class=\"node\">\n<title>14</title>\n<polygon fill=\"#c1ffc1\" stroke=\"none\" points=\"247,-3865.75 69,-3865.75 69,-3821.75 247,-3821.75 247,-3865.75\"/>\n<polygon fill=\"none\" stroke=\"black\" points=\"69,-3821.75 69,-3865.75 124,-3865.75 124,-3821.75 69,-3821.75\"/>\n<text text-anchor=\"start\" x=\"74\" y=\"-3846.25\" font-family=\"Linux libertine\" font-size=\"10.00\">Sequential</text>\n<text text-anchor=\"start\" x=\"80\" y=\"-3834.25\" font-family=\"Linux libertine\" font-size=\"10.00\">depth:3</text>\n<polygon fill=\"none\" stroke=\"black\" points=\"124,-3843.75 124,-3865.75 167,-3865.75 167,-3843.75 124,-3843.75\"/>\n<text text-anchor=\"start\" x=\"133.12\" y=\"-3851.25\" font-family=\"Linux libertine\" font-size=\"10.00\">input:</text>\n<polygon fill=\"none\" stroke=\"black\" points=\"167,-3843.75 167,-3865.75 247,-3865.75 247,-3843.75 167,-3843.75\"/>\n<text text-anchor=\"start\" x=\"174.38\" y=\"-3851.25\" font-family=\"Linux libertine\" font-size=\"10.00\">(1, 24, 56, 56) </text>\n<polygon fill=\"none\" stroke=\"black\" points=\"124,-3821.75 124,-3843.75 167,-3843.75 167,-3821.75 124,-3821.75\"/>\n<text text-anchor=\"start\" x=\"128.62\" y=\"-3829.25\" font-family=\"Linux libertine\" font-size=\"10.00\">output: </text>\n<polygon fill=\"none\" stroke=\"black\" points=\"167,-3821.75 167,-3843.75 247,-3843.75 247,-3821.75 167,-3821.75\"/>\n<text text-anchor=\"start\" x=\"171.75\" y=\"-3829.25\" font-family=\"Linux libertine\" font-size=\"10.00\">(1, 144, 56, 56) </text>\n</g>\n<!-- 13&#45;&gt;14 -->\n<g id=\"edge16\" class=\"edge\">\n<title>13&#45;&gt;14</title>\n<path fill=\"none\" stroke=\"black\" d=\"M158,-3912.09C158,-3901.54 158,-3888.51 158,-3876.73\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"161.5,-3877.03 158,-3867.03 154.5,-3877.03 161.5,-3877.03\"/>\n</g>\n<!-- 19 -->\n<g id=\"node20\" class=\"node\">\n<title>19</title>\n<polygon fill=\"aliceblue\" stroke=\"none\" points=\"242.5,-3465.75 65.5,-3465.75 65.5,-3421.75 242.5,-3421.75 242.5,-3465.75\"/>\n<polygon fill=\"none\" stroke=\"black\" points=\"65.5,-3421.75 65.5,-3465.75 108.5,-3465.75 108.5,-3421.75 65.5,-3421.75\"/>\n<text text-anchor=\"start\" x=\"76.5\" y=\"-3446.25\" font-family=\"Linux libertine\" font-size=\"10.00\">add_</text>\n<text text-anchor=\"start\" x=\"70.5\" y=\"-3434.25\" font-family=\"Linux libertine\" font-size=\"10.00\">depth:3</text>\n<polygon fill=\"none\" stroke=\"black\" points=\"108.5,-3443.75 108.5,-3465.75 151.5,-3465.75 151.5,-3443.75 108.5,-3443.75\"/>\n<text text-anchor=\"start\" x=\"117.62\" y=\"-3451.25\" font-family=\"Linux libertine\" font-size=\"10.00\">input:</text>\n<polygon fill=\"none\" stroke=\"black\" points=\"151.5,-3443.75 151.5,-3465.75 242.5,-3465.75 242.5,-3443.75 151.5,-3443.75\"/>\n<text text-anchor=\"start\" x=\"156.5\" y=\"-3451.25\" font-family=\"Linux libertine\" font-size=\"10.00\">2 x (1, 24, 56, 56) </text>\n<polygon fill=\"none\" stroke=\"black\" points=\"108.5,-3421.75 108.5,-3443.75 151.5,-3443.75 151.5,-3421.75 108.5,-3421.75\"/>\n<text text-anchor=\"start\" x=\"113.12\" y=\"-3429.25\" font-family=\"Linux libertine\" font-size=\"10.00\">output: </text>\n<polygon fill=\"none\" stroke=\"black\" points=\"151.5,-3421.75 151.5,-3443.75 242.5,-3443.75 242.5,-3421.75 151.5,-3421.75\"/>\n<text text-anchor=\"start\" x=\"164.38\" y=\"-3429.25\" font-family=\"Linux libertine\" font-size=\"10.00\">(1, 24, 56, 56) </text>\n</g>\n<!-- 13&#45;&gt;19 -->\n<g id=\"edge17\" class=\"edge\">\n<title>13&#45;&gt;19</title>\n<path fill=\"none\" stroke=\"black\" d=\"M237.63,-3912.11C244.6,-3907.72 250.92,-3902.42 256,-3896 292.49,-3849.87 273,-3823.57 273,-3764.75 273,-3764.75 273,-3764.75 273,-3602.75 273,-3556.28 273.7,-3539.06 246,-3501.75 237.07,-3489.73 224.79,-3479.67 212.11,-3471.51\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"214.04,-3468.59 203.67,-3466.43 210.43,-3474.59 214.04,-3468.59\"/>\n</g>\n<!-- 15 -->\n<g id=\"node16\" class=\"node\">\n<title>15</title>\n<polygon fill=\"#c1ffc1\" stroke=\"none\" points=\"247,-3785.75 69,-3785.75 69,-3741.75 247,-3741.75 247,-3785.75\"/>\n<polygon fill=\"none\" stroke=\"black\" points=\"69,-3741.75 69,-3785.75 124,-3785.75 124,-3741.75 69,-3741.75\"/>\n<text text-anchor=\"start\" x=\"74\" y=\"-3766.25\" font-family=\"Linux libertine\" font-size=\"10.00\">Sequential</text>\n<text text-anchor=\"start\" x=\"80\" y=\"-3754.25\" font-family=\"Linux libertine\" font-size=\"10.00\">depth:3</text>\n<polygon fill=\"none\" stroke=\"black\" points=\"124,-3763.75 124,-3785.75 167,-3785.75 167,-3763.75 124,-3763.75\"/>\n<text text-anchor=\"start\" x=\"133.12\" y=\"-3771.25\" font-family=\"Linux libertine\" font-size=\"10.00\">input:</text>\n<polygon fill=\"none\" stroke=\"black\" points=\"167,-3763.75 167,-3785.75 247,-3785.75 247,-3763.75 167,-3763.75\"/>\n<text text-anchor=\"start\" x=\"171.75\" y=\"-3771.25\" font-family=\"Linux libertine\" font-size=\"10.00\">(1, 144, 56, 56) </text>\n<polygon fill=\"none\" stroke=\"black\" points=\"124,-3741.75 124,-3763.75 167,-3763.75 167,-3741.75 124,-3741.75\"/>\n<text text-anchor=\"start\" x=\"128.62\" y=\"-3749.25\" font-family=\"Linux libertine\" font-size=\"10.00\">output: </text>\n<polygon fill=\"none\" stroke=\"black\" points=\"167,-3741.75 167,-3763.75 247,-3763.75 247,-3741.75 167,-3741.75\"/>\n<text text-anchor=\"start\" x=\"171.75\" y=\"-3749.25\" font-family=\"Linux libertine\" font-size=\"10.00\">(1, 144, 56, 56) </text>\n</g>\n<!-- 14&#45;&gt;15 -->\n<g id=\"edge18\" class=\"edge\">\n<title>14&#45;&gt;15</title>\n<path fill=\"none\" stroke=\"black\" d=\"M158,-3821.85C158,-3814.24 158,-3805.45 158,-3797.09\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"161.5,-3797.22 158,-3787.22 154.5,-3797.22 161.5,-3797.22\"/>\n</g>\n<!-- 16 -->\n<g id=\"node17\" class=\"node\">\n<title>16</title>\n<polygon fill=\"#c1ffc1\" stroke=\"none\" points=\"251,-3705.75 73,-3705.75 73,-3661.75 251,-3661.75 251,-3705.75\"/>\n<polygon fill=\"none\" stroke=\"black\" points=\"73,-3661.75 73,-3705.75 128,-3705.75 128,-3661.75 73,-3661.75\"/>\n<text text-anchor=\"start\" x=\"78\" y=\"-3686.25\" font-family=\"Linux libertine\" font-size=\"10.00\">Sequential</text>\n<text text-anchor=\"start\" x=\"84\" y=\"-3674.25\" font-family=\"Linux libertine\" font-size=\"10.00\">depth:3</text>\n<polygon fill=\"none\" stroke=\"black\" points=\"128,-3683.75 128,-3705.75 171,-3705.75 171,-3683.75 128,-3683.75\"/>\n<text text-anchor=\"start\" x=\"137.12\" y=\"-3691.25\" font-family=\"Linux libertine\" font-size=\"10.00\">input:</text>\n<polygon fill=\"none\" stroke=\"black\" points=\"171,-3683.75 171,-3705.75 251,-3705.75 251,-3683.75 171,-3683.75\"/>\n<text text-anchor=\"start\" x=\"175.75\" y=\"-3691.25\" font-family=\"Linux libertine\" font-size=\"10.00\">(1, 144, 56, 56) </text>\n<polygon fill=\"none\" stroke=\"black\" points=\"128,-3661.75 128,-3683.75 171,-3683.75 171,-3661.75 128,-3661.75\"/>\n<text text-anchor=\"start\" x=\"132.62\" y=\"-3669.25\" font-family=\"Linux libertine\" font-size=\"10.00\">output: </text>\n<polygon fill=\"none\" stroke=\"black\" points=\"171,-3661.75 171,-3683.75 251,-3683.75 251,-3661.75 171,-3661.75\"/>\n<text text-anchor=\"start\" x=\"181\" y=\"-3669.25\" font-family=\"Linux libertine\" font-size=\"10.00\">(1, 144, 1, 1) </text>\n</g>\n<!-- 15&#45;&gt;16 -->\n<g id=\"edge19\" class=\"edge\">\n<title>15&#45;&gt;16</title>\n<path fill=\"none\" stroke=\"black\" d=\"M159.07,-3741.85C159.46,-3734.24 159.91,-3725.45 160.34,-3717.09\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"163.83,-3717.39 160.85,-3707.22 156.84,-3717.03 163.83,-3717.39\"/>\n</g>\n<!-- 17 -->\n<g id=\"node18\" class=\"node\">\n<title>17</title>\n<polygon fill=\"aliceblue\" stroke=\"none\" points=\"253.5,-3625.75 24.5,-3625.75 24.5,-3581.75 253.5,-3581.75 253.5,-3625.75\"/>\n<polygon fill=\"none\" stroke=\"black\" points=\"24.5,-3581.75 24.5,-3625.75 67.5,-3625.75 67.5,-3581.75 24.5,-3581.75\"/>\n<text text-anchor=\"start\" x=\"38.12\" y=\"-3606.25\" font-family=\"Linux libertine\" font-size=\"10.00\">mul</text>\n<text text-anchor=\"start\" x=\"29.5\" y=\"-3594.25\" font-family=\"Linux libertine\" font-size=\"10.00\">depth:3</text>\n<polygon fill=\"none\" stroke=\"black\" points=\"67.5,-3603.75 67.5,-3625.75 110.5,-3625.75 110.5,-3603.75 67.5,-3603.75\"/>\n<text text-anchor=\"start\" x=\"76.62\" y=\"-3611.25\" font-family=\"Linux libertine\" font-size=\"10.00\">input:</text>\n<polygon fill=\"none\" stroke=\"black\" points=\"110.5,-3603.75 110.5,-3625.75 253.5,-3625.75 253.5,-3603.75 110.5,-3603.75\"/>\n<text text-anchor=\"start\" x=\"115.25\" y=\"-3611.25\" font-family=\"Linux libertine\" font-size=\"10.00\">(1, 144, 56, 56), (1, 144, 1, 1) </text>\n<polygon fill=\"none\" stroke=\"black\" points=\"67.5,-3581.75 67.5,-3603.75 110.5,-3603.75 110.5,-3581.75 67.5,-3581.75\"/>\n<text text-anchor=\"start\" x=\"72.12\" y=\"-3589.25\" font-family=\"Linux libertine\" font-size=\"10.00\">output: </text>\n<polygon fill=\"none\" stroke=\"black\" points=\"110.5,-3581.75 110.5,-3603.75 253.5,-3603.75 253.5,-3581.75 110.5,-3581.75\"/>\n<text text-anchor=\"start\" x=\"146.75\" y=\"-3589.25\" font-family=\"Linux libertine\" font-size=\"10.00\">(1, 144, 56, 56) </text>\n</g>\n<!-- 15&#45;&gt;17 -->\n<g id=\"edge20\" class=\"edge\">\n<title>15&#45;&gt;17</title>\n<path fill=\"none\" stroke=\"black\" d=\"M103.29,-3741.94C87.81,-3733.22 72.8,-3721.38 64,-3705.75 54.4,-3688.71 55.31,-3679.27 64,-3661.75 69.73,-3650.19 79.06,-3640.34 89.21,-3632.25\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"91.07,-3635.23 97.06,-3626.49 86.93,-3629.58 91.07,-3635.23\"/>\n</g>\n<!-- 16&#45;&gt;17 -->\n<g id=\"edge21\" class=\"edge\">\n<title>16&#45;&gt;17</title>\n<path fill=\"none\" stroke=\"black\" d=\"M155.84,-3661.85C153.54,-3654.07 150.88,-3645.05 148.37,-3636.51\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"151.79,-3635.76 145.61,-3627.16 145.08,-3637.74 151.79,-3635.76\"/>\n</g>\n<!-- 18 -->\n<g id=\"node19\" class=\"node\">\n<title>18</title>\n<polygon fill=\"#c1ffc1\" stroke=\"none\" points=\"237,-3545.75 59,-3545.75 59,-3501.75 237,-3501.75 237,-3545.75\"/>\n<polygon fill=\"none\" stroke=\"black\" points=\"59,-3501.75 59,-3545.75 114,-3545.75 114,-3501.75 59,-3501.75\"/>\n<text text-anchor=\"start\" x=\"64\" y=\"-3526.25\" font-family=\"Linux libertine\" font-size=\"10.00\">Sequential</text>\n<text text-anchor=\"start\" x=\"70\" y=\"-3514.25\" font-family=\"Linux libertine\" font-size=\"10.00\">depth:3</text>\n<polygon fill=\"none\" stroke=\"black\" points=\"114,-3523.75 114,-3545.75 157,-3545.75 157,-3523.75 114,-3523.75\"/>\n<text text-anchor=\"start\" x=\"123.12\" y=\"-3531.25\" font-family=\"Linux libertine\" font-size=\"10.00\">input:</text>\n<polygon fill=\"none\" stroke=\"black\" points=\"157,-3523.75 157,-3545.75 237,-3545.75 237,-3523.75 157,-3523.75\"/>\n<text text-anchor=\"start\" x=\"161.75\" y=\"-3531.25\" font-family=\"Linux libertine\" font-size=\"10.00\">(1, 144, 56, 56) </text>\n<polygon fill=\"none\" stroke=\"black\" points=\"114,-3501.75 114,-3523.75 157,-3523.75 157,-3501.75 114,-3501.75\"/>\n<text text-anchor=\"start\" x=\"118.62\" y=\"-3509.25\" font-family=\"Linux libertine\" font-size=\"10.00\">output: </text>\n<polygon fill=\"none\" stroke=\"black\" points=\"157,-3501.75 157,-3523.75 237,-3523.75 237,-3501.75 157,-3501.75\"/>\n<text text-anchor=\"start\" x=\"164.38\" y=\"-3509.25\" font-family=\"Linux libertine\" font-size=\"10.00\">(1, 24, 56, 56) </text>\n</g>\n<!-- 17&#45;&gt;18 -->\n<g id=\"edge22\" class=\"edge\">\n<title>17&#45;&gt;18</title>\n<path fill=\"none\" stroke=\"black\" d=\"M141.41,-3581.85C142.29,-3574.24 143.3,-3565.45 144.27,-3557.09\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"147.74,-3557.55 145.41,-3547.21 140.78,-3556.75 147.74,-3557.55\"/>\n</g>\n<!-- 18&#45;&gt;19 -->\n<g id=\"edge23\" class=\"edge\">\n<title>18&#45;&gt;19</title>\n<path fill=\"none\" stroke=\"black\" d=\"M149.61,-3501.85C150.19,-3494.24 150.87,-3485.45 151.51,-3477.09\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"154.99,-3477.46 152.27,-3467.22 148.01,-3476.92 154.99,-3477.46\"/>\n</g>\n<!-- 20 -->\n<g id=\"node21\" class=\"node\">\n<title>20</title>\n<polygon fill=\"#c1ffc1\" stroke=\"none\" points=\"234.5,-3385.75 73.5,-3385.75 73.5,-3341.75 234.5,-3341.75 234.5,-3385.75\"/>\n<polygon fill=\"none\" stroke=\"black\" points=\"73.5,-3341.75 73.5,-3385.75 116.5,-3385.75 116.5,-3341.75 73.5,-3341.75\"/>\n<text text-anchor=\"start\" x=\"78.12\" y=\"-3366.25\" font-family=\"Linux libertine\" font-size=\"10.00\">Dropout</text>\n<text text-anchor=\"start\" x=\"78.5\" y=\"-3354.25\" font-family=\"Linux libertine\" font-size=\"10.00\">depth:3</text>\n<polygon fill=\"none\" stroke=\"black\" points=\"116.5,-3363.75 116.5,-3385.75 159.5,-3385.75 159.5,-3363.75 116.5,-3363.75\"/>\n<text text-anchor=\"start\" x=\"125.62\" y=\"-3371.25\" font-family=\"Linux libertine\" font-size=\"10.00\">input:</text>\n<polygon fill=\"none\" stroke=\"black\" points=\"159.5,-3363.75 159.5,-3385.75 234.5,-3385.75 234.5,-3363.75 159.5,-3363.75\"/>\n<text text-anchor=\"start\" x=\"164.38\" y=\"-3371.25\" font-family=\"Linux libertine\" font-size=\"10.00\">(1, 24, 56, 56) </text>\n<polygon fill=\"none\" stroke=\"black\" points=\"116.5,-3341.75 116.5,-3363.75 159.5,-3363.75 159.5,-3341.75 116.5,-3341.75\"/>\n<text text-anchor=\"start\" x=\"121.12\" y=\"-3349.25\" font-family=\"Linux libertine\" font-size=\"10.00\">output: </text>\n<polygon fill=\"none\" stroke=\"black\" points=\"159.5,-3341.75 159.5,-3363.75 234.5,-3363.75 234.5,-3341.75 159.5,-3341.75\"/>\n<text text-anchor=\"start\" x=\"164.38\" y=\"-3349.25\" font-family=\"Linux libertine\" font-size=\"10.00\">(1, 24, 56, 56) </text>\n</g>\n<!-- 19&#45;&gt;20 -->\n<g id=\"edge24\" class=\"edge\">\n<title>19&#45;&gt;20</title>\n<path fill=\"none\" stroke=\"black\" d=\"M154,-3421.85C154,-3414.24 154,-3405.45 154,-3397.09\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"157.5,-3397.22 154,-3387.22 150.5,-3397.22 157.5,-3397.22\"/>\n</g>\n<!-- 21 -->\n<g id=\"node22\" class=\"node\">\n<title>21</title>\n<polygon fill=\"#c1ffc1\" stroke=\"none\" points=\"243,-3295.5 65,-3295.5 65,-3251.5 243,-3251.5 243,-3295.5\"/>\n<polygon fill=\"none\" stroke=\"black\" points=\"65,-3251.5 65,-3295.5 120,-3295.5 120,-3251.5 65,-3251.5\"/>\n<text text-anchor=\"start\" x=\"70\" y=\"-3276\" font-family=\"Linux libertine\" font-size=\"10.00\">Sequential</text>\n<text text-anchor=\"start\" x=\"76\" y=\"-3264\" font-family=\"Linux libertine\" font-size=\"10.00\">depth:3</text>\n<polygon fill=\"none\" stroke=\"black\" points=\"120,-3273.5 120,-3295.5 163,-3295.5 163,-3273.5 120,-3273.5\"/>\n<text text-anchor=\"start\" x=\"129.12\" y=\"-3281\" font-family=\"Linux libertine\" font-size=\"10.00\">input:</text>\n<polygon fill=\"none\" stroke=\"black\" points=\"163,-3273.5 163,-3295.5 243,-3295.5 243,-3273.5 163,-3273.5\"/>\n<text text-anchor=\"start\" x=\"170.38\" y=\"-3281\" font-family=\"Linux libertine\" font-size=\"10.00\">(1, 24, 56, 56) </text>\n<polygon fill=\"none\" stroke=\"black\" points=\"120,-3251.5 120,-3273.5 163,-3273.5 163,-3251.5 120,-3251.5\"/>\n<text text-anchor=\"start\" x=\"124.62\" y=\"-3259\" font-family=\"Linux libertine\" font-size=\"10.00\">output: </text>\n<polygon fill=\"none\" stroke=\"black\" points=\"163,-3251.5 163,-3273.5 243,-3273.5 243,-3251.5 163,-3251.5\"/>\n<text text-anchor=\"start\" x=\"167.75\" y=\"-3259\" font-family=\"Linux libertine\" font-size=\"10.00\">(1, 144, 56, 56) </text>\n</g>\n<!-- 20&#45;&gt;21 -->\n<g id=\"edge25\" class=\"edge\">\n<title>20&#45;&gt;21</title>\n<path fill=\"none\" stroke=\"black\" d=\"M154,-3341.84C154,-3331.29 154,-3318.26 154,-3306.48\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"157.5,-3306.78 154,-3296.78 150.5,-3306.78 157.5,-3306.78\"/>\n</g>\n<!-- 22 -->\n<g id=\"node23\" class=\"node\">\n<title>22</title>\n<polygon fill=\"#c1ffc1\" stroke=\"none\" points=\"243,-3215.5 65,-3215.5 65,-3171.5 243,-3171.5 243,-3215.5\"/>\n<polygon fill=\"none\" stroke=\"black\" points=\"65,-3171.5 65,-3215.5 120,-3215.5 120,-3171.5 65,-3171.5\"/>\n<text text-anchor=\"start\" x=\"70\" y=\"-3196\" font-family=\"Linux libertine\" font-size=\"10.00\">Sequential</text>\n<text text-anchor=\"start\" x=\"76\" y=\"-3184\" font-family=\"Linux libertine\" font-size=\"10.00\">depth:3</text>\n<polygon fill=\"none\" stroke=\"black\" points=\"120,-3193.5 120,-3215.5 163,-3215.5 163,-3193.5 120,-3193.5\"/>\n<text text-anchor=\"start\" x=\"129.12\" y=\"-3201\" font-family=\"Linux libertine\" font-size=\"10.00\">input:</text>\n<polygon fill=\"none\" stroke=\"black\" points=\"163,-3193.5 163,-3215.5 243,-3215.5 243,-3193.5 163,-3193.5\"/>\n<text text-anchor=\"start\" x=\"167.75\" y=\"-3201\" font-family=\"Linux libertine\" font-size=\"10.00\">(1, 144, 56, 56) </text>\n<polygon fill=\"none\" stroke=\"black\" points=\"120,-3171.5 120,-3193.5 163,-3193.5 163,-3171.5 120,-3171.5\"/>\n<text text-anchor=\"start\" x=\"124.62\" y=\"-3179\" font-family=\"Linux libertine\" font-size=\"10.00\">output: </text>\n<polygon fill=\"none\" stroke=\"black\" points=\"163,-3171.5 163,-3193.5 243,-3193.5 243,-3171.5 163,-3171.5\"/>\n<text text-anchor=\"start\" x=\"167.75\" y=\"-3179\" font-family=\"Linux libertine\" font-size=\"10.00\">(1, 144, 28, 28) </text>\n</g>\n<!-- 21&#45;&gt;22 -->\n<g id=\"edge26\" class=\"edge\">\n<title>21&#45;&gt;22</title>\n<path fill=\"none\" stroke=\"black\" d=\"M154,-3251.6C154,-3243.99 154,-3235.2 154,-3226.84\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"157.5,-3226.97 154,-3216.97 150.5,-3226.97 157.5,-3226.97\"/>\n</g>\n<!-- 23 -->\n<g id=\"node24\" class=\"node\">\n<title>23</title>\n<polygon fill=\"#c1ffc1\" stroke=\"none\" points=\"253,-3135.5 75,-3135.5 75,-3091.5 253,-3091.5 253,-3135.5\"/>\n<polygon fill=\"none\" stroke=\"black\" points=\"75,-3091.5 75,-3135.5 130,-3135.5 130,-3091.5 75,-3091.5\"/>\n<text text-anchor=\"start\" x=\"80\" y=\"-3116\" font-family=\"Linux libertine\" font-size=\"10.00\">Sequential</text>\n<text text-anchor=\"start\" x=\"86\" y=\"-3104\" font-family=\"Linux libertine\" font-size=\"10.00\">depth:3</text>\n<polygon fill=\"none\" stroke=\"black\" points=\"130,-3113.5 130,-3135.5 173,-3135.5 173,-3113.5 130,-3113.5\"/>\n<text text-anchor=\"start\" x=\"139.12\" y=\"-3121\" font-family=\"Linux libertine\" font-size=\"10.00\">input:</text>\n<polygon fill=\"none\" stroke=\"black\" points=\"173,-3113.5 173,-3135.5 253,-3135.5 253,-3113.5 173,-3113.5\"/>\n<text text-anchor=\"start\" x=\"177.75\" y=\"-3121\" font-family=\"Linux libertine\" font-size=\"10.00\">(1, 144, 28, 28) </text>\n<polygon fill=\"none\" stroke=\"black\" points=\"130,-3091.5 130,-3113.5 173,-3113.5 173,-3091.5 130,-3091.5\"/>\n<text text-anchor=\"start\" x=\"134.62\" y=\"-3099\" font-family=\"Linux libertine\" font-size=\"10.00\">output: </text>\n<polygon fill=\"none\" stroke=\"black\" points=\"173,-3091.5 173,-3113.5 253,-3113.5 253,-3091.5 173,-3091.5\"/>\n<text text-anchor=\"start\" x=\"183\" y=\"-3099\" font-family=\"Linux libertine\" font-size=\"10.00\">(1, 144, 1, 1) </text>\n</g>\n<!-- 22&#45;&gt;23 -->\n<g id=\"edge27\" class=\"edge\">\n<title>22&#45;&gt;23</title>\n<path fill=\"none\" stroke=\"black\" d=\"M156.68,-3171.6C157.66,-3163.99 158.78,-3155.2 159.85,-3146.84\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"163.32,-3147.33 161.12,-3136.96 156.38,-3146.44 163.32,-3147.33\"/>\n</g>\n<!-- 24 -->\n<g id=\"node25\" class=\"node\">\n<title>24</title>\n<polygon fill=\"aliceblue\" stroke=\"none\" points=\"265.5,-3055.5 36.5,-3055.5 36.5,-3011.5 265.5,-3011.5 265.5,-3055.5\"/>\n<polygon fill=\"none\" stroke=\"black\" points=\"36.5,-3011.5 36.5,-3055.5 79.5,-3055.5 79.5,-3011.5 36.5,-3011.5\"/>\n<text text-anchor=\"start\" x=\"50.12\" y=\"-3036\" font-family=\"Linux libertine\" font-size=\"10.00\">mul</text>\n<text text-anchor=\"start\" x=\"41.5\" y=\"-3024\" font-family=\"Linux libertine\" font-size=\"10.00\">depth:3</text>\n<polygon fill=\"none\" stroke=\"black\" points=\"79.5,-3033.5 79.5,-3055.5 122.5,-3055.5 122.5,-3033.5 79.5,-3033.5\"/>\n<text text-anchor=\"start\" x=\"88.62\" y=\"-3041\" font-family=\"Linux libertine\" font-size=\"10.00\">input:</text>\n<polygon fill=\"none\" stroke=\"black\" points=\"122.5,-3033.5 122.5,-3055.5 265.5,-3055.5 265.5,-3033.5 122.5,-3033.5\"/>\n<text text-anchor=\"start\" x=\"127.25\" y=\"-3041\" font-family=\"Linux libertine\" font-size=\"10.00\">(1, 144, 28, 28), (1, 144, 1, 1) </text>\n<polygon fill=\"none\" stroke=\"black\" points=\"79.5,-3011.5 79.5,-3033.5 122.5,-3033.5 122.5,-3011.5 79.5,-3011.5\"/>\n<text text-anchor=\"start\" x=\"84.12\" y=\"-3019\" font-family=\"Linux libertine\" font-size=\"10.00\">output: </text>\n<polygon fill=\"none\" stroke=\"black\" points=\"122.5,-3011.5 122.5,-3033.5 265.5,-3033.5 265.5,-3011.5 122.5,-3011.5\"/>\n<text text-anchor=\"start\" x=\"158.75\" y=\"-3019\" font-family=\"Linux libertine\" font-size=\"10.00\">(1, 144, 28, 28) </text>\n</g>\n<!-- 22&#45;&gt;24 -->\n<g id=\"edge28\" class=\"edge\">\n<title>22&#45;&gt;24</title>\n<path fill=\"none\" stroke=\"black\" d=\"M103.63,-3171.53C88.81,-3162.71 74.35,-3150.85 66,-3135.5 56.66,-3118.32 56.8,-3108.75 66,-3091.5 72.4,-3079.5 82.58,-3069.58 93.7,-3061.56\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"95.53,-3064.55 101.94,-3056.11 91.66,-3058.71 95.53,-3064.55\"/>\n</g>\n<!-- 23&#45;&gt;24 -->\n<g id=\"edge29\" class=\"edge\">\n<title>23&#45;&gt;24</title>\n<path fill=\"none\" stroke=\"black\" d=\"M160.52,-3091.6C159.23,-3083.9 157.75,-3075 156.34,-3066.55\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"159.84,-3066.24 154.74,-3056.95 152.93,-3067.39 159.84,-3066.24\"/>\n</g>\n<!-- 25 -->\n<g id=\"node26\" class=\"node\">\n<title>25</title>\n<polygon fill=\"#c1ffc1\" stroke=\"none\" points=\"243,-2975.5 65,-2975.5 65,-2931.5 243,-2931.5 243,-2975.5\"/>\n<polygon fill=\"none\" stroke=\"black\" points=\"65,-2931.5 65,-2975.5 120,-2975.5 120,-2931.5 65,-2931.5\"/>\n<text text-anchor=\"start\" x=\"70\" y=\"-2956\" font-family=\"Linux libertine\" font-size=\"10.00\">Sequential</text>\n<text text-anchor=\"start\" x=\"76\" y=\"-2944\" font-family=\"Linux libertine\" font-size=\"10.00\">depth:3</text>\n<polygon fill=\"none\" stroke=\"black\" points=\"120,-2953.5 120,-2975.5 163,-2975.5 163,-2953.5 120,-2953.5\"/>\n<text text-anchor=\"start\" x=\"129.12\" y=\"-2961\" font-family=\"Linux libertine\" font-size=\"10.00\">input:</text>\n<polygon fill=\"none\" stroke=\"black\" points=\"163,-2953.5 163,-2975.5 243,-2975.5 243,-2953.5 163,-2953.5\"/>\n<text text-anchor=\"start\" x=\"167.75\" y=\"-2961\" font-family=\"Linux libertine\" font-size=\"10.00\">(1, 144, 28, 28) </text>\n<polygon fill=\"none\" stroke=\"black\" points=\"120,-2931.5 120,-2953.5 163,-2953.5 163,-2931.5 120,-2931.5\"/>\n<text text-anchor=\"start\" x=\"124.62\" y=\"-2939\" font-family=\"Linux libertine\" font-size=\"10.00\">output: </text>\n<polygon fill=\"none\" stroke=\"black\" points=\"163,-2931.5 163,-2953.5 243,-2953.5 243,-2931.5 163,-2931.5\"/>\n<text text-anchor=\"start\" x=\"170.38\" y=\"-2939\" font-family=\"Linux libertine\" font-size=\"10.00\">(1, 40, 28, 28) </text>\n</g>\n<!-- 24&#45;&gt;25 -->\n<g id=\"edge30\" class=\"edge\">\n<title>24&#45;&gt;25</title>\n<path fill=\"none\" stroke=\"black\" d=\"M151.8,-3011.6C152.1,-3003.99 152.43,-2995.2 152.76,-2986.84\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"156.25,-2987.1 153.14,-2976.97 149.25,-2986.83 156.25,-2987.1\"/>\n</g>\n<!-- 26 -->\n<g id=\"node27\" class=\"node\">\n<title>26</title>\n<polygon fill=\"#c1ffc1\" stroke=\"none\" points=\"243,-2885.25 65,-2885.25 65,-2841.25 243,-2841.25 243,-2885.25\"/>\n<polygon fill=\"none\" stroke=\"black\" points=\"65,-2841.25 65,-2885.25 120,-2885.25 120,-2841.25 65,-2841.25\"/>\n<text text-anchor=\"start\" x=\"70\" y=\"-2865.75\" font-family=\"Linux libertine\" font-size=\"10.00\">Sequential</text>\n<text text-anchor=\"start\" x=\"76\" y=\"-2853.75\" font-family=\"Linux libertine\" font-size=\"10.00\">depth:3</text>\n<polygon fill=\"none\" stroke=\"black\" points=\"120,-2863.25 120,-2885.25 163,-2885.25 163,-2863.25 120,-2863.25\"/>\n<text text-anchor=\"start\" x=\"129.12\" y=\"-2870.75\" font-family=\"Linux libertine\" font-size=\"10.00\">input:</text>\n<polygon fill=\"none\" stroke=\"black\" points=\"163,-2863.25 163,-2885.25 243,-2885.25 243,-2863.25 163,-2863.25\"/>\n<text text-anchor=\"start\" x=\"170.38\" y=\"-2870.75\" font-family=\"Linux libertine\" font-size=\"10.00\">(1, 40, 28, 28) </text>\n<polygon fill=\"none\" stroke=\"black\" points=\"120,-2841.25 120,-2863.25 163,-2863.25 163,-2841.25 120,-2841.25\"/>\n<text text-anchor=\"start\" x=\"124.62\" y=\"-2848.75\" font-family=\"Linux libertine\" font-size=\"10.00\">output: </text>\n<polygon fill=\"none\" stroke=\"black\" points=\"163,-2841.25 163,-2863.25 243,-2863.25 243,-2841.25 163,-2841.25\"/>\n<text text-anchor=\"start\" x=\"167.75\" y=\"-2848.75\" font-family=\"Linux libertine\" font-size=\"10.00\">(1, 240, 28, 28) </text>\n</g>\n<!-- 25&#45;&gt;26 -->\n<g id=\"edge31\" class=\"edge\">\n<title>25&#45;&gt;26</title>\n<path fill=\"none\" stroke=\"black\" d=\"M154,-2931.59C154,-2921.04 154,-2908.01 154,-2896.23\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"157.5,-2896.53 154,-2886.53 150.5,-2896.53 157.5,-2896.53\"/>\n</g>\n<!-- 31 -->\n<g id=\"node32\" class=\"node\">\n<title>31</title>\n<polygon fill=\"aliceblue\" stroke=\"none\" points=\"242.5,-2485.25 65.5,-2485.25 65.5,-2441.25 242.5,-2441.25 242.5,-2485.25\"/>\n<polygon fill=\"none\" stroke=\"black\" points=\"65.5,-2441.25 65.5,-2485.25 108.5,-2485.25 108.5,-2441.25 65.5,-2441.25\"/>\n<text text-anchor=\"start\" x=\"76.5\" y=\"-2465.75\" font-family=\"Linux libertine\" font-size=\"10.00\">add_</text>\n<text text-anchor=\"start\" x=\"70.5\" y=\"-2453.75\" font-family=\"Linux libertine\" font-size=\"10.00\">depth:3</text>\n<polygon fill=\"none\" stroke=\"black\" points=\"108.5,-2463.25 108.5,-2485.25 151.5,-2485.25 151.5,-2463.25 108.5,-2463.25\"/>\n<text text-anchor=\"start\" x=\"117.62\" y=\"-2470.75\" font-family=\"Linux libertine\" font-size=\"10.00\">input:</text>\n<polygon fill=\"none\" stroke=\"black\" points=\"151.5,-2463.25 151.5,-2485.25 242.5,-2485.25 242.5,-2463.25 151.5,-2463.25\"/>\n<text text-anchor=\"start\" x=\"156.5\" y=\"-2470.75\" font-family=\"Linux libertine\" font-size=\"10.00\">2 x (1, 40, 28, 28) </text>\n<polygon fill=\"none\" stroke=\"black\" points=\"108.5,-2441.25 108.5,-2463.25 151.5,-2463.25 151.5,-2441.25 108.5,-2441.25\"/>\n<text text-anchor=\"start\" x=\"113.12\" y=\"-2448.75\" font-family=\"Linux libertine\" font-size=\"10.00\">output: </text>\n<polygon fill=\"none\" stroke=\"black\" points=\"151.5,-2441.25 151.5,-2463.25 242.5,-2463.25 242.5,-2441.25 151.5,-2441.25\"/>\n<text text-anchor=\"start\" x=\"164.38\" y=\"-2448.75\" font-family=\"Linux libertine\" font-size=\"10.00\">(1, 40, 28, 28) </text>\n</g>\n<!-- 25&#45;&gt;31 -->\n<g id=\"edge32\" class=\"edge\">\n<title>25&#45;&gt;31</title>\n<path fill=\"none\" stroke=\"black\" d=\"M232.97,-2931.74C240.16,-2927.33 246.71,-2921.98 252,-2915.5 289.34,-2869.72 273,-2843.33 273,-2784.25 273,-2784.25 273,-2784.25 273,-2622.25 273,-2575.78 273.7,-2558.56 246,-2521.25 237.07,-2509.23 224.79,-2499.17 212.11,-2491.01\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"214.04,-2488.09 203.67,-2485.93 210.43,-2494.09 214.04,-2488.09\"/>\n</g>\n<!-- 27 -->\n<g id=\"node28\" class=\"node\">\n<title>27</title>\n<polygon fill=\"#c1ffc1\" stroke=\"none\" points=\"243,-2805.25 65,-2805.25 65,-2761.25 243,-2761.25 243,-2805.25\"/>\n<polygon fill=\"none\" stroke=\"black\" points=\"65,-2761.25 65,-2805.25 120,-2805.25 120,-2761.25 65,-2761.25\"/>\n<text text-anchor=\"start\" x=\"70\" y=\"-2785.75\" font-family=\"Linux libertine\" font-size=\"10.00\">Sequential</text>\n<text text-anchor=\"start\" x=\"76\" y=\"-2773.75\" font-family=\"Linux libertine\" font-size=\"10.00\">depth:3</text>\n<polygon fill=\"none\" stroke=\"black\" points=\"120,-2783.25 120,-2805.25 163,-2805.25 163,-2783.25 120,-2783.25\"/>\n<text text-anchor=\"start\" x=\"129.12\" y=\"-2790.75\" font-family=\"Linux libertine\" font-size=\"10.00\">input:</text>\n<polygon fill=\"none\" stroke=\"black\" points=\"163,-2783.25 163,-2805.25 243,-2805.25 243,-2783.25 163,-2783.25\"/>\n<text text-anchor=\"start\" x=\"167.75\" y=\"-2790.75\" font-family=\"Linux libertine\" font-size=\"10.00\">(1, 240, 28, 28) </text>\n<polygon fill=\"none\" stroke=\"black\" points=\"120,-2761.25 120,-2783.25 163,-2783.25 163,-2761.25 120,-2761.25\"/>\n<text text-anchor=\"start\" x=\"124.62\" y=\"-2768.75\" font-family=\"Linux libertine\" font-size=\"10.00\">output: </text>\n<polygon fill=\"none\" stroke=\"black\" points=\"163,-2761.25 163,-2783.25 243,-2783.25 243,-2761.25 163,-2761.25\"/>\n<text text-anchor=\"start\" x=\"167.75\" y=\"-2768.75\" font-family=\"Linux libertine\" font-size=\"10.00\">(1, 240, 28, 28) </text>\n</g>\n<!-- 26&#45;&gt;27 -->\n<g id=\"edge33\" class=\"edge\">\n<title>26&#45;&gt;27</title>\n<path fill=\"none\" stroke=\"black\" d=\"M154,-2841.35C154,-2833.74 154,-2824.95 154,-2816.59\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"157.5,-2816.72 154,-2806.72 150.5,-2816.72 157.5,-2816.72\"/>\n</g>\n<!-- 28 -->\n<g id=\"node29\" class=\"node\">\n<title>28</title>\n<polygon fill=\"#c1ffc1\" stroke=\"none\" points=\"247,-2725.25 69,-2725.25 69,-2681.25 247,-2681.25 247,-2725.25\"/>\n<polygon fill=\"none\" stroke=\"black\" points=\"69,-2681.25 69,-2725.25 124,-2725.25 124,-2681.25 69,-2681.25\"/>\n<text text-anchor=\"start\" x=\"74\" y=\"-2705.75\" font-family=\"Linux libertine\" font-size=\"10.00\">Sequential</text>\n<text text-anchor=\"start\" x=\"80\" y=\"-2693.75\" font-family=\"Linux libertine\" font-size=\"10.00\">depth:3</text>\n<polygon fill=\"none\" stroke=\"black\" points=\"124,-2703.25 124,-2725.25 167,-2725.25 167,-2703.25 124,-2703.25\"/>\n<text text-anchor=\"start\" x=\"133.12\" y=\"-2710.75\" font-family=\"Linux libertine\" font-size=\"10.00\">input:</text>\n<polygon fill=\"none\" stroke=\"black\" points=\"167,-2703.25 167,-2725.25 247,-2725.25 247,-2703.25 167,-2703.25\"/>\n<text text-anchor=\"start\" x=\"171.75\" y=\"-2710.75\" font-family=\"Linux libertine\" font-size=\"10.00\">(1, 240, 28, 28) </text>\n<polygon fill=\"none\" stroke=\"black\" points=\"124,-2681.25 124,-2703.25 167,-2703.25 167,-2681.25 124,-2681.25\"/>\n<text text-anchor=\"start\" x=\"128.62\" y=\"-2688.75\" font-family=\"Linux libertine\" font-size=\"10.00\">output: </text>\n<polygon fill=\"none\" stroke=\"black\" points=\"167,-2681.25 167,-2703.25 247,-2703.25 247,-2681.25 167,-2681.25\"/>\n<text text-anchor=\"start\" x=\"177\" y=\"-2688.75\" font-family=\"Linux libertine\" font-size=\"10.00\">(1, 240, 1, 1) </text>\n</g>\n<!-- 27&#45;&gt;28 -->\n<g id=\"edge34\" class=\"edge\">\n<title>27&#45;&gt;28</title>\n<path fill=\"none\" stroke=\"black\" d=\"M155.07,-2761.35C155.46,-2753.74 155.91,-2744.95 156.34,-2736.59\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"159.83,-2736.89 156.85,-2726.72 152.84,-2736.53 159.83,-2736.89\"/>\n</g>\n<!-- 29 -->\n<g id=\"node30\" class=\"node\">\n<title>29</title>\n<polygon fill=\"aliceblue\" stroke=\"none\" points=\"253.5,-2645.25 24.5,-2645.25 24.5,-2601.25 253.5,-2601.25 253.5,-2645.25\"/>\n<polygon fill=\"none\" stroke=\"black\" points=\"24.5,-2601.25 24.5,-2645.25 67.5,-2645.25 67.5,-2601.25 24.5,-2601.25\"/>\n<text text-anchor=\"start\" x=\"38.12\" y=\"-2625.75\" font-family=\"Linux libertine\" font-size=\"10.00\">mul</text>\n<text text-anchor=\"start\" x=\"29.5\" y=\"-2613.75\" font-family=\"Linux libertine\" font-size=\"10.00\">depth:3</text>\n<polygon fill=\"none\" stroke=\"black\" points=\"67.5,-2623.25 67.5,-2645.25 110.5,-2645.25 110.5,-2623.25 67.5,-2623.25\"/>\n<text text-anchor=\"start\" x=\"76.62\" y=\"-2630.75\" font-family=\"Linux libertine\" font-size=\"10.00\">input:</text>\n<polygon fill=\"none\" stroke=\"black\" points=\"110.5,-2623.25 110.5,-2645.25 253.5,-2645.25 253.5,-2623.25 110.5,-2623.25\"/>\n<text text-anchor=\"start\" x=\"115.25\" y=\"-2630.75\" font-family=\"Linux libertine\" font-size=\"10.00\">(1, 240, 28, 28), (1, 240, 1, 1) </text>\n<polygon fill=\"none\" stroke=\"black\" points=\"67.5,-2601.25 67.5,-2623.25 110.5,-2623.25 110.5,-2601.25 67.5,-2601.25\"/>\n<text text-anchor=\"start\" x=\"72.12\" y=\"-2608.75\" font-family=\"Linux libertine\" font-size=\"10.00\">output: </text>\n<polygon fill=\"none\" stroke=\"black\" points=\"110.5,-2601.25 110.5,-2623.25 253.5,-2623.25 253.5,-2601.25 110.5,-2601.25\"/>\n<text text-anchor=\"start\" x=\"146.75\" y=\"-2608.75\" font-family=\"Linux libertine\" font-size=\"10.00\">(1, 240, 28, 28) </text>\n</g>\n<!-- 27&#45;&gt;29 -->\n<g id=\"edge35\" class=\"edge\">\n<title>27&#45;&gt;29</title>\n<path fill=\"none\" stroke=\"black\" d=\"M99.29,-2761.44C83.81,-2752.72 68.8,-2740.88 60,-2725.25 50.4,-2708.21 51.09,-2698.66 60,-2681.25 65.96,-2669.6 75.53,-2659.79 85.98,-2651.77\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"87.93,-2654.67 94.09,-2646.05 83.9,-2648.95 87.93,-2654.67\"/>\n</g>\n<!-- 28&#45;&gt;29 -->\n<g id=\"edge36\" class=\"edge\">\n<title>28&#45;&gt;29</title>\n<path fill=\"none\" stroke=\"black\" d=\"M152.91,-2681.35C151.03,-2673.65 148.87,-2664.75 146.81,-2656.3\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"150.23,-2655.57 144.46,-2646.68 143.43,-2657.23 150.23,-2655.57\"/>\n</g>\n<!-- 30 -->\n<g id=\"node31\" class=\"node\">\n<title>30</title>\n<polygon fill=\"#c1ffc1\" stroke=\"none\" points=\"237,-2565.25 59,-2565.25 59,-2521.25 237,-2521.25 237,-2565.25\"/>\n<polygon fill=\"none\" stroke=\"black\" points=\"59,-2521.25 59,-2565.25 114,-2565.25 114,-2521.25 59,-2521.25\"/>\n<text text-anchor=\"start\" x=\"64\" y=\"-2545.75\" font-family=\"Linux libertine\" font-size=\"10.00\">Sequential</text>\n<text text-anchor=\"start\" x=\"70\" y=\"-2533.75\" font-family=\"Linux libertine\" font-size=\"10.00\">depth:3</text>\n<polygon fill=\"none\" stroke=\"black\" points=\"114,-2543.25 114,-2565.25 157,-2565.25 157,-2543.25 114,-2543.25\"/>\n<text text-anchor=\"start\" x=\"123.12\" y=\"-2550.75\" font-family=\"Linux libertine\" font-size=\"10.00\">input:</text>\n<polygon fill=\"none\" stroke=\"black\" points=\"157,-2543.25 157,-2565.25 237,-2565.25 237,-2543.25 157,-2543.25\"/>\n<text text-anchor=\"start\" x=\"161.75\" y=\"-2550.75\" font-family=\"Linux libertine\" font-size=\"10.00\">(1, 240, 28, 28) </text>\n<polygon fill=\"none\" stroke=\"black\" points=\"114,-2521.25 114,-2543.25 157,-2543.25 157,-2521.25 114,-2521.25\"/>\n<text text-anchor=\"start\" x=\"118.62\" y=\"-2528.75\" font-family=\"Linux libertine\" font-size=\"10.00\">output: </text>\n<polygon fill=\"none\" stroke=\"black\" points=\"157,-2521.25 157,-2543.25 237,-2543.25 237,-2521.25 157,-2521.25\"/>\n<text text-anchor=\"start\" x=\"164.38\" y=\"-2528.75\" font-family=\"Linux libertine\" font-size=\"10.00\">(1, 40, 28, 28) </text>\n</g>\n<!-- 29&#45;&gt;30 -->\n<g id=\"edge37\" class=\"edge\">\n<title>29&#45;&gt;30</title>\n<path fill=\"none\" stroke=\"black\" d=\"M141.41,-2601.35C142.29,-2593.74 143.3,-2584.95 144.27,-2576.59\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"147.74,-2577.05 145.41,-2566.71 140.78,-2576.25 147.74,-2577.05\"/>\n</g>\n<!-- 30&#45;&gt;31 -->\n<g id=\"edge38\" class=\"edge\">\n<title>30&#45;&gt;31</title>\n<path fill=\"none\" stroke=\"black\" d=\"M149.61,-2521.35C150.19,-2513.74 150.87,-2504.95 151.51,-2496.59\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"154.99,-2496.96 152.27,-2486.72 148.01,-2496.42 154.99,-2496.96\"/>\n</g>\n<!-- 32 -->\n<g id=\"node33\" class=\"node\">\n<title>32</title>\n<polygon fill=\"#c1ffc1\" stroke=\"none\" points=\"234.5,-2405.25 73.5,-2405.25 73.5,-2361.25 234.5,-2361.25 234.5,-2405.25\"/>\n<polygon fill=\"none\" stroke=\"black\" points=\"73.5,-2361.25 73.5,-2405.25 116.5,-2405.25 116.5,-2361.25 73.5,-2361.25\"/>\n<text text-anchor=\"start\" x=\"78.12\" y=\"-2385.75\" font-family=\"Linux libertine\" font-size=\"10.00\">Dropout</text>\n<text text-anchor=\"start\" x=\"78.5\" y=\"-2373.75\" font-family=\"Linux libertine\" font-size=\"10.00\">depth:3</text>\n<polygon fill=\"none\" stroke=\"black\" points=\"116.5,-2383.25 116.5,-2405.25 159.5,-2405.25 159.5,-2383.25 116.5,-2383.25\"/>\n<text text-anchor=\"start\" x=\"125.62\" y=\"-2390.75\" font-family=\"Linux libertine\" font-size=\"10.00\">input:</text>\n<polygon fill=\"none\" stroke=\"black\" points=\"159.5,-2383.25 159.5,-2405.25 234.5,-2405.25 234.5,-2383.25 159.5,-2383.25\"/>\n<text text-anchor=\"start\" x=\"164.38\" y=\"-2390.75\" font-family=\"Linux libertine\" font-size=\"10.00\">(1, 40, 28, 28) </text>\n<polygon fill=\"none\" stroke=\"black\" points=\"116.5,-2361.25 116.5,-2383.25 159.5,-2383.25 159.5,-2361.25 116.5,-2361.25\"/>\n<text text-anchor=\"start\" x=\"121.12\" y=\"-2368.75\" font-family=\"Linux libertine\" font-size=\"10.00\">output: </text>\n<polygon fill=\"none\" stroke=\"black\" points=\"159.5,-2361.25 159.5,-2383.25 234.5,-2383.25 234.5,-2361.25 159.5,-2361.25\"/>\n<text text-anchor=\"start\" x=\"164.38\" y=\"-2368.75\" font-family=\"Linux libertine\" font-size=\"10.00\">(1, 40, 28, 28) </text>\n</g>\n<!-- 31&#45;&gt;32 -->\n<g id=\"edge39\" class=\"edge\">\n<title>31&#45;&gt;32</title>\n<path fill=\"none\" stroke=\"black\" d=\"M154,-2441.35C154,-2433.74 154,-2424.95 154,-2416.59\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"157.5,-2416.72 154,-2406.72 150.5,-2416.72 157.5,-2416.72\"/>\n</g>\n<!-- 33 -->\n<g id=\"node34\" class=\"node\">\n<title>33</title>\n<polygon fill=\"#c1ffc1\" stroke=\"none\" points=\"243,-2315 65,-2315 65,-2271 243,-2271 243,-2315\"/>\n<polygon fill=\"none\" stroke=\"black\" points=\"65,-2271 65,-2315 120,-2315 120,-2271 65,-2271\"/>\n<text text-anchor=\"start\" x=\"70\" y=\"-2295.5\" font-family=\"Linux libertine\" font-size=\"10.00\">Sequential</text>\n<text text-anchor=\"start\" x=\"76\" y=\"-2283.5\" font-family=\"Linux libertine\" font-size=\"10.00\">depth:3</text>\n<polygon fill=\"none\" stroke=\"black\" points=\"120,-2293 120,-2315 163,-2315 163,-2293 120,-2293\"/>\n<text text-anchor=\"start\" x=\"129.12\" y=\"-2300.5\" font-family=\"Linux libertine\" font-size=\"10.00\">input:</text>\n<polygon fill=\"none\" stroke=\"black\" points=\"163,-2293 163,-2315 243,-2315 243,-2293 163,-2293\"/>\n<text text-anchor=\"start\" x=\"170.38\" y=\"-2300.5\" font-family=\"Linux libertine\" font-size=\"10.00\">(1, 40, 28, 28) </text>\n<polygon fill=\"none\" stroke=\"black\" points=\"120,-2271 120,-2293 163,-2293 163,-2271 120,-2271\"/>\n<text text-anchor=\"start\" x=\"124.62\" y=\"-2278.5\" font-family=\"Linux libertine\" font-size=\"10.00\">output: </text>\n<polygon fill=\"none\" stroke=\"black\" points=\"163,-2271 163,-2293 243,-2293 243,-2271 163,-2271\"/>\n<text text-anchor=\"start\" x=\"167.75\" y=\"-2278.5\" font-family=\"Linux libertine\" font-size=\"10.00\">(1, 240, 28, 28) </text>\n</g>\n<!-- 32&#45;&gt;33 -->\n<g id=\"edge40\" class=\"edge\">\n<title>32&#45;&gt;33</title>\n<path fill=\"none\" stroke=\"black\" d=\"M154,-2361.34C154,-2350.79 154,-2337.76 154,-2325.98\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"157.5,-2326.28 154,-2316.28 150.5,-2326.28 157.5,-2326.28\"/>\n</g>\n<!-- 34 -->\n<g id=\"node35\" class=\"node\">\n<title>34</title>\n<polygon fill=\"#c1ffc1\" stroke=\"none\" points=\"243,-2235 65,-2235 65,-2191 243,-2191 243,-2235\"/>\n<polygon fill=\"none\" stroke=\"black\" points=\"65,-2191 65,-2235 120,-2235 120,-2191 65,-2191\"/>\n<text text-anchor=\"start\" x=\"70\" y=\"-2215.5\" font-family=\"Linux libertine\" font-size=\"10.00\">Sequential</text>\n<text text-anchor=\"start\" x=\"76\" y=\"-2203.5\" font-family=\"Linux libertine\" font-size=\"10.00\">depth:3</text>\n<polygon fill=\"none\" stroke=\"black\" points=\"120,-2213 120,-2235 163,-2235 163,-2213 120,-2213\"/>\n<text text-anchor=\"start\" x=\"129.12\" y=\"-2220.5\" font-family=\"Linux libertine\" font-size=\"10.00\">input:</text>\n<polygon fill=\"none\" stroke=\"black\" points=\"163,-2213 163,-2235 243,-2235 243,-2213 163,-2213\"/>\n<text text-anchor=\"start\" x=\"167.75\" y=\"-2220.5\" font-family=\"Linux libertine\" font-size=\"10.00\">(1, 240, 28, 28) </text>\n<polygon fill=\"none\" stroke=\"black\" points=\"120,-2191 120,-2213 163,-2213 163,-2191 120,-2191\"/>\n<text text-anchor=\"start\" x=\"124.62\" y=\"-2198.5\" font-family=\"Linux libertine\" font-size=\"10.00\">output: </text>\n<polygon fill=\"none\" stroke=\"black\" points=\"163,-2191 163,-2213 243,-2213 243,-2191 163,-2191\"/>\n<text text-anchor=\"start\" x=\"167.75\" y=\"-2198.5\" font-family=\"Linux libertine\" font-size=\"10.00\">(1, 240, 14, 14) </text>\n</g>\n<!-- 33&#45;&gt;34 -->\n<g id=\"edge41\" class=\"edge\">\n<title>33&#45;&gt;34</title>\n<path fill=\"none\" stroke=\"black\" d=\"M154,-2271.1C154,-2263.49 154,-2254.7 154,-2246.34\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"157.5,-2246.47 154,-2236.47 150.5,-2246.47 157.5,-2246.47\"/>\n</g>\n<!-- 35 -->\n<g id=\"node36\" class=\"node\">\n<title>35</title>\n<polygon fill=\"#c1ffc1\" stroke=\"none\" points=\"253,-2155 75,-2155 75,-2111 253,-2111 253,-2155\"/>\n<polygon fill=\"none\" stroke=\"black\" points=\"75,-2111 75,-2155 130,-2155 130,-2111 75,-2111\"/>\n<text text-anchor=\"start\" x=\"80\" y=\"-2135.5\" font-family=\"Linux libertine\" font-size=\"10.00\">Sequential</text>\n<text text-anchor=\"start\" x=\"86\" y=\"-2123.5\" font-family=\"Linux libertine\" font-size=\"10.00\">depth:3</text>\n<polygon fill=\"none\" stroke=\"black\" points=\"130,-2133 130,-2155 173,-2155 173,-2133 130,-2133\"/>\n<text text-anchor=\"start\" x=\"139.12\" y=\"-2140.5\" font-family=\"Linux libertine\" font-size=\"10.00\">input:</text>\n<polygon fill=\"none\" stroke=\"black\" points=\"173,-2133 173,-2155 253,-2155 253,-2133 173,-2133\"/>\n<text text-anchor=\"start\" x=\"177.75\" y=\"-2140.5\" font-family=\"Linux libertine\" font-size=\"10.00\">(1, 240, 14, 14) </text>\n<polygon fill=\"none\" stroke=\"black\" points=\"130,-2111 130,-2133 173,-2133 173,-2111 130,-2111\"/>\n<text text-anchor=\"start\" x=\"134.62\" y=\"-2118.5\" font-family=\"Linux libertine\" font-size=\"10.00\">output: </text>\n<polygon fill=\"none\" stroke=\"black\" points=\"173,-2111 173,-2133 253,-2133 253,-2111 173,-2111\"/>\n<text text-anchor=\"start\" x=\"183\" y=\"-2118.5\" font-family=\"Linux libertine\" font-size=\"10.00\">(1, 240, 1, 1) </text>\n</g>\n<!-- 34&#45;&gt;35 -->\n<g id=\"edge42\" class=\"edge\">\n<title>34&#45;&gt;35</title>\n<path fill=\"none\" stroke=\"black\" d=\"M156.68,-2191.1C157.66,-2183.49 158.78,-2174.7 159.85,-2166.34\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"163.32,-2166.83 161.12,-2156.46 156.38,-2165.94 163.32,-2166.83\"/>\n</g>\n<!-- 36 -->\n<g id=\"node37\" class=\"node\">\n<title>36</title>\n<polygon fill=\"aliceblue\" stroke=\"none\" points=\"265.5,-2075 36.5,-2075 36.5,-2031 265.5,-2031 265.5,-2075\"/>\n<polygon fill=\"none\" stroke=\"black\" points=\"36.5,-2031 36.5,-2075 79.5,-2075 79.5,-2031 36.5,-2031\"/>\n<text text-anchor=\"start\" x=\"50.12\" y=\"-2055.5\" font-family=\"Linux libertine\" font-size=\"10.00\">mul</text>\n<text text-anchor=\"start\" x=\"41.5\" y=\"-2043.5\" font-family=\"Linux libertine\" font-size=\"10.00\">depth:3</text>\n<polygon fill=\"none\" stroke=\"black\" points=\"79.5,-2053 79.5,-2075 122.5,-2075 122.5,-2053 79.5,-2053\"/>\n<text text-anchor=\"start\" x=\"88.62\" y=\"-2060.5\" font-family=\"Linux libertine\" font-size=\"10.00\">input:</text>\n<polygon fill=\"none\" stroke=\"black\" points=\"122.5,-2053 122.5,-2075 265.5,-2075 265.5,-2053 122.5,-2053\"/>\n<text text-anchor=\"start\" x=\"127.25\" y=\"-2060.5\" font-family=\"Linux libertine\" font-size=\"10.00\">(1, 240, 14, 14), (1, 240, 1, 1) </text>\n<polygon fill=\"none\" stroke=\"black\" points=\"79.5,-2031 79.5,-2053 122.5,-2053 122.5,-2031 79.5,-2031\"/>\n<text text-anchor=\"start\" x=\"84.12\" y=\"-2038.5\" font-family=\"Linux libertine\" font-size=\"10.00\">output: </text>\n<polygon fill=\"none\" stroke=\"black\" points=\"122.5,-2031 122.5,-2053 265.5,-2053 265.5,-2031 122.5,-2031\"/>\n<text text-anchor=\"start\" x=\"158.75\" y=\"-2038.5\" font-family=\"Linux libertine\" font-size=\"10.00\">(1, 240, 14, 14) </text>\n</g>\n<!-- 34&#45;&gt;36 -->\n<g id=\"edge43\" class=\"edge\">\n<title>34&#45;&gt;36</title>\n<path fill=\"none\" stroke=\"black\" d=\"M103.63,-2191.03C88.81,-2182.21 74.35,-2170.35 66,-2155 56.66,-2137.82 56.8,-2128.25 66,-2111 72.4,-2099 82.58,-2089.08 93.7,-2081.06\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"95.53,-2084.05 101.94,-2075.61 91.66,-2078.21 95.53,-2084.05\"/>\n</g>\n<!-- 35&#45;&gt;36 -->\n<g id=\"edge44\" class=\"edge\">\n<title>35&#45;&gt;36</title>\n<path fill=\"none\" stroke=\"black\" d=\"M160.52,-2111.1C159.23,-2103.4 157.75,-2094.5 156.34,-2086.05\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"159.84,-2085.74 154.74,-2076.45 152.93,-2086.89 159.84,-2085.74\"/>\n</g>\n<!-- 37 -->\n<g id=\"node38\" class=\"node\">\n<title>37</title>\n<polygon fill=\"#c1ffc1\" stroke=\"none\" points=\"243,-1995 65,-1995 65,-1951 243,-1951 243,-1995\"/>\n<polygon fill=\"none\" stroke=\"black\" points=\"65,-1951 65,-1995 120,-1995 120,-1951 65,-1951\"/>\n<text text-anchor=\"start\" x=\"70\" y=\"-1975.5\" font-family=\"Linux libertine\" font-size=\"10.00\">Sequential</text>\n<text text-anchor=\"start\" x=\"76\" y=\"-1963.5\" font-family=\"Linux libertine\" font-size=\"10.00\">depth:3</text>\n<polygon fill=\"none\" stroke=\"black\" points=\"120,-1973 120,-1995 163,-1995 163,-1973 120,-1973\"/>\n<text text-anchor=\"start\" x=\"129.12\" y=\"-1980.5\" font-family=\"Linux libertine\" font-size=\"10.00\">input:</text>\n<polygon fill=\"none\" stroke=\"black\" points=\"163,-1973 163,-1995 243,-1995 243,-1973 163,-1973\"/>\n<text text-anchor=\"start\" x=\"167.75\" y=\"-1980.5\" font-family=\"Linux libertine\" font-size=\"10.00\">(1, 240, 14, 14) </text>\n<polygon fill=\"none\" stroke=\"black\" points=\"120,-1951 120,-1973 163,-1973 163,-1951 120,-1951\"/>\n<text text-anchor=\"start\" x=\"124.62\" y=\"-1958.5\" font-family=\"Linux libertine\" font-size=\"10.00\">output: </text>\n<polygon fill=\"none\" stroke=\"black\" points=\"163,-1951 163,-1973 243,-1973 243,-1951 163,-1951\"/>\n<text text-anchor=\"start\" x=\"170.38\" y=\"-1958.5\" font-family=\"Linux libertine\" font-size=\"10.00\">(1, 80, 14, 14) </text>\n</g>\n<!-- 36&#45;&gt;37 -->\n<g id=\"edge45\" class=\"edge\">\n<title>36&#45;&gt;37</title>\n<path fill=\"none\" stroke=\"black\" d=\"M151.8,-2031.1C152.1,-2023.49 152.43,-2014.7 152.76,-2006.34\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"156.25,-2006.6 153.14,-1996.47 149.25,-2006.33 156.25,-2006.6\"/>\n</g>\n<!-- 38 -->\n<g id=\"node39\" class=\"node\">\n<title>38</title>\n<polygon fill=\"#c1ffc1\" stroke=\"none\" points=\"243,-1904.75 65,-1904.75 65,-1860.75 243,-1860.75 243,-1904.75\"/>\n<polygon fill=\"none\" stroke=\"black\" points=\"65,-1860.75 65,-1904.75 120,-1904.75 120,-1860.75 65,-1860.75\"/>\n<text text-anchor=\"start\" x=\"70\" y=\"-1885.25\" font-family=\"Linux libertine\" font-size=\"10.00\">Sequential</text>\n<text text-anchor=\"start\" x=\"76\" y=\"-1873.25\" font-family=\"Linux libertine\" font-size=\"10.00\">depth:3</text>\n<polygon fill=\"none\" stroke=\"black\" points=\"120,-1882.75 120,-1904.75 163,-1904.75 163,-1882.75 120,-1882.75\"/>\n<text text-anchor=\"start\" x=\"129.12\" y=\"-1890.25\" font-family=\"Linux libertine\" font-size=\"10.00\">input:</text>\n<polygon fill=\"none\" stroke=\"black\" points=\"163,-1882.75 163,-1904.75 243,-1904.75 243,-1882.75 163,-1882.75\"/>\n<text text-anchor=\"start\" x=\"170.38\" y=\"-1890.25\" font-family=\"Linux libertine\" font-size=\"10.00\">(1, 80, 14, 14) </text>\n<polygon fill=\"none\" stroke=\"black\" points=\"120,-1860.75 120,-1882.75 163,-1882.75 163,-1860.75 120,-1860.75\"/>\n<text text-anchor=\"start\" x=\"124.62\" y=\"-1868.25\" font-family=\"Linux libertine\" font-size=\"10.00\">output: </text>\n<polygon fill=\"none\" stroke=\"black\" points=\"163,-1860.75 163,-1882.75 243,-1882.75 243,-1860.75 163,-1860.75\"/>\n<text text-anchor=\"start\" x=\"167.75\" y=\"-1868.25\" font-family=\"Linux libertine\" font-size=\"10.00\">(1, 480, 14, 14) </text>\n</g>\n<!-- 37&#45;&gt;38 -->\n<g id=\"edge46\" class=\"edge\">\n<title>37&#45;&gt;38</title>\n<path fill=\"none\" stroke=\"black\" d=\"M154,-1951.09C154,-1940.54 154,-1927.51 154,-1915.73\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"157.5,-1916.03 154,-1906.03 150.5,-1916.03 157.5,-1916.03\"/>\n</g>\n<!-- 43 -->\n<g id=\"node44\" class=\"node\">\n<title>43</title>\n<polygon fill=\"aliceblue\" stroke=\"none\" points=\"253.5,-1504.75 76.5,-1504.75 76.5,-1460.75 253.5,-1460.75 253.5,-1504.75\"/>\n<polygon fill=\"none\" stroke=\"black\" points=\"76.5,-1460.75 76.5,-1504.75 119.5,-1504.75 119.5,-1460.75 76.5,-1460.75\"/>\n<text text-anchor=\"start\" x=\"87.5\" y=\"-1485.25\" font-family=\"Linux libertine\" font-size=\"10.00\">add_</text>\n<text text-anchor=\"start\" x=\"81.5\" y=\"-1473.25\" font-family=\"Linux libertine\" font-size=\"10.00\">depth:3</text>\n<polygon fill=\"none\" stroke=\"black\" points=\"119.5,-1482.75 119.5,-1504.75 162.5,-1504.75 162.5,-1482.75 119.5,-1482.75\"/>\n<text text-anchor=\"start\" x=\"128.62\" y=\"-1490.25\" font-family=\"Linux libertine\" font-size=\"10.00\">input:</text>\n<polygon fill=\"none\" stroke=\"black\" points=\"162.5,-1482.75 162.5,-1504.75 253.5,-1504.75 253.5,-1482.75 162.5,-1482.75\"/>\n<text text-anchor=\"start\" x=\"167.5\" y=\"-1490.25\" font-family=\"Linux libertine\" font-size=\"10.00\">2 x (1, 80, 14, 14) </text>\n<polygon fill=\"none\" stroke=\"black\" points=\"119.5,-1460.75 119.5,-1482.75 162.5,-1482.75 162.5,-1460.75 119.5,-1460.75\"/>\n<text text-anchor=\"start\" x=\"124.12\" y=\"-1468.25\" font-family=\"Linux libertine\" font-size=\"10.00\">output: </text>\n<polygon fill=\"none\" stroke=\"black\" points=\"162.5,-1460.75 162.5,-1482.75 253.5,-1482.75 253.5,-1460.75 162.5,-1460.75\"/>\n<text text-anchor=\"start\" x=\"175.38\" y=\"-1468.25\" font-family=\"Linux libertine\" font-size=\"10.00\">(1, 80, 14, 14) </text>\n</g>\n<!-- 37&#45;&gt;43 -->\n<g id=\"edge47\" class=\"edge\">\n<title>37&#45;&gt;43</title>\n<path fill=\"none\" stroke=\"black\" d=\"M232.97,-1951.24C240.16,-1946.83 246.71,-1941.48 252,-1935 289.34,-1889.22 273,-1862.83 273,-1803.75 273,-1803.75 273,-1803.75 273,-1641.75 273,-1595.71 276.07,-1578.69 250,-1540.75 241.9,-1528.96 230.49,-1518.95 218.66,-1510.77\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"220.7,-1507.92 210.4,-1505.42 216.89,-1513.79 220.7,-1507.92\"/>\n</g>\n<!-- 39 -->\n<g id=\"node40\" class=\"node\">\n<title>39</title>\n<polygon fill=\"#c1ffc1\" stroke=\"none\" points=\"243,-1824.75 65,-1824.75 65,-1780.75 243,-1780.75 243,-1824.75\"/>\n<polygon fill=\"none\" stroke=\"black\" points=\"65,-1780.75 65,-1824.75 120,-1824.75 120,-1780.75 65,-1780.75\"/>\n<text text-anchor=\"start\" x=\"70\" y=\"-1805.25\" font-family=\"Linux libertine\" font-size=\"10.00\">Sequential</text>\n<text text-anchor=\"start\" x=\"76\" y=\"-1793.25\" font-family=\"Linux libertine\" font-size=\"10.00\">depth:3</text>\n<polygon fill=\"none\" stroke=\"black\" points=\"120,-1802.75 120,-1824.75 163,-1824.75 163,-1802.75 120,-1802.75\"/>\n<text text-anchor=\"start\" x=\"129.12\" y=\"-1810.25\" font-family=\"Linux libertine\" font-size=\"10.00\">input:</text>\n<polygon fill=\"none\" stroke=\"black\" points=\"163,-1802.75 163,-1824.75 243,-1824.75 243,-1802.75 163,-1802.75\"/>\n<text text-anchor=\"start\" x=\"167.75\" y=\"-1810.25\" font-family=\"Linux libertine\" font-size=\"10.00\">(1, 480, 14, 14) </text>\n<polygon fill=\"none\" stroke=\"black\" points=\"120,-1780.75 120,-1802.75 163,-1802.75 163,-1780.75 120,-1780.75\"/>\n<text text-anchor=\"start\" x=\"124.62\" y=\"-1788.25\" font-family=\"Linux libertine\" font-size=\"10.00\">output: </text>\n<polygon fill=\"none\" stroke=\"black\" points=\"163,-1780.75 163,-1802.75 243,-1802.75 243,-1780.75 163,-1780.75\"/>\n<text text-anchor=\"start\" x=\"167.75\" y=\"-1788.25\" font-family=\"Linux libertine\" font-size=\"10.00\">(1, 480, 14, 14) </text>\n</g>\n<!-- 38&#45;&gt;39 -->\n<g id=\"edge48\" class=\"edge\">\n<title>38&#45;&gt;39</title>\n<path fill=\"none\" stroke=\"black\" d=\"M154,-1860.85C154,-1853.24 154,-1844.45 154,-1836.09\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"157.5,-1836.22 154,-1826.22 150.5,-1836.22 157.5,-1836.22\"/>\n</g>\n<!-- 40 -->\n<g id=\"node41\" class=\"node\">\n<title>40</title>\n<polygon fill=\"#c1ffc1\" stroke=\"none\" points=\"250,-1744.75 72,-1744.75 72,-1700.75 250,-1700.75 250,-1744.75\"/>\n<polygon fill=\"none\" stroke=\"black\" points=\"72,-1700.75 72,-1744.75 127,-1744.75 127,-1700.75 72,-1700.75\"/>\n<text text-anchor=\"start\" x=\"77\" y=\"-1725.25\" font-family=\"Linux libertine\" font-size=\"10.00\">Sequential</text>\n<text text-anchor=\"start\" x=\"83\" y=\"-1713.25\" font-family=\"Linux libertine\" font-size=\"10.00\">depth:3</text>\n<polygon fill=\"none\" stroke=\"black\" points=\"127,-1722.75 127,-1744.75 170,-1744.75 170,-1722.75 127,-1722.75\"/>\n<text text-anchor=\"start\" x=\"136.12\" y=\"-1730.25\" font-family=\"Linux libertine\" font-size=\"10.00\">input:</text>\n<polygon fill=\"none\" stroke=\"black\" points=\"170,-1722.75 170,-1744.75 250,-1744.75 250,-1722.75 170,-1722.75\"/>\n<text text-anchor=\"start\" x=\"174.75\" y=\"-1730.25\" font-family=\"Linux libertine\" font-size=\"10.00\">(1, 480, 14, 14) </text>\n<polygon fill=\"none\" stroke=\"black\" points=\"127,-1700.75 127,-1722.75 170,-1722.75 170,-1700.75 127,-1700.75\"/>\n<text text-anchor=\"start\" x=\"131.62\" y=\"-1708.25\" font-family=\"Linux libertine\" font-size=\"10.00\">output: </text>\n<polygon fill=\"none\" stroke=\"black\" points=\"170,-1700.75 170,-1722.75 250,-1722.75 250,-1700.75 170,-1700.75\"/>\n<text text-anchor=\"start\" x=\"180\" y=\"-1708.25\" font-family=\"Linux libertine\" font-size=\"10.00\">(1, 480, 1, 1) </text>\n</g>\n<!-- 39&#45;&gt;40 -->\n<g id=\"edge49\" class=\"edge\">\n<title>39&#45;&gt;40</title>\n<path fill=\"none\" stroke=\"black\" d=\"M155.88,-1780.85C156.56,-1773.24 157.35,-1764.45 158.1,-1756.09\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"161.58,-1756.49 158.98,-1746.22 154.6,-1755.86 161.58,-1756.49\"/>\n</g>\n<!-- 41 -->\n<g id=\"node42\" class=\"node\">\n<title>41</title>\n<polygon fill=\"aliceblue\" stroke=\"none\" points=\"253.5,-1664.75 24.5,-1664.75 24.5,-1620.75 253.5,-1620.75 253.5,-1664.75\"/>\n<polygon fill=\"none\" stroke=\"black\" points=\"24.5,-1620.75 24.5,-1664.75 67.5,-1664.75 67.5,-1620.75 24.5,-1620.75\"/>\n<text text-anchor=\"start\" x=\"38.12\" y=\"-1645.25\" font-family=\"Linux libertine\" font-size=\"10.00\">mul</text>\n<text text-anchor=\"start\" x=\"29.5\" y=\"-1633.25\" font-family=\"Linux libertine\" font-size=\"10.00\">depth:3</text>\n<polygon fill=\"none\" stroke=\"black\" points=\"67.5,-1642.75 67.5,-1664.75 110.5,-1664.75 110.5,-1642.75 67.5,-1642.75\"/>\n<text text-anchor=\"start\" x=\"76.62\" y=\"-1650.25\" font-family=\"Linux libertine\" font-size=\"10.00\">input:</text>\n<polygon fill=\"none\" stroke=\"black\" points=\"110.5,-1642.75 110.5,-1664.75 253.5,-1664.75 253.5,-1642.75 110.5,-1642.75\"/>\n<text text-anchor=\"start\" x=\"115.25\" y=\"-1650.25\" font-family=\"Linux libertine\" font-size=\"10.00\">(1, 480, 14, 14), (1, 480, 1, 1) </text>\n<polygon fill=\"none\" stroke=\"black\" points=\"67.5,-1620.75 67.5,-1642.75 110.5,-1642.75 110.5,-1620.75 67.5,-1620.75\"/>\n<text text-anchor=\"start\" x=\"72.12\" y=\"-1628.25\" font-family=\"Linux libertine\" font-size=\"10.00\">output: </text>\n<polygon fill=\"none\" stroke=\"black\" points=\"110.5,-1620.75 110.5,-1642.75 253.5,-1642.75 253.5,-1620.75 110.5,-1620.75\"/>\n<text text-anchor=\"start\" x=\"146.75\" y=\"-1628.25\" font-family=\"Linux libertine\" font-size=\"10.00\">(1, 480, 14, 14) </text>\n</g>\n<!-- 39&#45;&gt;41 -->\n<g id=\"edge50\" class=\"edge\">\n<title>39&#45;&gt;41</title>\n<path fill=\"none\" stroke=\"black\" d=\"M101.47,-1780.86C86.32,-1772.09 71.58,-1760.24 63,-1744.75 53.53,-1727.64 54.25,-1718.24 63,-1700.75 68.76,-1689.23 78.08,-1679.43 88.26,-1671.37\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"90.11,-1674.36 96.12,-1665.64 85.98,-1668.7 90.11,-1674.36\"/>\n</g>\n<!-- 40&#45;&gt;41 -->\n<g id=\"edge51\" class=\"edge\">\n<title>40&#45;&gt;41</title>\n<path fill=\"none\" stroke=\"black\" d=\"M155.1,-1700.85C152.91,-1693.07 150.37,-1684.05 147.96,-1675.51\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"151.41,-1674.84 145.32,-1666.17 144.67,-1676.74 151.41,-1674.84\"/>\n</g>\n<!-- 42 -->\n<g id=\"node43\" class=\"node\">\n<title>42</title>\n<polygon fill=\"#c1ffc1\" stroke=\"none\" points=\"241,-1584.75 63,-1584.75 63,-1540.75 241,-1540.75 241,-1584.75\"/>\n<polygon fill=\"none\" stroke=\"black\" points=\"63,-1540.75 63,-1584.75 118,-1584.75 118,-1540.75 63,-1540.75\"/>\n<text text-anchor=\"start\" x=\"68\" y=\"-1565.25\" font-family=\"Linux libertine\" font-size=\"10.00\">Sequential</text>\n<text text-anchor=\"start\" x=\"74\" y=\"-1553.25\" font-family=\"Linux libertine\" font-size=\"10.00\">depth:3</text>\n<polygon fill=\"none\" stroke=\"black\" points=\"118,-1562.75 118,-1584.75 161,-1584.75 161,-1562.75 118,-1562.75\"/>\n<text text-anchor=\"start\" x=\"127.12\" y=\"-1570.25\" font-family=\"Linux libertine\" font-size=\"10.00\">input:</text>\n<polygon fill=\"none\" stroke=\"black\" points=\"161,-1562.75 161,-1584.75 241,-1584.75 241,-1562.75 161,-1562.75\"/>\n<text text-anchor=\"start\" x=\"165.75\" y=\"-1570.25\" font-family=\"Linux libertine\" font-size=\"10.00\">(1, 480, 14, 14) </text>\n<polygon fill=\"none\" stroke=\"black\" points=\"118,-1540.75 118,-1562.75 161,-1562.75 161,-1540.75 118,-1540.75\"/>\n<text text-anchor=\"start\" x=\"122.62\" y=\"-1548.25\" font-family=\"Linux libertine\" font-size=\"10.00\">output: </text>\n<polygon fill=\"none\" stroke=\"black\" points=\"161,-1540.75 161,-1562.75 241,-1562.75 241,-1540.75 161,-1540.75\"/>\n<text text-anchor=\"start\" x=\"168.38\" y=\"-1548.25\" font-family=\"Linux libertine\" font-size=\"10.00\">(1, 80, 14, 14) </text>\n</g>\n<!-- 41&#45;&gt;42 -->\n<g id=\"edge52\" class=\"edge\">\n<title>41&#45;&gt;42</title>\n<path fill=\"none\" stroke=\"black\" d=\"M142.48,-1620.85C143.77,-1613.15 145.25,-1604.25 146.66,-1595.8\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"150.07,-1596.64 148.26,-1586.2 143.16,-1595.49 150.07,-1596.64\"/>\n</g>\n<!-- 42&#45;&gt;43 -->\n<g id=\"edge53\" class=\"edge\">\n<title>42&#45;&gt;43</title>\n<path fill=\"none\" stroke=\"black\" d=\"M155.48,-1540.85C156.77,-1533.15 158.25,-1524.25 159.66,-1515.8\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"163.07,-1516.64 161.26,-1506.2 156.16,-1515.49 163.07,-1516.64\"/>\n</g>\n<!-- 44 -->\n<g id=\"node45\" class=\"node\">\n<title>44</title>\n<polygon fill=\"#c1ffc1\" stroke=\"none\" points=\"245.5,-1424.75 84.5,-1424.75 84.5,-1380.75 245.5,-1380.75 245.5,-1424.75\"/>\n<polygon fill=\"none\" stroke=\"black\" points=\"84.5,-1380.75 84.5,-1424.75 127.5,-1424.75 127.5,-1380.75 84.5,-1380.75\"/>\n<text text-anchor=\"start\" x=\"89.12\" y=\"-1405.25\" font-family=\"Linux libertine\" font-size=\"10.00\">Dropout</text>\n<text text-anchor=\"start\" x=\"89.5\" y=\"-1393.25\" font-family=\"Linux libertine\" font-size=\"10.00\">depth:3</text>\n<polygon fill=\"none\" stroke=\"black\" points=\"127.5,-1402.75 127.5,-1424.75 170.5,-1424.75 170.5,-1402.75 127.5,-1402.75\"/>\n<text text-anchor=\"start\" x=\"136.62\" y=\"-1410.25\" font-family=\"Linux libertine\" font-size=\"10.00\">input:</text>\n<polygon fill=\"none\" stroke=\"black\" points=\"170.5,-1402.75 170.5,-1424.75 245.5,-1424.75 245.5,-1402.75 170.5,-1402.75\"/>\n<text text-anchor=\"start\" x=\"175.38\" y=\"-1410.25\" font-family=\"Linux libertine\" font-size=\"10.00\">(1, 80, 14, 14) </text>\n<polygon fill=\"none\" stroke=\"black\" points=\"127.5,-1380.75 127.5,-1402.75 170.5,-1402.75 170.5,-1380.75 127.5,-1380.75\"/>\n<text text-anchor=\"start\" x=\"132.12\" y=\"-1388.25\" font-family=\"Linux libertine\" font-size=\"10.00\">output: </text>\n<polygon fill=\"none\" stroke=\"black\" points=\"170.5,-1380.75 170.5,-1402.75 245.5,-1402.75 245.5,-1380.75 170.5,-1380.75\"/>\n<text text-anchor=\"start\" x=\"175.38\" y=\"-1388.25\" font-family=\"Linux libertine\" font-size=\"10.00\">(1, 80, 14, 14) </text>\n</g>\n<!-- 43&#45;&gt;44 -->\n<g id=\"edge54\" class=\"edge\">\n<title>43&#45;&gt;44</title>\n<path fill=\"none\" stroke=\"black\" d=\"M165,-1460.85C165,-1453.24 165,-1444.45 165,-1436.09\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"168.5,-1436.22 165,-1426.22 161.5,-1436.22 168.5,-1436.22\"/>\n</g>\n<!-- 45 -->\n<g id=\"node46\" class=\"node\">\n<title>45</title>\n<polygon fill=\"#c1ffc1\" stroke=\"none\" points=\"254,-1334.5 76,-1334.5 76,-1290.5 254,-1290.5 254,-1334.5\"/>\n<polygon fill=\"none\" stroke=\"black\" points=\"76,-1290.5 76,-1334.5 131,-1334.5 131,-1290.5 76,-1290.5\"/>\n<text text-anchor=\"start\" x=\"81\" y=\"-1315\" font-family=\"Linux libertine\" font-size=\"10.00\">Sequential</text>\n<text text-anchor=\"start\" x=\"87\" y=\"-1303\" font-family=\"Linux libertine\" font-size=\"10.00\">depth:3</text>\n<polygon fill=\"none\" stroke=\"black\" points=\"131,-1312.5 131,-1334.5 174,-1334.5 174,-1312.5 131,-1312.5\"/>\n<text text-anchor=\"start\" x=\"140.12\" y=\"-1320\" font-family=\"Linux libertine\" font-size=\"10.00\">input:</text>\n<polygon fill=\"none\" stroke=\"black\" points=\"174,-1312.5 174,-1334.5 254,-1334.5 254,-1312.5 174,-1312.5\"/>\n<text text-anchor=\"start\" x=\"181.38\" y=\"-1320\" font-family=\"Linux libertine\" font-size=\"10.00\">(1, 80, 14, 14) </text>\n<polygon fill=\"none\" stroke=\"black\" points=\"131,-1290.5 131,-1312.5 174,-1312.5 174,-1290.5 131,-1290.5\"/>\n<text text-anchor=\"start\" x=\"135.62\" y=\"-1298\" font-family=\"Linux libertine\" font-size=\"10.00\">output: </text>\n<polygon fill=\"none\" stroke=\"black\" points=\"174,-1290.5 174,-1312.5 254,-1312.5 254,-1290.5 174,-1290.5\"/>\n<text text-anchor=\"start\" x=\"178.75\" y=\"-1298\" font-family=\"Linux libertine\" font-size=\"10.00\">(1, 480, 14, 14) </text>\n</g>\n<!-- 44&#45;&gt;45 -->\n<g id=\"edge55\" class=\"edge\">\n<title>44&#45;&gt;45</title>\n<path fill=\"none\" stroke=\"black\" d=\"M165,-1380.84C165,-1370.29 165,-1357.26 165,-1345.48\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"168.5,-1345.78 165,-1335.78 161.5,-1345.78 168.5,-1345.78\"/>\n</g>\n<!-- 50 -->\n<g id=\"node51\" class=\"node\">\n<title>50</title>\n<polygon fill=\"aliceblue\" stroke=\"none\" points=\"246.5,-934.5 69.5,-934.5 69.5,-890.5 246.5,-890.5 246.5,-934.5\"/>\n<polygon fill=\"none\" stroke=\"black\" points=\"69.5,-890.5 69.5,-934.5 112.5,-934.5 112.5,-890.5 69.5,-890.5\"/>\n<text text-anchor=\"start\" x=\"80.5\" y=\"-915\" font-family=\"Linux libertine\" font-size=\"10.00\">add_</text>\n<text text-anchor=\"start\" x=\"74.5\" y=\"-903\" font-family=\"Linux libertine\" font-size=\"10.00\">depth:3</text>\n<polygon fill=\"none\" stroke=\"black\" points=\"112.5,-912.5 112.5,-934.5 155.5,-934.5 155.5,-912.5 112.5,-912.5\"/>\n<text text-anchor=\"start\" x=\"121.62\" y=\"-920\" font-family=\"Linux libertine\" font-size=\"10.00\">input:</text>\n<polygon fill=\"none\" stroke=\"black\" points=\"155.5,-912.5 155.5,-934.5 246.5,-934.5 246.5,-912.5 155.5,-912.5\"/>\n<text text-anchor=\"start\" x=\"160.5\" y=\"-920\" font-family=\"Linux libertine\" font-size=\"10.00\">2 x (1, 80, 14, 14) </text>\n<polygon fill=\"none\" stroke=\"black\" points=\"112.5,-890.5 112.5,-912.5 155.5,-912.5 155.5,-890.5 112.5,-890.5\"/>\n<text text-anchor=\"start\" x=\"117.12\" y=\"-898\" font-family=\"Linux libertine\" font-size=\"10.00\">output: </text>\n<polygon fill=\"none\" stroke=\"black\" points=\"155.5,-890.5 155.5,-912.5 246.5,-912.5 246.5,-890.5 155.5,-890.5\"/>\n<text text-anchor=\"start\" x=\"168.38\" y=\"-898\" font-family=\"Linux libertine\" font-size=\"10.00\">(1, 80, 14, 14) </text>\n</g>\n<!-- 44&#45;&gt;50 -->\n<g id=\"edge56\" class=\"edge\">\n<title>44&#45;&gt;50</title>\n<path fill=\"none\" stroke=\"black\" d=\"M245.44,-1380.83C252.16,-1376.45 258.2,-1371.15 263,-1364.75 298.07,-1317.93 273,-1292 273,-1233.5 273,-1233.5 273,-1233.5 273,-1071.5 273,-1024.67 270.75,-1008.22 243,-970.5 234.44,-958.87 222.75,-948.88 210.78,-940.66\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"212.74,-937.76 202.44,-935.27 208.94,-943.64 212.74,-937.76\"/>\n</g>\n<!-- 46 -->\n<g id=\"node47\" class=\"node\">\n<title>46</title>\n<polygon fill=\"#c1ffc1\" stroke=\"none\" points=\"254,-1254.5 76,-1254.5 76,-1210.5 254,-1210.5 254,-1254.5\"/>\n<polygon fill=\"none\" stroke=\"black\" points=\"76,-1210.5 76,-1254.5 131,-1254.5 131,-1210.5 76,-1210.5\"/>\n<text text-anchor=\"start\" x=\"81\" y=\"-1235\" font-family=\"Linux libertine\" font-size=\"10.00\">Sequential</text>\n<text text-anchor=\"start\" x=\"87\" y=\"-1223\" font-family=\"Linux libertine\" font-size=\"10.00\">depth:3</text>\n<polygon fill=\"none\" stroke=\"black\" points=\"131,-1232.5 131,-1254.5 174,-1254.5 174,-1232.5 131,-1232.5\"/>\n<text text-anchor=\"start\" x=\"140.12\" y=\"-1240\" font-family=\"Linux libertine\" font-size=\"10.00\">input:</text>\n<polygon fill=\"none\" stroke=\"black\" points=\"174,-1232.5 174,-1254.5 254,-1254.5 254,-1232.5 174,-1232.5\"/>\n<text text-anchor=\"start\" x=\"178.75\" y=\"-1240\" font-family=\"Linux libertine\" font-size=\"10.00\">(1, 480, 14, 14) </text>\n<polygon fill=\"none\" stroke=\"black\" points=\"131,-1210.5 131,-1232.5 174,-1232.5 174,-1210.5 131,-1210.5\"/>\n<text text-anchor=\"start\" x=\"135.62\" y=\"-1218\" font-family=\"Linux libertine\" font-size=\"10.00\">output: </text>\n<polygon fill=\"none\" stroke=\"black\" points=\"174,-1210.5 174,-1232.5 254,-1232.5 254,-1210.5 174,-1210.5\"/>\n<text text-anchor=\"start\" x=\"178.75\" y=\"-1218\" font-family=\"Linux libertine\" font-size=\"10.00\">(1, 480, 14, 14) </text>\n</g>\n<!-- 45&#45;&gt;46 -->\n<g id=\"edge57\" class=\"edge\">\n<title>45&#45;&gt;46</title>\n<path fill=\"none\" stroke=\"black\" d=\"M165,-1290.6C165,-1282.99 165,-1274.2 165,-1265.84\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"168.5,-1265.97 165,-1255.97 161.5,-1265.97 168.5,-1265.97\"/>\n</g>\n<!-- 47 -->\n<g id=\"node48\" class=\"node\">\n<title>47</title>\n<polygon fill=\"#c1ffc1\" stroke=\"none\" points=\"254,-1174.5 76,-1174.5 76,-1130.5 254,-1130.5 254,-1174.5\"/>\n<polygon fill=\"none\" stroke=\"black\" points=\"76,-1130.5 76,-1174.5 131,-1174.5 131,-1130.5 76,-1130.5\"/>\n<text text-anchor=\"start\" x=\"81\" y=\"-1155\" font-family=\"Linux libertine\" font-size=\"10.00\">Sequential</text>\n<text text-anchor=\"start\" x=\"87\" y=\"-1143\" font-family=\"Linux libertine\" font-size=\"10.00\">depth:3</text>\n<polygon fill=\"none\" stroke=\"black\" points=\"131,-1152.5 131,-1174.5 174,-1174.5 174,-1152.5 131,-1152.5\"/>\n<text text-anchor=\"start\" x=\"140.12\" y=\"-1160\" font-family=\"Linux libertine\" font-size=\"10.00\">input:</text>\n<polygon fill=\"none\" stroke=\"black\" points=\"174,-1152.5 174,-1174.5 254,-1174.5 254,-1152.5 174,-1152.5\"/>\n<text text-anchor=\"start\" x=\"178.75\" y=\"-1160\" font-family=\"Linux libertine\" font-size=\"10.00\">(1, 480, 14, 14) </text>\n<polygon fill=\"none\" stroke=\"black\" points=\"131,-1130.5 131,-1152.5 174,-1152.5 174,-1130.5 131,-1130.5\"/>\n<text text-anchor=\"start\" x=\"135.62\" y=\"-1138\" font-family=\"Linux libertine\" font-size=\"10.00\">output: </text>\n<polygon fill=\"none\" stroke=\"black\" points=\"174,-1130.5 174,-1152.5 254,-1152.5 254,-1130.5 174,-1130.5\"/>\n<text text-anchor=\"start\" x=\"184\" y=\"-1138\" font-family=\"Linux libertine\" font-size=\"10.00\">(1, 480, 1, 1) </text>\n</g>\n<!-- 46&#45;&gt;47 -->\n<g id=\"edge58\" class=\"edge\">\n<title>46&#45;&gt;47</title>\n<path fill=\"none\" stroke=\"black\" d=\"M165,-1210.6C165,-1202.99 165,-1194.2 165,-1185.84\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"168.5,-1185.97 165,-1175.97 161.5,-1185.97 168.5,-1185.97\"/>\n</g>\n<!-- 48 -->\n<g id=\"node49\" class=\"node\">\n<title>48</title>\n<polygon fill=\"aliceblue\" stroke=\"none\" points=\"253.5,-1094.5 24.5,-1094.5 24.5,-1050.5 253.5,-1050.5 253.5,-1094.5\"/>\n<polygon fill=\"none\" stroke=\"black\" points=\"24.5,-1050.5 24.5,-1094.5 67.5,-1094.5 67.5,-1050.5 24.5,-1050.5\"/>\n<text text-anchor=\"start\" x=\"38.12\" y=\"-1075\" font-family=\"Linux libertine\" font-size=\"10.00\">mul</text>\n<text text-anchor=\"start\" x=\"29.5\" y=\"-1063\" font-family=\"Linux libertine\" font-size=\"10.00\">depth:3</text>\n<polygon fill=\"none\" stroke=\"black\" points=\"67.5,-1072.5 67.5,-1094.5 110.5,-1094.5 110.5,-1072.5 67.5,-1072.5\"/>\n<text text-anchor=\"start\" x=\"76.62\" y=\"-1080\" font-family=\"Linux libertine\" font-size=\"10.00\">input:</text>\n<polygon fill=\"none\" stroke=\"black\" points=\"110.5,-1072.5 110.5,-1094.5 253.5,-1094.5 253.5,-1072.5 110.5,-1072.5\"/>\n<text text-anchor=\"start\" x=\"115.25\" y=\"-1080\" font-family=\"Linux libertine\" font-size=\"10.00\">(1, 480, 14, 14), (1, 480, 1, 1) </text>\n<polygon fill=\"none\" stroke=\"black\" points=\"67.5,-1050.5 67.5,-1072.5 110.5,-1072.5 110.5,-1050.5 67.5,-1050.5\"/>\n<text text-anchor=\"start\" x=\"72.12\" y=\"-1058\" font-family=\"Linux libertine\" font-size=\"10.00\">output: </text>\n<polygon fill=\"none\" stroke=\"black\" points=\"110.5,-1050.5 110.5,-1072.5 253.5,-1072.5 253.5,-1050.5 110.5,-1050.5\"/>\n<text text-anchor=\"start\" x=\"146.75\" y=\"-1058\" font-family=\"Linux libertine\" font-size=\"10.00\">(1, 480, 14, 14) </text>\n</g>\n<!-- 46&#45;&gt;48 -->\n<g id=\"edge59\" class=\"edge\">\n<title>46&#45;&gt;48</title>\n<path fill=\"none\" stroke=\"black\" d=\"M106.99,-1210.62C91.22,-1201.97 76.03,-1190.2 67,-1174.5 57.25,-1157.55 58.48,-1148.1 67,-1130.5 72.48,-1119.18 81.41,-1109.43 91.15,-1101.35\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"93.22,-1104.17 99.05,-1095.32 88.97,-1098.61 93.22,-1104.17\"/>\n</g>\n<!-- 47&#45;&gt;48 -->\n<g id=\"edge60\" class=\"edge\">\n<title>47&#45;&gt;48</title>\n<path fill=\"none\" stroke=\"black\" d=\"M158.03,-1130.6C155.44,-1122.82 152.43,-1113.8 149.59,-1105.26\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"152.95,-1104.28 146.47,-1095.9 146.31,-1106.49 152.95,-1104.28\"/>\n</g>\n<!-- 49 -->\n<g id=\"node50\" class=\"node\">\n<title>49</title>\n<polygon fill=\"#c1ffc1\" stroke=\"none\" points=\"234,-1014.5 56,-1014.5 56,-970.5 234,-970.5 234,-1014.5\"/>\n<polygon fill=\"none\" stroke=\"black\" points=\"56,-970.5 56,-1014.5 111,-1014.5 111,-970.5 56,-970.5\"/>\n<text text-anchor=\"start\" x=\"61\" y=\"-995\" font-family=\"Linux libertine\" font-size=\"10.00\">Sequential</text>\n<text text-anchor=\"start\" x=\"67\" y=\"-983\" font-family=\"Linux libertine\" font-size=\"10.00\">depth:3</text>\n<polygon fill=\"none\" stroke=\"black\" points=\"111,-992.5 111,-1014.5 154,-1014.5 154,-992.5 111,-992.5\"/>\n<text text-anchor=\"start\" x=\"120.12\" y=\"-1000\" font-family=\"Linux libertine\" font-size=\"10.00\">input:</text>\n<polygon fill=\"none\" stroke=\"black\" points=\"154,-992.5 154,-1014.5 234,-1014.5 234,-992.5 154,-992.5\"/>\n<text text-anchor=\"start\" x=\"158.75\" y=\"-1000\" font-family=\"Linux libertine\" font-size=\"10.00\">(1, 480, 14, 14) </text>\n<polygon fill=\"none\" stroke=\"black\" points=\"111,-970.5 111,-992.5 154,-992.5 154,-970.5 111,-970.5\"/>\n<text text-anchor=\"start\" x=\"115.62\" y=\"-978\" font-family=\"Linux libertine\" font-size=\"10.00\">output: </text>\n<polygon fill=\"none\" stroke=\"black\" points=\"154,-970.5 154,-992.5 234,-992.5 234,-970.5 154,-970.5\"/>\n<text text-anchor=\"start\" x=\"161.38\" y=\"-978\" font-family=\"Linux libertine\" font-size=\"10.00\">(1, 80, 14, 14) </text>\n</g>\n<!-- 48&#45;&gt;49 -->\n<g id=\"edge61\" class=\"edge\">\n<title>48&#45;&gt;49</title>\n<path fill=\"none\" stroke=\"black\" d=\"M140.61,-1050.6C141.19,-1042.99 141.87,-1034.2 142.51,-1025.84\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"145.99,-1026.21 143.27,-1015.97 139.01,-1025.67 145.99,-1026.21\"/>\n</g>\n<!-- 49&#45;&gt;50 -->\n<g id=\"edge62\" class=\"edge\">\n<title>49&#45;&gt;50</title>\n<path fill=\"none\" stroke=\"black\" d=\"M148.48,-970.6C149.77,-962.9 151.25,-954 152.66,-945.55\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"156.07,-946.39 154.26,-935.95 149.16,-945.24 156.07,-946.39\"/>\n</g>\n<!-- 51 -->\n<g id=\"node52\" class=\"node\">\n<title>51</title>\n<polygon fill=\"#c1ffc1\" stroke=\"none\" points=\"238.5,-854.5 77.5,-854.5 77.5,-810.5 238.5,-810.5 238.5,-854.5\"/>\n<polygon fill=\"none\" stroke=\"black\" points=\"77.5,-810.5 77.5,-854.5 120.5,-854.5 120.5,-810.5 77.5,-810.5\"/>\n<text text-anchor=\"start\" x=\"82.12\" y=\"-835\" font-family=\"Linux libertine\" font-size=\"10.00\">Dropout</text>\n<text text-anchor=\"start\" x=\"82.5\" y=\"-823\" font-family=\"Linux libertine\" font-size=\"10.00\">depth:3</text>\n<polygon fill=\"none\" stroke=\"black\" points=\"120.5,-832.5 120.5,-854.5 163.5,-854.5 163.5,-832.5 120.5,-832.5\"/>\n<text text-anchor=\"start\" x=\"129.62\" y=\"-840\" font-family=\"Linux libertine\" font-size=\"10.00\">input:</text>\n<polygon fill=\"none\" stroke=\"black\" points=\"163.5,-832.5 163.5,-854.5 238.5,-854.5 238.5,-832.5 163.5,-832.5\"/>\n<text text-anchor=\"start\" x=\"168.38\" y=\"-840\" font-family=\"Linux libertine\" font-size=\"10.00\">(1, 80, 14, 14) </text>\n<polygon fill=\"none\" stroke=\"black\" points=\"120.5,-810.5 120.5,-832.5 163.5,-832.5 163.5,-810.5 120.5,-810.5\"/>\n<text text-anchor=\"start\" x=\"125.12\" y=\"-818\" font-family=\"Linux libertine\" font-size=\"10.00\">output: </text>\n<polygon fill=\"none\" stroke=\"black\" points=\"163.5,-810.5 163.5,-832.5 238.5,-832.5 238.5,-810.5 163.5,-810.5\"/>\n<text text-anchor=\"start\" x=\"168.38\" y=\"-818\" font-family=\"Linux libertine\" font-size=\"10.00\">(1, 80, 14, 14) </text>\n</g>\n<!-- 50&#45;&gt;51 -->\n<g id=\"edge63\" class=\"edge\">\n<title>50&#45;&gt;51</title>\n<path fill=\"none\" stroke=\"black\" d=\"M158,-890.6C158,-882.99 158,-874.2 158,-865.84\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"161.5,-865.97 158,-855.97 154.5,-865.97 161.5,-865.97\"/>\n</g>\n<!-- 52 -->\n<g id=\"node53\" class=\"node\">\n<title>52</title>\n<polygon fill=\"#c1ffc1\" stroke=\"none\" points=\"243.5,-756.25 72.5,-756.25 72.5,-712.25 243.5,-712.25 243.5,-756.25\"/>\n<polygon fill=\"none\" stroke=\"black\" points=\"72.5,-712.25 72.5,-756.25 115.5,-756.25 115.5,-712.25 72.5,-712.25\"/>\n<text text-anchor=\"start\" x=\"78.25\" y=\"-736.75\" font-family=\"Linux libertine\" font-size=\"10.00\">Conv2d</text>\n<text text-anchor=\"start\" x=\"77.5\" y=\"-724.75\" font-family=\"Linux libertine\" font-size=\"10.00\">depth:2</text>\n<polygon fill=\"none\" stroke=\"black\" points=\"115.5,-734.25 115.5,-756.25 158.5,-756.25 158.5,-734.25 115.5,-734.25\"/>\n<text text-anchor=\"start\" x=\"124.62\" y=\"-741.75\" font-family=\"Linux libertine\" font-size=\"10.00\">input:</text>\n<polygon fill=\"none\" stroke=\"black\" points=\"158.5,-734.25 158.5,-756.25 243.5,-756.25 243.5,-734.25 158.5,-734.25\"/>\n<text text-anchor=\"start\" x=\"168.38\" y=\"-741.75\" font-family=\"Linux libertine\" font-size=\"10.00\">(1, 80, 14, 14) </text>\n<polygon fill=\"none\" stroke=\"black\" points=\"115.5,-712.25 115.5,-734.25 158.5,-734.25 158.5,-712.25 115.5,-712.25\"/>\n<text text-anchor=\"start\" x=\"120.12\" y=\"-719.75\" font-family=\"Linux libertine\" font-size=\"10.00\">output: </text>\n<polygon fill=\"none\" stroke=\"black\" points=\"158.5,-712.25 158.5,-734.25 243.5,-734.25 243.5,-712.25 158.5,-712.25\"/>\n<text text-anchor=\"start\" x=\"163.12\" y=\"-719.75\" font-family=\"Linux libertine\" font-size=\"10.00\">(1, 1280, 14, 14) </text>\n</g>\n<!-- 51&#45;&gt;52 -->\n<g id=\"edge64\" class=\"edge\">\n<title>51&#45;&gt;52</title>\n<path fill=\"none\" stroke=\"black\" d=\"M158,-810.62C158,-798 158,-781.67 158,-767.43\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"161.5,-767.61 158,-757.61 154.5,-767.61 161.5,-767.61\"/>\n</g>\n<!-- 53 -->\n<g id=\"node54\" class=\"node\">\n<title>53</title>\n<polygon fill=\"#c1ffc1\" stroke=\"none\" points=\"255.5,-676.25 60.5,-676.25 60.5,-632.25 255.5,-632.25 255.5,-676.25\"/>\n<polygon fill=\"none\" stroke=\"black\" points=\"60.5,-632.25 60.5,-676.25 127.5,-676.25 127.5,-632.25 60.5,-632.25\"/>\n<text text-anchor=\"start\" x=\"65.5\" y=\"-656.75\" font-family=\"Linux libertine\" font-size=\"10.00\">BatchNorm2d</text>\n<text text-anchor=\"start\" x=\"77.5\" y=\"-644.75\" font-family=\"Linux libertine\" font-size=\"10.00\">depth:2</text>\n<polygon fill=\"none\" stroke=\"black\" points=\"127.5,-654.25 127.5,-676.25 170.5,-676.25 170.5,-654.25 127.5,-654.25\"/>\n<text text-anchor=\"start\" x=\"136.62\" y=\"-661.75\" font-family=\"Linux libertine\" font-size=\"10.00\">input:</text>\n<polygon fill=\"none\" stroke=\"black\" points=\"170.5,-654.25 170.5,-676.25 255.5,-676.25 255.5,-654.25 170.5,-654.25\"/>\n<text text-anchor=\"start\" x=\"175.12\" y=\"-661.75\" font-family=\"Linux libertine\" font-size=\"10.00\">(1, 1280, 14, 14) </text>\n<polygon fill=\"none\" stroke=\"black\" points=\"127.5,-632.25 127.5,-654.25 170.5,-654.25 170.5,-632.25 127.5,-632.25\"/>\n<text text-anchor=\"start\" x=\"132.12\" y=\"-639.75\" font-family=\"Linux libertine\" font-size=\"10.00\">output: </text>\n<polygon fill=\"none\" stroke=\"black\" points=\"170.5,-632.25 170.5,-654.25 255.5,-654.25 255.5,-632.25 170.5,-632.25\"/>\n<text text-anchor=\"start\" x=\"175.12\" y=\"-639.75\" font-family=\"Linux libertine\" font-size=\"10.00\">(1, 1280, 14, 14) </text>\n</g>\n<!-- 52&#45;&gt;53 -->\n<g id=\"edge65\" class=\"edge\">\n<title>52&#45;&gt;53</title>\n<path fill=\"none\" stroke=\"black\" d=\"M158,-712.35C158,-704.74 158,-695.95 158,-687.59\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"161.5,-687.72 158,-677.72 154.5,-687.72 161.5,-687.72\"/>\n</g>\n<!-- 54 -->\n<g id=\"node55\" class=\"node\">\n<title>54</title>\n<polygon fill=\"#c1ffc1\" stroke=\"none\" points=\"243.5,-596.25 72.5,-596.25 72.5,-552.25 243.5,-552.25 243.5,-596.25\"/>\n<polygon fill=\"none\" stroke=\"black\" points=\"72.5,-552.25 72.5,-596.25 115.5,-596.25 115.5,-552.25 72.5,-552.25\"/>\n<text text-anchor=\"start\" x=\"83.12\" y=\"-576.75\" font-family=\"Linux libertine\" font-size=\"10.00\">SELU</text>\n<text text-anchor=\"start\" x=\"77.5\" y=\"-564.75\" font-family=\"Linux libertine\" font-size=\"10.00\">depth:2</text>\n<polygon fill=\"none\" stroke=\"black\" points=\"115.5,-574.25 115.5,-596.25 158.5,-596.25 158.5,-574.25 115.5,-574.25\"/>\n<text text-anchor=\"start\" x=\"124.62\" y=\"-581.75\" font-family=\"Linux libertine\" font-size=\"10.00\">input:</text>\n<polygon fill=\"none\" stroke=\"black\" points=\"158.5,-574.25 158.5,-596.25 243.5,-596.25 243.5,-574.25 158.5,-574.25\"/>\n<text text-anchor=\"start\" x=\"163.12\" y=\"-581.75\" font-family=\"Linux libertine\" font-size=\"10.00\">(1, 1280, 14, 14) </text>\n<polygon fill=\"none\" stroke=\"black\" points=\"115.5,-552.25 115.5,-574.25 158.5,-574.25 158.5,-552.25 115.5,-552.25\"/>\n<text text-anchor=\"start\" x=\"120.12\" y=\"-559.75\" font-family=\"Linux libertine\" font-size=\"10.00\">output: </text>\n<polygon fill=\"none\" stroke=\"black\" points=\"158.5,-552.25 158.5,-574.25 243.5,-574.25 243.5,-552.25 158.5,-552.25\"/>\n<text text-anchor=\"start\" x=\"163.12\" y=\"-559.75\" font-family=\"Linux libertine\" font-size=\"10.00\">(1, 1280, 14, 14) </text>\n</g>\n<!-- 53&#45;&gt;54 -->\n<g id=\"edge66\" class=\"edge\">\n<title>53&#45;&gt;54</title>\n<path fill=\"none\" stroke=\"black\" d=\"M158,-632.35C158,-624.74 158,-615.95 158,-607.59\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"161.5,-607.72 158,-597.72 154.5,-607.72 161.5,-607.72\"/>\n</g>\n<!-- 55 -->\n<g id=\"node56\" class=\"node\">\n<title>55</title>\n<polygon fill=\"#c1ffc1\" stroke=\"none\" points=\"267.5,-516.25 48.5,-516.25 48.5,-472.25 267.5,-472.25 267.5,-516.25\"/>\n<polygon fill=\"none\" stroke=\"black\" points=\"48.5,-472.25 48.5,-516.25 139.5,-516.25 139.5,-472.25 48.5,-472.25\"/>\n<text text-anchor=\"start\" x=\"53.5\" y=\"-496.75\" font-family=\"Linux libertine\" font-size=\"10.00\">AdaptiveAvgPool2d</text>\n<text text-anchor=\"start\" x=\"77.5\" y=\"-484.75\" font-family=\"Linux libertine\" font-size=\"10.00\">depth:1</text>\n<polygon fill=\"none\" stroke=\"black\" points=\"139.5,-494.25 139.5,-516.25 182.5,-516.25 182.5,-494.25 139.5,-494.25\"/>\n<text text-anchor=\"start\" x=\"148.62\" y=\"-501.75\" font-family=\"Linux libertine\" font-size=\"10.00\">input:</text>\n<polygon fill=\"none\" stroke=\"black\" points=\"182.5,-494.25 182.5,-516.25 267.5,-516.25 267.5,-494.25 182.5,-494.25\"/>\n<text text-anchor=\"start\" x=\"187.12\" y=\"-501.75\" font-family=\"Linux libertine\" font-size=\"10.00\">(1, 1280, 14, 14) </text>\n<polygon fill=\"none\" stroke=\"black\" points=\"139.5,-472.25 139.5,-494.25 182.5,-494.25 182.5,-472.25 139.5,-472.25\"/>\n<text text-anchor=\"start\" x=\"144.12\" y=\"-479.75\" font-family=\"Linux libertine\" font-size=\"10.00\">output: </text>\n<polygon fill=\"none\" stroke=\"black\" points=\"182.5,-472.25 182.5,-494.25 267.5,-494.25 267.5,-472.25 182.5,-472.25\"/>\n<text text-anchor=\"start\" x=\"192.38\" y=\"-479.75\" font-family=\"Linux libertine\" font-size=\"10.00\">(1, 1280, 1, 1) </text>\n</g>\n<!-- 54&#45;&gt;55 -->\n<g id=\"edge67\" class=\"edge\">\n<title>54&#45;&gt;55</title>\n<path fill=\"none\" stroke=\"black\" d=\"M158,-552.35C158,-544.74 158,-535.95 158,-527.59\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"161.5,-527.72 158,-517.72 154.5,-527.72 161.5,-527.72\"/>\n</g>\n<!-- 56 -->\n<g id=\"node57\" class=\"node\">\n<title>56</title>\n<polygon fill=\"aliceblue\" stroke=\"none\" points=\"238.5,-436.25 77.5,-436.25 77.5,-392.25 238.5,-392.25 238.5,-436.25\"/>\n<polygon fill=\"none\" stroke=\"black\" points=\"77.5,-392.25 77.5,-436.25 120.5,-436.25 120.5,-392.25 77.5,-392.25\"/>\n<text text-anchor=\"start\" x=\"89.25\" y=\"-416.75\" font-family=\"Linux libertine\" font-size=\"10.00\">view</text>\n<text text-anchor=\"start\" x=\"82.5\" y=\"-404.75\" font-family=\"Linux libertine\" font-size=\"10.00\">depth:1</text>\n<polygon fill=\"none\" stroke=\"black\" points=\"120.5,-414.25 120.5,-436.25 163.5,-436.25 163.5,-414.25 120.5,-414.25\"/>\n<text text-anchor=\"start\" x=\"129.62\" y=\"-421.75\" font-family=\"Linux libertine\" font-size=\"10.00\">input:</text>\n<polygon fill=\"none\" stroke=\"black\" points=\"163.5,-414.25 163.5,-436.25 238.5,-436.25 238.5,-414.25 163.5,-414.25\"/>\n<text text-anchor=\"start\" x=\"168.38\" y=\"-421.75\" font-family=\"Linux libertine\" font-size=\"10.00\">(1, 1280, 1, 1) </text>\n<polygon fill=\"none\" stroke=\"black\" points=\"120.5,-392.25 120.5,-414.25 163.5,-414.25 163.5,-392.25 120.5,-392.25\"/>\n<text text-anchor=\"start\" x=\"125.12\" y=\"-399.75\" font-family=\"Linux libertine\" font-size=\"10.00\">output: </text>\n<polygon fill=\"none\" stroke=\"black\" points=\"163.5,-392.25 163.5,-414.25 238.5,-414.25 238.5,-392.25 163.5,-392.25\"/>\n<text text-anchor=\"start\" x=\"179.62\" y=\"-399.75\" font-family=\"Linux libertine\" font-size=\"10.00\">(1, 1280) </text>\n</g>\n<!-- 55&#45;&gt;56 -->\n<g id=\"edge68\" class=\"edge\">\n<title>55&#45;&gt;56</title>\n<path fill=\"none\" stroke=\"black\" d=\"M158,-472.35C158,-464.74 158,-455.95 158,-447.59\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"161.5,-447.72 158,-437.72 154.5,-447.72 161.5,-447.72\"/>\n</g>\n<!-- 57 -->\n<g id=\"node58\" class=\"node\">\n<title>57</title>\n<polygon fill=\"#c1ffc1\" stroke=\"none\" points=\"227,-354 89,-354 89,-310 227,-310 227,-354\"/>\n<polygon fill=\"none\" stroke=\"black\" points=\"89,-310 89,-354 132,-354 132,-310 89,-310\"/>\n<text text-anchor=\"start\" x=\"97.38\" y=\"-334.5\" font-family=\"Linux libertine\" font-size=\"10.00\">Linear</text>\n<text text-anchor=\"start\" x=\"94\" y=\"-322.5\" font-family=\"Linux libertine\" font-size=\"10.00\">depth:2</text>\n<polygon fill=\"none\" stroke=\"black\" points=\"132,-332 132,-354 175,-354 175,-332 132,-332\"/>\n<text text-anchor=\"start\" x=\"141.12\" y=\"-339.5\" font-family=\"Linux libertine\" font-size=\"10.00\">input:</text>\n<polygon fill=\"none\" stroke=\"black\" points=\"175,-332 175,-354 227,-354 227,-332 175,-332\"/>\n<text text-anchor=\"start\" x=\"179.62\" y=\"-339.5\" font-family=\"Linux libertine\" font-size=\"10.00\">(1, 1280) </text>\n<polygon fill=\"none\" stroke=\"black\" points=\"132,-310 132,-332 175,-332 175,-310 132,-310\"/>\n<text text-anchor=\"start\" x=\"136.62\" y=\"-317.5\" font-family=\"Linux libertine\" font-size=\"10.00\">output: </text>\n<polygon fill=\"none\" stroke=\"black\" points=\"175,-310 175,-332 227,-332 227,-310 175,-310\"/>\n<text text-anchor=\"start\" x=\"182.25\" y=\"-317.5\" font-family=\"Linux libertine\" font-size=\"10.00\">(1, 512) </text>\n</g>\n<!-- 56&#45;&gt;57 -->\n<g id=\"edge69\" class=\"edge\">\n<title>56&#45;&gt;57</title>\n<path fill=\"none\" stroke=\"black\" d=\"M158,-392.58C158,-384.22 158,-374.38 158,-365.12\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"161.5,-365.39 158,-355.39 154.5,-365.39 161.5,-365.39\"/>\n</g>\n<!-- 58 -->\n<g id=\"node59\" class=\"node\">\n<title>58</title>\n<polygon fill=\"#c1ffc1\" stroke=\"none\" points=\"224.5,-274 91.5,-274 91.5,-230 224.5,-230 224.5,-274\"/>\n<polygon fill=\"none\" stroke=\"black\" points=\"91.5,-230 91.5,-274 134.5,-274 134.5,-230 91.5,-230\"/>\n<text text-anchor=\"start\" x=\"102.12\" y=\"-254.5\" font-family=\"Linux libertine\" font-size=\"10.00\">SELU</text>\n<text text-anchor=\"start\" x=\"96.5\" y=\"-242.5\" font-family=\"Linux libertine\" font-size=\"10.00\">depth:2</text>\n<polygon fill=\"none\" stroke=\"black\" points=\"134.5,-252 134.5,-274 177.5,-274 177.5,-252 134.5,-252\"/>\n<text text-anchor=\"start\" x=\"143.62\" y=\"-259.5\" font-family=\"Linux libertine\" font-size=\"10.00\">input:</text>\n<polygon fill=\"none\" stroke=\"black\" points=\"177.5,-252 177.5,-274 224.5,-274 224.5,-252 177.5,-252\"/>\n<text text-anchor=\"start\" x=\"182.25\" y=\"-259.5\" font-family=\"Linux libertine\" font-size=\"10.00\">(1, 512) </text>\n<polygon fill=\"none\" stroke=\"black\" points=\"134.5,-230 134.5,-252 177.5,-252 177.5,-230 134.5,-230\"/>\n<text text-anchor=\"start\" x=\"139.12\" y=\"-237.5\" font-family=\"Linux libertine\" font-size=\"10.00\">output: </text>\n<polygon fill=\"none\" stroke=\"black\" points=\"177.5,-230 177.5,-252 224.5,-252 224.5,-230 177.5,-230\"/>\n<text text-anchor=\"start\" x=\"182.25\" y=\"-237.5\" font-family=\"Linux libertine\" font-size=\"10.00\">(1, 512) </text>\n</g>\n<!-- 57&#45;&gt;58 -->\n<g id=\"edge70\" class=\"edge\">\n<title>57&#45;&gt;58</title>\n<path fill=\"none\" stroke=\"black\" d=\"M158,-310.1C158,-302.49 158,-293.7 158,-285.34\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"161.5,-285.47 158,-275.47 154.5,-285.47 161.5,-285.47\"/>\n</g>\n<!-- 59 -->\n<g id=\"node60\" class=\"node\">\n<title>59</title>\n<polygon fill=\"#c1ffc1\" stroke=\"none\" points=\"236.5,-194 79.5,-194 79.5,-150 236.5,-150 236.5,-194\"/>\n<polygon fill=\"none\" stroke=\"black\" points=\"79.5,-150 79.5,-194 146.5,-194 146.5,-150 79.5,-150\"/>\n<text text-anchor=\"start\" x=\"84.5\" y=\"-174.5\" font-family=\"Linux libertine\" font-size=\"10.00\">BatchNorm1d</text>\n<text text-anchor=\"start\" x=\"96.5\" y=\"-162.5\" font-family=\"Linux libertine\" font-size=\"10.00\">depth:2</text>\n<polygon fill=\"none\" stroke=\"black\" points=\"146.5,-172 146.5,-194 189.5,-194 189.5,-172 146.5,-172\"/>\n<text text-anchor=\"start\" x=\"155.62\" y=\"-179.5\" font-family=\"Linux libertine\" font-size=\"10.00\">input:</text>\n<polygon fill=\"none\" stroke=\"black\" points=\"189.5,-172 189.5,-194 236.5,-194 236.5,-172 189.5,-172\"/>\n<text text-anchor=\"start\" x=\"194.25\" y=\"-179.5\" font-family=\"Linux libertine\" font-size=\"10.00\">(1, 512) </text>\n<polygon fill=\"none\" stroke=\"black\" points=\"146.5,-150 146.5,-172 189.5,-172 189.5,-150 146.5,-150\"/>\n<text text-anchor=\"start\" x=\"151.12\" y=\"-157.5\" font-family=\"Linux libertine\" font-size=\"10.00\">output: </text>\n<polygon fill=\"none\" stroke=\"black\" points=\"189.5,-150 189.5,-172 236.5,-172 236.5,-150 189.5,-150\"/>\n<text text-anchor=\"start\" x=\"194.25\" y=\"-157.5\" font-family=\"Linux libertine\" font-size=\"10.00\">(1, 512) </text>\n</g>\n<!-- 58&#45;&gt;59 -->\n<g id=\"edge71\" class=\"edge\">\n<title>58&#45;&gt;59</title>\n<path fill=\"none\" stroke=\"black\" d=\"M158,-230.1C158,-222.49 158,-213.7 158,-205.34\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"161.5,-205.47 158,-195.47 154.5,-205.47 161.5,-205.47\"/>\n</g>\n<!-- 60 -->\n<g id=\"node61\" class=\"node\">\n<title>60</title>\n<polygon fill=\"#c1ffc1\" stroke=\"none\" points=\"224.5,-114 91.5,-114 91.5,-70 224.5,-70 224.5,-114\"/>\n<polygon fill=\"none\" stroke=\"black\" points=\"91.5,-70 91.5,-114 134.5,-114 134.5,-70 91.5,-70\"/>\n<text text-anchor=\"start\" x=\"99.88\" y=\"-94.5\" font-family=\"Linux libertine\" font-size=\"10.00\">Linear</text>\n<text text-anchor=\"start\" x=\"96.5\" y=\"-82.5\" font-family=\"Linux libertine\" font-size=\"10.00\">depth:1</text>\n<polygon fill=\"none\" stroke=\"black\" points=\"134.5,-92 134.5,-114 177.5,-114 177.5,-92 134.5,-92\"/>\n<text text-anchor=\"start\" x=\"143.62\" y=\"-99.5\" font-family=\"Linux libertine\" font-size=\"10.00\">input:</text>\n<polygon fill=\"none\" stroke=\"black\" points=\"177.5,-92 177.5,-114 224.5,-114 224.5,-92 177.5,-92\"/>\n<text text-anchor=\"start\" x=\"182.25\" y=\"-99.5\" font-family=\"Linux libertine\" font-size=\"10.00\">(1, 512) </text>\n<polygon fill=\"none\" stroke=\"black\" points=\"134.5,-70 134.5,-92 177.5,-92 177.5,-70 134.5,-70\"/>\n<text text-anchor=\"start\" x=\"139.12\" y=\"-77.5\" font-family=\"Linux libertine\" font-size=\"10.00\">output: </text>\n<polygon fill=\"none\" stroke=\"black\" points=\"177.5,-70 177.5,-92 224.5,-92 224.5,-70 177.5,-70\"/>\n<text text-anchor=\"start\" x=\"187.5\" y=\"-77.5\" font-family=\"Linux libertine\" font-size=\"10.00\">(1, 5) </text>\n</g>\n<!-- 59&#45;&gt;60 -->\n<g id=\"edge72\" class=\"edge\">\n<title>59&#45;&gt;60</title>\n<path fill=\"none\" stroke=\"black\" d=\"M158,-150.1C158,-142.49 158,-133.7 158,-125.34\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"161.5,-125.47 158,-115.47 154.5,-125.47 161.5,-125.47\"/>\n</g>\n<!-- 61 -->\n<g id=\"node62\" class=\"node\">\n<title>61</title>\n<polygon fill=\"lightyellow\" stroke=\"none\" points=\"208.88,-34 107.12,-34 107.12,0 208.88,0 208.88,-34\"/>\n<polygon fill=\"none\" stroke=\"black\" points=\"107.12,0 107.12,-34 174.88,-34 174.88,0 107.12,0\"/>\n<text text-anchor=\"start\" x=\"112.12\" y=\"-19.5\" font-family=\"Linux libertine\" font-size=\"10.00\">output&#45;tensor</text>\n<text text-anchor=\"start\" x=\"124.5\" y=\"-7.5\" font-family=\"Linux libertine\" font-size=\"10.00\">depth:0</text>\n<polygon fill=\"none\" stroke=\"black\" points=\"174.88,0 174.88,-34 208.88,-34 208.88,0 174.88,0\"/>\n<text text-anchor=\"start\" x=\"179.88\" y=\"-13.5\" font-family=\"Linux libertine\" font-size=\"10.00\">(1, 5)</text>\n</g>\n<!-- 60&#45;&gt;61 -->\n<g id=\"edge73\" class=\"edge\">\n<title>60&#45;&gt;61</title>\n<path fill=\"none\" stroke=\"black\" d=\"M158,-70.28C158,-62.46 158,-53.45 158,-45.13\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"161.5,-45.18 158,-35.18 154.5,-45.18 161.5,-45.18\"/>\n</g>\n</g>\n</svg>\n",
      "text/plain": "<graphviz.graphs.Digraph at 0x2311d3da990>"
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torchview import draw_graph\n",
    "\n",
    "model_graph = draw_graph(model, input_size=(1,3,224,224), expand_nested=True)\n",
    "model_graph.visual_graph"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-01T11:12:57.981543700Z",
     "start_time": "2023-11-01T11:12:57.278320900Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "(dot.exe:40644): Pango-WARNING **: couldn't load font \"Linux libertine Not-Rotated 10\", falling back to \"Sans Not-Rotated 10\", expect ugly output.\r\n"
     ]
    },
    {
     "data": {
      "text/plain": "'model_architecture.png'"
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_graph.visual_graph.format = 'png'\n",
    "model_graph.visual_graph.render(filename='model_architecture')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-30T05:11:17.420711Z",
     "start_time": "2023-10-30T05:11:17.211630700Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.9",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "51ee1b965d6f75a20b2b6babb72920dce4fab5775c12eb1659af0fb55d185fed"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
