{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "P6Z1Snuk7rIK"
   },
   "source": [
    "# MIS 583 Assignment 6: Text Sentiment Classification with Prompt Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oSwr9MgZogRZ"
   },
   "source": [
    "Before we start, please put your name and SID in following format: <br>\n",
    ": LASTNAME Firstname, ?00000000   //   e.g.) 李晨愷, M114020035"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6DzsjuDhlz_k"
   },
   "source": [
    "**Your Answer:**   \n",
    "Hi I'm 鄔仁迪, B104020009"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5d-Zzebq7rIM"
   },
   "source": [
    "## Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Kc9gd_Wk7rIN"
   },
   "source": [
    "**Sentiment Classification** is an automated process of identifying opinions in text and labeling them as positive or negative based on the emotions customers express within them.\n",
    "\n",
    "In Task 1, you need to fine-tune a pre-trained language model (e.g., BERT) to predict the sentiment of given tweets.\n",
    "\n",
    "In Task 2, we employ prompts to enable the model to perform sentiment analysis through in-context learning, eliminating the need for additional training.\n",
    "\n",
    "In Task 3, you will use the method called LM-BFF to utilize the model in generating the optimal template and verbalizer autonomously.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "K-lO56Mkms_d"
   },
   "source": [
    "# Notice\n",
    "**You are not allow to use the model like GPT family or pre-trained weight using SST-2 and twitter dataset!!!!!!!!!!!!!!!!!**\n",
    "\n",
    "You can use BERT and RoBERTa encoder model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "giUId1Naqacs",
    "tags": []
   },
   "source": [
    "##  Versions of used packages\n",
    "\n",
    "We will check PyTorch version to make sure everything work properly.  \n",
    "We use `python==3.7.14`, `torch==1.12.1+cu113` and `torchvision==0.13.1+cu113`.  \n",
    "This is the default version in Google Colab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-14T01:05:28.407189900Z",
     "start_time": "2023-12-14T01:05:24.189736900Z"
    },
    "id": "Vuw-gNvjqcYe",
    "outputId": "fac3b4dd-5b1a-4291-a3a3-18be16c72f2d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python 3.11.2 (tags/v3.11.2:878ead1, Feb  7 2023, 16:38:35) [MSC v.1934 64 bit (AMD64)]\n",
      "torch 2.1.0+cu118\n",
      "torchvision 0.16.0+cu118\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import torch\n",
    "import torchvision\n",
    "print('python', sys.version.split('\\n')[0])\n",
    "print('torch', torch.__version__)\n",
    "print('torchvision', torchvision.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c35f9X0ems_f"
   },
   "source": [
    "# Task 1: Text Sentiment Classification (40 points)\n",
    "\n",
    "In this task, you need to fine-tune a pre-trained language model (e.g., BERT or RoBERTa encoder) to predict the sentiment of given tweets.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0a4s_a5D7rIR"
   },
   "source": [
    "## Loading Model and Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GPUkTbnL7rIR"
   },
   "source": [
    "First, let's talk about the model. The Hugging Face team has created an amazing framework called \"transformers\" for NLP tasks. It includes many state-of-the-art machine learning models for PyTorch, TensorFlow, and JAX.\n",
    "\n",
    "To start with this package, follow [this link to installation and a basic tutorial](https://pytorch.org/hub/huggingface_pytorch-transformers/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-14T01:05:28.411353500Z",
     "start_time": "2023-12-14T01:05:28.407189900Z"
    },
    "id": "rK0ouXa09pDU",
    "outputId": "fac3fddc-fc54-472b-9d40-e27830b1034c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'!echo happy installation\\n!pip -V\\n!pip install grpcio\\n!pip install google-auth\\n!pip install protobuf==3.9.2\\n!pip install pyprind\\n!pip install tqdm boto3 requests regex sentencepiece sacremoses'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# you might need some additional installations there\n",
    "\"\"\"!echo happy installation\n",
    "!pip -V\n",
    "!pip install grpcio\n",
    "!pip install google-auth\n",
    "!pip install protobuf==3.9.2\n",
    "!pip install pyprind\n",
    "!pip install tqdm boto3 requests regex sentencepiece sacremoses\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-14T01:05:34.011347100Z",
     "start_time": "2023-12-14T01:05:28.413353600Z"
    },
    "id": "dmGCAevi7rIS",
    "outputId": "d70c21a2-5351-401a-ca98-c1ebc8b5506c"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.weight', 'classifier.out_proj.weight', 'classifier.out_proj.bias', 'classifier.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from torch import nn\n",
    "\n",
    "#########################################################################\n",
    "#            Loading tokenizer and model from transformer               #\n",
    "#########################################################################\n",
    "from transformers import AutoTokenizer, RobertaForSequenceClassification, AutoConfig\n",
    "\n",
    "bert_type = 'roberta-base'\n",
    "\n",
    "# ---------- 1. load from torch.hub ----------\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"roberta-base\")\n",
    "\n",
    "# create a Bert-extended task (classification)\n",
    "model = RobertaForSequenceClassification.from_pretrained(bert_type)\n",
    "\n",
    "# finetune from the output from bert to your task\n",
    "# Replace the out_proj layer in the classifier with a new Linear layer for 3 classes\n",
    "model.classifier.out_proj = nn.Linear(in_features=768, out_features=3, bias=True)\n",
    "#########################################################################\n",
    "#                          End of your code                             #\n",
    "#########################################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IiMThsYeDa2O"
   },
   "source": [
    "## How to Get Data\n",
    "\n",
    "Please open the file `twitter_sentiment.zip`, creat shortcut to your Google Drive.\n",
    "\n",
    "1. open [LINK of Google Drive](https://drive.google.com/file/d/19Ty2lVAm55VL5QIM-MMQhhOzWXeMtxeV/view?usp=sharing)\n",
    "2. Click \"Add shortcut to Drive\" in the top-right corner.\n",
    "3. Select the location where you want to place the shortcut.\n",
    "4. Click Add shortcut.\n",
    "\n",
    "After above procedures, we have a shortcut of zip file of dataset.  \n",
    "We can access this in colab after granting the permission of Google Drive.\n",
    "\n",
    "---\n",
    "\n",
    "請先到共用雲端硬碟將檔案 `twitter_sentiment.zip`，建立捷徑到自己的雲端硬碟中。\n",
    "\n",
    "> 操作步驟\n",
    "1. 點開雲端[連結](https://drive.google.com/file/d/19Ty2lVAm55VL5QIM-MMQhhOzWXeMtxeV/view?usp=sharing)\n",
    "2. 點選右上角「新增雲端硬碟捷徑」\n",
    "3. 點選「我的雲端硬碟」\n",
    "4. 點選「新增捷徑」\n",
    "\n",
    "完成以上流程會在你的雲端硬碟中建立一個檔案的捷徑，接著我們在colab中取得權限即可使用。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-14T00:44:38.519294200Z",
     "start_time": "2023-12-14T00:44:38.507704400Z"
    },
    "id": "lZnFgi5i_2oA"
   },
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cqO8DiB6VRQZ"
   },
   "source": [
    "## Unzip Data\n",
    "\n",
    "解壓縮 `twitter_sentiment.zip` 後可以發現裡面有三個csv檔。\n",
    "\n",
    "- `train.csv`, `test.csv` and `val.csv`\n",
    "\n",
    "Training set 有 **10248** 筆資料.  \n",
    "Validation set 有 **1317** 筆資料.  \n",
    "Testing set 有 **3075** 筆資料.  \n",
    "\n",
    "注意: 若有另外設定存放在雲端硬碟中的路徑，請記得本處路徑也須做更動。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-14T00:44:40.191002200Z",
     "start_time": "2023-12-14T00:44:38.512294300Z"
    },
    "id": "OSlTMdxf8Zd7"
   },
   "outputs": [],
   "source": [
    "# !unzip -qq ./drive/MyDrive/twitter_sentiment.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-14T01:05:37.568337500Z",
     "start_time": "2023-12-14T01:05:37.563012900Z"
    },
    "id": "wf5GXTme7rIT"
   },
   "outputs": [],
   "source": [
    "# Utility function to extract text and label from csv file\n",
    "def get_texts(f_name='./twitter_sentiment', mode='train'):\n",
    "    text_list = []\n",
    "    label_list = []\n",
    "\n",
    "    f_path = os.path.join(f_name, '{}.csv'.format(mode))\n",
    "    with open(f_path, encoding='utf-8') as f:\n",
    "        reader = csv.DictReader(f)\n",
    "        for line in reader:\n",
    "            text_list.append(line['text'])\n",
    "            if mode != 'test':\n",
    "                label_list.append(int(line['sentiment_label']))\n",
    "\n",
    "    return text_list, label_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-14T01:05:38.005925400Z",
     "start_time": "2023-12-14T01:05:38.001002300Z"
    },
    "id": "6fpY0ZrK7rIV"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "class TwitterDataset(Dataset):\n",
    "    def __init__(self, f_name='./twitter_sentiment', mode='train'):\n",
    "        self.mode = mode\n",
    "\n",
    "        text_list, label_list = get_texts(f_name, mode)\n",
    "        print('mode', mode, 'has', len(text_list), 'datas')\n",
    "        text_list = tokenizer(text_list,\n",
    "                             truncation=True, padding=True,\n",
    "                             return_tensors='pt')\n",
    "\n",
    "        self.text_list = text_list['input_ids']\n",
    "        self.mask_list = text_list['attention_mask']\n",
    "\n",
    "        self.label_list = label_list\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        text = self.text_list[idx]\n",
    "        mask = self.mask_list[idx]\n",
    "        if self.mode == 'test':\n",
    "            return text, mask\n",
    "        label = torch.tensor(self.label_list[idx])\n",
    "        return text, mask, label\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.text_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-14T01:05:39.614131300Z",
     "start_time": "2023-12-14T01:05:38.437924500Z"
    },
    "id": "nCmM4FSw7rIW",
    "outputId": "e9fb5c0c-0646-43c1-dffa-dbae3121f66d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mode train has 10248 datas\n",
      "mode val has 1317 datas\n",
      "mode test has 3075 datas\n"
     ]
    }
   ],
   "source": [
    "dataset_train = TwitterDataset(mode='train')\n",
    "dataset_val = TwitterDataset(mode='val')\n",
    "dataset_test = TwitterDataset(mode='test')\n",
    "\n",
    "batch_size = 32\n",
    "train_data = DataLoader(dataset_train, batch_size=batch_size,\n",
    "                       shuffle=True)\n",
    "val_data = DataLoader(dataset_val, batch_size=batch_size // 2,\n",
    "                       shuffle=False)\n",
    "test_data = DataLoader(dataset_test, batch_size=batch_size // 2,\n",
    "                       shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-14T01:05:39.620959200Z",
     "start_time": "2023-12-14T01:05:39.615121600Z"
    },
    "id": "bqkvofHc7rIY",
    "outputId": "29e30f10-fbfb-4dd4-88ff-35fcd4867b8e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "token ['<s>', '@', 'united', 'ĠI', 'Ġhave', 'Ġnever', 'Ġbeen', 'Ġmislead', 'Ġby', 'Ġa', 'Ġcompany', 'Ġas', 'Ġmany', 'Ġtimes', 'Ġas', 'ĠI', 'Ġhave', 'Ġthis', 'Ġweek', 'Ġby', 'ĠUnited', 'ĠAirlines', '!', '</s>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>']\n",
      "token to s <s>@united I have never been mislead by a company as many times as I have this week by United Airlines!</s><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>\n"
     ]
    }
   ],
   "source": [
    "t = tokenizer.convert_ids_to_tokens(dataset_train[0][0])\n",
    "print('token', t)\n",
    "print('token to s', tokenizer.convert_tokens_to_string(t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-14T01:05:40.571095700Z",
     "start_time": "2023-12-14T01:05:40.343472700Z"
    },
    "id": "DxZrfCqW7rIY"
   },
   "outputs": [],
   "source": [
    "device = torch.device('cuda')\n",
    "\n",
    "from torch import nn\n",
    "from torch.optim import AdamW\n",
    "\n",
    "optimizer = AdamW(model.parameters(), lr=1e-5, weight_decay=0.01)\n",
    "\n",
    "# 定義標籤平滑化的KL損失函數 Paper: https://arxiv.org/pdf/2312.06522.pdf\n",
    "class LabelSmoothingLoss(nn.Module):\n",
    "    def __init__(self, classes, smoothing=0.0):\n",
    "        super(LabelSmoothingLoss, self).__init__()\n",
    "        self.confidence = 1.0 - smoothing\n",
    "        self.smoothing = smoothing\n",
    "        self.cls = classes\n",
    "        self.dim = -1\n",
    "\n",
    "    def forward(self, pred, target):\n",
    "        pred = pred.log_softmax(dim=self.dim)\n",
    "        with torch.no_grad():\n",
    "            true_dist = torch.zeros_like(pred)\n",
    "            true_dist.fill_(self.smoothing / (self.cls - 1))\n",
    "            true_dist.scatter_(1, target.data.unsqueeze(1), self.confidence)\n",
    "        return torch.mean(torch.sum(-true_dist * pred, dim=self.dim))\n",
    "\n",
    "# 設定標籤平滑化水平\n",
    "\"\"\"\n",
    "LS2: smoothing=0.03（即3%平滑化）\n",
    "LS3: smoothing=0.075（即7.5%平滑化）\n",
    "LS4: smoothing=0.15（即15%平滑化）\n",
    "LS5: smoothing=0.3（即30%平滑化）\n",
    "\"\"\"\n",
    "criterion = LabelSmoothingLoss(classes=3, smoothing=0.075)\n",
    "\n",
    "model = model.to(device)\n",
    "criterion = criterion.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UpwgE2Gd7rIZ"
   },
   "source": [
    "## Utility Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-14T01:05:41.536729Z",
     "start_time": "2023-12-14T01:05:41.530983Z"
    },
    "id": "zlaiAZAD7rIa"
   },
   "outputs": [],
   "source": [
    "def accuracy(raw_preds, y):\n",
    "    preds = raw_preds.argmax(dim=1)\n",
    "    acc = (preds == y).sum()\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-14T01:05:42.366761300Z",
     "start_time": "2023-12-14T01:05:41.880851600Z"
    },
    "id": "dmc_Gms97rIa"
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "train_loss_list = []\n",
    "val_loss_list = []\n",
    "\n",
    "def train(model, data, optimizer, criterion):\n",
    "    model.train()\n",
    "\n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    total = 0\n",
    "    for text, mask, label in tqdm(data, total=len(data)):\n",
    "        text = text.to(device)\n",
    "        mask = mask.to(device)\n",
    "        label = label.to(device)\n",
    "\n",
    "        #########################################################################\n",
    "        #                          Testing process                              #\n",
    "        #########################################################################\n",
    "        # 1. Clean the gradients of optimizer\n",
    "        # 2. Put correct variables into model\n",
    "        # 3. Get prediction\n",
    "        # 4. Evalutate by criterion and accuracy\n",
    "\n",
    "        # Clean the gradients of optimizer\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(text, attention_mask=mask)\n",
    "\n",
    "        # Compute loss\n",
    "        loss = criterion(outputs.logits, label)\n",
    "\n",
    "        # Compute accuracy using the provided function\n",
    "        acc = accuracy(outputs.logits, label)\n",
    "        #########################################################################\n",
    "        #                          End of your code                             #\n",
    "        #########################################################################\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        epoch_loss += loss.item()\n",
    "        train_loss_list.append(loss.item())\n",
    "        epoch_acc += acc.item()\n",
    "        total += len(text)\n",
    "    return epoch_loss / total, epoch_acc / total\n",
    "\n",
    "def test(model, data, criterion, log_loss=False):\n",
    "    model.eval()\n",
    "\n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    total = 0\n",
    "    for text, mask, label in tqdm(data, total=len(data)):\n",
    "        text = text.to(device)\n",
    "        mask = mask.to(device)\n",
    "        label = label.to(device)\n",
    "\n",
    "        #########################################################################\n",
    "        #                          Training process                             #\n",
    "        #########################################################################\n",
    "        # 1. Put correct variables into model\n",
    "        # 2. Get prediction\n",
    "        # 3. Evalutate by criterion and accuracy\n",
    "\n",
    "        # No gradient calculation for evaluation\n",
    "        with torch.no_grad():\n",
    "            # Forward pass\n",
    "            outputs = model(text, attention_mask=mask)\n",
    "\n",
    "            # Compute loss\n",
    "            loss = criterion(outputs.logits, label)\n",
    "\n",
    "            # Compute accuracy\n",
    "            acc = accuracy(outputs.logits, label)\n",
    "        #########################################################################\n",
    "        #                          End of your code                             #\n",
    "        #########################################################################\n",
    "\n",
    "        epoch_loss += loss.item()\n",
    "        if log_loss:\n",
    "            val_loss_list.append(loss.item())\n",
    "        epoch_acc += acc.item()\n",
    "        total += len(text)\n",
    "    return epoch_loss / total, epoch_acc / total\n",
    "\n",
    "# class for monitoring train and test acc/loss\n",
    "class Meter:\n",
    "    def __init__(self):\n",
    "        self.train_loss_list = []\n",
    "        self.train_acc_list = []\n",
    "        self.val_loss_list = []\n",
    "        self.val_acc_list = []\n",
    "\n",
    "    def update(self, train_loss, train_acc, val_loss, val_acc):\n",
    "        self.train_loss_list.append(train_loss)\n",
    "        self.train_acc_list.append(train_acc)\n",
    "        self.val_loss_list.append(val_loss)\n",
    "        self.val_acc_list.append(val_acc)\n",
    "\n",
    "    def plot(self):\n",
    "        x = range(len(self.train_loss_list))\n",
    "        plt.plot(x, self.train_loss_list)\n",
    "        plt.plot(x, self.val_loss_list, color='r')\n",
    "        plt.legend(['train_loss', 'val_loss'])\n",
    "        plt.show()\n",
    "        plt.plot(x, self.train_acc_list)\n",
    "        plt.plot(x, self.val_acc_list, color='r')\n",
    "        plt.legend(['train_acc', 'val_acc'])\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ExZyrKd57rIb"
   },
   "source": [
    "## Start Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-14T01:28:54.727431100Z",
     "start_time": "2023-12-14T01:05:44.278045800Z"
    },
    "id": "bVDe-fRe7rIc",
    "outputId": "0e41f257-3299-4e94-ba99-cae667d855dd"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 321/321 [04:02<00:00,  1.33it/s]\n",
      "100%|██████████| 83/83 [00:05<00:00, 15.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 train_loss: 0.021190216626672424 train_acc: 0.7865925058548009\n",
      "Epoch 1 val_loss:  0.03611378207655684 val_acc : 0.856492027334852\n",
      "---------- e 1 save best model ----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 321/321 [03:58<00:00,  1.35it/s]\n",
      "100%|██████████| 83/83 [00:05<00:00, 16.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 train_loss: 0.01728838843865659 train_acc: 0.8663153786104606\n",
      "Epoch 2 val_loss:  0.03550267371157398 val_acc : 0.8549734244495064\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 321/321 [04:27<00:00,  1.20it/s]\n",
      "100%|██████████| 83/83 [00:06<00:00, 12.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 train_loss: 0.016003124642707145 train_acc: 0.8943208430913349\n",
      "Epoch 3 val_loss:  0.036412288247407526 val_acc : 0.8602885345482156\n",
      "---------- e 3 save best model ----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 321/321 [05:02<00:00,  1.06it/s]\n",
      "100%|██████████| 83/83 [00:06<00:00, 12.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4 train_loss: 0.014820262336060928 train_acc: 0.917447306791569\n",
      "Epoch 4 val_loss:  0.037863983018161136 val_acc : 0.8587699316628702\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 321/321 [05:02<00:00,  1.06it/s]\n",
      "100%|██████████| 83/83 [00:06<00:00, 12.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5 train_loss: 0.013743110239552297 train_acc: 0.9374512099921936\n",
      "Epoch 5 val_loss:  0.03764960034018497 val_acc : 0.8602885345482156\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#########################################################################\n",
    "#                          Hyper-parameters                             #\n",
    "#########################################################################\n",
    "max_epoch = 5\n",
    "log_interval = 1\n",
    "best_acc = 0\n",
    "#########################################################################\n",
    "#                          End of your code                             #\n",
    "#########################################################################\n",
    "\n",
    "m = Meter()\n",
    "\n",
    "for epoch in range(1, max_epoch + 1):\n",
    "    train_loss, train_acc = train(model, train_data, optimizer, criterion)\n",
    "    val_loss, val_acc = test(model, val_data, criterion, log_loss=True)\n",
    "\n",
    "    if epoch % log_interval == 0:\n",
    "        print('Epoch {} train_loss: {} train_acc: {}'.format(\n",
    "            epoch, train_loss, train_acc\n",
    "        ))\n",
    "        print('Epoch {} val_loss:  {} val_acc : {}'.format(\n",
    "            epoch, val_loss, val_acc\n",
    "        ))\n",
    "\n",
    "    m.update(train_loss, train_acc, val_loss, val_acc)\n",
    "\n",
    "    # model checkpoint\n",
    "    if val_acc > best_acc:\n",
    "        best_model = model\n",
    "        best_acc = val_acc\n",
    "        print('-'*10, 'e', epoch, 'save best model', '-'*10)\n",
    "        torch.save(model.state_dict(), 'ckpts/e{}.pt'.format(epoch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-14T01:32:12.916837200Z",
     "start_time": "2023-12-14T01:32:12.467070300Z"
    },
    "id": "SmtW58OR7rIc",
    "outputId": "8f447abf-3e1c-4f77-cca2-cce0a8f63b93"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot them out\n",
    "m.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YcJcHf7n7rId"
   },
   "source": [
    "## Prediction\n",
    "\n",
    "Predict the results based on testing set. Upload to [Kaggle](https://www.kaggle.com/t/f072e95f51bc48978225941dba218241).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-14T01:37:39.512960700Z",
     "start_time": "2023-12-14T01:37:38.718967400Z"
    },
    "id": "ODFFyAA9ms_i",
    "outputId": "b2fca652-bdb7-42c7-a7a9-39349b56bd26"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model = model\n",
    "best_model.load_state_dict(torch.load('ckpts/e1.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-14T01:37:55.153492300Z",
     "start_time": "2023-12-14T01:37:40.649958600Z"
    },
    "id": "Sf5UTlMZ7rId",
    "outputId": "d55c9abf-68ea-4ce2-db56-eeb62f916c90"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 193/193 [00:14<00:00, 13.43it/s]\n"
     ]
    }
   ],
   "source": [
    "best_model.eval()\n",
    "\n",
    "total_out = []\n",
    "for text, mask in tqdm(test_data, total=len(test_data)):\n",
    "    text = text.to(device)\n",
    "    mask = mask.to(device)\n",
    "\n",
    "    output = best_model(text, mask)\n",
    "    pred = output.logits\n",
    "    pred = torch.argmax(pred, dim=1)\n",
    "    total_out.append(pred)\n",
    "\n",
    "total_out = torch.cat(total_out).cpu().numpy().tolist()\n",
    "\n",
    "with open('pred.csv', 'w') as f:\n",
    "    f.write('index,sentiment_label\\n')\n",
    "    for i, pred in enumerate(total_out):\n",
    "        f.write('{},{}\\n'.format(i, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-13T18:03:51.107060Z",
     "start_time": "2023-12-13T18:03:49.503594900Z"
    },
    "id": "Gm_Ml9Wbms_i"
   },
   "outputs": [],
   "source": [
    "# Save best model\n",
    "torch.save(best_model.state_dict(), 'ckpts/best_model.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dVHEGtUums_i"
   },
   "source": [
    "# Task 2: In-Context learning (32 points)\n",
    "\n",
    "In this task, you will learn how to perform sentiment classification using prompts without the need for training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-14T04:23:07.805617400Z",
     "start_time": "2023-12-14T04:23:07.657616100Z"
    },
    "id": "2adroXkcms_i"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import pyprind\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "from transformers import BertConfig, BertTokenizer, BertForMaskedLM\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "erFMGaJsms_i"
   },
   "source": [
    "# Loading model and setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-14T04:23:41.653925300Z",
     "start_time": "2023-12-14T04:23:08.468919700Z"
    },
    "id": "Ezj5tkTpms_i",
    "outputId": "6be475a3-bf2d-4db4-84de-ac5a5e70338c"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.weight', 'bert.pooler.dense.weight', 'cls.seq_relationship.bias', 'bert.pooler.dense.bias']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.weight', 'bert.pooler.dense.weight', 'cls.seq_relationship.bias', 'bert.pooler.dense.bias']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "#########################################################################\n",
    "#         TODO: Design your own template(prefix) and verbalizer         #\n",
    "#########################################################################\n",
    "class Config:\n",
    "    def __init__(self):\n",
    "        # Zero-shot learning template\n",
    "        # self.prefix = \"Sentence for emotion: This sentence is [MASK].\"\n",
    "\n",
    "        # One-shot learning template\n",
    "        # self.prefix = (\n",
    "        #     \"Sentence for emotion: This sentence is negative. @united be worse?oh you can't! delayed with no reason on the way to Lon. [SEP] \"\n",
    "        #     \"Sentence for emotion: This sentence is [MASK].\"\n",
    "        # )\n",
    "\n",
    "        # Few-shot learning template\n",
    "        self.prefix = (\n",
    "            \"Sentence for emotion: This sentence is negative. @united be worse?oh you can't! delayed with no reason on the way to Lon. [SEP] \"\n",
    "            \"Sentence for emotion: This sentence is neutral. @AmericanAir what's the best number to use? [SEP] \"\n",
    "            \"Sentence for emotion: This sentence is positive. @JetBlue I was so excited when I saw that you fly there! #ionlyflyblue. [SEP] \"\n",
    "            \"Sentence for emotion: This sentence is [MASK].\"\n",
    "        )\n",
    "\n",
    "        self.verbalizer = {\n",
    "            'negative': 0,\n",
    "            'neutral': 1,\n",
    "            'positive': 2,\n",
    "        }\n",
    "\n",
    "        self.max_seq_length = 512\n",
    "        self.batch_size = 32\n",
    "\n",
    "\n",
    "config = Config()\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "bert_type = 'bert-base-uncased'\n",
    "\n",
    "model = BertForMaskedLM.from_pretrained(bert_type, num_labels=3)\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained(bert_type)\n",
    "\n",
    "bert_config = BertConfig.from_pretrained(bert_type)\n",
    "\n",
    "bert = model.from_pretrained(bert_type, config=bert_config).to(device)\n",
    "\n",
    "#######################################################################\n",
    "#                        End of your code                             #\n",
    "#######################################################################\n",
    "\n",
    "softmax = nn.Softmax(dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-14T04:23:41.669400500Z",
     "start_time": "2023-12-14T04:23:41.659932600Z"
    },
    "id": "29cIvyhxms_j"
   },
   "outputs": [],
   "source": [
    "# Utility function to obtaion verbalizer ids\n",
    "def obtain_verbalizer_ids(verbalizer, tokenizer):\n",
    "    verbalizer_ids = tokenizer.convert_tokens_to_ids(list(verbalizer.keys()))\n",
    "    index2ids = {i: verbalizer_ids[i] for i in range(len(verbalizer_ids))}\n",
    "    return verbalizer_ids, index2ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-14T04:23:41.691879500Z",
     "start_time": "2023-12-14T04:23:41.674400900Z"
    },
    "id": "w2FOydFKms_j"
   },
   "outputs": [],
   "source": [
    "verbalizer_ids, index2ids = obtain_verbalizer_ids(config.verbalizer, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-14T04:23:41.695893400Z",
     "start_time": "2023-12-14T04:23:41.686988Z"
    },
    "id": "uIAAfFKQms_j"
   },
   "outputs": [],
   "source": [
    "# Utility function to concatenate prefix and text\n",
    "def concatenate_prefix(texts, config):\n",
    "    ##################################################\n",
    "    #   TODO: concatenate your own prefix and text   #\n",
    "    ##################################################\n",
    "    prefix_texts = [config.prefix + \" \" + text for text in texts]\n",
    "    ##################################################\n",
    "    #                 End of your code               #\n",
    "    ##################################################\n",
    "    return prefix_texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-14T04:23:41.870492800Z",
     "start_time": "2023-12-14T04:23:41.701976Z"
    },
    "id": "LH9W8ESqms_q"
   },
   "outputs": [],
   "source": [
    "def load_data(config):\n",
    "    # ['texts', 'labels']\n",
    "    df = pd.read_csv('./twitter_sentiment/train.csv')\n",
    "    original_texts = df['text'].tolist()\n",
    "    labels = df['sentiment_label'].tolist()\n",
    "\n",
    "    texts = concatenate_prefix(original_texts, config)\n",
    "\n",
    "    return texts, labels\n",
    "\n",
    "\n",
    "texts, labels = load_data(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-14T04:23:41.896934700Z",
     "start_time": "2023-12-14T04:23:41.874492900Z"
    },
    "id": "rbZ1e5mLms_q",
    "outputId": "43c347b2-6f5f-47a6-9803-f4394d1bd59c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "token ['[CLS]', 'sentence', 'for', 'emotion', ':', 'this', 'sentence', 'is', 'negative', '.', '@', 'united', 'be', 'worse', '?', 'oh', 'you', 'can', \"'\", 't', '!', 'delayed', 'with', 'no', 'reason', 'on', 'the', 'way', 'to', 'lo', '##n', '.', '[SEP]', 'sentence', 'for', 'emotion', ':', 'this', 'sentence', 'is', 'neutral', '.', '@', 'americana', '##ir', 'what', \"'\", 's', 'the', 'best', 'number', 'to', 'use', '?', '[SEP]', 'sentence', 'for', 'emotion', ':', 'this', 'sentence', 'is', 'positive', '.', '@', 'jet', '##bl', '##ue', 'i', 'was', 'so', 'excited', 'when', 'i', 'saw', 'that', 'you', 'fly', 'there', '!', '#', 'ion', '##ly', '##fly', '##bl', '##ue', '.', '[SEP]', 'sentence', 'for', 'emotion', ':', 'this', 'sentence', 'is', '[MASK]', '.', '@', 'united', 'i', 'have', 'never', 'been', 'mis', '##lea', '##d', 'by', 'a', 'company', 'as', 'many', 'times', 'as', 'i', 'have', 'this', 'week', 'by', 'united', 'airlines', '!', '[SEP]']\n",
      "token to s [CLS] sentence for emotion : this sentence is negative . @ united be worse ? oh you can ' t ! delayed with no reason on the way to lon . [SEP] sentence for emotion : this sentence is neutral . @ americanair what ' s the best number to use ? [SEP] sentence for emotion : this sentence is positive . @ jetblue i was so excited when i saw that you fly there ! # ionlyflyblue . [SEP] sentence for emotion : this sentence is [MASK] . @ united i have never been mislead by a company as many times as i have this week by united airlines ! [SEP]\n"
     ]
    }
   ],
   "source": [
    "t = tokenizer.convert_ids_to_tokens(tokenizer.encode(texts[0], add_special_tokens=True))\n",
    "print('token', t)\n",
    "print('token to s', tokenizer.convert_tokens_to_string(t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-14T04:23:41.923988100Z",
     "start_time": "2023-12-14T04:23:41.907934100Z"
    },
    "id": "-XqoOdf-ms_q"
   },
   "outputs": [],
   "source": [
    "# Batching of texts and labels for training or processing in batches\n",
    "def pack_batch(texts, labels, batch_size):\n",
    "    \"\"\"\n",
    "    :param texts: list\n",
    "    :param labels: list\n",
    "    :param batch_size: int\n",
    "    :return batch_X: list\n",
    "            [[text11, text12, ...], [text21, text22, ...], ...]\n",
    "    :return batch_y: list\n",
    "            [[label11, label12, ...], [label21, label22, ...], ...]\n",
    "    :return batch_count: int\n",
    "    \"\"\"\n",
    "    assert len(texts) == len(labels)\n",
    "\n",
    "    if len(texts) % batch_size != 0:\n",
    "        flag = False\n",
    "        batch_count = int(len(texts) / batch_size) + 1\n",
    "    else:\n",
    "        flag = True\n",
    "        batch_count = int(len(texts) / batch_size)\n",
    "\n",
    "    batch_X, batch_y = [], []\n",
    "\n",
    "    if flag:\n",
    "        for i in range(batch_count):\n",
    "            batch_X.append(texts[i * batch_size: (i + 1) * batch_size])\n",
    "            batch_y.append(labels[i * batch_size: (i + 1) * batch_size])\n",
    "    else:\n",
    "        for i in range(batch_count):\n",
    "            if i == batch_count - 1:\n",
    "                batch_X.append(texts[i * batch_size:])\n",
    "                batch_y.append(labels[i * batch_size:])\n",
    "            else:\n",
    "                batch_X.append(texts[i * batch_size: (i + 1) * batch_size])\n",
    "                batch_y.append(labels[i * batch_size: (i + 1) * batch_size])\n",
    "\n",
    "    return batch_X, batch_y, batch_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-14T04:23:41.926987500Z",
     "start_time": "2023-12-14T04:23:41.925002Z"
    },
    "id": "FEYPpqfwms_r"
   },
   "outputs": [],
   "source": [
    "batch_X, batch_y, batch_count = pack_batch(texts, labels, config.batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-14T04:35:08.825776100Z",
     "start_time": "2023-12-14T04:23:41.938032100Z"
    },
    "id": "R_3vJd4Ems_r",
    "outputId": "54b2a2ff-298f-42a3-d95b-90b8414d0dec"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[100 %] Time elapsed: 00:05:04 | ETA: 00:00:00"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.696331 | precision: 0.651213 | recall: 0.696331 | f1: 0.637934\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Total time elapsed: 00:05:04\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    predict_all = np.array([], dtype=int)\n",
    "    labels_all = np.array([], dtype=int)\n",
    "    pper = pyprind.ProgPercent(batch_count)\n",
    "    for i in range(batch_count):\n",
    "        inputs = batch_X[i]\n",
    "        labels = batch_y[i]\n",
    "\n",
    "        tokens = tokenizer.batch_encode_plus(inputs, add_special_tokens=True,\n",
    "                                             max_length=config.max_seq_length,\n",
    "                                             padding='max_length', truncation=True)\n",
    "\n",
    "        ids = torch.tensor(tokens['input_ids']).to(device)\n",
    "        attention_mask = torch.tensor(tokens['attention_mask']).to(device)\n",
    "\n",
    "        # Shape: (batch_size, max_seq_length, vocab_size)\n",
    "        logits = bert(ids, attention_mask=attention_mask).logits\n",
    "\n",
    "        mask_token_index = (ids == tokenizer.mask_token_id).nonzero(as_tuple=True)\n",
    "\n",
    "        # Find [MASK] logits\n",
    "        # shape: (batch_size, vocab_size)\n",
    "        masked_logits = logits[mask_token_index[0], mask_token_index[1], :]\n",
    "\n",
    "        # Extract the logits of the word in the verbalizer at the [MASK] position\n",
    "        # shape: (batch_size, verbalizer_size)\n",
    "        verbalizer_logits = masked_logits[:, verbalizer_ids]\n",
    "\n",
    "        # Construct a pseudo-distribution from the logits in these verbalizers\n",
    "        pseudo_distribution = softmax(verbalizer_logits)\n",
    "\n",
    "        #################################################################################\n",
    "        #   1. Find the index with the maximum probability in the pseudo-distribution   #\n",
    "        #   2. Convert the index to the corresponding word ID                           #\n",
    "        #   3. Convert the ID to a token                                                #\n",
    "        #   4. Find the label corresponding to the token                                #\n",
    "        #################################################################################\n",
    "        # 1. Find the index with the maximum probability in the pseudo-distribution\n",
    "        pred_indices = torch.argmax(pseudo_distribution, dim=1)\n",
    "\n",
    "        # 2. Convert the index to the corresponding word ID\n",
    "        pred_ids = [verbalizer_ids[index] for index in pred_indices]\n",
    "\n",
    "        # 3. Convert the ID to a token\n",
    "        pred_tokens = tokenizer.convert_ids_to_tokens(pred_ids)\n",
    "\n",
    "        # 4. Find the label corresponding to the token\n",
    "        pred_labels = [config.verbalizer[token] if token in config.verbalizer else -1 for token in pred_tokens]\n",
    "        pred_labels = np.array(pred_labels)\n",
    "        #################################################################################\n",
    "        #                             End of your code                                  #\n",
    "        #################################################################################\n",
    "\n",
    "        predict_all = np.append(predict_all, pred_labels)\n",
    "        labels_all = np.append(labels_all, labels)\n",
    "\n",
    "        pper.update()\n",
    "\n",
    "    acc = accuracy_score(labels_all, predict_all)\n",
    "    p = precision_score(labels_all, predict_all, average=\"weighted\")\n",
    "    r = recall_score(labels_all, predict_all, average=\"weighted\")\n",
    "    f1 = f1_score(labels_all, predict_all, average=\"weighted\")\n",
    "\n",
    "    print('accuracy: %f | precision: %f | recall: %f | f1: %f' % (acc, p, r, f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-13T17:25:48.681832600Z",
     "start_time": "2023-12-13T17:25:48.428696300Z"
    },
    "id": "m884Dtjlms_r",
    "outputId": "65ac3a70-953a-4c5b-92c3-d745ec18ce30"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1\n",
       "1    10248\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame([labels_all, predict_all]).T[1].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jAOhTCtKms_r"
   },
   "source": [
    "# Task 3: LM-BFF (45 points)\n",
    "\n",
    "https://arxiv.org/pdf/2012.15723.pdf\n",
    "\n",
    "Unlike the previous task, LM-BFF can generate templates and verbalizers automatically."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5Bgms7nnms_r"
   },
   "source": [
    "# Get Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3AeVEBuKms_r"
   },
   "source": [
    "請先到共用雲端硬碟將檔案 `SST-2.zip`，建立捷徑到自己的雲端硬碟中。\n",
    "\n",
    "> 操作步驟\n",
    "1. 點開雲端[連結](https://drive.google.com/file/d/14MDYFasXU94dUE9DjgfcZE61iTRI2007/view?usp=sharing)\n",
    "2. 點選右上角「新增雲端硬碟捷徑」\n",
    "3. 點選「我的雲端硬碟」\n",
    "4. 點選「新增捷徑」\n",
    "\n",
    "完成以上流程會在你的雲端硬碟中建立一個檔案的捷徑，接著我們在colab中取得權限即可使用。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ojZviGGcms_r"
   },
   "source": [
    "# Install openprompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-09T03:31:13.543193800Z",
     "start_time": "2023-12-09T03:30:21.808076200Z"
    },
    "id": "7n4ZBRjNms_r",
    "outputId": "7422dc2b-8ad4-4ad7-b0a7-f104a90230d4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting openprompt\n",
      "  Downloading openprompt-1.0.1-py3-none-any.whl (146 kB)\n",
      "     ---------------------------------------- 0.0/146.4 kB ? eta -:--:--\n",
      "     ---------------- ---------------------- 61.4/146.4 kB 1.7 MB/s eta 0:00:01\n",
      "     -------------------------------------- 146.4/146.4 kB 1.7 MB/s eta 0:00:00\n",
      "Collecting transformers>=4.10.0 (from openprompt)\n",
      "  Obtaining dependency information for transformers>=4.10.0 from https://files.pythonhosted.org/packages/12/dd/f17b11a93a9ca27728e12512d167eb1281c151c4c6881d3ab59eb58f4127/transformers-4.35.2-py3-none-any.whl.metadata\n",
      "  Downloading transformers-4.35.2-py3-none-any.whl.metadata (123 kB)\n",
      "     ---------------------------------------- 0.0/123.5 kB ? eta -:--:--\n",
      "     -------------------------------------- 123.5/123.5 kB 2.4 MB/s eta 0:00:00\n",
      "Collecting sentencepiece==0.1.96 (from openprompt)\n",
      "  Downloading sentencepiece-0.1.96-cp39-cp39-win_amd64.whl (1.1 MB)\n",
      "     ---------------------------------------- 0.0/1.1 MB ? eta -:--:--\n",
      "     ---- ----------------------------------- 0.1/1.1 MB 2.2 MB/s eta 0:00:01\n",
      "     ------ --------------------------------- 0.2/1.1 MB 2.1 MB/s eta 0:00:01\n",
      "     ---------- ----------------------------- 0.3/1.1 MB 2.0 MB/s eta 0:00:01\n",
      "     ------------- -------------------------- 0.4/1.1 MB 2.1 MB/s eta 0:00:01\n",
      "     ---------------- ----------------------- 0.5/1.1 MB 2.0 MB/s eta 0:00:01\n",
      "     -------------------- ------------------- 0.6/1.1 MB 2.0 MB/s eta 0:00:01\n",
      "     ----------------------- ---------------- 0.6/1.1 MB 2.0 MB/s eta 0:00:01\n",
      "     --------------------------- ------------ 0.7/1.1 MB 1.9 MB/s eta 0:00:01\n",
      "     ------------------------------ --------- 0.8/1.1 MB 2.0 MB/s eta 0:00:01\n",
      "     --------------------------------- ------ 0.9/1.1 MB 2.0 MB/s eta 0:00:01\n",
      "     ------------------------------------ --- 1.0/1.1 MB 2.0 MB/s eta 0:00:01\n",
      "     ---------------------------------------  1.1/1.1 MB 2.0 MB/s eta 0:00:01\n",
      "     ---------------------------------------- 1.1/1.1 MB 1.9 MB/s eta 0:00:00\n",
      "Collecting tqdm>=4.62.2 (from openprompt)\n",
      "  Obtaining dependency information for tqdm>=4.62.2 from https://files.pythonhosted.org/packages/00/e5/f12a80907d0884e6dff9c16d0c0114d81b8cd07dc3ae54c5e962cc83037e/tqdm-4.66.1-py3-none-any.whl.metadata\n",
      "  Downloading tqdm-4.66.1-py3-none-any.whl.metadata (57 kB)\n",
      "     ---------------------------------------- 0.0/57.6 kB ? eta -:--:--\n",
      "     ---------------------------------------- 57.6/57.6 kB 3.2 MB/s eta 0:00:00\n",
      "Collecting tensorboardX (from openprompt)\n",
      "  Obtaining dependency information for tensorboardX from https://files.pythonhosted.org/packages/44/71/f3e7c9b2ab67e28c572ab4e9d5fa3499e0d252650f96d8a3a03e26677f53/tensorboardX-2.6.2.2-py2.py3-none-any.whl.metadata\n",
      "  Downloading tensorboardX-2.6.2.2-py2.py3-none-any.whl.metadata (5.8 kB)\n",
      "Collecting nltk (from openprompt)\n",
      "  Using cached nltk-3.8.1-py3-none-any.whl (1.5 MB)\n",
      "Collecting yacs (from openprompt)\n",
      "  Downloading yacs-0.1.8-py3-none-any.whl (14 kB)\n",
      "Collecting dill (from openprompt)\n",
      "  Obtaining dependency information for dill from https://files.pythonhosted.org/packages/f5/3a/74a29b11cf2cdfcd6ba89c0cecd70b37cd1ba7b77978ce611eb7a146a832/dill-0.3.7-py3-none-any.whl.metadata\n",
      "  Downloading dill-0.3.7-py3-none-any.whl.metadata (9.9 kB)\n",
      "Collecting datasets (from openprompt)\n",
      "  Obtaining dependency information for datasets from https://files.pythonhosted.org/packages/e2/cf/db41e572d7ed958e8679018f8190438ef700aeb501b62da9e1eed9e4d69a/datasets-2.15.0-py3-none-any.whl.metadata\n",
      "  Downloading datasets-2.15.0-py3-none-any.whl.metadata (20 kB)\n",
      "Collecting rouge==1.0.0 (from openprompt)\n",
      "  Downloading rouge-1.0.0-py3-none-any.whl (14 kB)\n",
      "Collecting pyarrow (from openprompt)\n",
      "  Obtaining dependency information for pyarrow from https://files.pythonhosted.org/packages/28/82/9adfafaf0de581a39a1c86002cafd1a55a1255c9e0d362dc3e970aab0656/pyarrow-14.0.1-cp39-cp39-win_amd64.whl.metadata\n",
      "  Downloading pyarrow-14.0.1-cp39-cp39-win_amd64.whl.metadata (3.1 kB)\n",
      "Requirement already satisfied: scipy in c:\\users\\eddie\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from openprompt) (1.8.0)\n",
      "Requirement already satisfied: six in c:\\users\\eddie\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from rouge==1.0.0->openprompt) (1.16.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\eddie\\appdata\\roaming\\python\\python39\\site-packages (from tqdm>=4.62.2->openprompt) (0.4.4)\n",
      "Collecting filelock (from transformers>=4.10.0->openprompt)\n",
      "  Obtaining dependency information for filelock from https://files.pythonhosted.org/packages/81/54/84d42a0bee35edba99dee7b59a8d4970eccdd44b99fe728ed912106fc781/filelock-3.13.1-py3-none-any.whl.metadata\n",
      "  Downloading filelock-3.13.1-py3-none-any.whl.metadata (2.8 kB)\n",
      "Collecting huggingface-hub<1.0,>=0.16.4 (from transformers>=4.10.0->openprompt)\n",
      "  Obtaining dependency information for huggingface-hub<1.0,>=0.16.4 from https://files.pythonhosted.org/packages/05/09/1945ca6ba3ad8ad6e2872ba682ce8d68c5e63c8e55458ed8ab4885709f1d/huggingface_hub-0.19.4-py3-none-any.whl.metadata\n",
      "  Downloading huggingface_hub-0.19.4-py3-none-any.whl.metadata (14 kB)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\eddie\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from transformers>=4.10.0->openprompt) (1.22.2)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\eddie\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from transformers>=4.10.0->openprompt) (21.3)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\eddie\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from transformers>=4.10.0->openprompt) (6.0)\n",
      "Collecting regex!=2019.12.17 (from transformers>=4.10.0->openprompt)\n",
      "  Obtaining dependency information for regex!=2019.12.17 from https://files.pythonhosted.org/packages/fc/85/0d1038f068900896a8590d6d0da198b90d31f731a39166a432aa2b92249b/regex-2023.10.3-cp39-cp39-win_amd64.whl.metadata\n",
      "  Downloading regex-2023.10.3-cp39-cp39-win_amd64.whl.metadata (41 kB)\n",
      "     ---------------------------------------- 0.0/42.0 kB ? eta -:--:--\n",
      "     ---------------------------------------- 42.0/42.0 kB 2.1 MB/s eta 0:00:00\n",
      "Requirement already satisfied: requests in c:\\users\\eddie\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from transformers>=4.10.0->openprompt) (2.25.1)\n",
      "Collecting tokenizers<0.19,>=0.14 (from transformers>=4.10.0->openprompt)\n",
      "  Obtaining dependency information for tokenizers<0.19,>=0.14 from https://files.pythonhosted.org/packages/9f/90/a6821e7757d2db194c16cbca78c80e206f30f6cc62c7f15fb27428f8c6dd/tokenizers-0.15.0-cp39-none-win_amd64.whl.metadata\n",
      "  Downloading tokenizers-0.15.0-cp39-none-win_amd64.whl.metadata (6.8 kB)\n",
      "Collecting safetensors>=0.3.1 (from transformers>=4.10.0->openprompt)\n",
      "  Obtaining dependency information for safetensors>=0.3.1 from https://files.pythonhosted.org/packages/4e/96/f4ee4434d8b6452fe7d5d44df2e72d1c6b2add1c3a5fb5c81aae83cb90c6/safetensors-0.4.1-cp39-none-win_amd64.whl.metadata\n",
      "  Downloading safetensors-0.4.1-cp39-none-win_amd64.whl.metadata (3.8 kB)\n",
      "Collecting pyarrow-hotfix (from datasets->openprompt)\n",
      "  Obtaining dependency information for pyarrow-hotfix from https://files.pythonhosted.org/packages/e4/f4/9ec2222f5f5f8ea04f66f184caafd991a39c8782e31f5b0266f101cb68ca/pyarrow_hotfix-0.6-py3-none-any.whl.metadata\n",
      "  Downloading pyarrow_hotfix-0.6-py3-none-any.whl.metadata (3.6 kB)\n",
      "Requirement already satisfied: pandas in c:\\users\\eddie\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from datasets->openprompt) (1.4.1)\n",
      "Collecting xxhash (from datasets->openprompt)\n",
      "  Obtaining dependency information for xxhash from https://files.pythonhosted.org/packages/33/db/e07aa80e39a7ee82e9ca6f5a0fa9bf0b4465934272116a1b578eaee7f4b3/xxhash-3.4.1-cp39-cp39-win_amd64.whl.metadata\n",
      "  Downloading xxhash-3.4.1-cp39-cp39-win_amd64.whl.metadata (12 kB)\n",
      "Collecting multiprocess (from datasets->openprompt)\n",
      "  Obtaining dependency information for multiprocess from https://files.pythonhosted.org/packages/c6/c9/820b5ab056f4ada76fbe05bd481a948f287957d6cbfd59e2dd2618b408c1/multiprocess-0.70.15-py39-none-any.whl.metadata\n",
      "  Downloading multiprocess-0.70.15-py39-none-any.whl.metadata (7.2 kB)\n",
      "Collecting fsspec[http]<=2023.10.0,>=2023.1.0 (from datasets->openprompt)\n",
      "  Obtaining dependency information for fsspec[http]<=2023.10.0,>=2023.1.0 from https://files.pythonhosted.org/packages/e8/f6/3eccfb530aac90ad1301c582da228e4763f19e719ac8200752a4841b0b2d/fsspec-2023.10.0-py3-none-any.whl.metadata\n",
      "  Downloading fsspec-2023.10.0-py3-none-any.whl.metadata (6.8 kB)\n",
      "Requirement already satisfied: aiohttp in c:\\users\\eddie\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from datasets->openprompt) (3.7.4.post0)\n",
      "Requirement already satisfied: click in c:\\users\\eddie\\appdata\\roaming\\python\\python39\\site-packages (from nltk->openprompt) (8.0.4)\n",
      "Requirement already satisfied: joblib in c:\\users\\eddie\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from nltk->openprompt) (1.1.0)\n",
      "Collecting protobuf>=3.20 (from tensorboardX->openprompt)\n",
      "  Obtaining dependency information for protobuf>=3.20 from https://files.pythonhosted.org/packages/b6/4b/f4f3334784576822d7817a664b757030ebb35b981978baf9c2eb3c5f33a8/protobuf-4.25.1-cp39-cp39-win_amd64.whl.metadata\n",
      "  Downloading protobuf-4.25.1-cp39-cp39-win_amd64.whl.metadata (541 bytes)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\eddie\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from aiohttp->datasets->openprompt) (21.2.0)\n",
      "Requirement already satisfied: chardet<5.0,>=2.0 in c:\\users\\eddie\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from aiohttp->datasets->openprompt) (3.0.4)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\eddie\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from aiohttp->datasets->openprompt) (5.2.0)\n",
      "Requirement already satisfied: async-timeout<4.0,>=3.0 in c:\\users\\eddie\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from aiohttp->datasets->openprompt) (3.0.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\eddie\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from aiohttp->datasets->openprompt) (1.7.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.5 in c:\\users\\eddie\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from aiohttp->datasets->openprompt) (4.8.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\eddie\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from packaging>=20.0->transformers>=4.10.0->openprompt) (3.0.7)\n",
      "Requirement already satisfied: idna<3,>=2.5 in c:\\users\\eddie\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from requests->transformers>=4.10.0->openprompt) (2.10)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\eddie\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from requests->transformers>=4.10.0->openprompt) (1.26.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\eddie\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from requests->transformers>=4.10.0->openprompt) (2021.10.8)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\users\\eddie\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from pandas->datasets->openprompt) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\eddie\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from pandas->datasets->openprompt) (2021.3)\n",
      "Downloading tqdm-4.66.1-py3-none-any.whl (78 kB)\n",
      "   ---------------------------------------- 0.0/78.3 kB ? eta -:--:--\n",
      "   -------------------- ------------------- 41.0/78.3 kB ? eta -:--:--\n",
      "   ---------------------------------------- 78.3/78.3 kB 1.1 MB/s eta 0:00:00\n",
      "Downloading transformers-4.35.2-py3-none-any.whl (7.9 MB)\n",
      "   ---------------------------------------- 0.0/7.9 MB ? eta -:--:--\n",
      "    --------------------------------------- 0.1/7.9 MB 3.2 MB/s eta 0:00:03\n",
      "    --------------------------------------- 0.2/7.9 MB 2.0 MB/s eta 0:00:04\n",
      "   - -------------------------------------- 0.3/7.9 MB 2.0 MB/s eta 0:00:04\n",
      "   - -------------------------------------- 0.4/7.9 MB 2.1 MB/s eta 0:00:04\n",
      "   -- ------------------------------------- 0.4/7.9 MB 2.1 MB/s eta 0:00:04\n",
      "   -- ------------------------------------- 0.6/7.9 MB 2.0 MB/s eta 0:00:04\n",
      "   --- ------------------------------------ 0.6/7.9 MB 2.1 MB/s eta 0:00:04\n",
      "   --- ------------------------------------ 0.7/7.9 MB 2.0 MB/s eta 0:00:04\n",
      "   ---- ----------------------------------- 0.8/7.9 MB 2.0 MB/s eta 0:00:04\n",
      "   ---- ----------------------------------- 0.9/7.9 MB 2.0 MB/s eta 0:00:04\n",
      "   ----- ---------------------------------- 1.0/7.9 MB 2.0 MB/s eta 0:00:04\n",
      "   ----- ---------------------------------- 1.1/7.9 MB 2.0 MB/s eta 0:00:04\n",
      "   ------ --------------------------------- 1.2/7.9 MB 2.0 MB/s eta 0:00:04\n",
      "   ------ --------------------------------- 1.3/7.9 MB 2.0 MB/s eta 0:00:04\n",
      "   ------- -------------------------------- 1.4/7.9 MB 2.0 MB/s eta 0:00:04\n",
      "   ------- -------------------------------- 1.5/7.9 MB 2.0 MB/s eta 0:00:04\n",
      "   ------- -------------------------------- 1.6/7.9 MB 2.0 MB/s eta 0:00:04\n",
      "   -------- ------------------------------- 1.7/7.9 MB 2.0 MB/s eta 0:00:04\n",
      "   -------- ------------------------------- 1.8/7.9 MB 2.0 MB/s eta 0:00:04\n",
      "   --------- ------------------------------ 1.9/7.9 MB 2.0 MB/s eta 0:00:04\n",
      "   --------- ------------------------------ 2.0/7.9 MB 2.0 MB/s eta 0:00:03\n",
      "   ---------- ----------------------------- 2.0/7.9 MB 2.0 MB/s eta 0:00:03\n",
      "   ---------- ----------------------------- 2.1/7.9 MB 2.0 MB/s eta 0:00:03\n",
      "   ----------- ---------------------------- 2.2/7.9 MB 2.0 MB/s eta 0:00:03\n",
      "   ----------- ---------------------------- 2.3/7.9 MB 2.0 MB/s eta 0:00:03\n",
      "   ------------ --------------------------- 2.4/7.9 MB 2.0 MB/s eta 0:00:03\n",
      "   ------------ --------------------------- 2.5/7.9 MB 2.0 MB/s eta 0:00:03\n",
      "   ------------- -------------------------- 2.6/7.9 MB 2.0 MB/s eta 0:00:03\n",
      "   ------------- -------------------------- 2.7/7.9 MB 2.0 MB/s eta 0:00:03\n",
      "   -------------- ------------------------- 2.8/7.9 MB 2.0 MB/s eta 0:00:03\n",
      "   -------------- ------------------------- 2.9/7.9 MB 2.0 MB/s eta 0:00:03\n",
      "   -------------- ------------------------- 3.0/7.9 MB 2.0 MB/s eta 0:00:03\n",
      "   --------------- ------------------------ 3.1/7.9 MB 2.0 MB/s eta 0:00:03\n",
      "   --------------- ------------------------ 3.1/7.9 MB 2.0 MB/s eta 0:00:03\n",
      "   --------------- ------------------------ 3.1/7.9 MB 1.9 MB/s eta 0:00:03\n",
      "   ---------------- ----------------------- 3.2/7.9 MB 1.9 MB/s eta 0:00:03\n",
      "   ---------------- ----------------------- 3.3/7.9 MB 1.9 MB/s eta 0:00:03\n",
      "   ----------------- ---------------------- 3.4/7.9 MB 1.9 MB/s eta 0:00:03\n",
      "   ----------------- ---------------------- 3.5/7.9 MB 1.9 MB/s eta 0:00:03\n",
      "   ----------------- ---------------------- 3.5/7.9 MB 1.9 MB/s eta 0:00:03\n",
      "   ------------------ --------------------- 3.6/7.9 MB 1.9 MB/s eta 0:00:03\n",
      "   ------------------ --------------------- 3.7/7.9 MB 1.9 MB/s eta 0:00:03\n",
      "   ------------------- -------------------- 3.8/7.9 MB 1.9 MB/s eta 0:00:03\n",
      "   ------------------- -------------------- 3.8/7.9 MB 1.9 MB/s eta 0:00:03\n",
      "   ------------------- -------------------- 3.9/7.9 MB 1.9 MB/s eta 0:00:03\n",
      "   -------------------- ------------------- 4.0/7.9 MB 1.9 MB/s eta 0:00:03\n",
      "   -------------------- ------------------- 4.1/7.9 MB 1.9 MB/s eta 0:00:03\n",
      "   --------------------- ------------------ 4.2/7.9 MB 1.9 MB/s eta 0:00:03\n",
      "   --------------------- ------------------ 4.3/7.9 MB 1.9 MB/s eta 0:00:02\n",
      "   --------------------- ------------------ 4.4/7.9 MB 1.9 MB/s eta 0:00:02\n",
      "   ---------------------- ----------------- 4.4/7.9 MB 1.9 MB/s eta 0:00:02\n",
      "   ---------------------- ----------------- 4.5/7.9 MB 1.9 MB/s eta 0:00:02\n",
      "   ----------------------- ---------------- 4.6/7.9 MB 1.9 MB/s eta 0:00:02\n",
      "   ----------------------- ---------------- 4.7/7.9 MB 1.9 MB/s eta 0:00:02\n",
      "   ------------------------ --------------- 4.8/7.9 MB 1.9 MB/s eta 0:00:02\n",
      "   ------------------------ --------------- 4.9/7.9 MB 1.9 MB/s eta 0:00:02\n",
      "   ------------------------- -------------- 5.0/7.9 MB 1.9 MB/s eta 0:00:02\n",
      "   ------------------------- -------------- 5.1/7.9 MB 1.9 MB/s eta 0:00:02\n",
      "   -------------------------- ------------- 5.2/7.9 MB 1.9 MB/s eta 0:00:02\n",
      "   -------------------------- ------------- 5.3/7.9 MB 1.9 MB/s eta 0:00:02\n",
      "   --------------------------- ------------ 5.4/7.9 MB 1.9 MB/s eta 0:00:02\n",
      "   --------------------------- ------------ 5.5/7.9 MB 1.9 MB/s eta 0:00:02\n",
      "   ---------------------------- ----------- 5.6/7.9 MB 1.9 MB/s eta 0:00:02\n",
      "   ---------------------------- ----------- 5.7/7.9 MB 1.9 MB/s eta 0:00:02\n",
      "   ----------------------------- ---------- 5.8/7.9 MB 1.9 MB/s eta 0:00:02\n",
      "   ----------------------------- ---------- 5.8/7.9 MB 1.9 MB/s eta 0:00:02\n",
      "   ------------------------------ --------- 5.9/7.9 MB 1.9 MB/s eta 0:00:02\n",
      "   ------------------------------ --------- 6.0/7.9 MB 1.9 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 6.1/7.9 MB 1.9 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 6.2/7.9 MB 1.9 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 6.3/7.9 MB 1.9 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 6.4/7.9 MB 1.9 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 6.5/7.9 MB 1.9 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 6.6/7.9 MB 1.9 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 6.7/7.9 MB 1.9 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 6.8/7.9 MB 1.9 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 6.9/7.9 MB 1.9 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 7.0/7.9 MB 1.9 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 7.1/7.9 MB 1.9 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 7.2/7.9 MB 1.9 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 7.2/7.9 MB 1.9 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 7.3/7.9 MB 1.9 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 7.4/7.9 MB 1.9 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 7.5/7.9 MB 1.9 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 7.6/7.9 MB 1.9 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 7.7/7.9 MB 1.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------  7.8/7.9 MB 1.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------  7.9/7.9 MB 1.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 7.9/7.9 MB 1.9 MB/s eta 0:00:00\n",
      "Downloading datasets-2.15.0-py3-none-any.whl (521 kB)\n",
      "   ---------------------------------------- 0.0/521.2 kB ? eta -:--:--\n",
      "   ------- -------------------------------- 92.2/521.2 kB 2.6 MB/s eta 0:00:01\n",
      "   ------------- -------------------------- 174.1/521.2 kB 2.1 MB/s eta 0:00:01\n",
      "   --------------------- ------------------ 276.5/521.2 kB 2.1 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 368.6/521.2 kB 2.1 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 471.0/521.2 kB 2.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 521.2/521.2 kB 1.9 MB/s eta 0:00:00\n",
      "Downloading dill-0.3.7-py3-none-any.whl (115 kB)\n",
      "   ---------------------------------------- 0.0/115.3 kB ? eta -:--:--\n",
      "   --------------------- ------------------ 61.4/115.3 kB 1.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 115.3/115.3 kB 2.2 MB/s eta 0:00:00\n",
      "Downloading pyarrow-14.0.1-cp39-cp39-win_amd64.whl (24.6 MB)\n",
      "   ---------------------------------------- 0.0/24.6 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.1/24.6 MB 3.2 MB/s eta 0:00:08\n",
      "   ---------------------------------------- 0.2/24.6 MB 2.6 MB/s eta 0:00:10\n",
      "   ---------------------------------------- 0.3/24.6 MB 2.1 MB/s eta 0:00:12\n",
      "    --------------------------------------- 0.4/24.6 MB 2.1 MB/s eta 0:00:12\n",
      "    --------------------------------------- 0.5/24.6 MB 2.1 MB/s eta 0:00:12\n",
      "    --------------------------------------- 0.6/24.6 MB 2.2 MB/s eta 0:00:12\n",
      "   - -------------------------------------- 0.7/24.6 MB 2.1 MB/s eta 0:00:12\n",
      "   - -------------------------------------- 0.8/24.6 MB 2.1 MB/s eta 0:00:12\n",
      "   - -------------------------------------- 0.8/24.6 MB 2.1 MB/s eta 0:00:12\n",
      "   - -------------------------------------- 0.9/24.6 MB 2.1 MB/s eta 0:00:12\n",
      "   - -------------------------------------- 1.0/24.6 MB 2.1 MB/s eta 0:00:12\n",
      "   - -------------------------------------- 1.1/24.6 MB 2.1 MB/s eta 0:00:12\n",
      "   - -------------------------------------- 1.2/24.6 MB 2.0 MB/s eta 0:00:12\n",
      "   -- ------------------------------------- 1.3/24.6 MB 2.0 MB/s eta 0:00:12\n",
      "   -- ------------------------------------- 1.4/24.6 MB 1.9 MB/s eta 0:00:12\n",
      "   -- ------------------------------------- 1.4/24.6 MB 2.0 MB/s eta 0:00:12\n",
      "   -- ------------------------------------- 1.6/24.6 MB 2.0 MB/s eta 0:00:12\n",
      "   -- ------------------------------------- 1.6/24.6 MB 2.0 MB/s eta 0:00:12\n",
      "   -- ------------------------------------- 1.7/24.6 MB 2.0 MB/s eta 0:00:12\n",
      "   -- ------------------------------------- 1.8/24.6 MB 2.0 MB/s eta 0:00:12\n",
      "   --- ------------------------------------ 1.9/24.6 MB 2.0 MB/s eta 0:00:12\n",
      "   --- ------------------------------------ 2.0/24.6 MB 2.0 MB/s eta 0:00:12\n",
      "   --- ------------------------------------ 2.1/24.6 MB 2.0 MB/s eta 0:00:12\n",
      "   --- ------------------------------------ 2.2/24.6 MB 2.0 MB/s eta 0:00:12\n",
      "   --- ------------------------------------ 2.3/24.6 MB 2.0 MB/s eta 0:00:12\n",
      "   --- ------------------------------------ 2.4/24.6 MB 2.0 MB/s eta 0:00:12\n",
      "   ---- ----------------------------------- 2.5/24.6 MB 2.0 MB/s eta 0:00:12\n",
      "   ---- ----------------------------------- 2.6/24.6 MB 2.0 MB/s eta 0:00:11\n",
      "   ---- ----------------------------------- 2.7/24.6 MB 2.0 MB/s eta 0:00:11\n",
      "   ---- ----------------------------------- 2.8/24.6 MB 2.0 MB/s eta 0:00:11\n",
      "   ---- ----------------------------------- 2.9/24.6 MB 2.0 MB/s eta 0:00:11\n",
      "   ---- ----------------------------------- 3.0/24.6 MB 2.0 MB/s eta 0:00:11\n",
      "   ----- ---------------------------------- 3.1/24.6 MB 2.0 MB/s eta 0:00:11\n",
      "   ----- ---------------------------------- 3.2/24.6 MB 2.0 MB/s eta 0:00:11\n",
      "   ----- ---------------------------------- 3.3/24.6 MB 2.0 MB/s eta 0:00:11\n",
      "   ----- ---------------------------------- 3.4/24.6 MB 2.0 MB/s eta 0:00:11\n",
      "   ----- ---------------------------------- 3.5/24.6 MB 2.0 MB/s eta 0:00:11\n",
      "   ----- ---------------------------------- 3.6/24.6 MB 2.0 MB/s eta 0:00:11\n",
      "   ----- ---------------------------------- 3.7/24.6 MB 2.0 MB/s eta 0:00:11\n",
      "   ------ --------------------------------- 3.8/24.6 MB 2.0 MB/s eta 0:00:11\n",
      "   ------ --------------------------------- 3.9/24.6 MB 2.0 MB/s eta 0:00:11\n",
      "   ------ --------------------------------- 4.0/24.6 MB 2.0 MB/s eta 0:00:11\n",
      "   ------ --------------------------------- 4.1/24.6 MB 2.0 MB/s eta 0:00:11\n",
      "   ------ --------------------------------- 4.1/24.6 MB 2.0 MB/s eta 0:00:11\n",
      "   ------ --------------------------------- 4.2/24.6 MB 2.0 MB/s eta 0:00:11\n",
      "   ------- -------------------------------- 4.3/24.6 MB 2.0 MB/s eta 0:00:11\n",
      "   ------- -------------------------------- 4.4/24.6 MB 2.0 MB/s eta 0:00:11\n",
      "   ------- -------------------------------- 4.5/24.6 MB 2.0 MB/s eta 0:00:10\n",
      "   ------- -------------------------------- 4.6/24.6 MB 2.0 MB/s eta 0:00:10\n",
      "   ------- -------------------------------- 4.7/24.6 MB 2.0 MB/s eta 0:00:10\n",
      "   ------- -------------------------------- 4.8/24.6 MB 2.0 MB/s eta 0:00:10\n",
      "   ------- -------------------------------- 4.9/24.6 MB 2.0 MB/s eta 0:00:10\n",
      "   -------- ------------------------------- 5.0/24.6 MB 2.0 MB/s eta 0:00:10\n",
      "   -------- ------------------------------- 5.1/24.6 MB 2.0 MB/s eta 0:00:10\n",
      "   -------- ------------------------------- 5.2/24.6 MB 2.0 MB/s eta 0:00:10\n",
      "   -------- ------------------------------- 5.3/24.6 MB 2.0 MB/s eta 0:00:10\n",
      "   -------- ------------------------------- 5.4/24.6 MB 2.0 MB/s eta 0:00:10\n",
      "   -------- ------------------------------- 5.5/24.6 MB 2.0 MB/s eta 0:00:10\n",
      "   --------- ------------------------------ 5.6/24.6 MB 2.0 MB/s eta 0:00:10\n",
      "   --------- ------------------------------ 5.7/24.6 MB 2.0 MB/s eta 0:00:10\n",
      "   --------- ------------------------------ 5.7/24.6 MB 2.0 MB/s eta 0:00:10\n",
      "   --------- ------------------------------ 5.8/24.6 MB 2.0 MB/s eta 0:00:10\n",
      "   --------- ------------------------------ 5.9/24.6 MB 2.0 MB/s eta 0:00:10\n",
      "   --------- ------------------------------ 6.0/24.6 MB 2.0 MB/s eta 0:00:10\n",
      "   --------- ------------------------------ 6.1/24.6 MB 2.0 MB/s eta 0:00:10\n",
      "   ---------- ----------------------------- 6.2/24.6 MB 2.0 MB/s eta 0:00:10\n",
      "   ---------- ----------------------------- 6.3/24.6 MB 2.0 MB/s eta 0:00:10\n",
      "   ---------- ----------------------------- 6.4/24.6 MB 2.0 MB/s eta 0:00:10\n",
      "   ---------- ----------------------------- 6.5/24.6 MB 2.0 MB/s eta 0:00:09\n",
      "   ---------- ----------------------------- 6.6/24.6 MB 2.0 MB/s eta 0:00:09\n",
      "   ---------- ----------------------------- 6.7/24.6 MB 2.0 MB/s eta 0:00:09\n",
      "   ----------- ---------------------------- 6.8/24.6 MB 2.0 MB/s eta 0:00:09\n",
      "   ----------- ---------------------------- 6.9/24.6 MB 2.0 MB/s eta 0:00:09\n",
      "   ----------- ---------------------------- 7.0/24.6 MB 2.0 MB/s eta 0:00:09\n",
      "   ----------- ---------------------------- 7.1/24.6 MB 2.0 MB/s eta 0:00:09\n",
      "   ----------- ---------------------------- 7.2/24.6 MB 2.0 MB/s eta 0:00:09\n",
      "   ----------- ---------------------------- 7.3/24.6 MB 2.0 MB/s eta 0:00:09\n",
      "   ----------- ---------------------------- 7.4/24.6 MB 2.0 MB/s eta 0:00:09\n",
      "   ------------ --------------------------- 7.4/24.6 MB 2.0 MB/s eta 0:00:09\n",
      "   ------------ --------------------------- 7.5/24.6 MB 2.0 MB/s eta 0:00:09\n",
      "   ------------ --------------------------- 7.6/24.6 MB 2.0 MB/s eta 0:00:09\n",
      "   ------------ --------------------------- 7.7/24.6 MB 2.0 MB/s eta 0:00:09\n",
      "   ------------ --------------------------- 7.8/24.6 MB 2.0 MB/s eta 0:00:09\n",
      "   ------------ --------------------------- 7.9/24.6 MB 2.0 MB/s eta 0:00:09\n",
      "   ------------- -------------------------- 8.0/24.6 MB 2.0 MB/s eta 0:00:09\n",
      "   ------------- -------------------------- 8.1/24.6 MB 2.0 MB/s eta 0:00:09\n",
      "   ------------- -------------------------- 8.2/24.6 MB 2.0 MB/s eta 0:00:09\n",
      "   ------------- -------------------------- 8.3/24.6 MB 2.0 MB/s eta 0:00:09\n",
      "   ------------- -------------------------- 8.4/24.6 MB 2.0 MB/s eta 0:00:09\n",
      "   ------------- -------------------------- 8.5/24.6 MB 2.0 MB/s eta 0:00:08\n",
      "   ------------- -------------------------- 8.6/24.6 MB 2.0 MB/s eta 0:00:08\n",
      "   -------------- ------------------------- 8.7/24.6 MB 2.0 MB/s eta 0:00:08\n",
      "   -------------- ------------------------- 8.8/24.6 MB 2.0 MB/s eta 0:00:08\n",
      "   -------------- ------------------------- 8.9/24.6 MB 2.0 MB/s eta 0:00:08\n",
      "   -------------- ------------------------- 8.9/24.6 MB 2.0 MB/s eta 0:00:08\n",
      "   -------------- ------------------------- 9.1/24.6 MB 2.0 MB/s eta 0:00:08\n",
      "   -------------- ------------------------- 9.1/24.6 MB 2.0 MB/s eta 0:00:08\n",
      "   -------------- ------------------------- 9.2/24.6 MB 2.0 MB/s eta 0:00:08\n",
      "   --------------- ------------------------ 9.3/24.6 MB 2.0 MB/s eta 0:00:08\n",
      "   --------------- ------------------------ 9.4/24.6 MB 2.0 MB/s eta 0:00:08\n",
      "   --------------- ------------------------ 9.5/24.6 MB 2.0 MB/s eta 0:00:08\n",
      "   --------------- ------------------------ 9.6/24.6 MB 2.0 MB/s eta 0:00:08\n",
      "   --------------- ------------------------ 9.7/24.6 MB 2.0 MB/s eta 0:00:08\n",
      "   --------------- ------------------------ 9.8/24.6 MB 2.0 MB/s eta 0:00:08\n",
      "   ---------------- ----------------------- 9.9/24.6 MB 2.0 MB/s eta 0:00:08\n",
      "   ---------------- ----------------------- 10.0/24.6 MB 2.0 MB/s eta 0:00:08\n",
      "   ---------------- ----------------------- 10.1/24.6 MB 2.0 MB/s eta 0:00:08\n",
      "   ---------------- ----------------------- 10.2/24.6 MB 2.0 MB/s eta 0:00:08\n",
      "   ---------------- ----------------------- 10.2/24.6 MB 2.0 MB/s eta 0:00:08\n",
      "   ---------------- ----------------------- 10.3/24.6 MB 2.0 MB/s eta 0:00:08\n",
      "   ---------------- ----------------------- 10.4/24.6 MB 2.0 MB/s eta 0:00:08\n",
      "   ----------------- ---------------------- 10.5/24.6 MB 2.0 MB/s eta 0:00:07\n",
      "   ----------------- ---------------------- 10.6/24.6 MB 2.0 MB/s eta 0:00:07\n",
      "   ----------------- ---------------------- 10.7/24.6 MB 2.0 MB/s eta 0:00:07\n",
      "   ----------------- ---------------------- 10.8/24.6 MB 2.0 MB/s eta 0:00:07\n",
      "   ----------------- ---------------------- 10.9/24.6 MB 2.0 MB/s eta 0:00:07\n",
      "   ----------------- ---------------------- 11.0/24.6 MB 2.0 MB/s eta 0:00:07\n",
      "   ------------------ --------------------- 11.1/24.6 MB 2.0 MB/s eta 0:00:07\n",
      "   ------------------ --------------------- 11.2/24.6 MB 2.0 MB/s eta 0:00:07\n",
      "   ------------------ --------------------- 11.3/24.6 MB 2.0 MB/s eta 0:00:07\n",
      "   ------------------ --------------------- 11.4/24.6 MB 2.0 MB/s eta 0:00:07\n",
      "   ------------------ --------------------- 11.5/24.6 MB 2.0 MB/s eta 0:00:07\n",
      "   ------------------ --------------------- 11.6/24.6 MB 2.0 MB/s eta 0:00:07\n",
      "   ------------------ --------------------- 11.7/24.6 MB 2.0 MB/s eta 0:00:07\n",
      "   ------------------- -------------------- 11.8/24.6 MB 2.0 MB/s eta 0:00:07\n",
      "   ------------------- -------------------- 11.9/24.6 MB 2.0 MB/s eta 0:00:07\n",
      "   ------------------- -------------------- 12.0/24.6 MB 2.0 MB/s eta 0:00:07\n",
      "   ------------------- -------------------- 12.1/24.6 MB 2.0 MB/s eta 0:00:07\n",
      "   ------------------- -------------------- 12.2/24.6 MB 2.0 MB/s eta 0:00:07\n",
      "   ------------------- -------------------- 12.3/24.6 MB 2.0 MB/s eta 0:00:07\n",
      "   -------------------- ------------------- 12.3/24.6 MB 2.0 MB/s eta 0:00:07\n",
      "   -------------------- ------------------- 12.5/24.6 MB 2.0 MB/s eta 0:00:07\n",
      "   -------------------- ------------------- 12.5/24.6 MB 2.0 MB/s eta 0:00:06\n",
      "   -------------------- ------------------- 12.6/24.6 MB 2.0 MB/s eta 0:00:06\n",
      "   -------------------- ------------------- 12.7/24.6 MB 2.0 MB/s eta 0:00:06\n",
      "   -------------------- ------------------- 12.8/24.6 MB 2.0 MB/s eta 0:00:06\n",
      "   -------------------- ------------------- 12.9/24.6 MB 2.0 MB/s eta 0:00:06\n",
      "   --------------------- ------------------ 13.0/24.6 MB 2.0 MB/s eta 0:00:06\n",
      "   --------------------- ------------------ 13.1/24.6 MB 2.0 MB/s eta 0:00:06\n",
      "   --------------------- ------------------ 13.2/24.6 MB 2.0 MB/s eta 0:00:06\n",
      "   --------------------- ------------------ 13.3/24.6 MB 2.0 MB/s eta 0:00:06\n",
      "   --------------------- ------------------ 13.4/24.6 MB 2.0 MB/s eta 0:00:06\n",
      "   --------------------- ------------------ 13.5/24.6 MB 2.0 MB/s eta 0:00:06\n",
      "   ---------------------- ----------------- 13.6/24.6 MB 2.0 MB/s eta 0:00:06\n",
      "   ---------------------- ----------------- 13.7/24.6 MB 2.0 MB/s eta 0:00:06\n",
      "   ---------------------- ----------------- 13.8/24.6 MB 2.0 MB/s eta 0:00:06\n",
      "   ---------------------- ----------------- 13.9/24.6 MB 2.0 MB/s eta 0:00:06\n",
      "   ---------------------- ----------------- 13.9/24.6 MB 2.0 MB/s eta 0:00:06\n",
      "   ---------------------- ----------------- 14.1/24.6 MB 2.0 MB/s eta 0:00:06\n",
      "   ---------------------- ----------------- 14.2/24.6 MB 2.0 MB/s eta 0:00:06\n",
      "   ----------------------- ---------------- 14.2/24.6 MB 2.0 MB/s eta 0:00:06\n",
      "   ----------------------- ---------------- 14.3/24.6 MB 2.0 MB/s eta 0:00:06\n",
      "   ----------------------- ---------------- 14.4/24.6 MB 2.0 MB/s eta 0:00:06\n",
      "   ----------------------- ---------------- 14.4/24.6 MB 2.0 MB/s eta 0:00:06\n",
      "   ----------------------- ---------------- 14.5/24.6 MB 2.0 MB/s eta 0:00:06\n",
      "   ----------------------- ---------------- 14.6/24.6 MB 2.0 MB/s eta 0:00:06\n",
      "   ----------------------- ---------------- 14.6/24.6 MB 2.0 MB/s eta 0:00:06\n",
      "   ----------------------- ---------------- 14.7/24.6 MB 2.0 MB/s eta 0:00:05\n",
      "   ------------------------ --------------- 14.8/24.6 MB 2.0 MB/s eta 0:00:05\n",
      "   ------------------------ --------------- 14.9/24.6 MB 2.0 MB/s eta 0:00:05\n",
      "   ------------------------ --------------- 15.0/24.6 MB 2.0 MB/s eta 0:00:05\n",
      "   ------------------------ --------------- 15.1/24.6 MB 2.0 MB/s eta 0:00:05\n",
      "   ------------------------ --------------- 15.2/24.6 MB 2.0 MB/s eta 0:00:05\n",
      "   ------------------------ --------------- 15.3/24.6 MB 2.0 MB/s eta 0:00:05\n",
      "   ------------------------ --------------- 15.4/24.6 MB 2.0 MB/s eta 0:00:05\n",
      "   ------------------------- -------------- 15.5/24.6 MB 2.0 MB/s eta 0:00:05\n",
      "   ------------------------- -------------- 15.6/24.6 MB 2.0 MB/s eta 0:00:05\n",
      "   ------------------------- -------------- 15.6/24.6 MB 2.0 MB/s eta 0:00:05\n",
      "   ------------------------- -------------- 15.7/24.6 MB 2.0 MB/s eta 0:00:05\n",
      "   ------------------------- -------------- 15.8/24.6 MB 2.0 MB/s eta 0:00:05\n",
      "   ------------------------- -------------- 15.9/24.6 MB 2.0 MB/s eta 0:00:05\n",
      "   -------------------------- ------------- 16.0/24.6 MB 2.0 MB/s eta 0:00:05\n",
      "   -------------------------- ------------- 16.1/24.6 MB 2.0 MB/s eta 0:00:05\n",
      "   -------------------------- ------------- 16.2/24.6 MB 2.0 MB/s eta 0:00:05\n",
      "   -------------------------- ------------- 16.3/24.6 MB 2.0 MB/s eta 0:00:05\n",
      "   -------------------------- ------------- 16.4/24.6 MB 2.0 MB/s eta 0:00:05\n",
      "   -------------------------- ------------- 16.5/24.6 MB 2.0 MB/s eta 0:00:05\n",
      "   -------------------------- ------------- 16.6/24.6 MB 2.0 MB/s eta 0:00:05\n",
      "   --------------------------- ------------ 16.7/24.6 MB 2.0 MB/s eta 0:00:05\n",
      "   --------------------------- ------------ 16.8/24.6 MB 2.0 MB/s eta 0:00:04\n",
      "   --------------------------- ------------ 16.9/24.6 MB 2.0 MB/s eta 0:00:04\n",
      "   --------------------------- ------------ 17.0/24.6 MB 2.0 MB/s eta 0:00:04\n",
      "   --------------------------- ------------ 17.1/24.6 MB 2.0 MB/s eta 0:00:04\n",
      "   --------------------------- ------------ 17.2/24.6 MB 2.0 MB/s eta 0:00:04\n",
      "   ---------------------------- ----------- 17.2/24.6 MB 2.0 MB/s eta 0:00:04\n",
      "   ---------------------------- ----------- 17.3/24.6 MB 2.0 MB/s eta 0:00:04\n",
      "   ---------------------------- ----------- 17.4/24.6 MB 2.0 MB/s eta 0:00:04\n",
      "   ---------------------------- ----------- 17.5/24.6 MB 2.0 MB/s eta 0:00:04\n",
      "   ---------------------------- ----------- 17.6/24.6 MB 2.0 MB/s eta 0:00:04\n",
      "   ---------------------------- ----------- 17.7/24.6 MB 2.0 MB/s eta 0:00:04\n",
      "   ---------------------------- ----------- 17.8/24.6 MB 2.0 MB/s eta 0:00:04\n",
      "   ----------------------------- ---------- 17.9/24.6 MB 2.0 MB/s eta 0:00:04\n",
      "   ----------------------------- ---------- 18.0/24.6 MB 2.0 MB/s eta 0:00:04\n",
      "   ----------------------------- ---------- 18.1/24.6 MB 2.0 MB/s eta 0:00:04\n",
      "   ----------------------------- ---------- 18.2/24.6 MB 2.0 MB/s eta 0:00:04\n",
      "   ----------------------------- ---------- 18.3/24.6 MB 2.0 MB/s eta 0:00:04\n",
      "   ----------------------------- ---------- 18.4/24.6 MB 2.0 MB/s eta 0:00:04\n",
      "   ------------------------------ --------- 18.5/24.6 MB 2.0 MB/s eta 0:00:04\n",
      "   ------------------------------ --------- 18.6/24.6 MB 2.0 MB/s eta 0:00:04\n",
      "   ------------------------------ --------- 18.7/24.6 MB 2.0 MB/s eta 0:00:04\n",
      "   ------------------------------ --------- 18.7/24.6 MB 2.0 MB/s eta 0:00:03\n",
      "   ------------------------------ --------- 18.8/24.6 MB 2.0 MB/s eta 0:00:03\n",
      "   ------------------------------ --------- 18.9/24.6 MB 2.0 MB/s eta 0:00:03\n",
      "   ------------------------------ --------- 19.0/24.6 MB 2.0 MB/s eta 0:00:03\n",
      "   ------------------------------- -------- 19.1/24.6 MB 2.0 MB/s eta 0:00:03\n",
      "   ------------------------------- -------- 19.2/24.6 MB 2.0 MB/s eta 0:00:03\n",
      "   ------------------------------- -------- 19.3/24.6 MB 2.0 MB/s eta 0:00:03\n",
      "   ------------------------------- -------- 19.4/24.6 MB 2.0 MB/s eta 0:00:03\n",
      "   ------------------------------- -------- 19.5/24.6 MB 2.0 MB/s eta 0:00:03\n",
      "   ------------------------------- -------- 19.6/24.6 MB 2.0 MB/s eta 0:00:03\n",
      "   ------------------------------- -------- 19.7/24.6 MB 2.0 MB/s eta 0:00:03\n",
      "   -------------------------------- ------- 19.8/24.6 MB 2.0 MB/s eta 0:00:03\n",
      "   -------------------------------- ------- 19.9/24.6 MB 2.0 MB/s eta 0:00:03\n",
      "   -------------------------------- ------- 19.9/24.6 MB 2.0 MB/s eta 0:00:03\n",
      "   -------------------------------- ------- 20.0/24.6 MB 2.0 MB/s eta 0:00:03\n",
      "   -------------------------------- ------- 20.1/24.6 MB 2.0 MB/s eta 0:00:03\n",
      "   -------------------------------- ------- 20.2/24.6 MB 2.0 MB/s eta 0:00:03\n",
      "   -------------------------------- ------- 20.3/24.6 MB 2.0 MB/s eta 0:00:03\n",
      "   --------------------------------- ------ 20.4/24.6 MB 2.0 MB/s eta 0:00:03\n",
      "   --------------------------------- ------ 20.5/24.6 MB 2.0 MB/s eta 0:00:03\n",
      "   --------------------------------- ------ 20.6/24.6 MB 2.0 MB/s eta 0:00:03\n",
      "   --------------------------------- ------ 20.6/24.6 MB 2.0 MB/s eta 0:00:03\n",
      "   --------------------------------- ------ 20.7/24.6 MB 2.0 MB/s eta 0:00:02\n",
      "   --------------------------------- ------ 20.8/24.6 MB 2.0 MB/s eta 0:00:02\n",
      "   --------------------------------- ------ 20.9/24.6 MB 2.0 MB/s eta 0:00:02\n",
      "   ---------------------------------- ----- 21.0/24.6 MB 2.0 MB/s eta 0:00:02\n",
      "   ---------------------------------- ----- 21.1/24.6 MB 2.0 MB/s eta 0:00:02\n",
      "   ---------------------------------- ----- 21.2/24.6 MB 2.0 MB/s eta 0:00:02\n",
      "   ---------------------------------- ----- 21.3/24.6 MB 2.0 MB/s eta 0:00:02\n",
      "   ---------------------------------- ----- 21.4/24.6 MB 2.0 MB/s eta 0:00:02\n",
      "   ---------------------------------- ----- 21.5/24.6 MB 2.0 MB/s eta 0:00:02\n",
      "   ----------------------------------- ---- 21.6/24.6 MB 2.0 MB/s eta 0:00:02\n",
      "   ----------------------------------- ---- 21.6/24.6 MB 2.0 MB/s eta 0:00:02\n",
      "   ----------------------------------- ---- 21.8/24.6 MB 2.0 MB/s eta 0:00:02\n",
      "   ----------------------------------- ---- 21.8/24.6 MB 2.0 MB/s eta 0:00:02\n",
      "   ----------------------------------- ---- 21.9/24.6 MB 2.0 MB/s eta 0:00:02\n",
      "   ----------------------------------- ---- 22.0/24.6 MB 2.0 MB/s eta 0:00:02\n",
      "   ----------------------------------- ---- 22.1/24.6 MB 2.0 MB/s eta 0:00:02\n",
      "   ------------------------------------ --- 22.2/24.6 MB 2.0 MB/s eta 0:00:02\n",
      "   ------------------------------------ --- 22.3/24.6 MB 2.0 MB/s eta 0:00:02\n",
      "   ------------------------------------ --- 22.4/24.6 MB 2.0 MB/s eta 0:00:02\n",
      "   ------------------------------------ --- 22.5/24.6 MB 2.0 MB/s eta 0:00:02\n",
      "   ------------------------------------ --- 22.6/24.6 MB 2.0 MB/s eta 0:00:02\n",
      "   ------------------------------------ --- 22.7/24.6 MB 2.0 MB/s eta 0:00:02\n",
      "   ------------------------------------ --- 22.8/24.6 MB 2.0 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 22.9/24.6 MB 2.0 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 22.9/24.6 MB 2.0 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 23.1/24.6 MB 2.0 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 23.1/24.6 MB 2.0 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 23.2/24.6 MB 2.0 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 23.3/24.6 MB 2.0 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 23.4/24.6 MB 1.9 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 23.5/24.6 MB 2.0 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 23.6/24.6 MB 1.9 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 23.7/24.6 MB 2.0 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 23.8/24.6 MB 2.0 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 23.9/24.6 MB 1.9 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 23.9/24.6 MB 2.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------  24.1/24.6 MB 2.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------  24.1/24.6 MB 2.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------  24.2/24.6 MB 1.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------  24.3/24.6 MB 1.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------  24.4/24.6 MB 1.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------  24.5/24.6 MB 1.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------  24.6/24.6 MB 2.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------  24.6/24.6 MB 2.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------  24.6/24.6 MB 2.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 24.6/24.6 MB 1.9 MB/s eta 0:00:00\n",
      "Downloading tensorboardX-2.6.2.2-py2.py3-none-any.whl (101 kB)\n",
      "   ---------------------------------------- 0.0/101.7 kB ? eta -:--:--\n",
      "   ------------------------------------ --- 92.2/101.7 kB 1.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 101.7/101.7 kB 1.9 MB/s eta 0:00:00\n",
      "Downloading huggingface_hub-0.19.4-py3-none-any.whl (311 kB)\n",
      "   ---------------------------------------- 0.0/311.7 kB ? eta -:--:--\n",
      "   -------------- ------------------------- 112.6/311.7 kB 3.3 MB/s eta 0:00:01\n",
      "   ------------------------ --------------- 194.6/311.7 kB 2.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------  307.2/311.7 kB 2.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 311.7/311.7 kB 2.2 MB/s eta 0:00:00\n",
      "Downloading protobuf-4.25.1-cp39-cp39-win_amd64.whl (413 kB)\n",
      "   ---------------------------------------- 0.0/413.4 kB ? eta -:--:--\n",
      "   ---------- ----------------------------- 112.6/413.4 kB 2.2 MB/s eta 0:00:01\n",
      "   ------------------ --------------------- 194.6/413.4 kB 2.0 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 307.2/413.4 kB 2.1 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 368.6/413.4 kB 2.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 413.4/413.4 kB 2.0 MB/s eta 0:00:00\n",
      "Downloading regex-2023.10.3-cp39-cp39-win_amd64.whl (269 kB)\n",
      "   ---------------------------------------- 0.0/269.6 kB ? eta -:--:--\n",
      "   ------------- -------------------------- 92.2/269.6 kB 1.7 MB/s eta 0:00:01\n",
      "   ------------------------- -------------- 174.1/269.6 kB 2.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------  266.2/269.6 kB 2.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 269.6/269.6 kB 1.8 MB/s eta 0:00:00\n",
      "Downloading safetensors-0.4.1-cp39-none-win_amd64.whl (277 kB)\n",
      "   ---------------------------------------- 0.0/277.8 kB ? eta -:--:--\n",
      "   ---------------- ----------------------- 112.6/277.8 kB 3.3 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 194.6/277.8 kB 2.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 277.8/277.8 kB 2.1 MB/s eta 0:00:00\n",
      "Downloading tokenizers-0.15.0-cp39-none-win_amd64.whl (2.2 MB)\n",
      "   ---------------------------------------- 0.0/2.2 MB ? eta -:--:--\n",
      "   - -------------------------------------- 0.1/2.2 MB 1.7 MB/s eta 0:00:02\n",
      "   --- ------------------------------------ 0.2/2.2 MB 2.1 MB/s eta 0:00:01\n",
      "   ----- ---------------------------------- 0.3/2.2 MB 1.9 MB/s eta 0:00:02\n",
      "   ------ --------------------------------- 0.4/2.2 MB 2.1 MB/s eta 0:00:01\n",
      "   -------- ------------------------------- 0.5/2.2 MB 2.0 MB/s eta 0:00:01\n",
      "   ---------- ----------------------------- 0.6/2.2 MB 2.1 MB/s eta 0:00:01\n",
      "   ----------- ---------------------------- 0.6/2.2 MB 2.0 MB/s eta 0:00:01\n",
      "   ------------- -------------------------- 0.7/2.2 MB 2.1 MB/s eta 0:00:01\n",
      "   --------------- ------------------------ 0.8/2.2 MB 2.0 MB/s eta 0:00:01\n",
      "   ----------------- ---------------------- 1.0/2.2 MB 2.1 MB/s eta 0:00:01\n",
      "   ------------------ --------------------- 1.0/2.2 MB 2.0 MB/s eta 0:00:01\n",
      "   -------------------- ------------------- 1.1/2.2 MB 2.1 MB/s eta 0:00:01\n",
      "   ---------------------- ----------------- 1.2/2.2 MB 2.0 MB/s eta 0:00:01\n",
      "   ------------------------ --------------- 1.3/2.2 MB 2.0 MB/s eta 0:00:01\n",
      "   ------------------------- -------------- 1.4/2.2 MB 2.0 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 1.5/2.2 MB 2.0 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 1.6/2.2 MB 2.0 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 1.7/2.2 MB 2.0 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 1.8/2.2 MB 2.0 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 1.9/2.2 MB 2.0 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 2.0/2.2 MB 2.0 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 2.0/2.2 MB 2.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------  2.2/2.2 MB 2.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.2/2.2 MB 2.0 MB/s eta 0:00:00\n",
      "Downloading filelock-3.13.1-py3-none-any.whl (11 kB)\n",
      "Downloading multiprocess-0.70.15-py39-none-any.whl (133 kB)\n",
      "   ---------------------------------------- 0.0/133.3 kB ? eta -:--:--\n",
      "   --------------------------- ------------ 92.2/133.3 kB 2.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 133.3/133.3 kB 2.0 MB/s eta 0:00:00\n",
      "Downloading pyarrow_hotfix-0.6-py3-none-any.whl (7.9 kB)\n",
      "Downloading xxhash-3.4.1-cp39-cp39-win_amd64.whl (29 kB)\n",
      "Downloading fsspec-2023.10.0-py3-none-any.whl (166 kB)\n",
      "   ---------------------------------------- 0.0/166.4 kB ? eta -:--:--\n",
      "   ----------------- ---------------------- 71.7/166.4 kB 2.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 166.4/166.4 kB 2.0 MB/s eta 0:00:00\n",
      "Installing collected packages: sentencepiece, yacs, xxhash, tqdm, safetensors, rouge, regex, pyarrow-hotfix, pyarrow, protobuf, fsspec, filelock, dill, tensorboardX, nltk, multiprocess, huggingface-hub, tokenizers, transformers, datasets, openprompt\n",
      "Successfully installed datasets-2.15.0 dill-0.3.7 filelock-3.13.1 fsspec-2023.10.0 huggingface-hub-0.19.4 multiprocess-0.70.15 nltk-3.8.1 openprompt-1.0.1 protobuf-4.25.1 pyarrow-14.0.1 pyarrow-hotfix-0.6 regex-2023.10.3 rouge-1.0.0 safetensors-0.4.1 sentencepiece-0.1.96 tensorboardX-2.6.2.2 tokenizers-0.15.0 tqdm-4.66.1 transformers-4.35.2 xxhash-3.4.1 yacs-0.1.8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.2.1 -> 23.3.1\n",
      "[notice] To update, run: C:\\Users\\eddie\\AppData\\Local\\Programs\\Python\\Python39\\python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "# !pip install openprompt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "m0e0CsUHms_s"
   },
   "source": [
    "# Import openprompt package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-17T11:04:23.784486100Z",
     "start_time": "2023-12-17T11:04:17.736714800Z"
    },
    "id": "tNSoiDoMms_s",
    "outputId": "4777df26-d128-46bb-8bd9-9a84aebec708"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\eddie\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\transformers\\generation_utils.py:24: FutureWarning: Importing `GenerationMixin` from `src/transformers/generation_utils.py` is deprecated and will be removed in Transformers v5. Import as `from transformers import GenerationMixin` instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from openprompt.plms import load_plm\n",
    "from openprompt.prompts.prompt_generator import T5TemplateGenerator\n",
    "from openprompt.pipeline_base import PromptDataLoader, PromptForClassification\n",
    "from openprompt.prompts import ManualTemplate\n",
    "from openprompt.trainer import ClassificationRunner\n",
    "import copy\n",
    "import torch\n",
    "from transformers import  AdamW, get_linear_schedule_with_warmup\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-17T11:04:23.801486300Z",
     "start_time": "2023-12-17T11:04:23.785487500Z"
    },
    "id": "dGyoJ7R4ms_s"
   },
   "outputs": [],
   "source": [
    "cuda = True\n",
    "auto_t = False # Whether to perform automatic template generation\n",
    "auto_v = False # Whether to perform automatic verbalizer generation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "svjNaAHSms_s"
   },
   "source": [
    "# Load dataset and model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-17T11:04:23.823493600Z",
     "start_time": "2023-12-17T11:04:23.801486300Z"
    },
    "id": "LOOjhEd_ms_s"
   },
   "outputs": [],
   "source": [
    "from openprompt.data_utils.text_classification_dataset import SST2Processor\n",
    "dataset = {'train': SST2Processor().get_train_examples(\"SST-2/\"),\n",
    "           'validation': SST2Processor().get_dev_examples(\"SST-2/\"),\n",
    "           'test': SST2Processor().get_test_examples(\"SST-2/\")}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-17T11:08:16.487862300Z",
     "start_time": "2023-12-17T11:07:40.428628900Z"
    },
    "id": "wCWYtFDtms_s",
    "outputId": "88d3c0a6-0289-4e5e-f161-142914bc7330"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\eddie\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\transformers\\models\\t5\\tokenization_t5.py:240: FutureWarning: This tokenizer was incorrectly instantiated with a model max length of 512 which will be corrected in Transformers v5.\n",
      "For now, this behavior is kept to avoid breaking backwards compatibility when padding/encoding with `truncation is True`.\n",
      "- Be aware that you SHOULD NOT rely on t5-large automatically truncating your input to 512 when padding/encoding.\n",
      "- If you want to encode/pad to sequences longer than 512 you can either instantiate this tokenizer with `model_max_length` or pass `max_length` when encoding/padding.\n",
      "- To avoid this warning, please instantiate this tokenizer with `model_max_length` set to your preferred value.\n",
      "  warnings.warn(\n",
      "You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thouroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset: {\n",
      "  \"guid\": \"train-0\",\n",
      "  \"label\": 0,\n",
      "  \"meta\": {},\n",
      "  \"text_a\": \"nothing happens , and it happens to flat characters .\",\n",
      "  \"text_b\": \"\",\n",
      "  \"tgt_text\": null\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#print('load model...')\n",
    "from openprompt.plms import load_plm\n",
    "# load mlm model for main tasks\n",
    "plm, tokenizer, model_config, WrapperClass = load_plm(\"roberta\", \"roberta-large\")\n",
    "\n",
    "# load generation model for template generation\n",
    "template_generate_model, template_generate_tokenizer, template_generate_model_config, template_tokenizer_wrapper = load_plm('t5', 't5-large')\n",
    "\n",
    "from openprompt.prompts import ManualVerbalizer, ManualTemplate\n",
    "\n",
    "\n",
    "###################################################################################################################\n",
    "#   TODO: You need to switch LMBFFTemplateGenerationTemplate or ManualTemplate to                                 #\n",
    "#         compare auto generate template and manual generate template                                             #\n",
    "###################################################################################################################\n",
    "from openprompt.prompts.prompt_generator import LMBFFTemplateGenerationTemplate\n",
    "########################################\n",
    "#   LMBFFTemplateGenerationTemplate    #\n",
    "########################################\n",
    "import random\n",
    "\n",
    "if auto_t:\n",
    "    verbalizer = ManualVerbalizer(tokenizer=tokenizer, num_classes=2, label_words=['terrible','great'])\n",
    "\n",
    "    # number of demonstrations\n",
    "    num_demonstrations = 1  # try different number\n",
    "\n",
    "    demonstrations = []\n",
    "\n",
    "    for _ in range(num_demonstrations):\n",
    "        # random choice training set example with label 0\n",
    "        random_example_1 = random.choice([example for example in dataset['train'] if example.label == 0])\n",
    "\n",
    "        # random choice training set example with label 1\n",
    "        random_example_2 = random.choice([example for example in dataset['train'] if example.label == 1])\n",
    "\n",
    "        demonstration = f'{random_example_1.text_a} It was terrible. {random_example_2.text_a} It was great.'\n",
    "        demonstrations.append(demonstration)\n",
    "\n",
    "    # You can modify the demonstrations and try different combinations\n",
    "    template_text = '{\"placeholder\": \"text_a\"} {\"mask\"} {\"meta\": \"labelword\"} {\"mask\"}.' + ' '.join(demonstrations)\n",
    "    template = LMBFFTemplateGenerationTemplate(tokenizer=template_generate_tokenizer, verbalizer=verbalizer, text=template_text)\n",
    "#############################################\n",
    "#   End of LMBFFTemplateGenerationTemplate  #\n",
    "#############################################\n",
    "\n",
    "########################################\n",
    "#          ManualTemplate              #\n",
    "########################################\n",
    "else:\n",
    "    # number of demonstrations\n",
    "    num_demonstrations = 1  # try different number\n",
    "\n",
    "    demonstrations = []\n",
    "\n",
    "    for _ in range(num_demonstrations):\n",
    "        # random choice training set example with label 0\n",
    "        random_example_1 = random.choice([example for example in dataset['train'] if example.label == 0])\n",
    "\n",
    "        # random choice training set example with label 1\n",
    "        random_example_2 = random.choice([example for example in dataset['train'] if example.label == 1])\n",
    "\n",
    "        demonstration = f'{random_example_1.text_a} Sentence for analyze: This sentence is negative. {random_example_2.text_a} Sentence for analyze: This sentence is positive.'\n",
    "        demonstrations.append(demonstration)\n",
    "    # ManualTemplate A\n",
    "    # template = ManualTemplate(tokenizer=tokenizer, text='{\"placeholder\":\"text_a\"} It was {\"mask\"}.' + ' '.join(demonstrations))\n",
    "    # verbalizer = ManualVerbalizer(tokenizer=tokenizer, num_classes=2, label_words=['terrible','great'])\n",
    "\n",
    "    # ManualTemplate B\n",
    "    # template = ManualTemplate(tokenizer=tokenizer, text='{\"placeholder\":\"text_a\"} This sentence is {\"mask\"}.' + ' '.join(demonstrations))\n",
    "    # verbalizer = ManualVerbalizer(tokenizer=tokenizer, num_classes=2, label_words=['bad','good'])\n",
    "\n",
    "    # ManualTemplate C\n",
    "    template = ManualTemplate(tokenizer=tokenizer, text='{\"placeholder\":\"text_a\"} Sentence for analyze: This sentence is {\"mask\"}.' + ' '.join(demonstrations))\n",
    "    verbalizer = ManualVerbalizer(tokenizer=tokenizer, num_classes=2, label_words=['negative','positive'])\n",
    "#############################################\n",
    "#          End of ManualTemplate            #\n",
    "#############################################\n",
    "\n",
    "###################################################################################################################\n",
    "#                                           End of your code                                                      #\n",
    "###################################################################################################################\n",
    "\n",
    "\n",
    "# view wrapped example\n",
    "wrapped_example = template.wrap_one_example(dataset['train'][0])\n",
    "print(\"dataset:\", dataset['train'][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hTc-RNTHms_s"
   },
   "source": [
    "# Utility Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-17T11:08:16.540697200Z",
     "start_time": "2023-12-17T11:08:16.496862200Z"
    },
    "id": "q2l6VlSUms_s"
   },
   "outputs": [],
   "source": [
    "import inspect\n",
    "from openprompt.plms import load_plm\n",
    "from openprompt.prompts.prompt_generator import T5TemplateGenerator\n",
    "from openprompt.pipeline_base import PromptDataLoader, PromptForClassification\n",
    "from openprompt.prompts import ManualTemplate\n",
    "from openprompt.trainer import ClassificationRunner\n",
    "import copy\n",
    "import torch\n",
    "from torch.optim import AdamW\n",
    "from transformers import  get_linear_schedule_with_warmup\n",
    "import numpy as np\n",
    "\n",
    "# Returns the best evaluation score achieved during training\n",
    "def fit(model, train_dataloader, val_dataloader, loss_func, optimizer, epochs=5):\n",
    "    best_score = 0.0\n",
    "    for epoch in range(epochs):\n",
    "        train_loss = train_epoch(model, train_dataloader, loss_func, optimizer)\n",
    "        score = evaluate(model, val_dataloader)\n",
    "        if score > best_score:\n",
    "            best_score = score\n",
    "            torch.save(model.state_dict(), 'ckpts/best_model_by_template.pt')\n",
    "        print(f\"Epoch {epoch+1}: Train loss={train_loss}, Eval score={score}\")\n",
    "    return best_score\n",
    "\n",
    "# Trains the model on the training data and computes the training loss\n",
    "def train_epoch(model, train_dataloader, loss_func, optimizer):\n",
    "    model.train()\n",
    "    loss_all = []\n",
    "    for step, inputs in enumerate(train_dataloader):\n",
    "        if cuda:\n",
    "            inputs = inputs.cuda()\n",
    "        #####################################################\n",
    "        # 1. Put correct variables into model to get logits #\n",
    "        # 2. Get labels                                     #\n",
    "        # 3. Evalutate using loss_func                      #\n",
    "        # 4. Append loss to loss_all                        #\n",
    "        #####################################################\n",
    "        # 1. Put correct variables into model to get logits\n",
    "        logits = model(batch=inputs)\n",
    "\n",
    "        # 2. Get labels\n",
    "        labels = inputs['label']\n",
    "\n",
    "        # 3. Evalutate using loss_func\n",
    "        loss = loss_func(logits, labels)\n",
    "        loss.backward()\n",
    "\n",
    "        # 4. Append loss to loss_all\n",
    "        loss_all.append(loss.item())\n",
    "        #####################################################\n",
    "        #                 End of your code                  #\n",
    "        #####################################################\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "    return np.mean(loss_all)\n",
    "\n",
    "def evaluate(model, val_dataloader):\n",
    "    model.eval()\n",
    "    allpreds = []\n",
    "    alllabels = []\n",
    "    with torch.no_grad():\n",
    "        for step, inputs in enumerate(val_dataloader):\n",
    "            if cuda:\n",
    "                inputs = inputs.cuda()\n",
    "            #####################################################\n",
    "            # 1. Put correct variables into model to get logits #\n",
    "            # 2. Get labels                                     #\n",
    "            # 3. Extend labels to list                          #\n",
    "            # 4. Get predictions and extend preds to list       #\n",
    "            #####################################################\n",
    "            # 1. Put correct variables into model to get logits\n",
    "            logits = model(batch=inputs)\n",
    "\n",
    "            # 2. Get labels\n",
    "            labels = inputs['label']\n",
    "\n",
    "            # 3. Extend labels to list\n",
    "            alllabels.extend(labels.cpu().numpy())\n",
    "\n",
    "            # 4. Get predictions and extend preds to list\n",
    "            preds = torch.argmax(logits, dim=1)\n",
    "            allpreds.extend(preds.cpu().numpy())\n",
    "            #####################################################\n",
    "            #                 End of your code                  #\n",
    "            #####################################################\n",
    "    acc = sum([int(i==j) for i,j in zip(allpreds, alllabels)])/len(allpreds)\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CceTS_lHms_s"
   },
   "source": [
    "# Template generation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jYj5c8mUms_s"
   },
   "source": [
    "generated template from TemplateGenerator and find the best template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-17T11:08:16.549706Z",
     "start_time": "2023-12-17T11:08:16.512856100Z"
    },
    "id": "lmaUNq2Tms_t"
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "class ManualTemplateWithoutParse(ManualTemplate):\n",
    "    \"\"\"The generated template from TemplateGenerator is a list of dict of parsed template_text. So no further parsing is needed.\"\"\"\n",
    "    def on_text_set(self):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "performing auto_t...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tokenizing: 32it [00:00, 500.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 18/18 [01:00<00:00,  3.34s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['{\"placeholder\": \"text_a\"} It was {\"mask\"} ..nothing happens , and it happens to flat characters . It was terrible. the filmmakers \\' eye for detail and the high standards of performance convey a strong sense of the girls \\' environment . It was great.', '{\"placeholder\": \"text_a\"} It was {\"mask\"} . nothing happens.nothing happens , and it happens to flat characters . It was terrible. the filmmakers \\' eye for detail and the high standards of performance convey a strong sense of the girls \\' environment . It was great.', '{\"placeholder\": \"text_a\"} It was {\"mask\"} . Nothing happens.nothing happens , and it happens to flat characters . It was terrible. the filmmakers \\' eye for detail and the high standards of performance convey a strong sense of the girls \\' environment . It was great.', '{\"placeholder\": \"text_a\"} It was {\"mask\"} . It was terrible.nothing happens , and it happens to flat characters . It was terrible. the filmmakers \\' eye for detail and the high standards of performance convey a strong sense of the girls \\' environment . It was great.', '{\"placeholder\": \"text_a\"} It was {\"mask\"} . It was horrible.nothing happens , and it happens to flat characters . It was terrible. the filmmakers \\' eye for detail and the high standards of performance convey a strong sense of the girls \\' environment . It was great.']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current template: {\"placeholder\": \"text_a\"} It was {\"mask\"} ..nothing happens , and it happens to flat characters . It was terrible. the filmmakers ' eye for detail and the high standards of performance convey a strong sense of the girls ' environment . It was great.\n",
      "\n",
      "Wrapped example: [[{'text': 'nothing happens , and it happens to flat characters .', 'loss_ids': 0, 'shortenable_ids': 1}, {'text': ' It was', 'loss_ids': 0, 'shortenable_ids': 0}, {'text': '<mask>', 'loss_ids': 1, 'shortenable_ids': 0}, {'text': \" ..nothing happens , and it happens to flat characters . It was terrible. the filmmakers ' eye for detail and the high standards of performance convey a strong sense of the girls ' environment . It was great.\", 'loss_ids': 0, 'shortenable_ids': 0}], {'guid': 'train-0', 'label': 0}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "tokenizing: 0it [00:00, ?it/s]\u001B[A\n",
      "tokenizing: 32it [00:00, 149.54it/s]A\n",
      "\n",
      "tokenizing: 32it [00:00, 516.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train loss=1.1528510210349197, Eval score=0.75\n",
      "Epoch 2: Train loss=0.37750999681793473, Eval score=0.8125\n",
      "Epoch 3: Train loss=0.2787289610332664, Eval score=0.84375\n",
      "Epoch 4: Train loss=0.025363265110854627, Eval score=0.90625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 1/5 [14:09<56:37, 849.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: Train loss=0.0018837267928901724, Eval score=0.90625\n",
      "Current template: {\"placeholder\": \"text_a\"} It was {\"mask\"} . nothing happens.nothing happens , and it happens to flat characters . It was terrible. the filmmakers ' eye for detail and the high standards of performance convey a strong sense of the girls ' environment . It was great.\n",
      "\n",
      "Wrapped example: [[{'text': 'nothing happens , and it happens to flat characters .', 'loss_ids': 0, 'shortenable_ids': 1}, {'text': ' It was', 'loss_ids': 0, 'shortenable_ids': 0}, {'text': '<mask>', 'loss_ids': 1, 'shortenable_ids': 0}, {'text': \" . nothing happens.nothing happens , and it happens to flat characters . It was terrible. the filmmakers ' eye for detail and the high standards of performance convey a strong sense of the girls ' environment . It was great.\", 'loss_ids': 0, 'shortenable_ids': 0}], {'guid': 'train-0', 'label': 0}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "tokenizing: 32it [00:00, 492.32it/s]\n",
      "\n",
      "tokenizing: 32it [00:00, 1103.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train loss=0.7332377739207914, Eval score=0.71875\n",
      "Epoch 2: Train loss=0.7168362253251246, Eval score=0.71875\n",
      "Epoch 3: Train loss=1.1837782733273343, Eval score=0.65625\n",
      "Epoch 4: Train loss=0.29956639541342156, Eval score=0.71875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 2/5 [32:09<49:15, 985.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: Train loss=0.3618921243223667, Eval score=0.8125\n",
      "Current template: {\"placeholder\": \"text_a\"} It was {\"mask\"} . Nothing happens.nothing happens , and it happens to flat characters . It was terrible. the filmmakers ' eye for detail and the high standards of performance convey a strong sense of the girls ' environment . It was great.\n",
      "\n",
      "Wrapped example: [[{'text': 'nothing happens , and it happens to flat characters .', 'loss_ids': 0, 'shortenable_ids': 1}, {'text': ' It was', 'loss_ids': 0, 'shortenable_ids': 0}, {'text': '<mask>', 'loss_ids': 1, 'shortenable_ids': 0}, {'text': \" . Nothing happens.nothing happens , and it happens to flat characters . It was terrible. the filmmakers ' eye for detail and the high standards of performance convey a strong sense of the girls ' environment . It was great.\", 'loss_ids': 0, 'shortenable_ids': 0}], {'guid': 'train-0', 'label': 0}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "tokenizing: 32it [00:00, 903.48it/s]\n",
      "\n",
      "tokenizing: 32it [00:00, 1595.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train loss=1.3148028787691146, Eval score=0.875\n",
      "Epoch 2: Train loss=0.28604804459155275, Eval score=0.6875\n",
      "Epoch 3: Train loss=0.33886124413311336, Eval score=0.84375\n",
      "Epoch 4: Train loss=0.4210491230323896, Eval score=0.78125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 3/5 [50:04<34:12, 1026.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: Train loss=0.0412714991791745, Eval score=0.875\n",
      "Current template: {\"placeholder\": \"text_a\"} It was {\"mask\"} . It was terrible.nothing happens , and it happens to flat characters . It was terrible. the filmmakers ' eye for detail and the high standards of performance convey a strong sense of the girls ' environment . It was great.\n",
      "\n",
      "Wrapped example: [[{'text': 'nothing happens , and it happens to flat characters .', 'loss_ids': 0, 'shortenable_ids': 1}, {'text': ' It was', 'loss_ids': 0, 'shortenable_ids': 0}, {'text': '<mask>', 'loss_ids': 1, 'shortenable_ids': 0}, {'text': \" . It was terrible.nothing happens , and it happens to flat characters . It was terrible. the filmmakers ' eye for detail and the high standards of performance convey a strong sense of the girls ' environment . It was great.\", 'loss_ids': 0, 'shortenable_ids': 0}], {'guid': 'train-0', 'label': 0}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "tokenizing: 32it [00:00, 1142.90it/s]\n",
      "\n",
      "tokenizing: 32it [00:00, 1684.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train loss=0.9599329188386037, Eval score=0.75\n",
      "Epoch 2: Train loss=0.06398752356241744, Eval score=0.875\n",
      "Epoch 3: Train loss=0.481681306836661, Eval score=0.71875\n",
      "Epoch 4: Train loss=0.43173675783464205, Eval score=0.78125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 4/5 [1:07:59<17:25, 1045.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: Train loss=0.005019660268544612, Eval score=0.84375\n",
      "Current template: {\"placeholder\": \"text_a\"} It was {\"mask\"} . It was horrible.nothing happens , and it happens to flat characters . It was terrible. the filmmakers ' eye for detail and the high standards of performance convey a strong sense of the girls ' environment . It was great.\n",
      "\n",
      "Wrapped example: [[{'text': 'nothing happens , and it happens to flat characters .', 'loss_ids': 0, 'shortenable_ids': 1}, {'text': ' It was', 'loss_ids': 0, 'shortenable_ids': 0}, {'text': '<mask>', 'loss_ids': 1, 'shortenable_ids': 0}, {'text': \" . It was horrible.nothing happens , and it happens to flat characters . It was terrible. the filmmakers ' eye for detail and the high standards of performance convey a strong sense of the girls ' environment . It was great.\", 'loss_ids': 0, 'shortenable_ids': 0}], {'guid': 'train-0', 'label': 0}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "tokenizing: 32it [00:00, 1391.25it/s]\n",
      "\n",
      "tokenizing: 32it [00:00, 1684.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train loss=0.7916011487250216, Eval score=0.5\n",
      "Epoch 2: Train loss=0.4517782203351999, Eval score=0.75\n",
      "Epoch 3: Train loss=0.10124535854902206, Eval score=0.75\n",
      "Epoch 4: Train loss=0.5454732134648577, Eval score=0.84375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [1:25:54<00:00, 1030.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: Train loss=0.0043100308675396715, Eval score=0.875\n",
      "Final best template: {\"placeholder\": \"text_a\"} It was {\"mask\"} ..nothing happens , and it happens to flat characters . It was terrible. the filmmakers ' eye for detail and the high standards of performance convey a strong sense of the girls ' environment . It was great.\n",
      "\n",
      "Wrapped example: [[{'text': 'nothing happens , and it happens to flat characters .', 'loss_ids': 0, 'shortenable_ids': 1}, {'text': ' It was', 'loss_ids': 0, 'shortenable_ids': 0}, {'text': '<mask>', 'loss_ids': 1, 'shortenable_ids': 0}, {'text': \" ..nothing happens , and it happens to flat characters . It was terrible. the filmmakers ' eye for detail and the high standards of performance convey a strong sense of the girls ' environment . It was great.\", 'loss_ids': 0, 'shortenable_ids': 0}], {'guid': 'train-0', 'label': 0}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Template generation\n",
    "if auto_t:\n",
    "    print('performing auto_t...')\n",
    "\n",
    "    if cuda:\n",
    "        template_generate_model = template_generate_model.cuda()\n",
    "    template_generator = T5TemplateGenerator(template_generate_model, template_generate_tokenizer, template_tokenizer_wrapper, verbalizer, beam_width=5) # Beam_width is set to 5 here for efficiency; to improve performance, try a larger number.\n",
    "\n",
    "\n",
    "    dataloader = PromptDataLoader(dataset['train'], template, tokenizer=template_generate_tokenizer, tokenizer_wrapper_class=template_tokenizer_wrapper, batch_size=len(dataset['train']), decoder_max_length=128, max_seq_length=128, shuffle=False, teacher_forcing=False) # Register all data at once\n",
    "    for data in dataloader:\n",
    "        if cuda:\n",
    "            data = data.cuda()\n",
    "        template_generator._register_buffer(data)\n",
    "\n",
    "    template_generate_model.eval()\n",
    "    print('generating...')\n",
    "    template_texts = template_generator._get_templates()\n",
    "\n",
    "    original_template = template.text\n",
    "    template_texts = [template_generator.convert_template(template_text, original_template) for template_text in template_texts]\n",
    "    # template_generator._show_template()\n",
    "    template_generator.release_memory()\n",
    "    # Generate a number of candidate template text\n",
    "    print(template_texts)\n",
    "\n",
    "    # Iterate over each candidate and select the best one\n",
    "    best_metrics = 0.0\n",
    "    best_template_text = None\n",
    "    for template_text in tqdm(template_texts):\n",
    "        verbalizer = ManualVerbalizer(tokenizer=tokenizer, num_classes=2, label_words=['terrible','great'])\n",
    "        template = LMBFFTemplateGenerationTemplate(tokenizer=template_generate_tokenizer, verbalizer=verbalizer, text=template_text)\n",
    "        print(f\"Current template: {template_text}\\n\\nWrapped example: {template.wrap_one_example(dataset['train'][0])}\")\n",
    "\n",
    "        train_dataloader = PromptDataLoader(dataset['train'], template, tokenizer=tokenizer, tokenizer_wrapper_class=WrapperClass, shuffle=True)\n",
    "        valid_dataloader = PromptDataLoader(dataset['validation'], template, tokenizer=tokenizer, tokenizer_wrapper_class=WrapperClass)\n",
    "\n",
    "        model = PromptForClassification(copy.deepcopy(plm), template, verbalizer)\n",
    "\n",
    "        loss_func = torch.nn.CrossEntropyLoss()\n",
    "        no_decay = ['bias', 'LayerNorm.weight']\n",
    "        # it's always good practice to set no decay to bias and LayerNorm parameters\n",
    "        optimizer_grouped_parameters = [\n",
    "            {'params': [p for n, p in model.named_parameters() if not any(nd in n for nd in no_decay)], 'weight_decay': 0.01},\n",
    "            {'params': [p for n, p in model.named_parameters() if any(nd in n for nd in no_decay)], 'weight_decay': 0.0}\n",
    "        ]\n",
    "\n",
    "        optimizer = AdamW(optimizer_grouped_parameters, lr=2e-5)\n",
    "        if cuda:\n",
    "            model = model.cuda()\n",
    "        score = fit(model, train_dataloader, valid_dataloader, loss_func, optimizer)\n",
    "\n",
    "        #######################################################\n",
    "        # TODO: Use score to Find your best template_text     #\n",
    "        #######################################################\n",
    "        if score > best_metrics:\n",
    "            best_metrics = score\n",
    "            best_template_text = template_text\n",
    "        #######################################################\n",
    "        #                 End of your code                    #\n",
    "        #######################################################\n",
    "    # Use the best template\n",
    "    verbalizer = ManualVerbalizer(tokenizer=tokenizer, num_classes=2, label_words=['terrible','great'])\n",
    "    template = LMBFFTemplateGenerationTemplate(tokenizer=template_generate_tokenizer, verbalizer=verbalizer, text=best_template_text)\n",
    "    print(\"Final best template:\", best_template_text)\n",
    "    print()\n",
    "    print(\"Wrapped example:\", template.wrap_one_example(dataset[\"train\"][0]))"
   ],
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-15T07:33:23.621972900Z",
     "start_time": "2023-12-15T06:06:23.164327900Z"
    },
    "id": "kXx6Kz4fms_t",
    "outputId": "fe094b8d-63b4-4f94-c8fc-59363b311283"
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nOu0FUcEms_t"
   },
   "source": [
    "# Verbalizer generation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "n2y1fqkbms_t"
   },
   "source": [
    "verbalizer template from VerbalizerGenerator and find the best verbalizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-15T14:20:15.158130400Z",
     "start_time": "2023-12-15T07:33:23.627972500Z"
    },
    "id": "f1AVgJGSms_t",
    "outputId": "12507049-200f-484e-b950-a6a500c29509"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "performing auto_v...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tokenizing: 32it [00:00, 1523.89it/s]\n",
      "  0%|          | 0/20 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current label_words: ['empty', 'fantastic']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "tokenizing: 32it [00:00, 820.56it/s]\n",
      "\n",
      "tokenizing: 32it [00:00, 1390.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train loss=1.7277246636681411, Eval score=0.625\n",
      "Epoch 2: Train loss=0.20180359936421155, Eval score=0.5625\n",
      "Epoch 3: Train loss=0.3495035150559431, Eval score=0.84375\n",
      "Epoch 4: Train loss=0.0778428362636987, Eval score=0.90625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 1/20 [19:12<6:05:01, 1152.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: Train loss=0.0011378601166427416, Eval score=0.8125\n",
      "current label_words: ['blah', 'good']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "tokenizing: 32it [00:00, 680.86it/s]\n",
      "\n",
      "tokenizing: 32it [00:00, 1391.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train loss=1.8388312356382812, Eval score=0.53125\n",
      "Epoch 2: Train loss=0.7813440004611039, Eval score=0.84375\n",
      "Epoch 3: Train loss=0.46763915856718086, Eval score=0.65625\n",
      "Epoch 4: Train loss=0.942800260071408, Eval score=0.625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 2/20 [38:21<5:45:02, 1150.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: Train loss=0.3121106020739717, Eval score=0.875\n",
      "current label_words: ['empty', 'wonderful']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "tokenizing: 32it [00:00, 908.86it/s]\n",
      "\n",
      "tokenizing: 32it [00:00, 1524.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train loss=1.869593019946478, Eval score=0.5\n",
      "Epoch 2: Train loss=1.3123270897503971, Eval score=0.65625\n",
      "Epoch 3: Train loss=0.18363191878961516, Eval score=0.84375\n",
      "Epoch 4: Train loss=0.2848355232636095, Eval score=0.75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▌        | 3/20 [57:23<5:24:53, 1146.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: Train loss=0.28126877755858004, Eval score=0.71875\n",
      "current label_words: ['pointless', 'perfect']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "tokenizing: 32it [00:00, 830.75it/s]\n",
      "\n",
      "tokenizing: 32it [00:00, 1279.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train loss=1.9799388142964744, Eval score=0.5\n",
      "Epoch 2: Train loss=0.8568148072226904, Eval score=0.5\n",
      "Epoch 3: Train loss=0.5827695988118649, Eval score=0.8125\n",
      "Epoch 4: Train loss=0.21080841389175475, Eval score=0.5625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 4/20 [1:16:25<5:05:18, 1144.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: Train loss=0.8208676349005657, Eval score=0.8125\n",
      "current label_words: ['empty', 'perfect']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "tokenizing: 32it [00:00, 941.01it/s]\n",
      "\n",
      "tokenizing: 32it [00:00, 1600.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train loss=2.476068645599298, Eval score=0.5\n",
      "Epoch 2: Train loss=0.901010129484348, Eval score=0.5\n",
      "Epoch 3: Train loss=0.9483203416748438, Eval score=0.5\n",
      "Epoch 4: Train loss=0.6026230306597427, Eval score=0.6875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 5/20 [1:35:27<4:45:58, 1143.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: Train loss=0.555505938220449, Eval score=0.53125\n",
      "current label_words: ['.', 'perfect']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "tokenizing: 32it [00:00, 1103.46it/s]\n",
      "\n",
      "tokenizing: 32it [00:00, 1600.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train loss=2.5694900336527553, Eval score=0.5\n",
      "Epoch 2: Train loss=0.8119717165827751, Eval score=0.75\n",
      "Epoch 3: Train loss=1.1474934419384226, Eval score=0.5\n",
      "Epoch 4: Train loss=0.8394799940288067, Eval score=0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 6/20 [1:54:29<4:26:41, 1142.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: Train loss=0.36556415481027216, Eval score=0.90625\n",
      "current label_words: ['like', 'great']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "tokenizing: 32it [00:00, 527.98it/s]\n",
      "\n",
      "tokenizing: 32it [00:00, 1140.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train loss=2.186818901929655, Eval score=0.59375\n",
      "Epoch 2: Train loss=0.5522109844459919, Eval score=0.9375\n",
      "Epoch 3: Train loss=0.1513119908659064, Eval score=0.9375\n",
      "Epoch 4: Train loss=0.2920998997363995, Eval score=0.6875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|███▌      | 7/20 [2:13:30<4:07:31, 1142.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: Train loss=0.13889465174133875, Eval score=0.59375\n",
      "current label_words: ['blah', 'fantastic']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "tokenizing: 32it [00:00, 535.07it/s]\n",
      "\n",
      "tokenizing: 32it [00:00, 1254.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train loss=2.402347931740223, Eval score=0.5\n",
      "Epoch 2: Train loss=0.7161554982885718, Eval score=0.5\n",
      "Epoch 3: Train loss=0.45777020710374927, Eval score=0.5625\n",
      "Epoch 4: Train loss=0.06542489577098798, Eval score=0.6875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 8/20 [2:32:30<3:48:19, 1141.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: Train loss=0.015131016795393526, Eval score=0.75\n",
      "current label_words: ['bad', 'great']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "tokenizing: 32it [00:00, 576.38it/s]\n",
      "\n",
      "tokenizing: 32it [00:00, 1185.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train loss=2.022520142098074, Eval score=0.625\n",
      "Epoch 2: Train loss=0.8677729353075847, Eval score=0.5\n",
      "Epoch 3: Train loss=0.9541345525940415, Eval score=0.5\n",
      "Epoch 4: Train loss=0.8184439683682285, Eval score=0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|████▌     | 9/20 [2:51:36<3:29:32, 1142.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: Train loss=0.8469566381536424, Eval score=0.5\n",
      "current label_words: ['pointless', 'good']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "tokenizing: 32it [00:00, 566.29it/s]\n",
      "\n",
      "tokenizing: 32it [00:00, 1263.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train loss=1.799568529240748, Eval score=0.8125\n",
      "Epoch 2: Train loss=0.28907117331846166, Eval score=0.84375\n",
      "Epoch 3: Train loss=0.5826322033431097, Eval score=0.65625\n",
      "Epoch 4: Train loss=0.09599794932000805, Eval score=0.8125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 10/20 [3:11:36<3:13:26, 1160.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: Train loss=0.0024231080218442003, Eval score=0.8125\n",
      "current label_words: ['nothing', 'good']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "tokenizing: 32it [00:00, 361.42it/s]\n",
      "\n",
      "tokenizing: 32it [00:00, 907.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train loss=1.7633443244558293, Eval score=0.875\n",
      "Epoch 2: Train loss=0.8186776932193425, Eval score=0.5\n",
      "Epoch 3: Train loss=0.7439045554492623, Eval score=0.5\n",
      "Epoch 4: Train loss=0.7379001765802968, Eval score=0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|█████▌    | 11/20 [3:32:38<2:58:44, 1191.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: Train loss=0.3660330718098521, Eval score=0.78125\n",
      "current label_words: ['pointless', 'fantastic']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "tokenizing: 32it [00:00, 499.94it/s]\n",
      "\n",
      "tokenizing: 32it [00:00, 1142.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train loss=2.5122941839476596, Eval score=0.5\n",
      "Epoch 2: Train loss=0.9648321308195591, Eval score=0.5\n",
      "Epoch 3: Train loss=0.551663753692992, Eval score=0.5625\n",
      "Epoch 4: Train loss=0.33809803229449265, Eval score=0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 12/20 [3:53:36<2:41:34, 1211.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: Train loss=0.7456019840615227, Eval score=0.65625\n",
      "current label_words: ['blah', 'wonderful']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "tokenizing: 32it [00:00, 493.88it/s]\n",
      "\n",
      "tokenizing: 32it [00:00, 1247.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train loss=2.8916631793465513, Eval score=0.53125\n",
      "Epoch 2: Train loss=0.691999132046476, Eval score=0.5\n",
      "Epoch 3: Train loss=0.3489301402032652, Eval score=0.8125\n",
      "Epoch 4: Train loss=0.007621254479861506, Eval score=0.875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|██████▌   | 13/20 [4:14:44<2:23:23, 1229.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: Train loss=1.280616385766861, Eval score=0.59375\n",
      "current label_words: ['blah', 'perfect']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "tokenizing: 32it [00:00, 524.61it/s]\n",
      "\n",
      "tokenizing: 32it [00:00, 1066.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train loss=2.997079571098311, Eval score=0.5\n",
      "Epoch 2: Train loss=0.9213496522279456, Eval score=0.40625\n",
      "Epoch 3: Train loss=0.7841200120747089, Eval score=0.5\n",
      "Epoch 4: Train loss=0.9426644382765517, Eval score=0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 14/20 [4:36:52<2:05:51, 1258.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: Train loss=0.9716125187696889, Eval score=0.5\n",
      "current label_words: ['nothing', 'fantastic']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "tokenizing: 32it [00:00, 492.76it/s]\n",
      "\n",
      "tokenizing: 32it [00:00, 1248.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train loss=1.4860612111647846, Eval score=0.5625\n",
      "Epoch 2: Train loss=0.8457897683256306, Eval score=0.8125\n",
      "Epoch 3: Train loss=0.4640673541952367, Eval score=0.5\n",
      "Epoch 4: Train loss=1.0802333870979055, Eval score=0.84375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 15/20 [4:58:34<1:45:59, 1271.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: Train loss=0.13888551097898016, Eval score=0.84375\n",
      "current label_words: ['empty', 'good']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "tokenizing: 32it [00:00, 500.31it/s]\n",
      "\n",
      "tokenizing: 32it [00:00, 1189.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train loss=2.1202581623510923, Eval score=0.5\n",
      "Epoch 2: Train loss=1.0466933535644785, Eval score=0.5\n",
      "Epoch 3: Train loss=0.7535003568045795, Eval score=0.75\n",
      "Epoch 4: Train loss=0.47330884481198154, Eval score=0.78125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 16/20 [5:19:50<1:24:52, 1273.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: Train loss=0.09935192804459803, Eval score=0.84375\n",
      "current label_words: ['nothing', 'great']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "tokenizing: 0it [00:00, ?it/s]\u001B[A\n",
      "tokenizing: 32it [00:00, 313.22it/s]\u001B[A\n",
      "\n",
      "tokenizing: 32it [00:00, 941.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train loss=2.124927480994245, Eval score=0.6875\n",
      "Epoch 2: Train loss=0.9805129619635409, Eval score=0.625\n",
      "Epoch 3: Train loss=0.3983721316108131, Eval score=0.8125\n",
      "Epoch 4: Train loss=0.0024634409897430487, Eval score=0.8125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|████████▌ | 17/20 [5:40:48<1:03:25, 1268.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: Train loss=0.0001455296979600007, Eval score=0.8125\n",
      "current label_words: ['horrible', 'great']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "tokenizing: 32it [00:00, 539.15it/s]\n",
      "\n",
      "tokenizing: 32it [00:00, 1032.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train loss=1.7018258452881128, Eval score=0.5\n",
      "Epoch 2: Train loss=0.5733988606225466, Eval score=0.8125\n",
      "Epoch 3: Train loss=0.7037830375347767, Eval score=0.65625\n",
      "Epoch 4: Train loss=0.1953793161228532, Eval score=0.6875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 18/20 [6:01:56<42:16, 1268.37s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: Train loss=0.004220143700422341, Eval score=0.71875\n",
      "current label_words: ['so', 'great']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "tokenizing: 32it [00:00, 572.32it/s]\n",
      "\n",
      "tokenizing: 32it [00:00, 1122.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train loss=1.7585840596802882, Eval score=0.46875\n",
      "Epoch 2: Train loss=0.9950216518482193, Eval score=0.5\n",
      "Epoch 3: Train loss=0.9548450000584126, Eval score=0.5\n",
      "Epoch 4: Train loss=0.7312759761698544, Eval score=0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|█████████▌| 19/20 [6:23:17<21:12, 1272.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: Train loss=0.7753531774505973, Eval score=0.5\n",
      "current label_words: ['.', 'good']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "tokenizing: 32it [00:00, 373.76it/s]\n",
      "\n",
      "tokenizing: 32it [00:00, 896.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train loss=2.4917918965884382, Eval score=0.5\n",
      "Epoch 2: Train loss=1.1836842977209017, Eval score=0.59375\n",
      "Epoch 3: Train loss=0.7693057809956372, Eval score=0.5625\n",
      "Epoch 4: Train loss=0.7626293436042033, Eval score=0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [6:44:47<00:00, 1214.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: Train loss=0.8419972651172429, Eval score=0.90625\n",
      "final best label words: ['like', 'great']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Verbalizer generation\n",
    "from openprompt.prompts.prompt_generator import RobertaVerbalizerGenerator\n",
    "if auto_v:\n",
    "    print('performing auto_v...')\n",
    "    # Load generation model for verbalizer generation\n",
    "    if cuda:\n",
    "        plm = plm.cuda()\n",
    "    verbalizer_generator = RobertaVerbalizerGenerator(model=plm, tokenizer=tokenizer, candidate_num=20, label_word_num_per_class=20)\n",
    "    # To improve performance, try larger numbers\n",
    "\n",
    "    dataloader = PromptDataLoader(dataset['train'], template, tokenizer=tokenizer, tokenizer_wrapper_class=WrapperClass, batch_size=32)\n",
    "    for data in dataloader:\n",
    "        if cuda:\n",
    "            data = data.cuda()\n",
    "        verbalizer_generator.register_buffer(data)\n",
    "    label_words_list = verbalizer_generator.generate()\n",
    "    verbalizer_generator.release_memory()\n",
    "\n",
    "    # Iterate over each candidate and select the best one\n",
    "    current_verbalizer = copy.deepcopy(verbalizer)\n",
    "    best_metrics = 0.0\n",
    "    best_label_words = None\n",
    "    for label_words in tqdm(label_words_list):\n",
    "        print(f\"current label_words: {label_words}\")\n",
    "        current_verbalizer.label_words = label_words\n",
    "        train_dataloader = PromptDataLoader(dataset['train'], template, tokenizer=tokenizer, tokenizer_wrapper_class=WrapperClass, shuffle=True)\n",
    "        valid_dataloader = PromptDataLoader(dataset['validation'], template, tokenizer=tokenizer, tokenizer_wrapper_class=WrapperClass)\n",
    "\n",
    "        model = PromptForClassification(copy.deepcopy(plm), template, current_verbalizer)\n",
    "\n",
    "        loss_func = torch.nn.CrossEntropyLoss()\n",
    "        no_decay = ['bias', 'LayerNorm.weight']\n",
    "        # it's always good practice to set no decay to bias and LayerNorm parameters\n",
    "        optimizer_grouped_parameters = [\n",
    "            {'params': [p for n, p in model.named_parameters() if not any(nd in n for nd in no_decay)], 'weight_decay': 0.01},\n",
    "            {'params': [p for n, p in model.named_parameters() if any(nd in n for nd in no_decay)], 'weight_decay': 0.0}\n",
    "        ]\n",
    "\n",
    "        optimizer = AdamW(optimizer_grouped_parameters, lr=2e-5)\n",
    "        if cuda:\n",
    "            model = model.cuda()\n",
    "        score = fit(model, train_dataloader, valid_dataloader, loss_func, optimizer)\n",
    "\n",
    "        #######################################################\n",
    "        # TODO: Use score to find your best_label_word        #\n",
    "        #######################################################\n",
    "        if score > best_metrics:\n",
    "            best_metrics = score\n",
    "            best_label_words = label_words\n",
    "        #######################################################\n",
    "        #                 End of your code                    #\n",
    "        #######################################################\n",
    "    # use the best verbalizer\n",
    "    print(\"final best label words:\", best_label_words)\n",
    "    verbalizer = ManualVerbalizer(tokenizer, num_classes=2, label_words=best_label_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Auto Generate Template"
   ],
   "metadata": {
    "collapsed": false,
    "id": "OTCOORthms_t"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-15T15:20:30.828348300Z",
     "start_time": "2023-12-15T14:44:49.937535900Z"
    },
    "id": "TNwuYgGBms_t",
    "outputId": "c0af1a00-0eab-4c55-d10d-d47c828de9e9"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tokenizing: 32it [00:00, 507.87it/s]\n",
      "tokenizing: 32it [00:00, 1599.39it/s]\n",
      "tokenizing: 872it [00:00, 1636.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train loss=1.5268860814145455, Eval score=0.875\n",
      "Epoch 2: Train loss=0.6383957030984675, Eval score=0.84375\n",
      "Epoch 3: Train loss=0.21628682622622364, Eval score=0.84375\n",
      "Epoch 4: Train loss=0.013896541672579588, Eval score=0.90625\n",
      "Epoch 5: Train loss=0.0023684717649530285, Eval score=0.90625\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataloader = PromptDataLoader(dataset['train'], template, tokenizer=tokenizer, tokenizer_wrapper_class=WrapperClass, shuffle=True)\n",
    "valid_dataloader = PromptDataLoader(dataset['validation'], template, tokenizer=tokenizer, tokenizer_wrapper_class=WrapperClass)\n",
    "test_dataloader = PromptDataLoader(dataset['test'], template, tokenizer=tokenizer, tokenizer_wrapper_class=WrapperClass)\n",
    "\n",
    "\n",
    "model = PromptForClassification(copy.deepcopy(plm), template, verbalizer)\n",
    "loss_func = torch.nn.CrossEntropyLoss()\n",
    "no_decay = ['bias', 'LayerNorm.weight']\n",
    "# It's always good practice to set no decay to bias and LayerNorm parameters\n",
    "optimizer_grouped_parameters = [\n",
    "    {'params': [p for n, p in model.named_parameters() if not any(nd in n for nd in no_decay)], 'weight_decay': 0.01},\n",
    "    {'params': [p for n, p in model.named_parameters() if any(nd in n for nd in no_decay)], 'weight_decay': 0.0}\n",
    "]\n",
    "\n",
    "optimizer = AdamW(optimizer_grouped_parameters, lr=1e-5)\n",
    "if cuda:\n",
    "    model = model.cuda()\n",
    "score = fit(model, train_dataloader, valid_dataloader, loss_func, optimizer)\n",
    "\n",
    "model.load_state_dict(torch.load('ckpts/best_model_by_template.pt'))"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Result 0.91147"
   ],
   "metadata": {
    "collapsed": false,
    "id": "3zkk-U-_ms_t"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Manual Template A: `It is [Mask].`"
   ],
   "metadata": {
    "collapsed": false,
    "id": "-RDcSOisms_t"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tokenizing: 32it [00:00, 1454.65it/s]\n",
      "tokenizing: 32it [00:00, 1882.49it/s]\n",
      "tokenizing: 872it [00:00, 1950.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train loss=0.6719597557093948, Eval score=0.875\n",
      "Epoch 2: Train loss=0.48374567173618743, Eval score=0.96875\n",
      "Epoch 3: Train loss=0.06472259495103572, Eval score=0.84375\n",
      "Epoch 4: Train loss=0.051785140017727826, Eval score=0.90625\n",
      "Epoch 5: Train loss=0.008065869993231445, Eval score=0.9375\n"
     ]
    },
    {
     "data": {
      "text/plain": "<All keys matched successfully>"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataloader = PromptDataLoader(dataset['train'], template, tokenizer=tokenizer, tokenizer_wrapper_class=WrapperClass, shuffle=True)\n",
    "valid_dataloader = PromptDataLoader(dataset['validation'], template, tokenizer=tokenizer, tokenizer_wrapper_class=WrapperClass)\n",
    "test_dataloader = PromptDataLoader(dataset['test'], template, tokenizer=tokenizer, tokenizer_wrapper_class=WrapperClass)\n",
    "\n",
    "\n",
    "model = PromptForClassification(copy.deepcopy(plm), template, verbalizer)\n",
    "loss_func = torch.nn.CrossEntropyLoss()\n",
    "no_decay = ['bias', 'LayerNorm.weight']\n",
    "# It's always good practice to set no decay to bias and LayerNorm parameters\n",
    "optimizer_grouped_parameters = [\n",
    "    {'params': [p for n, p in model.named_parameters() if not any(nd in n for nd in no_decay)], 'weight_decay': 0.01},\n",
    "    {'params': [p for n, p in model.named_parameters() if any(nd in n for nd in no_decay)], 'weight_decay': 0.0}\n",
    "]\n",
    "\n",
    "optimizer = AdamW(optimizer_grouped_parameters, lr=1e-5)\n",
    "if cuda:\n",
    "    model = model.cuda()\n",
    "score = fit(model, train_dataloader, valid_dataloader, loss_func, optimizer)\n",
    "\n",
    "model.load_state_dict(torch.load('ckpts/best_model_by_template.pt'))"
   ],
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-17T07:55:56.679003200Z",
     "start_time": "2023-12-17T07:41:17.017167900Z"
    },
    "id": "Zif8V0Jrms_u",
    "outputId": "697f9fbf-eb2c-4627-84dd-c1c194a5d799"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Result: 0.89672"
   ],
   "metadata": {
    "collapsed": false,
    "id": "rwLgtlVRms_u"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Manual Template B: `This sentence is [Mask].`"
   ],
   "metadata": {
    "collapsed": false,
    "id": "6BP2pQpDms_u"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tokenizing: 32it [00:00, 678.43it/s]\n",
      "tokenizing: 32it [00:00, 1032.41it/s]\n",
      "tokenizing: 872it [00:00, 1167.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train loss=1.1941386761609465, Eval score=0.75\n",
      "Epoch 2: Train loss=0.6013390739717579, Eval score=0.78125\n",
      "Epoch 3: Train loss=0.3433237061253749, Eval score=0.875\n",
      "Epoch 4: Train loss=0.023662671323108952, Eval score=0.90625\n",
      "Epoch 5: Train loss=0.004327693294726487, Eval score=0.875\n"
     ]
    },
    {
     "data": {
      "text/plain": "<All keys matched successfully>"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataloader = PromptDataLoader(dataset['train'], template, tokenizer=tokenizer, tokenizer_wrapper_class=WrapperClass, shuffle=True)\n",
    "valid_dataloader = PromptDataLoader(dataset['validation'], template, tokenizer=tokenizer, tokenizer_wrapper_class=WrapperClass)\n",
    "test_dataloader = PromptDataLoader(dataset['test'], template, tokenizer=tokenizer, tokenizer_wrapper_class=WrapperClass)\n",
    "\n",
    "\n",
    "model = PromptForClassification(copy.deepcopy(plm), template, verbalizer)\n",
    "loss_func = torch.nn.CrossEntropyLoss()\n",
    "no_decay = ['bias', 'LayerNorm.weight']\n",
    "# It's always good practice to set no decay to bias and LayerNorm parameters\n",
    "optimizer_grouped_parameters = [\n",
    "    {'params': [p for n, p in model.named_parameters() if not any(nd in n for nd in no_decay)], 'weight_decay': 0.01},\n",
    "    {'params': [p for n, p in model.named_parameters() if any(nd in n for nd in no_decay)], 'weight_decay': 0.0}\n",
    "]\n",
    "\n",
    "optimizer = AdamW(optimizer_grouped_parameters, lr=1e-5)\n",
    "if cuda:\n",
    "    model = model.cuda()\n",
    "score = fit(model, train_dataloader, valid_dataloader, loss_func, optimizer)\n",
    "\n",
    "model.load_state_dict(torch.load('ckpts/best_model_by_template.pt'))"
   ],
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-17T10:26:05.711191400Z",
     "start_time": "2023-12-17T10:11:47.308004600Z"
    },
    "id": "j5_tzWSJms_u",
    "outputId": "c84918ef-f182-441b-c401-cca802fe4b9f"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Result: 0.92786"
   ],
   "metadata": {
    "collapsed": false,
    "id": "-eFpUmxBms_u"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Manual Template C: `Sentence for analyze: This sentence is [Mask].`"
   ],
   "metadata": {
    "collapsed": false,
    "id": "LqtFpe9Bms_u"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tokenizing: 32it [00:00, 592.65it/s]\n",
      "tokenizing: 32it [00:00, 941.06it/s]\n",
      "tokenizing: 872it [00:00, 1199.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train loss=1.1839790968224406, Eval score=0.5\n",
      "Epoch 2: Train loss=0.884029311593622, Eval score=0.5\n",
      "Epoch 3: Train loss=0.7988081122748554, Eval score=0.5\n",
      "Epoch 4: Train loss=0.6566522549837828, Eval score=0.9375\n",
      "Epoch 5: Train loss=0.4711658735322999, Eval score=0.84375\n"
     ]
    },
    {
     "data": {
      "text/plain": "<All keys matched successfully>"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataloader = PromptDataLoader(dataset['train'], template, tokenizer=tokenizer, tokenizer_wrapper_class=WrapperClass, shuffle=True)\n",
    "valid_dataloader = PromptDataLoader(dataset['validation'], template, tokenizer=tokenizer, tokenizer_wrapper_class=WrapperClass)\n",
    "test_dataloader = PromptDataLoader(dataset['test'], template, tokenizer=tokenizer, tokenizer_wrapper_class=WrapperClass)\n",
    "\n",
    "\n",
    "model = PromptForClassification(copy.deepcopy(plm), template, verbalizer)\n",
    "loss_func = torch.nn.CrossEntropyLoss()\n",
    "no_decay = ['bias', 'LayerNorm.weight']\n",
    "# It's always good practice to set no decay to bias and LayerNorm parameters\n",
    "optimizer_grouped_parameters = [\n",
    "    {'params': [p for n, p in model.named_parameters() if not any(nd in n for nd in no_decay)], 'weight_decay': 0.01},\n",
    "    {'params': [p for n, p in model.named_parameters() if any(nd in n for nd in no_decay)], 'weight_decay': 0.0}\n",
    "]\n",
    "\n",
    "optimizer = AdamW(optimizer_grouped_parameters, lr=1e-5)\n",
    "if cuda:\n",
    "    model = model.cuda()\n",
    "score = fit(model, train_dataloader, valid_dataloader, loss_func, optimizer)\n",
    "\n",
    "model.load_state_dict(torch.load('ckpts/best_model_by_template.pt'))"
   ],
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-17T11:22:56.397680600Z",
     "start_time": "2023-12-17T11:08:54.448803Z"
    },
    "id": "qF2nRgPhms_u",
    "outputId": "5090a5a5-c96c-4728-d176-faf7f9c92bb0"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Result: 0.93934"
   ],
   "metadata": {
    "collapsed": false,
    "id": "eBgmNPTwms_u"
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f0rJiFz2ms_v"
   },
   "source": [
    "# Prediction\n",
    "\n",
    "Predict the results based on testing set. Upload to [Kaggle](https://www.kaggle.com/t/5b8876ed26fd495b8353ad7ce94b6f65)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-17T11:57:10.378518500Z",
     "start_time": "2023-12-17T11:22:56.425175600Z"
    },
    "id": "EdWRucXQms_v"
   },
   "outputs": [],
   "source": [
    "model.eval()\n",
    "\n",
    "allpreds = []\n",
    "for step, inputs in tqdm(enumerate(test_dataloader)):\n",
    "    if cuda:\n",
    "        inputs = inputs.cuda()\n",
    "    logits = model(inputs)\n",
    "    allpreds.extend(torch.argmax(logits, dim=-1).cpu().tolist())\n",
    "\n",
    "\n",
    "with open('pred_task3.csv', 'w') as f:\n",
    "    f.write('index,sentiment_label\\n')\n",
    "    for i, pred in enumerate(allpreds):\n",
    "        f.write('{},{}\\n'.format(i, pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# A compare to standard fine-tuning"
   ],
   "metadata": {
    "collapsed": false,
    "id": "EHFZ6gGdms_u"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Mtt71bkhm-so",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1702919375341,
     "user_tz": -480,
     "elapsed": 19093,
     "user": {
      "displayName": "whats2000 _",
      "userId": "13524042620637171415"
     }
    },
    "outputId": "267f245f-e799-40bd-be64-ae54d1379883"
   },
   "execution_count": 1,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "fc8dc8e6baf04c22943b24870a1817a4"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "da6a5c7ded2a48e09d7023bc2342fa15"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "b567b7d6ab3e4fa6ab02f58618d6c757"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "config.json:   0%|          | 0.00/481 [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "7fe9bfa31ab0499d9e0ada1b179b4916"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Number of training examples: 32\n",
      "Number of validation examples: 32\n",
      "Number of testing examples: 872\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import RobertaTokenizer, RobertaForSequenceClassification\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.optim import AdamW\n",
    "from transformers import get_linear_schedule_with_warmup\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n",
    "import copy\n",
    "\n",
    "cuda = True\n",
    "\n",
    "# Define the Dataset class\n",
    "class SST2Dataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, filename, tokenizer, max_len):\n",
    "        self.data = pd.read_csv(filename, delimiter='\\t')\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        text, label = self.data.iloc[idx]\n",
    "        inputs = self.tokenizer.encode_plus(\n",
    "            text,\n",
    "            None,\n",
    "            add_special_tokens=True,\n",
    "            max_length=self.max_len,\n",
    "            padding='max_length',\n",
    "            return_token_type_ids=True,\n",
    "            truncation=True\n",
    "        )\n",
    "        return {\n",
    "            'input_ids': torch.tensor(inputs['input_ids'], dtype=torch.long),\n",
    "            'attention_mask': torch.tensor(inputs['attention_mask'], dtype=torch.long),\n",
    "            'labels': torch.tensor(label, dtype=torch.long)\n",
    "        }\n",
    "\n",
    "def create_balanced_subsample(dataset, examples_per_class):\n",
    "    subsampled_data = pd.DataFrame()\n",
    "    for label in dataset.data['label'].unique():\n",
    "        label_subset = dataset.data[dataset.data['label'] == label]\n",
    "        subsampled_label_data = label_subset.sample(n=examples_per_class, replace=True)\n",
    "        subsampled_data = pd.concat([subsampled_data, subsampled_label_data])\n",
    "\n",
    "    # Create a new dataset from the subsampled data\n",
    "    subsampled_dataset = copy.deepcopy(dataset)\n",
    "    subsampled_dataset.data = subsampled_data.reset_index(drop=True)\n",
    "    return subsampled_dataset\n",
    "\n",
    "# Initialize the tokenizer\n",
    "tokenizer = RobertaTokenizer.from_pretrained('roberta-base')\n",
    "\n",
    "# Create the datasets\n",
    "train_dataset = SST2Dataset('/content/drive/MyDrive/Colab Notebooks/SST-2/train.tsv', tokenizer, max_len=512)\n",
    "dev_dataset = SST2Dataset('/content/drive/MyDrive/Colab Notebooks/SST-2/dev.tsv', tokenizer, max_len=512)\n",
    "test_dataset = SST2Dataset('/content/drive/MyDrive/Colab Notebooks/SST-2/test.tsv', tokenizer, max_len=512)\n",
    "\n",
    "# Create the DataLoaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "dev_loader = DataLoader(dev_dataset, batch_size=8, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=8, shuffle=False)\n",
    "\n",
    "print('Number of training examples: {}'.format(len(train_dataset)))\n",
    "print('Number of validation examples: {}'.format(len(dev_dataset)))\n",
    "print('Number of testing examples: {}'.format(len(test_dataset)))"
   ],
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-18T15:34:15.108007500Z",
     "start_time": "2023-12-18T15:34:10.013187700Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 197,
     "referenced_widgets": [
      "fc8dc8e6baf04c22943b24870a1817a4",
      "eef1838dc5ae40c6be9bbce0b9b593b5",
      "b25e6b39e2024788bba9d0098eda4feb",
      "6a4bd69564ab444085ee0e2f201cea57",
      "9ee170c1d9924be1b3c1c0b89ca9b23c",
      "0a557cee97d241dc8a084b73adb2917b",
      "8ce7987c3b0e43c7b7867478efe5a8a2",
      "0a044f0dcdd14fdc8b966b9a2db81038",
      "04a880cf7c494c6a830788b3c6fe0eb7",
      "e6c70eb8a7ab4c5481a0c21f71140bc3",
      "d6c8d7c8787442959521244366fd651c",
      "da6a5c7ded2a48e09d7023bc2342fa15",
      "56e36f15029844b08cd2c9d2463127ea",
      "a75bad1520d64374a70078aeb6064fa4",
      "9570eb5384014f398b7a15bf2f0dadbc",
      "0a58bd49b57b4708b3cc6902e98a6789",
      "ef455204be394f428386150002b457a6",
      "9c33ff2d359b45a4be14bf448a91490e",
      "1b45e060e419436085e719c8a3f50a15",
      "6aa177607340454db2410533640d4a5f",
      "28a09858e10a4174be46969ceb4edb73",
      "a07a075e6d174e4c8388ad82784f51c9",
      "b567b7d6ab3e4fa6ab02f58618d6c757",
      "a317963045744493a236cd02e42b4bd3",
      "d7124fc63d0143c9951d0920e7e1f51e",
      "995ed402ca6e43e0877e3db25dcb761d",
      "5db8f87fdf2d470bb01f1fdd389c4b64",
      "f0c2c7bebfc847cc954d87b6c06a55a1",
      "1737a887e27f43a28e231f462d666a52",
      "681efcc4b982455a8489b90dcfc90a23",
      "8b5f02b436384b63957a632b4a38f444",
      "103276e04360477a91e11e57c1937e16",
      "7989de8b7f764c9ba837a35b5fc434e5",
      "7fe9bfa31ab0499d9e0ada1b179b4916",
      "92ab616b50644c558b0724afd766630d",
      "3b80a6f9eff84e8c899085baed039e2d",
      "2ed2a02c30664e47be4d8330a3afbce2",
      "9b31f92ce8fc4466bfb020d328f828c0",
      "1d03116f89fa4dc6b3003cdc293a7bfd",
      "94c0daefc65849db9d815bacbfa221ef",
      "2095686fb94747399a5d01cd633f5c5d",
      "7c5120cb98ba490a9c9b790021a14026",
      "f18b5308424b408aba94f0bc967661ac",
      "bc15730aafca4157859e3865ee90cb3d"
     ]
    },
    "id": "k_FxV74kms_u",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1702919396313,
     "user_tz": -480,
     "elapsed": 17173,
     "user": {
      "displayName": "whats2000 _",
      "userId": "13524042620637171415"
     }
    },
    "outputId": "99fc306b-c81b-4259-c717-102560548cde"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm\n",
    "\n",
    "# Define a function for calculating accuracy\n",
    "def flat_accuracy(preds, labels):\n",
    "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
    "    labels_flat = labels.flatten()\n",
    "    return np.sum(pred_flat == labels_flat) / len(labels_flat)\n",
    "\n",
    "def train_model_with_subsample(train_dataset, dev_loader, examples_per_class, epochs=100):\n",
    "  subsample_train_dataset = create_balanced_subsample(train_dataset, examples_per_class)\n",
    "  subsample_train_loader = DataLoader(subsample_train_dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "  # Initialize the model\n",
    "  model = RobertaForSequenceClassification.from_pretrained('roberta-base', num_labels=2)\n",
    "\n",
    "  # Define the optimizer\n",
    "  no_decay = ['bias', 'LayerNorm.weight']\n",
    "  optimizer_grouped_parameters = [\n",
    "      {'params': [p for n, p in model.named_parameters() if not any(nd in n for nd in no_decay)], 'weight_decay': 0.01},\n",
    "      {'params': [p for n, p in model.named_parameters() if any(nd in n for nd in no_decay)], 'weight_decay': 0.0}\n",
    "  ]\n",
    "\n",
    "  optimizer = AdamW(optimizer_grouped_parameters, lr=1e-5)\n",
    "\n",
    "  # Move model to GPU if available\n",
    "  device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "  model.to(device)\n",
    "\n",
    "  # Track the best validation accuracy\n",
    "  best_valid_acc = 0.0\n",
    "  best_model_state = None\n",
    "\n",
    "  # Training loop with tqdm\n",
    "  for epoch in range(epochs):\n",
    "      model.train()\n",
    "      total_loss = 0\n",
    "      total_accuracy = 0\n",
    "\n",
    "      # Training loop\n",
    "      for step, batch in enumerate(subsample_train_loader):\n",
    "          batch = {k: v.to(device) for k, v in batch.items()}\n",
    "          outputs = model(**batch)\n",
    "          loss = outputs.loss\n",
    "          logits = outputs.logits\n",
    "          total_loss += loss.item()\n",
    "\n",
    "          loss.backward()\n",
    "          torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "          optimizer.step()\n",
    "          model.zero_grad()\n",
    "\n",
    "      avg_train_loss = total_loss / len(subsample_train_loader)\n",
    "\n",
    "      # Validation loop\n",
    "      model.eval()\n",
    "      total_eval_accuracy = 0\n",
    "      for batch in dev_loader:\n",
    "          batch = {k: v.to(device) for k, v in batch.items()}\n",
    "          with torch.no_grad():\n",
    "              outputs = model(**batch)\n",
    "\n",
    "          logits = outputs.logits.detach().cpu().numpy()\n",
    "          label_ids = batch['labels'].to('cpu').numpy()\n",
    "          total_eval_accuracy += flat_accuracy(logits, label_ids)\n",
    "\n",
    "      avg_val_accuracy = total_eval_accuracy / len(dev_loader)\n",
    "\n",
    "      # Check for best accuracy\n",
    "      if avg_val_accuracy > best_valid_acc:\n",
    "          best_valid_acc = avg_val_accuracy\n",
    "          best_model_state = copy.deepcopy(model.state_dict())\n",
    "\n",
    "      # Print training and validation results\n",
    "      if (epoch + 1) % 5 == 0:\n",
    "        print(f'Epoch {epoch+1}: Train loss={avg_train_loss}, Eval score={avg_val_accuracy}')\n",
    "\n",
    "  # Roll back to the best model state\n",
    "  if best_model_state is not None:\n",
    "      model.load_state_dict(best_model_state)\n",
    "\n",
    "  return model, best_valid_acc"
   ],
   "metadata": {
    "id": "PVY9Ko_wms_u",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1702919400398,
     "user_tz": -480,
     "elapsed": 309,
     "user": {
      "displayName": "whats2000 _",
      "userId": "13524042620637171415"
     }
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.out_proj.weight', 'classifier.dense.bias', 'classifier.out_proj.bias', 'classifier.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 5: Train loss=0.6598491668701172, Eval score=0.5\n",
      "Epoch 10: Train loss=0.6504192352294922, Eval score=0.5\n",
      "Epoch 15: Train loss=0.5765002965927124, Eval score=0.5625\n",
      "Epoch 20: Train loss=0.39982685446739197, Eval score=0.59375\n",
      "Epoch 25: Train loss=0.23536762595176697, Eval score=0.5625\n",
      "Epoch 30: Train loss=0.1400073915719986, Eval score=0.59375\n",
      "Epoch 35: Train loss=0.14781221747398376, Eval score=0.59375\n",
      "Epoch 40: Train loss=0.04025143012404442, Eval score=0.59375\n",
      "Epoch 45: Train loss=0.00931935478001833, Eval score=0.59375\n",
      "Epoch 50: Train loss=0.007407527882605791, Eval score=0.625\n",
      "Epoch 55: Train loss=0.004335816949605942, Eval score=0.625\n",
      "Epoch 60: Train loss=0.0030754953622817993, Eval score=0.625\n",
      "Epoch 65: Train loss=0.003189811948686838, Eval score=0.625\n",
      "Epoch 70: Train loss=0.003338342998176813, Eval score=0.625\n",
      "Epoch 75: Train loss=0.005852481350302696, Eval score=0.625\n",
      "Epoch 80: Train loss=0.002267958130687475, Eval score=0.59375\n",
      "Epoch 85: Train loss=0.0015595434233546257, Eval score=0.59375\n",
      "Epoch 90: Train loss=0.0009203332010656595, Eval score=0.59375\n",
      "Epoch 95: Train loss=0.0016998103819787502, Eval score=0.59375\n",
      "Epoch 100: Train loss=0.0010163302067667246, Eval score=0.59375\n"
     ]
    }
   ],
   "source": [
    "# Sample = 1:\n",
    "model, best_acc = train_model_with_subsample(train_dataset, dev_loader, 1, epochs=100)"
   ],
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-18T15:35:40.004360800Z",
     "start_time": "2023-12-18T15:34:21.156477Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fyUqwd1Ams_v",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1702918724392,
     "user_tz": -480,
     "elapsed": 117023,
     "user": {
      "displayName": "whats2000 _",
      "userId": "13524042620637171415"
     }
    },
    "outputId": "d9933694-45ed-4176-9006-7987dad6bad3"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Result: 0.51147"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# Sample = 2:\n",
    "model, best_acc = train_model_with_subsample(train_dataset, dev_loader, 2, epochs=100)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "w5YfNQ-839Uw",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1702919092255,
     "user_tz": -480,
     "elapsed": 132845,
     "user": {
      "displayName": "whats2000 _",
      "userId": "13524042620637171415"
     }
    },
    "outputId": "0d8c7876-b4d0-4119-f1bb-12c6b45c0d77"
   },
   "execution_count": 42,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.out_proj.weight', 'classifier.dense.bias', 'classifier.out_proj.bias', 'classifier.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 5: Train loss=0.6794461607933044, Eval score=0.5\n",
      "Epoch 10: Train loss=0.6317405104637146, Eval score=0.5625\n",
      "Epoch 15: Train loss=0.6060734391212463, Eval score=0.5625\n",
      "Epoch 20: Train loss=0.4598703682422638, Eval score=0.59375\n",
      "Epoch 25: Train loss=0.24159368872642517, Eval score=0.625\n",
      "Epoch 30: Train loss=0.15617643296718597, Eval score=0.6875\n",
      "Epoch 35: Train loss=0.06994253396987915, Eval score=0.625\n",
      "Epoch 40: Train loss=0.04539429396390915, Eval score=0.625\n",
      "Epoch 45: Train loss=0.010577242821455002, Eval score=0.625\n",
      "Epoch 50: Train loss=0.005801016464829445, Eval score=0.625\n",
      "Epoch 55: Train loss=0.004292221274226904, Eval score=0.65625\n",
      "Epoch 60: Train loss=0.0031686837319284678, Eval score=0.65625\n",
      "Epoch 65: Train loss=0.003247876651585102, Eval score=0.65625\n",
      "Epoch 70: Train loss=0.0023325993679463863, Eval score=0.65625\n",
      "Epoch 75: Train loss=0.001626856392249465, Eval score=0.65625\n",
      "Epoch 80: Train loss=0.0011777759063988924, Eval score=0.65625\n",
      "Epoch 85: Train loss=0.0012396734673529863, Eval score=0.65625\n",
      "Epoch 90: Train loss=0.001067392178811133, Eval score=0.65625\n",
      "Epoch 95: Train loss=0.0012099248124286532, Eval score=0.65625\n",
      "Epoch 100: Train loss=0.00117316166870296, Eval score=0.65625\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Result: 0.61639"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# Sample = 4:\n",
    "model, best_acc = train_model_with_subsample(train_dataset, dev_loader, 4, epochs=100)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vCkJdcWO4BHv",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1702919583923,
     "user_tz": -480,
     "elapsed": 166806,
     "user": {
      "displayName": "whats2000 _",
      "userId": "13524042620637171415"
     }
    },
    "outputId": "2bbe241b-76a2-4585-a47e-1e9fae2569a3"
   },
   "execution_count": 5,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.out_proj.weight', 'classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 5: Train loss=0.6888564229011536, Eval score=0.5\n",
      "Epoch 10: Train loss=0.6693909764289856, Eval score=0.5\n",
      "Epoch 15: Train loss=0.6218469738960266, Eval score=0.59375\n",
      "Epoch 20: Train loss=0.4935681223869324, Eval score=0.71875\n",
      "Epoch 25: Train loss=0.2058834433555603, Eval score=0.71875\n",
      "Epoch 30: Train loss=0.0655217245221138, Eval score=0.71875\n",
      "Epoch 35: Train loss=0.024141060188412666, Eval score=0.75\n",
      "Epoch 40: Train loss=0.008887006901204586, Eval score=0.75\n",
      "Epoch 45: Train loss=0.00521630747243762, Eval score=0.75\n",
      "Epoch 50: Train loss=0.003704759990796447, Eval score=0.75\n",
      "Epoch 55: Train loss=0.002091299742460251, Eval score=0.75\n",
      "Epoch 60: Train loss=0.0016093305312097073, Eval score=0.71875\n",
      "Epoch 65: Train loss=0.001457412727177143, Eval score=0.71875\n",
      "Epoch 70: Train loss=0.0015115158166736364, Eval score=0.71875\n",
      "Epoch 75: Train loss=0.0012039917055517435, Eval score=0.75\n",
      "Epoch 80: Train loss=0.001253269612789154, Eval score=0.75\n",
      "Epoch 85: Train loss=0.0010078888153657317, Eval score=0.75\n",
      "Epoch 90: Train loss=0.0009261149098165333, Eval score=0.75\n",
      "Epoch 95: Train loss=0.0007995811174623668, Eval score=0.75\n",
      "Epoch 100: Train loss=0.0008457970689050853, Eval score=0.75\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Result: 0.67868"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "source": [
    "model.eval()\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "allpreds = []\n",
    "\n",
    "# Assuming test_loader is your DataLoader for the test set\n",
    "for batch in tqdm(test_loader):\n",
    "    input_ids = batch['input_ids'].to(device)\n",
    "    attention_mask = batch['attention_mask'].to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        logits = outputs.logits\n",
    "        preds = torch.argmax(logits, dim=-1)\n",
    "        allpreds.extend(preds.cpu().tolist())\n",
    "\n",
    "with open('pred_task3.csv', 'w') as f:\n",
    "    f.write('index,sentiment_label\\n')\n",
    "    for i, pred in enumerate(allpreds):\n",
    "        f.write(f\"{i},{pred}\\n\")"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 49,
     "referenced_widgets": [
      "ac6780bc71b242c6b53ff9ca8e228a32",
      "f49a1221e60148feb964eba6f2a4737e",
      "ac567991697941a5aa1385f9d4e6552c",
      "fac7cd21745442d9b0f5fadb42bea635",
      "eab71b14e49f42c88df0ec05d92e01cc",
      "dd9d75d951b0406e9b8bb1cee96e0616",
      "5fc4ba0b1ddd4526babd67017be81660",
      "26ef033457f444f0aeb23e347aa1ab5a",
      "72c6ff3ddb2d452eb15d98deed27440e",
      "bebd41e39fa843ac9661b526a810cdc1",
      "265fa4f0b84040fa9ff4a73408c2a02c"
     ]
    },
    "id": "tUd3S9z60uPg",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1702919629684,
     "user_tz": -480,
     "elapsed": 26717,
     "user": {
      "displayName": "whats2000 _",
      "userId": "13524042620637171415"
     }
    },
    "outputId": "acb2de13-5ef7-49cc-d498-9a35f28334c4"
   },
   "execution_count": 7,
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "  0%|          | 0/109 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "ac6780bc71b242c6b53ff9ca8e228a32"
      }
     },
     "metadata": {}
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rUXbpLA8ms_v"
   },
   "source": [
    "# Report (15 points)\n",
    "\n",
    "- Task 1: Compare **two** different models you employed and provide a brief discussion of your implementation.\n",
    "\n",
    "- Task 2: You need to try at least **three** different templates and verbalizers to compare how your prompts work with the model. Report your performance in zero-shot, one-shot, and few-shot scenarios, with examples drawn from the training set.\n",
    "\n",
    "- Task 3: Try at least three different manually crafted templates to compare them with auto-generated templates. Evaluate the performance with different numbers of demonstrations and plot the graph from Figure 3 in the paper (https://arxiv.org/pdf/2012.15723.pdf). Also, report your best template and verbalizer.\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "fc8dc8e6baf04c22943b24870a1817a4": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_eef1838dc5ae40c6be9bbce0b9b593b5",
       "IPY_MODEL_b25e6b39e2024788bba9d0098eda4feb",
       "IPY_MODEL_6a4bd69564ab444085ee0e2f201cea57"
      ],
      "layout": "IPY_MODEL_9ee170c1d9924be1b3c1c0b89ca9b23c"
     }
    },
    "eef1838dc5ae40c6be9bbce0b9b593b5": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_0a557cee97d241dc8a084b73adb2917b",
      "placeholder": "​",
      "style": "IPY_MODEL_8ce7987c3b0e43c7b7867478efe5a8a2",
      "value": "vocab.json: 100%"
     }
    },
    "b25e6b39e2024788bba9d0098eda4feb": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_0a044f0dcdd14fdc8b966b9a2db81038",
      "max": 898823,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_04a880cf7c494c6a830788b3c6fe0eb7",
      "value": 898823
     }
    },
    "6a4bd69564ab444085ee0e2f201cea57": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_e6c70eb8a7ab4c5481a0c21f71140bc3",
      "placeholder": "​",
      "style": "IPY_MODEL_d6c8d7c8787442959521244366fd651c",
      "value": " 899k/899k [00:00&lt;00:00, 4.59MB/s]"
     }
    },
    "9ee170c1d9924be1b3c1c0b89ca9b23c": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "0a557cee97d241dc8a084b73adb2917b": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8ce7987c3b0e43c7b7867478efe5a8a2": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "0a044f0dcdd14fdc8b966b9a2db81038": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "04a880cf7c494c6a830788b3c6fe0eb7": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "e6c70eb8a7ab4c5481a0c21f71140bc3": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d6c8d7c8787442959521244366fd651c": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "da6a5c7ded2a48e09d7023bc2342fa15": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_56e36f15029844b08cd2c9d2463127ea",
       "IPY_MODEL_a75bad1520d64374a70078aeb6064fa4",
       "IPY_MODEL_9570eb5384014f398b7a15bf2f0dadbc"
      ],
      "layout": "IPY_MODEL_0a58bd49b57b4708b3cc6902e98a6789"
     }
    },
    "56e36f15029844b08cd2c9d2463127ea": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_ef455204be394f428386150002b457a6",
      "placeholder": "​",
      "style": "IPY_MODEL_9c33ff2d359b45a4be14bf448a91490e",
      "value": "merges.txt: 100%"
     }
    },
    "a75bad1520d64374a70078aeb6064fa4": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_1b45e060e419436085e719c8a3f50a15",
      "max": 456318,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_6aa177607340454db2410533640d4a5f",
      "value": 456318
     }
    },
    "9570eb5384014f398b7a15bf2f0dadbc": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_28a09858e10a4174be46969ceb4edb73",
      "placeholder": "​",
      "style": "IPY_MODEL_a07a075e6d174e4c8388ad82784f51c9",
      "value": " 456k/456k [00:00&lt;00:00, 3.61MB/s]"
     }
    },
    "0a58bd49b57b4708b3cc6902e98a6789": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ef455204be394f428386150002b457a6": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9c33ff2d359b45a4be14bf448a91490e": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "1b45e060e419436085e719c8a3f50a15": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6aa177607340454db2410533640d4a5f": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "28a09858e10a4174be46969ceb4edb73": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a07a075e6d174e4c8388ad82784f51c9": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "b567b7d6ab3e4fa6ab02f58618d6c757": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_a317963045744493a236cd02e42b4bd3",
       "IPY_MODEL_d7124fc63d0143c9951d0920e7e1f51e",
       "IPY_MODEL_995ed402ca6e43e0877e3db25dcb761d"
      ],
      "layout": "IPY_MODEL_5db8f87fdf2d470bb01f1fdd389c4b64"
     }
    },
    "a317963045744493a236cd02e42b4bd3": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_f0c2c7bebfc847cc954d87b6c06a55a1",
      "placeholder": "​",
      "style": "IPY_MODEL_1737a887e27f43a28e231f462d666a52",
      "value": "tokenizer.json: 100%"
     }
    },
    "d7124fc63d0143c9951d0920e7e1f51e": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_681efcc4b982455a8489b90dcfc90a23",
      "max": 1355863,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_8b5f02b436384b63957a632b4a38f444",
      "value": 1355863
     }
    },
    "995ed402ca6e43e0877e3db25dcb761d": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_103276e04360477a91e11e57c1937e16",
      "placeholder": "​",
      "style": "IPY_MODEL_7989de8b7f764c9ba837a35b5fc434e5",
      "value": " 1.36M/1.36M [00:00&lt;00:00, 5.09MB/s]"
     }
    },
    "5db8f87fdf2d470bb01f1fdd389c4b64": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f0c2c7bebfc847cc954d87b6c06a55a1": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1737a887e27f43a28e231f462d666a52": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "681efcc4b982455a8489b90dcfc90a23": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8b5f02b436384b63957a632b4a38f444": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "103276e04360477a91e11e57c1937e16": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7989de8b7f764c9ba837a35b5fc434e5": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "7fe9bfa31ab0499d9e0ada1b179b4916": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_92ab616b50644c558b0724afd766630d",
       "IPY_MODEL_3b80a6f9eff84e8c899085baed039e2d",
       "IPY_MODEL_2ed2a02c30664e47be4d8330a3afbce2"
      ],
      "layout": "IPY_MODEL_9b31f92ce8fc4466bfb020d328f828c0"
     }
    },
    "92ab616b50644c558b0724afd766630d": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_1d03116f89fa4dc6b3003cdc293a7bfd",
      "placeholder": "​",
      "style": "IPY_MODEL_94c0daefc65849db9d815bacbfa221ef",
      "value": "config.json: 100%"
     }
    },
    "3b80a6f9eff84e8c899085baed039e2d": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_2095686fb94747399a5d01cd633f5c5d",
      "max": 481,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_7c5120cb98ba490a9c9b790021a14026",
      "value": 481
     }
    },
    "2ed2a02c30664e47be4d8330a3afbce2": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_f18b5308424b408aba94f0bc967661ac",
      "placeholder": "​",
      "style": "IPY_MODEL_bc15730aafca4157859e3865ee90cb3d",
      "value": " 481/481 [00:00&lt;00:00, 10.1kB/s]"
     }
    },
    "9b31f92ce8fc4466bfb020d328f828c0": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1d03116f89fa4dc6b3003cdc293a7bfd": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "94c0daefc65849db9d815bacbfa221ef": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "2095686fb94747399a5d01cd633f5c5d": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7c5120cb98ba490a9c9b790021a14026": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "f18b5308424b408aba94f0bc967661ac": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "bc15730aafca4157859e3865ee90cb3d": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "ac6780bc71b242c6b53ff9ca8e228a32": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_f49a1221e60148feb964eba6f2a4737e",
       "IPY_MODEL_ac567991697941a5aa1385f9d4e6552c",
       "IPY_MODEL_fac7cd21745442d9b0f5fadb42bea635"
      ],
      "layout": "IPY_MODEL_eab71b14e49f42c88df0ec05d92e01cc"
     }
    },
    "f49a1221e60148feb964eba6f2a4737e": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_dd9d75d951b0406e9b8bb1cee96e0616",
      "placeholder": "​",
      "style": "IPY_MODEL_5fc4ba0b1ddd4526babd67017be81660",
      "value": "100%"
     }
    },
    "ac567991697941a5aa1385f9d4e6552c": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_26ef033457f444f0aeb23e347aa1ab5a",
      "max": 109,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_72c6ff3ddb2d452eb15d98deed27440e",
      "value": 109
     }
    },
    "fac7cd21745442d9b0f5fadb42bea635": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_bebd41e39fa843ac9661b526a810cdc1",
      "placeholder": "​",
      "style": "IPY_MODEL_265fa4f0b84040fa9ff4a73408c2a02c",
      "value": " 109/109 [00:26&lt;00:00,  4.15it/s]"
     }
    },
    "eab71b14e49f42c88df0ec05d92e01cc": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "dd9d75d951b0406e9b8bb1cee96e0616": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5fc4ba0b1ddd4526babd67017be81660": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "26ef033457f444f0aeb23e347aa1ab5a": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "72c6ff3ddb2d452eb15d98deed27440e": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "bebd41e39fa843ac9661b526a810cdc1": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "265fa4f0b84040fa9ff4a73408c2a02c": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
