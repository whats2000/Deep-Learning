{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MIS 583 Assignment 4: Self-supervised and transfer learning on CIFAR10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we start, please put your name and SID in following format: <br>\n",
    ": LASTNAME Firstname, ?00000000   //   e.g.) 李晨愷 M114020035"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Your Answer:**    \n",
    "Hi I'm 鄔仁迪, B104020009."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IWMWW8Ab_345"
   },
   "source": [
    "## Google Colab Setup\n",
    "Next we need to run a few commands to set up our environment on Google Colab. If you are running this notebook on a local machine you can skip this section.\n",
    "\n",
    "Run the following cell to mount your Google Drive. Follow the link, sign in to your Google account (the same account you used to store this notebook!) and copy the authorization code into the text box that appears below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "vH4wc4iD_6w_",
    "ExecuteTime": {
     "end_time": "2023-11-02T13:57:44.100889100Z",
     "start_time": "2023-11-02T13:57:44.080377500Z"
    }
   },
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "XpNsPHZc_879",
    "ExecuteTime": {
     "end_time": "2023-11-02T14:01:30.105633300Z",
     "start_time": "2023-11-02T14:01:30.092624900Z"
    }
   },
   "outputs": [],
   "source": [
    "# fill in the path in your Google Drive in the string below. Note: do not escape slashes or spaces\n",
    "import os\n",
    "# datadir = \"/content/assignment4\"\n",
    "# if not os.path.exists(datadir):\n",
    "#  !ln -s \"/content/drive/My Drive/Your/A4/path/\" $datadir # TODO: Fill your A3 path\n",
    "# os.chdir(datadir)\n",
    "# !pwd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Um5DJvBwb6xT"
   },
   "source": [
    "# Data Setup (5 points)\n",
    "\n",
    "The first thing to do is implement a dataset class to load rotated CIFAR10 images with matching labels. Since there is already a CIFAR10 dataset class implemented in `torchvision`, we will extend this class and modify the `__get_item__` method appropriately to load rotated images.\n",
    "\n",
    "Each rotation label should be an integer in the set {0, 1, 2, 3} which correspond to rotations of 0, 90, 180, or 270 degrees respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "oHkeNUOKiFbP",
    "ExecuteTime": {
     "end_time": "2023-11-02T14:01:48.438060500Z",
     "start_time": "2023-11-02T14:01:39.589028500Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "\n",
    "def rotate_img(img, rot):\n",
    "    if rot == 0: # 0 degrees rotation\n",
    "        return img\n",
    "    #######################################################################\n",
    "    #        TODO: Implement rotate_img() - return the rotated img        #                           \n",
    "    #######################################################################\n",
    "    angles = {0: 0, 1: 90, 2: 180, 3: 270}\n",
    "    if rot in angles:\n",
    "        return transforms.function.rotate(img, angles[rot])\n",
    "    else:\n",
    "        raise ValueError('rotation should be 0, 90, 180, or 270 degrees')\n",
    "\n",
    "    #######################################################################\n",
    "    #                           End of your code                          #\n",
    "    #######################################################################\n",
    "\n",
    "class CIFAR10Rotation(torchvision.datasets.CIFAR10):\n",
    "\n",
    "    def __init__(self, root, train, download, transform) -> None:\n",
    "        super().__init__(root=root, train=train, download=download, transform=transform)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, index: int):\n",
    "        image, cls_label = super().__getitem__(index)\n",
    "\n",
    "        # randomly select image rotation\n",
    "        rotation_label = random.choice([0, 1, 2, 3])\n",
    "        image_rotated = rotate_img(image, rotation_label)\n",
    "\n",
    "        rotation_label = torch.tensor(rotation_label).long()\n",
    "        return image, image_rotated, rotation_label, torch.tensor(cls_label).long()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "CCBSpNWpb8uw",
    "ExecuteTime": {
     "end_time": "2023-11-02T14:15:51.075671200Z",
     "start_time": "2023-11-02T14:02:19.147706600Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data\\cifar-10-python.tar.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 170498071/170498071 [13:25<00:00, 211580.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data\\cifar-10-python.tar.gz to ./data\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "transform_train = transforms.Compose([\n",
    "    transforms.RandomCrop(32, padding=4),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])\n",
    "\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])\n",
    "\n",
    "batch_size = 128\n",
    "\n",
    "trainset = CIFAR10Rotation(root='./data', train=True,\n",
    "                                        download=True, transform=transform_train)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,\n",
    "                                          shuffle=True, num_workers=2)\n",
    "\n",
    "testset = CIFAR10Rotation(root='./data', train=False,\n",
    "                                       download=True, transform=transform_test)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size,\n",
    "                                         shuffle=False, num_workers=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dOCWMyGhVOJB"
   },
   "source": [
    "Show some example images and rotated images with labels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "A9wN4BJWVMzB"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat',\n",
    "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "\n",
    "rot_classes = ('0', '90', '180', '270')\n",
    "\n",
    "\n",
    "def imshow(img):\n",
    "    # unnormalize\n",
    "    img = transforms.Normalize((0, 0, 0), (1/0.2023, 1/0.1994, 1/0.2010))(img)\n",
    "    img = transforms.Normalize((-0.4914, -0.4822, -0.4465), (1, 1, 1))(img)\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "dataiter = iter(trainloader)\n",
    "images, rot_images, rot_labels, labels = next(dataiter)\n",
    "\n",
    "# print images and rotated images\n",
    "img_grid = imshow(torchvision.utils.make_grid(images[:4], padding=0))\n",
    "print('Class labels: ', ' '.join(f'{classes[labels[j]]:5s}' for j in range(4)))\n",
    "img_grid = imshow(torchvision.utils.make_grid(rot_images[:4], padding=0))\n",
    "print('Rotation labels: ', ' '.join(f'{rot_classes[rot_labels[j]]:5s}' for j in range(4)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "unCucbHexG4W"
   },
   "source": [
    "# Evaluation code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pptQRpqK0rOl"
   },
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def run_test(net, testloader, criterion, task):\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    avg_test_loss = 0.0\n",
    "    # since we're not training, we don't need to calculate the gradients for our outputs\n",
    "    with torch.no_grad():\n",
    "        for images, images_rotated, labels, cls_labels in testloader:\n",
    "            if task == 'rotation':\n",
    "              images, labels = images_rotated.to(device), labels.to(device)\n",
    "            elif task == 'classification':\n",
    "              images, labels = images.to(device), cls_labels.to(device)\n",
    "            #######################################################################\n",
    "            # TODO: Calculate outputs by running images through the network       #\n",
    "            # The class with the highest energy is what we choose as prediction   #\n",
    "            #######################################################################\n",
    "            ...\n",
    "            #######################################################################\n",
    "            #                           End of your code                          #\n",
    "            #######################################################################\n",
    "            avg_test_loss += criterion(outputs, labels)  / len(testloader)\n",
    "    print('TESTING:')\n",
    "    print(f'Accuracy of the network on the 10000 test images: {100 * correct / total:.2f} %')\n",
    "    print(f'Average loss on the 10000 test images: {avg_test_loss:.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hf698c16A9k5"
   },
   "outputs": [],
   "source": [
    "def adjust_learning_rate(optimizer, epoch, init_lr, decay_epochs=30):\n",
    "    \"\"\"Sets the learning rate to the initial LR decayed by 10 every 30 epochs\"\"\"\n",
    "    lr = init_lr * (0.1 ** (epoch // decay_epochs))\n",
    "    for param_group in optimizer.param_groups:\n",
    "        param_group['lr'] = lr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3lYdnb1Wsta_"
   },
   "source": [
    "# Train a ResNet18 on the rotation task (9 points)\n",
    "\n",
    "In this section, we will train a ResNet18 model **from scratch** on the rotation task. The input is a rotated image and the model predicts the rotation label. See the Data Setup section for details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "knAiwdURvBHk"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cpu'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Notice: You should not use pretrained weights from ImageNet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "235MEIUgsv65"
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torchvision.models import resnet18\n",
    "\n",
    "net = resnet18(weights = None, num_classes=4) # Do not modify this line.\n",
    "net = net.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Vuhiw0ZoszAd"
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "################################################################################\n",
    "# TODO: Define loss and optmizer functions                                     #\n",
    "# Try any loss or optimizer function and learning rate to get better result    #\n",
    "# hint: torch.nn and torch.optim                                               #\n",
    "################################################################################\n",
    "criterion = ...\n",
    "optimizer = ...\n",
    "################################################################################\n",
    "#                               End of your code                               #\n",
    "################################################################################\n",
    "criterion = criterion.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WleH-YBgs0rq"
   },
   "outputs": [],
   "source": [
    "# Both the self-supervised rotation task and supervised CIFAR10 classification are\n",
    "# trained with the CrossEntropyLoss, so we can use the training loop code.\n",
    "\n",
    "def train(net, criterion, optimizer, num_epochs, decay_epochs, init_lr, task):\n",
    "\n",
    "    for epoch in range(num_epochs):  # loop over the dataset multiple times\n",
    "\n",
    "        running_loss = 0.0\n",
    "        running_correct = 0.0\n",
    "        running_total = 0.0\n",
    "        start_time = time.time()\n",
    "\n",
    "        net.train()\n",
    "\n",
    "        for i, (imgs, imgs_rotated, rotation_label, cls_label) in enumerate(trainloader, 0):\n",
    "            adjust_learning_rate(optimizer, epoch, init_lr, decay_epochs)\n",
    "            ######################################################################################################\n",
    "            # TODO: Set the data to the correct device; Different task will use different inputs and labels      #  \n",
    "            # TODO: Zero the parameter gradients                                                                 #\n",
    "            # TODO: forward + backward + optimize                                                                #\n",
    "            # TODO: Get predicted results                                                                        #\n",
    "            ######################################################################################################\n",
    "\n",
    "            ######################################################################################################\n",
    "            #                               End of your code                                                     #\n",
    "            ######################################################################################################                                            \n",
    "\n",
    "            \n",
    "            predicted = None\n",
    "\n",
    "            # print statistics\n",
    "            print_freq = 100\n",
    "            running_loss += loss.item()\n",
    "\n",
    "            # calc acc\n",
    "            running_total += labels.size(0)\n",
    "            running_correct += (predicted == labels).sum().item()\n",
    "\n",
    "            if i % print_freq == (print_freq - 1):    # print every 2000 mini-batches\n",
    "                print(f'[{epoch + 1}, {i + 1:5d}] loss: {running_loss / print_freq:.3f} acc: {100*running_correct / running_total:.2f} time: {time.time() - start_time:.2f}')\n",
    "                running_loss, running_correct, running_total = 0.0, 0.0, 0.0\n",
    "                start_time = time.time()\n",
    "        ######################################################################################################\n",
    "        # TODO: Run the run_test() function after each epoch; Set the model to the evaluation mode.          #\n",
    "        ######################################################################################################\n",
    "        ...\n",
    "        ######################################################################################################\n",
    "        #                               End of your code                                                     #\n",
    "        ######################################################################################################  \n",
    "\n",
    "    print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2u4AsfAKtaQS"
   },
   "outputs": [],
   "source": [
    "train(net, criterion, optimizer, num_epochs=45, decay_epochs=15, init_lr=0.01, task='rotation')\n",
    "################################\n",
    "#     TODO: Save the model     #  \n",
    "################################\n",
    "...\n",
    "################################\n",
    "#      End of your code        #  \n",
    "################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PLLMRTS9rTnk"
   },
   "source": [
    "## Fine-tuning on the pre-trained model (9 points)\n",
    "\n",
    "In this section, we will load the ResNet18 model pre-trained on the rotation task and fine-tune on the classification task. We will freeze all previous layers except for the 'layer4' block and 'fc' layer.\n",
    "\n",
    "**Then we will use the trained model from rotation task as the pretrained weights. Notice, you should not use the pretrained weights from ImageNet.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "S4nX4ExlrymI"
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torchvision.models import resnet18\n",
    "\n",
    "#####################################################\n",
    "#     TODO: Load the pre-trained ResNet18 model     #  \n",
    "#####################################################\n",
    "\n",
    "####################################################\n",
    "#                End of your code                  #   \n",
    "####################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kD44g-TxwYdU"
   },
   "outputs": [],
   "source": [
    "#################################################################################################\n",
    "#   TODO: Freeze all previous layers; only keep the 'layer4' block and 'fc' layer trainable     #\n",
    "#################################################################################################\n",
    "\n",
    "#################################################################################################\n",
    "#                                          End of your code                                     #\n",
    "#################################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9T5DX0efr4fh"
   },
   "outputs": [],
   "source": [
    "# Print all the trainable parameters\n",
    "params_to_update = net.parameters()\n",
    "print(\"Params to learn:\")\n",
    "params_to_update = []\n",
    "for name,param in net.named_parameters():\n",
    "    if param.requires_grad == True:\n",
    "        params_to_update.append(param)\n",
    "        print(\"\\t\",name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xb032dG700ph"
   },
   "outputs": [],
   "source": [
    "# TODO: Define criterion and optimizer\n",
    "# Note that your optimizer only needs to update the parameters that are trainable.\n",
    "criterion = None\n",
    "optimizer = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3vLSwOo6sBjl"
   },
   "outputs": [],
   "source": [
    "train(net, criterion, optimizer, num_epochs=20, decay_epochs=10, init_lr=0.01, task='classification')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ghPNhcJBrcNj"
   },
   "source": [
    "## Fine-tuning on the randomly initialized model (9 points)\n",
    "In this section, we will randomly initialize a ResNet18 model and fine-tune on the classification task. We will freeze all previous layers except for the 'layer4' block and 'fc' layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2RfXAh9vxXRB"
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torchvision.models import resnet18\n",
    "#################################################\n",
    "# TODO: Randomly initialize a ResNet18 model    #\n",
    "#################################################\n",
    "\n",
    "#################################################\n",
    "#              End of your code                 #\n",
    "#################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fpx-SYAizt4p"
   },
   "outputs": [],
   "source": [
    "#################################################################################################\n",
    "# TODO: Freeze all previous layers; only keep the 'layer4' block and 'fc' layer trainable       #\n",
    "# To do this, you should set requires_grad=False for the frozen layers.                         #\n",
    "#################################################################################################\n",
    "\n",
    "#################################################################################################\n",
    "#                                          End of your code                                     #\n",
    "#################################################################################################\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BUFWizbHxgm2"
   },
   "outputs": [],
   "source": [
    "# Print all the trainable parameters\n",
    "params_to_update = net.parameters()\n",
    "print(\"Params to learn:\")\n",
    "params_to_update = []\n",
    "for name,param in net.named_parameters():\n",
    "    if param.requires_grad == True:\n",
    "        params_to_update.append(param)\n",
    "        print(\"\\t\",name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BxFrGj091AN_"
   },
   "outputs": [],
   "source": [
    "# TODO: Define criterion and optimizer\n",
    "# Note that your optimizer only needs to update the parameters that are trainable.\n",
    "criterion = None\n",
    "optimizer = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GzRVy0MZxpoL"
   },
   "outputs": [],
   "source": [
    "train(net, criterion, optimizer, num_epochs=20, decay_epochs=10, init_lr=0.01, task='classification')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WcN54tcNN15U"
   },
   "source": [
    "## Supervised training on the pre-trained model (9 points)\n",
    "In this section, we will load the ResNet18 model pre-trained on the rotation task and re-train the whole model on the classification task.\n",
    "\n",
    "**Then we will use the trained model from rotation task as the pretrained weights. Notice, you should not use the pretrained weights from ImageNet.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9xR9h_S1N6Xi"
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torchvision.models import resnet18\n",
    "\n",
    "#####################################################\n",
    "#     TODO: Load the pre-trained ResNet18 model     #  \n",
    "#####################################################\n",
    "\n",
    "#####################################################\n",
    "#                End of your code                   #   \n",
    "#####################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gGozc2cM0ADw"
   },
   "outputs": [],
   "source": [
    "# TODO: Define criterion and optimizer\n",
    "criterion = None\n",
    "optimizer = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JGWW7gzCz_Bu"
   },
   "outputs": [],
   "source": [
    "train(net, criterion, optimizer, num_epochs=20, decay_epochs=10, init_lr=0.01, task='classification')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xjVTp9jhefTi"
   },
   "source": [
    "## Supervised training on the randomly initialized model (9 points)\n",
    "In this section, we will randomly initialize a ResNet18 model and re-train the whole model on the classification task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uEjy8TBieeLK"
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torchvision.models import resnet18\n",
    "\n",
    "#################################################\n",
    "# TODO: Randomly initialize a ResNet18 model    #\n",
    "#################################################\n",
    "...\n",
    "#################################################\n",
    "#              End of your code                 #\n",
    "#################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jEY90pK_0ZAm"
   },
   "outputs": [],
   "source": [
    "# TODO: Define criterion and optimizer\n",
    "criterion = None\n",
    "optimizer = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lMDwelhY0auO"
   },
   "outputs": [],
   "source": [
    "train(net, criterion, optimizer, num_epochs=20, decay_epochs=10, init_lr=0.01, task='classification')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Write report (37 points)\n",
    "\n",
    "本次作業主要有3個tasks需要大家完成，在A4.pdf中有希望大家達成的baseline **(不能低於baseline最多2%，沒有達到不會給全部分數)**，report的撰寫就希望大家可以透過去調整不同的訓練方法、損失函數、優化器，或者是調整凍結不同的層來進行這次的實驗，就請大家將嘗試的結果寫在report裡，祝大家順利！\n",
    "\n",
    "- Rotation task (13 points)\n",
    "- Fine-tuning the specified layers of the pre-trained model (12 points)\n",
    "- Fine-tuning the whole pre-trained model (12 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extra Credit (13 points)\n",
    "\n",
    "上面基本的code跟report最高可以拿到87分，這個加分部分並沒有要求同學們一定要做，若同學們想要獲得更高的分數可以根據以下的加分要求來獲得加分。\n",
    "\n",
    "- In Figure 5(b) from the Gidaris et al. paper, the authors show a plot of CIFAR10 classification performance vs. number of training examples per category for a supervised CIFAR10 model vs. a RotNet model with the final layers fine-tuned on CIFAR10. The plot shows that pre-training on the Rotation task can be advantageous when only a small amount of labeled data is available. Using your RotNet fine-tuning code and supervised CIFAR10 training code from the main assignment, try to create a similar plot by performing supervised fine-tuning/training on only a subset of CIFAR10.\n",
    "- Use a more advanced model than ResNet18 to try to get higher accuracy on the rotation prediction task, as well as for transfer to supervised CIFAR10 classification.\n",
    "  \n",
    "- If you have a good amount of compute at your disposal, try to train a rotation prediction model on the larger ImageNette dataset (still smaller than ImageNet, though).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": [
    {
     "file_id": "1qQ3NEaCUln7yDSksrEOnDwrt3u9dYNr4",
     "timestamp": 1677623843954
    }
   ]
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3.8.13",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "aaa478f9632825e83f6a2247407c7a2930de96a6810af7910643e423346524f9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
