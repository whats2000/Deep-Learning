{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MIS 583 Assignment 4: Self-supervised and transfer learning on CIFAR10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we start, please put your name and SID in following format: <br>\n",
    ": LASTNAME Firstname, ?00000000   //   e.g.) 李晨愷 M114020035"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Your Answer:**    \n",
    "Hi I'm 鄔仁迪, B104020009."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "data": {
      "text/plain": "Empty DataFrame\nColumns: [Experiment Type, Epoch, Train Accuracy, Train Loss, Valid Accuracy, Valid Loss]\nIndex: []",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Experiment Type</th>\n      <th>Epoch</th>\n      <th>Train Accuracy</th>\n      <th>Train Loss</th>\n      <th>Valid Accuracy</th>\n      <th>Valid Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "experience_name = 'self_supervised_direction_6'\n",
    "label_smoothing = 0.1\n",
    "rotation_direction = 6\n",
    "\n",
    "# Define columns for the DataFrame\n",
    "columns = ['Experiment Type', 'Epoch', 'Train Accuracy', 'Train Loss', 'Valid Accuracy', 'Valid Loss']\n",
    "\n",
    "# Initialize an empty DataFrame with these columns\n",
    "experience_report = pd.DataFrame(columns=columns)\n",
    "\n",
    "experience_report"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-05T06:15:07.975742600Z",
     "start_time": "2023-11-05T06:15:07.072615300Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "# Function to set the seed\n",
    "def set_seed(seed_value=42):\n",
    "    \"\"\"Set seed for reproducibility.\"\"\"\n",
    "    torch.manual_seed(seed_value)\n",
    "    torch.cuda.manual_seed(seed_value)\n",
    "    torch.cuda.manual_seed_all(seed_value)  # if you are using multi-GPU.\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    np.random.seed(seed_value)\n",
    "    random.seed(seed_value)\n",
    "\n",
    "set_seed()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-05T06:15:07.976741800Z",
     "start_time": "2023-11-05T06:15:07.081010300Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IWMWW8Ab_345"
   },
   "source": [
    "## Google Colab Setup\n",
    "Next we need to run a few commands to set up our environment on Google Colab. If you are running this notebook on a local machine you can skip this section.\n",
    "\n",
    "Run the following cell to mount your Google Drive. Follow the link, sign in to your Google account (the same account you used to store this notebook!) and copy the authorization code into the text box that appears below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "vH4wc4iD_6w_",
    "ExecuteTime": {
     "end_time": "2023-11-05T06:15:08.065742Z",
     "start_time": "2023-11-05T06:15:07.099459500Z"
    }
   },
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "XpNsPHZc_879",
    "ExecuteTime": {
     "end_time": "2023-11-05T06:15:08.103740400Z",
     "start_time": "2023-11-05T06:15:07.110024400Z"
    }
   },
   "outputs": [],
   "source": [
    "# fill in the path in your Google Drive in the string below. Note: do not escape slashes or spaces\n",
    "# import os\n",
    "# datadir = \"C:/Users/eddie/GitHub/Deep-Learning/PyTorch/Class/pytorch104\"\n",
    "# if not os.path.exists(datadir):\n",
    "#  !ln -s \"/content/drive/My Drive/Your/A4/path/\" $datadir # TODO: Fill your A3 path\n",
    "# os.chdir(datadir)\n",
    "# !pwd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Um5DJvBwb6xT"
   },
   "source": [
    "# Data Setup (5 points)\n",
    "\n",
    "The first thing to do is implement a dataset class to load rotated CIFAR10 images with matching labels. Since there is already a CIFAR10 dataset class implemented in `torchvision`, we will extend this class and modify the `__get_item__` method appropriately to load rotated images.\n",
    "\n",
    "Each rotation label should be an integer in the set {0, 1, 2, 3} which correspond to rotations of 0, 90, 180, or 270 degrees respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "oHkeNUOKiFbP",
    "ExecuteTime": {
     "end_time": "2023-11-05T06:15:08.104740600Z",
     "start_time": "2023-11-05T06:15:07.127044900Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "\n",
    "def rotate_img(img, rot):\n",
    "    \"\"\"\n",
    "    Rotates the image by a specified angle.\n",
    "\n",
    "    Parameters:\n",
    "    - img (PIL Image or Tensor): The image to be rotated.\n",
    "    - rot (int): The rotation label indicating the angle of rotation. Should be in the range [0, rotation_direction-1].\n",
    "\n",
    "    Returns:\n",
    "    - PIL Image or Tensor: The rotated image.\n",
    "    \"\"\"\n",
    "    angle = (360 / rotation_direction) * rot  # Calculate the rotation angle based on the label and the total directions\n",
    "\n",
    "    if not (0 <= rot < rotation_direction):\n",
    "        raise ValueError(f'rotation should be an integer in range [0, {rotation_direction - 1}]')\n",
    "\n",
    "    # Perform the rotation\n",
    "    return transforms.functional.rotate(img, angle)\n",
    "\n",
    "class CIFAR10Rotation(torchvision.datasets.CIFAR10):\n",
    "\n",
    "    def __init__(self, root, train, download, transform) -> None:\n",
    "        super().__init__(root=root, train=train, download=download, transform=transform)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, index: int):\n",
    "        image, cls_label = super().__getitem__(index)\n",
    "\n",
    "        # Randomly select image rotation based on the number of directions\n",
    "        rotation_label = random.randrange(rotation_direction)\n",
    "        image_rotated = rotate_img(image, rotation_label)\n",
    "\n",
    "        rotation_label = torch.tensor(rotation_label).long()\n",
    "        return image, image_rotated, rotation_label, torch.tensor(cls_label).long()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "CCBSpNWpb8uw",
    "ExecuteTime": {
     "end_time": "2023-11-05T06:15:09.631601600Z",
     "start_time": "2023-11-05T06:15:07.143025400Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "transform_train = transforms.Compose([\n",
    "    transforms.RandomCrop(32, padding=4),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])\n",
    "\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])\n",
    "\n",
    "batch_size = 128\n",
    "\n",
    "trainset = CIFAR10Rotation(root='../data', train=True,\n",
    "                                        download=True, transform=transform_train)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,\n",
    "                                          shuffle=True, num_workers=0)\n",
    "\n",
    "testset = CIFAR10Rotation(root='../data', train=False,\n",
    "                                       download=True, transform=transform_test)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size,\n",
    "                                         shuffle=False, num_workers=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dOCWMyGhVOJB"
   },
   "source": [
    "Show some example images and rotated images with labels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "A9wN4BJWVMzB",
    "ExecuteTime": {
     "end_time": "2023-11-05T06:15:10.202609400Z",
     "start_time": "2023-11-05T06:15:08.949107Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "data": {
      "text/plain": "<Figure size 640x480 with 1 Axes>",
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class labels:  frog  plane deer  car  \n"
     ]
    },
    {
     "data": {
      "text/plain": "<Figure size 640x480 with 1 Axes>",
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rotation labels:  300   0     0     300  \n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat',\n",
    "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "\n",
    "# Calculate the step size based on 360 degrees and the number of directions\n",
    "step_size = 360 // rotation_direction\n",
    "\n",
    "# Generate the rotation classes based on the number of directions\n",
    "rot_classes = tuple(str(i * step_size) for i in range(rotation_direction))\n",
    "\n",
    "\n",
    "def imshow(img):\n",
    "    # unnormalize\n",
    "    img = transforms.Normalize((0, 0, 0), (1/0.2023, 1/0.1994, 1/0.2010))(img)\n",
    "    img = transforms.Normalize((-0.4914, -0.4822, -0.4465), (1, 1, 1))(img)\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "dataiter = iter(trainloader)\n",
    "images, rot_images, rot_labels, labels = next(dataiter)\n",
    "\n",
    "# print images and rotated images\n",
    "img_grid = imshow(torchvision.utils.make_grid(images[:4], padding=0))\n",
    "print('Class labels: ', ' '.join(f'{classes[labels[j]]:5s}' for j in range(4)))\n",
    "img_grid = imshow(torchvision.utils.make_grid(rot_images[:4], padding=0))\n",
    "print('Rotation labels: ', ' '.join(f'{rot_classes[rot_labels[j]]:5s}' for j in range(4)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "unCucbHexG4W"
   },
   "source": [
    "# Evaluation code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "pptQRpqK0rOl",
    "ExecuteTime": {
     "end_time": "2023-11-05T06:15:10.292601900Z",
     "start_time": "2023-11-05T06:15:09.290669300Z"
    }
   },
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def run_test(net, testloader, criterion, task):\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    avg_test_loss = 0.0\n",
    "    # since we're not training, we don't need to calculate the gradients for our outputs\n",
    "    with torch.no_grad():\n",
    "        for images, images_rotated, labels, cls_labels in testloader:\n",
    "            if task == 'rotation':\n",
    "              images, labels = images_rotated.to(device), labels.to(device)\n",
    "            elif task == 'classification':\n",
    "              images, labels = images.to(device), cls_labels.to(device)\n",
    "            #######################################################################\n",
    "            # TODO: Calculate outputs by running images through the network       #\n",
    "            # The class with the highest energy is what we choose as prediction   #\n",
    "            #######################################################################\n",
    "            # Calculate outputs by running images through the network\n",
    "            outputs = net(images)\n",
    "\n",
    "            # The class with the highest score is what we choose as our prediction\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            #######################################################################\n",
    "            #                           End of your code                          #\n",
    "            #######################################################################\n",
    "            avg_test_loss += criterion(outputs, labels)  / len(testloader)\n",
    "    print('TESTING:')\n",
    "    print(f'Accuracy of the network on the 10000 test images: {100 * correct / total:.2f} %')\n",
    "    print(f'Average loss on the 10000 test images: {avg_test_loss:.3f}')\n",
    "\n",
    "    return avg_test_loss, 100 * correct / total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "hf698c16A9k5",
    "ExecuteTime": {
     "end_time": "2023-11-05T06:15:10.293608800Z",
     "start_time": "2023-11-05T06:15:09.299548100Z"
    }
   },
   "outputs": [],
   "source": [
    "def adjust_learning_rate(optimizer, epoch, init_lr, decay_epochs=30):\n",
    "    \"\"\"Sets the learning rate to the initial LR decayed by 10 every 30 epochs\"\"\"\n",
    "    lr = init_lr * (0.1 ** (epoch // decay_epochs))\n",
    "    for param_group in optimizer.param_groups:\n",
    "        param_group['lr'] = lr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3lYdnb1Wsta_"
   },
   "source": [
    "# Train a ResNet18 on the rotation task (9 points)\n",
    "\n",
    "In this section, we will train a ResNet18 model **from scratch** on the rotation task. The input is a rotated image and the model predicts the rotation label. See the Data Setup section for details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "knAiwdURvBHk",
    "ExecuteTime": {
     "end_time": "2023-11-05T06:15:10.333601400Z",
     "start_time": "2023-11-05T06:15:09.314990300Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "'cuda'"
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Notice: You should not use pretrained weights from ImageNet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "235MEIUgsv65",
    "ExecuteTime": {
     "end_time": "2023-11-05T06:15:10.417600800Z",
     "start_time": "2023-11-05T06:15:09.335087500Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torchvision.models import resnet18\n",
    "\n",
    "net = resnet18(weights = None, num_classes=rotation_direction) # Do not modify this line.\n",
    "net = net.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "Vuhiw0ZoszAd",
    "ExecuteTime": {
     "end_time": "2023-11-05T06:15:10.417600800Z",
     "start_time": "2023-11-05T06:15:09.549088100Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "################################################################################\n",
    "# TODO: Define loss and optmizer functions                                     #\n",
    "# Try any loss or optimizer function and learning rate to get better result    #\n",
    "# hint: torch.nn and torch.optim                                               #\n",
    "################################################################################\n",
    "# Loss and optimizer\n",
    "criterion = nn.CrossEntropyLoss(label_smoothing=label_smoothing)\n",
    "learning_rate = 0.001\n",
    "optimizer = optim.Adam(net.parameters(), lr=learning_rate)\n",
    "################################################################################\n",
    "#                               End of your code                               #\n",
    "################################################################################\n",
    "criterion = criterion.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "WleH-YBgs0rq",
    "ExecuteTime": {
     "end_time": "2023-11-05T06:15:10.418604Z",
     "start_time": "2023-11-05T06:15:09.559907800Z"
    }
   },
   "outputs": [],
   "source": [
    "# Both the self-supervised rotation task and supervised CIFAR10 classification are\n",
    "# trained with the CrossEntropyLoss, so we can use the training loop code.\n",
    "\n",
    "def train(net, criterion, optimizer, num_epochs, decay_epochs, init_lr, task, experiment_type=None):\n",
    "    global experience_report\n",
    "    best_valid_acc = 0.0  # Initialize best validation accuracy\n",
    "    best_model_state = None  # Initialize best model state\n",
    "\n",
    "    for epoch in range(num_epochs):  # loop over the dataset multiple times\n",
    "        # Initialize epoch variables\n",
    "        total_loss = 0.0\n",
    "        total_correct = 0.0\n",
    "        total_samples = 0.0\n",
    "\n",
    "        running_loss = 0.0\n",
    "        running_correct = 0.0\n",
    "        running_total = 0.0\n",
    "        start_time = time.time()\n",
    "\n",
    "        net.train()\n",
    "\n",
    "        for i, (imgs, imgs_rotated, rotation_label, cls_label) in enumerate(trainloader, 0):\n",
    "            adjust_learning_rate(optimizer, epoch, init_lr, decay_epochs)\n",
    "            ######################################################################################################\n",
    "            # TODO: Set the data to the correct device; Different task will use different inputs and labels      #  \n",
    "            # TODO: Zero the parameter gradients                                                                 #\n",
    "            # TODO: forward + backward + optimize                                                                #\n",
    "            # TODO: Get predicted results                                                                        #\n",
    "            ######################################################################################################\n",
    "            # Set data to the correct device\n",
    "            if task == 'rotation':\n",
    "                inputs, labels = imgs_rotated.to(device), rotation_label.to(device)\n",
    "            elif task == 'classification':\n",
    "                inputs, labels = imgs.to(device), cls_label.to(device)\n",
    "\n",
    "            optimizer.zero_grad()  # Zero the parameter gradients\n",
    "\n",
    "            # Forward + backward + optimize\n",
    "            outputs = net(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # Get predicted results for accuracy calculation\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            ######################################################################################################\n",
    "            #                               End of your code                                                     #\n",
    "            ######################################################################################################\n",
    "\n",
    "            # print statistics\n",
    "            print_freq = 100\n",
    "            running_loss += loss.item()\n",
    "\n",
    "            # calc acc\n",
    "            running_total += labels.size(0)\n",
    "            running_correct += (predicted == labels).sum().item()\n",
    "\n",
    "            # Update total counts for epoch averages\n",
    "            total_loss += loss.item()\n",
    "            total_samples += labels.size(0)\n",
    "            total_correct += (predicted == labels).sum().item()\n",
    "\n",
    "            if i % print_freq == (print_freq - 1):    # print every 2000 mini-batches\n",
    "                print(f'[{epoch + 1}, {i + 1:5d}] loss: {running_loss / print_freq:.3f} acc: {100*running_correct / running_total:.2f} time: {time.time() - start_time:.2f}')\n",
    "                running_loss, running_correct, running_total = 0.0, 0.0, 0.0\n",
    "                start_time = time.time()\n",
    "        ######################################################################################################\n",
    "        # TODO: Run the run_test() function after each epoch; Set the model to the evaluation mode.          #\n",
    "        ######################################################################################################\n",
    "        # Calculate average training loss and accuracy for the epoch\n",
    "        avg_train_loss = total_loss / len(trainloader)\n",
    "        avg_train_acc = 100 * total_correct / total_samples\n",
    "\n",
    "        # Evaluate the model after each epoch\n",
    "        net.eval()\n",
    "        test_loss, test_acc = run_test(net, testloader, criterion, task)\n",
    "\n",
    "        # Check if this is the best model so far\n",
    "        if test_acc > best_valid_acc:\n",
    "            best_valid_acc = test_acc\n",
    "            best_model_state = net.state_dict()  # Save the best model state\n",
    "\n",
    "        # Append the epoch's results to the report DataFrame\n",
    "        if experience_report is not None and experiment_type is not None:\n",
    "            new_row = pd.DataFrame({\n",
    "                'Experiment Type': [experiment_type],\n",
    "                'Epoch': [epoch + 1],\n",
    "                'Train Accuracy': [avg_train_acc.cpu().numpy()] if torch.is_tensor(avg_train_acc) else [avg_train_acc],\n",
    "                'Train Loss': [avg_train_loss.cpu().numpy()] if torch.is_tensor(avg_train_loss) else [avg_train_loss],\n",
    "                'Valid Accuracy': [test_acc.cpu().numpy()] if torch.is_tensor(test_acc) else [test_acc],\n",
    "                'Valid Loss': [test_loss.cpu().numpy()] if torch.is_tensor(test_loss) else [test_loss]\n",
    "            })\n",
    "            experience_report = pd.concat([experience_report, new_row], ignore_index=True)\n",
    "        ######################################################################################################\n",
    "        #                               End of your code                                                     #\n",
    "        ######################################################################################################\n",
    "    # Restore the best model state\n",
    "    if best_model_state:\n",
    "        net.load_state_dict(best_model_state)\n",
    "        print(f'Restored best model from epoch with validation accuracy: {best_valid_acc:.2f}%')\n",
    "\n",
    "    # Save the report DataFrame after the experiment\n",
    "    if experience_report is not None and experiment_type is not None:\n",
    "        experience_report.to_csv(f'{experience_name}.csv', index=False)\n",
    "\n",
    "    print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "2u4AsfAKtaQS",
    "ExecuteTime": {
     "end_time": "2023-11-05T06:46:33.386038800Z",
     "start_time": "2023-11-05T06:15:09.613602400Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,   100] loss: 1.291 acc: 50.26 time: 14.18\n",
      "[1,   200] loss: 0.994 acc: 62.08 time: 8.69\n",
      "[1,   300] loss: 0.955 acc: 63.60 time: 10.73\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 68.49 %\n",
      "Average loss on the 10000 test images: 0.905\n",
      "[2,   100] loss: 0.911 acc: 66.89 time: 10.81\n",
      "[2,   200] loss: 0.895 acc: 68.33 time: 11.40\n",
      "[2,   300] loss: 0.885 acc: 68.97 time: 9.45\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 68.52 %\n",
      "Average loss on the 10000 test images: 0.932\n",
      "[3,   100] loss: 0.876 acc: 69.74 time: 8.56\n",
      "[3,   200] loss: 0.867 acc: 70.52 time: 8.31\n",
      "[3,   300] loss: 0.862 acc: 70.68 time: 8.57\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 71.22 %\n",
      "Average loss on the 10000 test images: 0.869\n",
      "[4,   100] loss: 0.851 acc: 71.43 time: 8.31\n",
      "[4,   200] loss: 0.852 acc: 71.63 time: 8.11\n",
      "[4,   300] loss: 0.844 acc: 72.46 time: 8.29\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 72.61 %\n",
      "Average loss on the 10000 test images: 0.857\n",
      "[5,   100] loss: 0.840 acc: 72.70 time: 8.69\n",
      "[5,   200] loss: 0.835 acc: 73.09 time: 8.71\n",
      "[5,   300] loss: 0.832 acc: 73.27 time: 8.26\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 72.35 %\n",
      "Average loss on the 10000 test images: 0.850\n",
      "[6,   100] loss: 0.830 acc: 72.88 time: 8.48\n",
      "[6,   200] loss: 0.822 acc: 74.29 time: 8.67\n",
      "[6,   300] loss: 0.829 acc: 73.92 time: 8.75\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 75.40 %\n",
      "Average loss on the 10000 test images: 0.818\n",
      "[7,   100] loss: 0.816 acc: 74.30 time: 8.15\n",
      "[7,   200] loss: 0.822 acc: 74.02 time: 8.60\n",
      "[7,   300] loss: 0.820 acc: 74.22 time: 8.05\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 73.79 %\n",
      "Average loss on the 10000 test images: 0.833\n",
      "[8,   100] loss: 0.812 acc: 75.13 time: 8.36\n",
      "[8,   200] loss: 0.810 acc: 74.99 time: 8.00\n",
      "[8,   300] loss: 0.803 acc: 75.66 time: 8.04\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 75.15 %\n",
      "Average loss on the 10000 test images: 0.829\n",
      "[9,   100] loss: 0.801 acc: 76.10 time: 8.35\n",
      "[9,   200] loss: 0.799 acc: 76.35 time: 8.25\n",
      "[9,   300] loss: 0.804 acc: 75.68 time: 8.34\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 76.25 %\n",
      "Average loss on the 10000 test images: 0.813\n",
      "[10,   100] loss: 0.798 acc: 76.27 time: 7.94\n",
      "[10,   200] loss: 0.793 acc: 76.59 time: 8.24\n",
      "[10,   300] loss: 0.798 acc: 76.19 time: 9.11\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 77.48 %\n",
      "Average loss on the 10000 test images: 0.789\n",
      "[11,   100] loss: 0.791 acc: 77.09 time: 7.75\n",
      "[11,   200] loss: 0.788 acc: 77.59 time: 8.26\n",
      "[11,   300] loss: 0.791 acc: 76.90 time: 8.95\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 78.16 %\n",
      "Average loss on the 10000 test images: 0.784\n",
      "[12,   100] loss: 0.787 acc: 77.17 time: 8.92\n",
      "[12,   200] loss: 0.781 acc: 77.80 time: 8.78\n",
      "[12,   300] loss: 0.781 acc: 77.50 time: 8.67\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 78.54 %\n",
      "Average loss on the 10000 test images: 0.784\n",
      "[13,   100] loss: 0.778 acc: 77.96 time: 8.84\n",
      "[13,   200] loss: 0.780 acc: 77.74 time: 8.92\n",
      "[13,   300] loss: 0.774 acc: 78.16 time: 9.49\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 79.01 %\n",
      "Average loss on the 10000 test images: 0.776\n",
      "[14,   100] loss: 0.772 acc: 78.78 time: 8.00\n",
      "[14,   200] loss: 0.771 acc: 78.47 time: 7.88\n",
      "[14,   300] loss: 0.779 acc: 78.13 time: 8.41\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 79.39 %\n",
      "Average loss on the 10000 test images: 0.761\n",
      "[15,   100] loss: 0.775 acc: 78.10 time: 7.81\n",
      "[15,   200] loss: 0.762 acc: 79.13 time: 8.17\n",
      "[15,   300] loss: 0.765 acc: 78.66 time: 8.96\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 79.15 %\n",
      "Average loss on the 10000 test images: 0.765\n",
      "[16,   100] loss: 0.754 acc: 79.85 time: 8.05\n",
      "[16,   200] loss: 0.735 acc: 81.12 time: 8.60\n",
      "[16,   300] loss: 0.734 acc: 81.12 time: 8.06\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 81.89 %\n",
      "Average loss on the 10000 test images: 0.732\n",
      "[17,   100] loss: 0.731 acc: 81.72 time: 8.50\n",
      "[17,   200] loss: 0.729 acc: 81.47 time: 8.38\n",
      "[17,   300] loss: 0.722 acc: 81.93 time: 9.16\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 82.38 %\n",
      "Average loss on the 10000 test images: 0.724\n",
      "[18,   100] loss: 0.723 acc: 81.70 time: 8.15\n",
      "[18,   200] loss: 0.724 acc: 81.98 time: 9.06\n",
      "[18,   300] loss: 0.719 acc: 82.13 time: 9.23\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 82.31 %\n",
      "Average loss on the 10000 test images: 0.719\n",
      "[19,   100] loss: 0.723 acc: 81.91 time: 7.71\n",
      "[19,   200] loss: 0.717 acc: 82.34 time: 8.25\n",
      "[19,   300] loss: 0.715 acc: 82.69 time: 7.88\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 82.48 %\n",
      "Average loss on the 10000 test images: 0.721\n",
      "[20,   100] loss: 0.722 acc: 82.27 time: 8.40\n",
      "[20,   200] loss: 0.715 acc: 82.45 time: 8.79\n",
      "[20,   300] loss: 0.717 acc: 82.36 time: 8.96\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 82.25 %\n",
      "Average loss on the 10000 test images: 0.720\n",
      "[21,   100] loss: 0.717 acc: 82.58 time: 8.52\n",
      "[21,   200] loss: 0.715 acc: 82.78 time: 8.15\n",
      "[21,   300] loss: 0.709 acc: 82.86 time: 8.61\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 83.11 %\n",
      "Average loss on the 10000 test images: 0.711\n",
      "[22,   100] loss: 0.714 acc: 82.39 time: 8.25\n",
      "[22,   200] loss: 0.710 acc: 82.80 time: 8.51\n",
      "[22,   300] loss: 0.710 acc: 83.08 time: 8.50\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 83.35 %\n",
      "Average loss on the 10000 test images: 0.708\n",
      "[23,   100] loss: 0.711 acc: 82.60 time: 8.06\n",
      "[23,   200] loss: 0.706 acc: 82.88 time: 9.13\n",
      "[23,   300] loss: 0.710 acc: 83.06 time: 9.44\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 83.14 %\n",
      "Average loss on the 10000 test images: 0.711\n",
      "[24,   100] loss: 0.710 acc: 82.72 time: 8.33\n",
      "[24,   200] loss: 0.706 acc: 82.96 time: 8.06\n",
      "[24,   300] loss: 0.706 acc: 82.92 time: 9.30\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 83.58 %\n",
      "Average loss on the 10000 test images: 0.705\n",
      "[25,   100] loss: 0.702 acc: 83.22 time: 8.19\n",
      "[25,   200] loss: 0.706 acc: 83.02 time: 8.26\n",
      "[25,   300] loss: 0.703 acc: 83.11 time: 8.52\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 83.90 %\n",
      "Average loss on the 10000 test images: 0.703\n",
      "[26,   100] loss: 0.706 acc: 83.07 time: 7.92\n",
      "[26,   200] loss: 0.701 acc: 83.31 time: 7.93\n",
      "[26,   300] loss: 0.702 acc: 83.83 time: 8.53\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 83.35 %\n",
      "Average loss on the 10000 test images: 0.702\n",
      "[27,   100] loss: 0.702 acc: 83.44 time: 8.38\n",
      "[27,   200] loss: 0.702 acc: 83.38 time: 8.82\n",
      "[27,   300] loss: 0.701 acc: 83.57 time: 8.47\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 83.67 %\n",
      "Average loss on the 10000 test images: 0.698\n",
      "[28,   100] loss: 0.697 acc: 83.61 time: 8.64\n",
      "[28,   200] loss: 0.704 acc: 83.18 time: 9.01\n",
      "[28,   300] loss: 0.700 acc: 83.33 time: 8.59\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 84.10 %\n",
      "Average loss on the 10000 test images: 0.698\n",
      "[29,   100] loss: 0.694 acc: 83.93 time: 8.50\n",
      "[29,   200] loss: 0.704 acc: 83.49 time: 8.34\n",
      "[29,   300] loss: 0.696 acc: 83.76 time: 9.10\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 83.93 %\n",
      "Average loss on the 10000 test images: 0.698\n",
      "[30,   100] loss: 0.698 acc: 83.81 time: 8.26\n",
      "[30,   200] loss: 0.694 acc: 84.07 time: 8.38\n",
      "[30,   300] loss: 0.696 acc: 83.68 time: 8.36\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 83.93 %\n",
      "Average loss on the 10000 test images: 0.694\n",
      "[31,   100] loss: 0.691 acc: 84.23 time: 8.77\n",
      "[31,   200] loss: 0.692 acc: 84.03 time: 7.87\n",
      "[31,   300] loss: 0.695 acc: 83.76 time: 8.66\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 84.04 %\n",
      "Average loss on the 10000 test images: 0.694\n",
      "[32,   100] loss: 0.693 acc: 83.96 time: 8.12\n",
      "[32,   200] loss: 0.694 acc: 84.11 time: 8.26\n",
      "[32,   300] loss: 0.689 acc: 84.56 time: 8.32\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 84.18 %\n",
      "Average loss on the 10000 test images: 0.689\n",
      "[33,   100] loss: 0.684 acc: 84.85 time: 8.24\n",
      "[33,   200] loss: 0.689 acc: 84.36 time: 8.51\n",
      "[33,   300] loss: 0.692 acc: 84.03 time: 8.65\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 84.42 %\n",
      "Average loss on the 10000 test images: 0.691\n",
      "[34,   100] loss: 0.689 acc: 84.47 time: 8.57\n",
      "[34,   200] loss: 0.686 acc: 84.23 time: 8.81\n",
      "[34,   300] loss: 0.688 acc: 84.24 time: 8.78\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 84.05 %\n",
      "Average loss on the 10000 test images: 0.692\n",
      "[35,   100] loss: 0.692 acc: 83.95 time: 8.18\n",
      "[35,   200] loss: 0.688 acc: 84.44 time: 8.39\n",
      "[35,   300] loss: 0.687 acc: 84.49 time: 8.17\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 84.52 %\n",
      "Average loss on the 10000 test images: 0.685\n",
      "[36,   100] loss: 0.690 acc: 84.27 time: 8.20\n",
      "[36,   200] loss: 0.691 acc: 84.12 time: 9.06\n",
      "[36,   300] loss: 0.683 acc: 84.66 time: 9.02\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 84.63 %\n",
      "Average loss on the 10000 test images: 0.688\n",
      "[37,   100] loss: 0.681 acc: 84.68 time: 8.13\n",
      "[37,   200] loss: 0.687 acc: 84.29 time: 8.60\n",
      "[37,   300] loss: 0.687 acc: 84.41 time: 8.70\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 84.62 %\n",
      "Average loss on the 10000 test images: 0.686\n",
      "[38,   100] loss: 0.684 acc: 84.68 time: 8.35\n",
      "[38,   200] loss: 0.690 acc: 84.27 time: 8.19\n",
      "[38,   300] loss: 0.688 acc: 84.34 time: 7.95\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 84.69 %\n",
      "Average loss on the 10000 test images: 0.685\n",
      "[39,   100] loss: 0.685 acc: 84.59 time: 8.03\n",
      "[39,   200] loss: 0.687 acc: 84.52 time: 7.86\n",
      "[39,   300] loss: 0.685 acc: 84.47 time: 8.35\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 84.63 %\n",
      "Average loss on the 10000 test images: 0.686\n",
      "[40,   100] loss: 0.686 acc: 84.89 time: 8.03\n",
      "[40,   200] loss: 0.683 acc: 85.00 time: 8.19\n",
      "[40,   300] loss: 0.690 acc: 83.99 time: 8.06\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 85.05 %\n",
      "Average loss on the 10000 test images: 0.682\n",
      "[41,   100] loss: 0.686 acc: 84.77 time: 9.01\n",
      "[41,   200] loss: 0.685 acc: 84.68 time: 8.75\n",
      "[41,   300] loss: 0.684 acc: 84.66 time: 8.43\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 84.25 %\n",
      "Average loss on the 10000 test images: 0.692\n",
      "[42,   100] loss: 0.684 acc: 84.71 time: 8.72\n",
      "[42,   200] loss: 0.681 acc: 85.23 time: 8.21\n",
      "[42,   300] loss: 0.685 acc: 84.22 time: 8.22\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 84.50 %\n",
      "Average loss on the 10000 test images: 0.687\n",
      "[43,   100] loss: 0.691 acc: 83.98 time: 8.09\n",
      "[43,   200] loss: 0.686 acc: 84.77 time: 8.59\n",
      "[43,   300] loss: 0.675 acc: 85.10 time: 8.26\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 84.84 %\n",
      "Average loss on the 10000 test images: 0.688\n",
      "[44,   100] loss: 0.685 acc: 84.78 time: 8.67\n",
      "[44,   200] loss: 0.684 acc: 84.41 time: 8.68\n",
      "[44,   300] loss: 0.677 acc: 85.36 time: 8.74\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 84.48 %\n",
      "Average loss on the 10000 test images: 0.688\n",
      "[45,   100] loss: 0.680 acc: 85.03 time: 8.97\n",
      "[45,   200] loss: 0.687 acc: 84.54 time: 8.16\n",
      "[45,   300] loss: 0.688 acc: 84.16 time: 7.89\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 84.59 %\n",
      "Average loss on the 10000 test images: 0.683\n",
      "[46,   100] loss: 0.683 acc: 84.70 time: 8.25\n",
      "[46,   200] loss: 0.689 acc: 84.25 time: 8.45\n",
      "[46,   300] loss: 0.688 acc: 84.18 time: 8.00\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 84.71 %\n",
      "Average loss on the 10000 test images: 0.686\n",
      "[47,   100] loss: 0.683 acc: 84.55 time: 8.41\n",
      "[47,   200] loss: 0.682 acc: 84.85 time: 8.08\n",
      "[47,   300] loss: 0.685 acc: 84.39 time: 7.96\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 85.17 %\n",
      "Average loss on the 10000 test images: 0.684\n",
      "[48,   100] loss: 0.684 acc: 84.71 time: 8.58\n",
      "[48,   200] loss: 0.679 acc: 84.88 time: 8.44\n",
      "[48,   300] loss: 0.678 acc: 84.96 time: 8.36\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 84.19 %\n",
      "Average loss on the 10000 test images: 0.687\n",
      "[49,   100] loss: 0.685 acc: 84.62 time: 9.16\n",
      "[49,   200] loss: 0.676 acc: 85.02 time: 8.20\n",
      "[49,   300] loss: 0.685 acc: 84.45 time: 8.52\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 84.30 %\n",
      "Average loss on the 10000 test images: 0.687\n",
      "[50,   100] loss: 0.687 acc: 84.45 time: 8.87\n",
      "[50,   200] loss: 0.683 acc: 84.66 time: 8.01\n",
      "[50,   300] loss: 0.685 acc: 84.84 time: 8.28\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 84.39 %\n",
      "Average loss on the 10000 test images: 0.686\n",
      "Restored best model from epoch with validation accuracy: 85.17%\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "train(net, criterion, optimizer, num_epochs=50, decay_epochs=15, init_lr=0.01, task='rotation', experiment_type='Self-Supervise Rotation Model')\n",
    "################################\n",
    "#     TODO: Save the model     #  \n",
    "################################\n",
    "# Get current date and time\n",
    "# Save the model\n",
    "model_path = f\"{experience_name}.pth\"\n",
    "torch.save(net.state_dict(), model_path)\n",
    "################################\n",
    "#      End of your code        #  \n",
    "################################"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Fine-tuning on the pre-trained model (9 points)\n",
    "\n",
    "In this section, we will load the ResNet18 model pre-trained on the rotation task and fine-tune on the classification task. We will freeze all previous layers except for the 'layer4' block and 'fc' layer.\n",
    "\n",
    "**Then we will use the trained model from rotation task as the pretrained weights. Notice, you should not use the pretrained weights from ImageNet.**"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [
    {
     "data": {
      "text/plain": "<All keys matched successfully>"
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torchvision.models import resnet18\n",
    "\n",
    "#####################################################\n",
    "#     TODO: Load the pre-trained ResNet18 model     #\n",
    "#####################################################\n",
    "# load the trained classifier weights\n",
    "ckpt = torch.load(f\"{experience_name}.pth\")\n",
    "net.load_state_dict(ckpt)\n",
    "####################################################\n",
    "#                End of your code                  #\n",
    "####################################################"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-05T06:46:33.454062300Z",
     "start_time": "2023-11-05T06:46:33.381023500Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [
    {
     "data": {
      "text/plain": "ResNet(\n  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  (relu): ReLU(inplace=True)\n  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n  (layer1): Sequential(\n    (0): BasicBlock(\n      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n    (1): BasicBlock(\n      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n  )\n  (layer2): Sequential(\n    (0): BasicBlock(\n      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (downsample): Sequential(\n        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (1): BasicBlock(\n      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n  )\n  (layer3): Sequential(\n    (0): BasicBlock(\n      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (downsample): Sequential(\n        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (1): BasicBlock(\n      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n  )\n  (layer4): Sequential(\n    (0): BasicBlock(\n      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (downsample): Sequential(\n        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (1): BasicBlock(\n      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n  )\n  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n  (fc): Linear(in_features=512, out_features=10, bias=True)\n)"
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#################################################################################################\n",
    "#   TODO: Freeze all previous layers; only keep the 'layer4' block and 'fc' layer trainable     #\n",
    "#################################################################################################\n",
    "# Freeze all parameters\n",
    "net.requires_grad_(False)\n",
    "\n",
    "# Adjusting the fully connected layer to have 10 outputs for 10 classes\n",
    "net.fc = nn.Linear(net.fc.in_features, 10)  # Re-define the fc layer\n",
    "\n",
    "# Unfreeze the last block (layer4) and the fully connected (fc) layer\n",
    "net.layer4.requires_grad_(True)\n",
    "net.fc.requires_grad_(True)\n",
    "\n",
    "# Make sure to move the model to the device after modifying it\n",
    "net.to(device)\n",
    "#################################################################################################\n",
    "#                                          End of your code                                     #\n",
    "#################################################################################################"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-05T06:46:33.461945700Z",
     "start_time": "2023-11-05T06:46:33.449052900Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Params to learn:\n",
      "\t layer4.0.conv1.weight\n",
      "\t layer4.0.bn1.weight\n",
      "\t layer4.0.bn1.bias\n",
      "\t layer4.0.conv2.weight\n",
      "\t layer4.0.bn2.weight\n",
      "\t layer4.0.bn2.bias\n",
      "\t layer4.0.downsample.0.weight\n",
      "\t layer4.0.downsample.1.weight\n",
      "\t layer4.0.downsample.1.bias\n",
      "\t layer4.1.conv1.weight\n",
      "\t layer4.1.bn1.weight\n",
      "\t layer4.1.bn1.bias\n",
      "\t layer4.1.conv2.weight\n",
      "\t layer4.1.bn2.weight\n",
      "\t layer4.1.bn2.bias\n",
      "\t fc.weight\n",
      "\t fc.bias\n"
     ]
    }
   ],
   "source": [
    "# Print all the trainable parameters\n",
    "params_to_update = net.parameters()\n",
    "print(\"Params to learn:\")\n",
    "params_to_update = []\n",
    "for name,param in net.named_parameters():\n",
    "    if param.requires_grad == True:\n",
    "        params_to_update.append(param)\n",
    "        print(\"\\t\",name)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-05T06:46:33.470062500Z",
     "start_time": "2023-11-05T06:46:33.460956800Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [
    {
     "data": {
      "text/plain": "CrossEntropyLoss()"
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO: Define criterion and optimizer\n",
    "# Note that your optimizer only needs to update the parameters that are trainable.\n",
    "criterion = nn.CrossEntropyLoss(label_smoothing=label_smoothing)\n",
    "\n",
    "# Optimizer: Update only the parameters of layer4 and fc\n",
    "optimizer = optim.Adam([\n",
    "    {'params': net.layer4.parameters()},\n",
    "    {'params': net.fc.parameters()}\n",
    "], lr=0.001)\n",
    "\n",
    "criterion.to(device)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-05T06:46:33.547798200Z",
     "start_time": "2023-11-05T06:46:33.467062600Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,   100] loss: 2.032 acc: 26.06 time: 7.60\n",
      "[1,   200] loss: 1.840 acc: 36.60 time: 7.82\n",
      "[1,   300] loss: 1.800 acc: 38.20 time: 8.24\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 43.26 %\n",
      "Average loss on the 10000 test images: 1.711\n",
      "[2,   100] loss: 1.737 acc: 41.95 time: 7.99\n",
      "[2,   200] loss: 1.723 acc: 42.65 time: 7.77\n",
      "[2,   300] loss: 1.725 acc: 42.14 time: 7.52\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 45.84 %\n",
      "Average loss on the 10000 test images: 1.640\n",
      "[3,   100] loss: 1.686 acc: 44.56 time: 7.48\n",
      "[3,   200] loss: 1.677 acc: 44.66 time: 7.28\n",
      "[3,   300] loss: 1.684 acc: 44.70 time: 7.20\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 46.55 %\n",
      "Average loss on the 10000 test images: 1.651\n",
      "[4,   100] loss: 1.660 acc: 46.02 time: 7.73\n",
      "[4,   200] loss: 1.665 acc: 45.83 time: 7.71\n",
      "[4,   300] loss: 1.656 acc: 46.45 time: 7.37\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 47.87 %\n",
      "Average loss on the 10000 test images: 1.613\n",
      "[5,   100] loss: 1.650 acc: 46.53 time: 7.73\n",
      "[5,   200] loss: 1.647 acc: 46.78 time: 7.58\n",
      "[5,   300] loss: 1.645 acc: 46.87 time: 7.49\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 48.98 %\n",
      "Average loss on the 10000 test images: 1.622\n",
      "[6,   100] loss: 1.621 acc: 48.19 time: 7.29\n",
      "[6,   200] loss: 1.634 acc: 47.59 time: 7.38\n",
      "[6,   300] loss: 1.636 acc: 47.20 time: 7.56\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 49.92 %\n",
      "Average loss on the 10000 test images: 1.596\n",
      "[7,   100] loss: 1.617 acc: 47.91 time: 7.31\n",
      "[7,   200] loss: 1.624 acc: 48.24 time: 7.26\n",
      "[7,   300] loss: 1.618 acc: 47.69 time: 7.05\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 50.47 %\n",
      "Average loss on the 10000 test images: 1.570\n",
      "[8,   100] loss: 1.600 acc: 49.11 time: 7.51\n",
      "[8,   200] loss: 1.613 acc: 48.14 time: 7.40\n",
      "[8,   300] loss: 1.611 acc: 48.09 time: 7.46\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 50.59 %\n",
      "Average loss on the 10000 test images: 1.574\n",
      "[9,   100] loss: 1.607 acc: 48.59 time: 7.73\n",
      "[9,   200] loss: 1.599 acc: 48.80 time: 7.42\n",
      "[9,   300] loss: 1.602 acc: 49.11 time: 7.31\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 51.32 %\n",
      "Average loss on the 10000 test images: 1.568\n",
      "[10,   100] loss: 1.589 acc: 49.96 time: 7.20\n",
      "[10,   200] loss: 1.608 acc: 48.85 time: 7.38\n",
      "[10,   300] loss: 1.588 acc: 49.77 time: 7.13\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 52.62 %\n",
      "Average loss on the 10000 test images: 1.540\n",
      "[11,   100] loss: 1.561 acc: 51.30 time: 7.49\n",
      "[11,   200] loss: 1.563 acc: 50.41 time: 7.13\n",
      "[11,   300] loss: 1.541 acc: 52.07 time: 7.59\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 53.89 %\n",
      "Average loss on the 10000 test images: 1.506\n",
      "[12,   100] loss: 1.541 acc: 52.46 time: 7.17\n",
      "[12,   200] loss: 1.540 acc: 52.27 time: 7.20\n",
      "[12,   300] loss: 1.548 acc: 51.90 time: 7.19\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 54.49 %\n",
      "Average loss on the 10000 test images: 1.500\n",
      "[13,   100] loss: 1.543 acc: 51.44 time: 7.45\n",
      "[13,   200] loss: 1.524 acc: 53.05 time: 7.21\n",
      "[13,   300] loss: 1.525 acc: 53.18 time: 7.85\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 54.65 %\n",
      "Average loss on the 10000 test images: 1.496\n",
      "[14,   100] loss: 1.535 acc: 52.59 time: 7.26\n",
      "[14,   200] loss: 1.520 acc: 53.23 time: 7.47\n",
      "[14,   300] loss: 1.532 acc: 52.26 time: 7.25\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 55.14 %\n",
      "Average loss on the 10000 test images: 1.491\n",
      "[15,   100] loss: 1.526 acc: 52.88 time: 7.31\n",
      "[15,   200] loss: 1.522 acc: 52.76 time: 7.45\n",
      "[15,   300] loss: 1.524 acc: 52.56 time: 7.42\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 54.98 %\n",
      "Average loss on the 10000 test images: 1.491\n",
      "[16,   100] loss: 1.530 acc: 52.28 time: 7.73\n",
      "[16,   200] loss: 1.524 acc: 52.80 time: 7.39\n",
      "[16,   300] loss: 1.516 acc: 52.70 time: 7.45\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 54.74 %\n",
      "Average loss on the 10000 test images: 1.491\n",
      "[17,   100] loss: 1.513 acc: 53.60 time: 7.61\n",
      "[17,   200] loss: 1.523 acc: 52.77 time: 7.33\n",
      "[17,   300] loss: 1.510 acc: 53.18 time: 7.37\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 54.94 %\n",
      "Average loss on the 10000 test images: 1.485\n",
      "[18,   100] loss: 1.526 acc: 52.39 time: 7.15\n",
      "[18,   200] loss: 1.507 acc: 53.50 time: 7.23\n",
      "[18,   300] loss: 1.517 acc: 52.38 time: 7.34\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 54.97 %\n",
      "Average loss on the 10000 test images: 1.486\n",
      "[19,   100] loss: 1.521 acc: 52.55 time: 7.61\n",
      "[19,   200] loss: 1.523 acc: 52.99 time: 7.13\n",
      "[19,   300] loss: 1.509 acc: 53.63 time: 7.05\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 55.02 %\n",
      "Average loss on the 10000 test images: 1.488\n",
      "[20,   100] loss: 1.512 acc: 53.32 time: 7.63\n",
      "[20,   200] loss: 1.513 acc: 53.02 time: 7.34\n",
      "[20,   300] loss: 1.532 acc: 51.99 time: 7.36\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 55.22 %\n",
      "Average loss on the 10000 test images: 1.486\n",
      "[21,   100] loss: 1.520 acc: 52.40 time: 7.19\n",
      "[21,   200] loss: 1.500 acc: 53.77 time: 7.03\n",
      "[21,   300] loss: 1.506 acc: 53.30 time: 7.15\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 55.55 %\n",
      "Average loss on the 10000 test images: 1.479\n",
      "[22,   100] loss: 1.506 acc: 53.97 time: 7.67\n",
      "[22,   200] loss: 1.517 acc: 53.02 time: 7.68\n",
      "[22,   300] loss: 1.499 acc: 54.17 time: 7.35\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 55.27 %\n",
      "Average loss on the 10000 test images: 1.478\n",
      "[23,   100] loss: 1.512 acc: 53.30 time: 7.37\n",
      "[23,   200] loss: 1.499 acc: 54.18 time: 7.31\n",
      "[23,   300] loss: 1.507 acc: 53.55 time: 7.32\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 55.38 %\n",
      "Average loss on the 10000 test images: 1.481\n",
      "[24,   100] loss: 1.515 acc: 53.08 time: 7.62\n",
      "[24,   200] loss: 1.506 acc: 53.79 time: 7.40\n",
      "[24,   300] loss: 1.500 acc: 54.15 time: 7.30\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 55.28 %\n",
      "Average loss on the 10000 test images: 1.477\n",
      "[25,   100] loss: 1.501 acc: 53.95 time: 7.33\n",
      "[25,   200] loss: 1.506 acc: 53.77 time: 7.31\n",
      "[25,   300] loss: 1.509 acc: 53.62 time: 7.11\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 55.51 %\n",
      "Average loss on the 10000 test images: 1.479\n",
      "[26,   100] loss: 1.505 acc: 53.61 time: 7.32\n",
      "[26,   200] loss: 1.507 acc: 53.01 time: 7.16\n",
      "[26,   300] loss: 1.504 acc: 53.57 time: 7.34\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 55.31 %\n",
      "Average loss on the 10000 test images: 1.480\n",
      "[27,   100] loss: 1.504 acc: 53.51 time: 7.34\n",
      "[27,   200] loss: 1.516 acc: 52.95 time: 7.47\n",
      "[27,   300] loss: 1.500 acc: 54.31 time: 7.02\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 55.29 %\n",
      "Average loss on the 10000 test images: 1.481\n",
      "[28,   100] loss: 1.504 acc: 53.39 time: 7.50\n",
      "[28,   200] loss: 1.511 acc: 53.45 time: 7.40\n",
      "[28,   300] loss: 1.497 acc: 54.26 time: 7.50\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 55.52 %\n",
      "Average loss on the 10000 test images: 1.477\n",
      "[29,   100] loss: 1.486 acc: 54.84 time: 7.58\n",
      "[29,   200] loss: 1.508 acc: 53.55 time: 7.31\n",
      "[29,   300] loss: 1.511 acc: 53.70 time: 7.36\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 55.43 %\n",
      "Average loss on the 10000 test images: 1.475\n",
      "[30,   100] loss: 1.498 acc: 53.89 time: 7.34\n",
      "[30,   200] loss: 1.505 acc: 53.30 time: 7.27\n",
      "[30,   300] loss: 1.502 acc: 53.73 time: 7.37\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 55.51 %\n",
      "Average loss on the 10000 test images: 1.475\n",
      "[31,   100] loss: 1.509 acc: 53.56 time: 7.33\n",
      "[31,   200] loss: 1.505 acc: 53.40 time: 7.26\n",
      "[31,   300] loss: 1.487 acc: 53.79 time: 7.39\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 55.59 %\n",
      "Average loss on the 10000 test images: 1.476\n",
      "[32,   100] loss: 1.490 acc: 54.53 time: 7.14\n",
      "[32,   200] loss: 1.520 acc: 52.65 time: 7.43\n",
      "[32,   300] loss: 1.503 acc: 53.89 time: 7.45\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 55.58 %\n",
      "Average loss on the 10000 test images: 1.477\n",
      "[33,   100] loss: 1.511 acc: 52.99 time: 7.30\n",
      "[33,   200] loss: 1.490 acc: 54.55 time: 7.31\n",
      "[33,   300] loss: 1.516 acc: 53.03 time: 7.09\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 55.67 %\n",
      "Average loss on the 10000 test images: 1.475\n",
      "[34,   100] loss: 1.500 acc: 54.09 time: 7.19\n",
      "[34,   200] loss: 1.505 acc: 53.58 time: 7.11\n",
      "[34,   300] loss: 1.505 acc: 53.45 time: 7.16\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 55.61 %\n",
      "Average loss on the 10000 test images: 1.475\n",
      "[35,   100] loss: 1.496 acc: 54.51 time: 7.10\n",
      "[35,   200] loss: 1.517 acc: 52.85 time: 7.48\n",
      "[35,   300] loss: 1.497 acc: 53.96 time: 7.44\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 55.49 %\n",
      "Average loss on the 10000 test images: 1.478\n",
      "[36,   100] loss: 1.514 acc: 52.83 time: 7.24\n",
      "[36,   200] loss: 1.510 acc: 53.05 time: 7.16\n",
      "[36,   300] loss: 1.490 acc: 53.99 time: 6.99\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 55.62 %\n",
      "Average loss on the 10000 test images: 1.474\n",
      "[37,   100] loss: 1.498 acc: 54.14 time: 7.45\n",
      "[37,   200] loss: 1.500 acc: 53.67 time: 7.51\n",
      "[37,   300] loss: 1.507 acc: 53.77 time: 7.44\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 55.51 %\n",
      "Average loss on the 10000 test images: 1.475\n",
      "[38,   100] loss: 1.510 acc: 53.52 time: 7.21\n",
      "[38,   200] loss: 1.504 acc: 53.26 time: 7.25\n",
      "[38,   300] loss: 1.501 acc: 53.53 time: 7.12\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 55.41 %\n",
      "Average loss on the 10000 test images: 1.478\n",
      "[39,   100] loss: 1.506 acc: 53.55 time: 7.25\n",
      "[39,   200] loss: 1.499 acc: 53.77 time: 7.41\n",
      "[39,   300] loss: 1.495 acc: 54.38 time: 7.28\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 55.47 %\n",
      "Average loss on the 10000 test images: 1.477\n",
      "[40,   100] loss: 1.502 acc: 53.73 time: 7.34\n",
      "[40,   200] loss: 1.504 acc: 53.70 time: 7.42\n",
      "[40,   300] loss: 1.507 acc: 53.35 time: 6.88\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 55.77 %\n",
      "Average loss on the 10000 test images: 1.474\n",
      "[41,   100] loss: 1.500 acc: 54.00 time: 7.22\n",
      "[41,   200] loss: 1.499 acc: 53.81 time: 7.16\n",
      "[41,   300] loss: 1.499 acc: 54.17 time: 7.32\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 55.60 %\n",
      "Average loss on the 10000 test images: 1.477\n",
      "[42,   100] loss: 1.507 acc: 53.32 time: 7.39\n",
      "[42,   200] loss: 1.508 acc: 53.44 time: 7.14\n",
      "[42,   300] loss: 1.496 acc: 53.88 time: 7.39\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 55.53 %\n",
      "Average loss on the 10000 test images: 1.475\n",
      "[43,   100] loss: 1.513 acc: 53.28 time: 7.83\n",
      "[43,   200] loss: 1.510 acc: 53.37 time: 7.13\n",
      "[43,   300] loss: 1.497 acc: 54.09 time: 7.10\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 55.53 %\n",
      "Average loss on the 10000 test images: 1.475\n",
      "[44,   100] loss: 1.499 acc: 54.23 time: 7.43\n",
      "[44,   200] loss: 1.511 acc: 53.27 time: 7.04\n",
      "[44,   300] loss: 1.506 acc: 53.73 time: 7.34\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 55.66 %\n",
      "Average loss on the 10000 test images: 1.477\n",
      "[45,   100] loss: 1.506 acc: 53.77 time: 7.18\n",
      "[45,   200] loss: 1.499 acc: 53.94 time: 7.28\n",
      "[45,   300] loss: 1.505 acc: 53.34 time: 7.74\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 55.50 %\n",
      "Average loss on the 10000 test images: 1.477\n",
      "[46,   100] loss: 1.502 acc: 53.30 time: 7.24\n",
      "[46,   200] loss: 1.495 acc: 54.05 time: 7.19\n",
      "[46,   300] loss: 1.503 acc: 53.73 time: 7.30\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 55.75 %\n",
      "Average loss on the 10000 test images: 1.475\n",
      "[47,   100] loss: 1.503 acc: 54.23 time: 7.07\n",
      "[47,   200] loss: 1.504 acc: 53.52 time: 7.43\n",
      "[47,   300] loss: 1.497 acc: 54.12 time: 7.17\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 55.57 %\n",
      "Average loss on the 10000 test images: 1.475\n",
      "[48,   100] loss: 1.509 acc: 53.59 time: 7.65\n",
      "[48,   200] loss: 1.513 acc: 53.27 time: 7.49\n",
      "[48,   300] loss: 1.494 acc: 54.39 time: 7.64\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 55.58 %\n",
      "Average loss on the 10000 test images: 1.477\n",
      "[49,   100] loss: 1.509 acc: 53.09 time: 7.08\n",
      "[49,   200] loss: 1.506 acc: 53.67 time: 7.35\n",
      "[49,   300] loss: 1.500 acc: 53.79 time: 6.97\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 55.51 %\n",
      "Average loss on the 10000 test images: 1.476\n",
      "[50,   100] loss: 1.509 acc: 53.23 time: 7.35\n",
      "[50,   200] loss: 1.507 acc: 53.42 time: 7.02\n",
      "[50,   300] loss: 1.502 acc: 53.57 time: 7.33\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 55.65 %\n",
      "Average loss on the 10000 test images: 1.476\n",
      "Restored best model from epoch with validation accuracy: 55.77%\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "train(net, criterion, optimizer, num_epochs=50, decay_epochs=10, init_lr=0.01, task='classification', experiment_type='Fine-tuning Pre-trained Model')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-05T07:14:04.059132300Z",
     "start_time": "2023-11-05T06:46:33.475798600Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Fine-tuning on the randomly initialized model (9 points)\n",
    "In this section, we will randomly initialize a ResNet18 model and fine-tune on the classification task. We will freeze all previous layers except for the 'layer4' block and 'fc' layer."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torchvision.models import resnet18\n",
    "#################################################\n",
    "# TODO: Randomly initialize a ResNet18 model    #\n",
    "#################################################\n",
    "# Randomly initialize a ResNet18 model\n",
    "net = resnet18(pretrained=False)\n",
    "#################################################\n",
    "#              End of your code                 #\n",
    "#################################################"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-05T07:14:04.188148800Z",
     "start_time": "2023-11-05T07:14:04.056129600Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [
    {
     "data": {
      "text/plain": "ResNet(\n  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  (relu): ReLU(inplace=True)\n  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n  (layer1): Sequential(\n    (0): BasicBlock(\n      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n    (1): BasicBlock(\n      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n  )\n  (layer2): Sequential(\n    (0): BasicBlock(\n      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (downsample): Sequential(\n        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (1): BasicBlock(\n      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n  )\n  (layer3): Sequential(\n    (0): BasicBlock(\n      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (downsample): Sequential(\n        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (1): BasicBlock(\n      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n  )\n  (layer4): Sequential(\n    (0): BasicBlock(\n      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (downsample): Sequential(\n        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (1): BasicBlock(\n      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n  )\n  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n  (fc): Linear(in_features=512, out_features=10, bias=True)\n)"
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#################################################################################################\n",
    "# TODO: Freeze all previous layers; only keep the 'layer4' block and 'fc' layer trainable       #\n",
    "# To do this, you should set requires_grad=False for the frozen layers.                         #\n",
    "#################################################################################################\n",
    "# Adjusting the fully connected layer for 10 classes\n",
    "net.fc = nn.Linear(net.fc.in_features, 10)\n",
    "\n",
    "# Freeze all layers in the randomly initialized model\n",
    "net.requires_grad_(False)\n",
    "\n",
    "# Unfreeze the last block (layer4) and the fully connected (fc) layer\n",
    "net.layer4.requires_grad_(True)\n",
    "net.fc.requires_grad_(True)\n",
    "\n",
    "# Move the model to the device\n",
    "net.to(device)\n",
    "#################################################################################################\n",
    "#                                          End of your code                                     #\n",
    "#################################################################################################"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-05T07:14:04.223991300Z",
     "start_time": "2023-11-05T07:14:04.190133800Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Params to learn:\n",
      "\t layer4.0.conv1.weight\n",
      "\t layer4.0.bn1.weight\n",
      "\t layer4.0.bn1.bias\n",
      "\t layer4.0.conv2.weight\n",
      "\t layer4.0.bn2.weight\n",
      "\t layer4.0.bn2.bias\n",
      "\t layer4.0.downsample.0.weight\n",
      "\t layer4.0.downsample.1.weight\n",
      "\t layer4.0.downsample.1.bias\n",
      "\t layer4.1.conv1.weight\n",
      "\t layer4.1.bn1.weight\n",
      "\t layer4.1.bn1.bias\n",
      "\t layer4.1.conv2.weight\n",
      "\t layer4.1.bn2.weight\n",
      "\t layer4.1.bn2.bias\n",
      "\t fc.weight\n",
      "\t fc.bias\n"
     ]
    }
   ],
   "source": [
    "# Print all the trainable parameters\n",
    "params_to_update = net.parameters()\n",
    "print(\"Params to learn:\")\n",
    "params_to_update = []\n",
    "for name,param in net.named_parameters():\n",
    "    if param.requires_grad == True:\n",
    "        params_to_update.append(param)\n",
    "        print(\"\\t\",name)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-05T07:14:04.285084500Z",
     "start_time": "2023-11-05T07:14:04.217883700Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [
    {
     "data": {
      "text/plain": "CrossEntropyLoss()"
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO: Define criterion and optimizer\n",
    "# Note that your optimizer only needs to update the parameters that are trainable.\n",
    "criterion = nn.CrossEntropyLoss(label_smoothing=label_smoothing)\n",
    "\n",
    "# Optimizer: Update only the parameters of layer4 and fc\n",
    "optimizer = optim.Adam([\n",
    "    {'params': net.layer4.parameters()},\n",
    "    {'params': net.fc.parameters()}\n",
    "], lr=0.001)\n",
    "\n",
    "criterion.to(device)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-05T07:14:04.298079500Z",
     "start_time": "2023-11-05T07:14:04.223991300Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,   100] loss: 2.303 acc: 24.45 time: 7.28\n",
      "[1,   200] loss: 2.024 acc: 30.10 time: 7.22\n",
      "[1,   300] loss: 1.980 acc: 32.05 time: 7.02\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 36.25 %\n",
      "Average loss on the 10000 test images: 1.867\n",
      "[2,   100] loss: 1.934 acc: 33.82 time: 7.20\n",
      "[2,   200] loss: 1.902 acc: 35.06 time: 7.12\n",
      "[2,   300] loss: 1.892 acc: 34.95 time: 7.14\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 39.04 %\n",
      "Average loss on the 10000 test images: 1.822\n",
      "[3,   100] loss: 1.883 acc: 35.97 time: 7.58\n",
      "[3,   200] loss: 1.870 acc: 36.98 time: 7.45\n",
      "[3,   300] loss: 1.867 acc: 36.14 time: 7.18\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 39.60 %\n",
      "Average loss on the 10000 test images: 1.800\n",
      "[4,   100] loss: 1.849 acc: 38.02 time: 7.89\n",
      "[4,   200] loss: 1.849 acc: 38.06 time: 7.29\n",
      "[4,   300] loss: 1.854 acc: 37.06 time: 7.44\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 40.46 %\n",
      "Average loss on the 10000 test images: 1.793\n",
      "[5,   100] loss: 1.843 acc: 38.09 time: 7.36\n",
      "[5,   200] loss: 1.832 acc: 38.23 time: 7.28\n",
      "[5,   300] loss: 1.843 acc: 37.77 time: 7.13\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 41.67 %\n",
      "Average loss on the 10000 test images: 1.781\n",
      "[6,   100] loss: 1.825 acc: 39.13 time: 7.21\n",
      "[6,   200] loss: 1.824 acc: 39.27 time: 7.08\n",
      "[6,   300] loss: 1.828 acc: 38.23 time: 7.24\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 42.44 %\n",
      "Average loss on the 10000 test images: 1.754\n",
      "[7,   100] loss: 1.815 acc: 39.34 time: 7.39\n",
      "[7,   200] loss: 1.799 acc: 40.11 time: 7.15\n",
      "[7,   300] loss: 1.814 acc: 38.89 time: 7.47\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 41.90 %\n",
      "Average loss on the 10000 test images: 1.763\n",
      "[8,   100] loss: 1.821 acc: 39.55 time: 7.50\n",
      "[8,   200] loss: 1.806 acc: 40.02 time: 7.19\n",
      "[8,   300] loss: 1.796 acc: 40.70 time: 7.32\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 43.13 %\n",
      "Average loss on the 10000 test images: 1.755\n",
      "[9,   100] loss: 1.800 acc: 40.30 time: 7.23\n",
      "[9,   200] loss: 1.795 acc: 41.34 time: 7.34\n",
      "[9,   300] loss: 1.811 acc: 39.68 time: 7.47\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 43.12 %\n",
      "Average loss on the 10000 test images: 1.746\n",
      "[10,   100] loss: 1.792 acc: 40.63 time: 7.62\n",
      "[10,   200] loss: 1.783 acc: 41.41 time: 7.05\n",
      "[10,   300] loss: 1.793 acc: 40.52 time: 7.10\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 43.21 %\n",
      "Average loss on the 10000 test images: 1.738\n",
      "[11,   100] loss: 1.780 acc: 41.27 time: 7.38\n",
      "[11,   200] loss: 1.761 acc: 41.77 time: 7.31\n",
      "[11,   300] loss: 1.756 acc: 42.30 time: 7.18\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 44.50 %\n",
      "Average loss on the 10000 test images: 1.712\n",
      "[12,   100] loss: 1.741 acc: 43.49 time: 7.75\n",
      "[12,   200] loss: 1.742 acc: 42.76 time: 7.20\n",
      "[12,   300] loss: 1.750 acc: 42.99 time: 7.39\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 44.68 %\n",
      "Average loss on the 10000 test images: 1.706\n",
      "[13,   100] loss: 1.734 acc: 43.34 time: 7.52\n",
      "[13,   200] loss: 1.740 acc: 43.15 time: 7.45\n",
      "[13,   300] loss: 1.736 acc: 43.07 time: 7.23\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 45.19 %\n",
      "Average loss on the 10000 test images: 1.700\n",
      "[14,   100] loss: 1.732 acc: 43.06 time: 7.18\n",
      "[14,   200] loss: 1.736 acc: 43.34 time: 7.43\n",
      "[14,   300] loss: 1.740 acc: 43.19 time: 7.34\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 45.50 %\n",
      "Average loss on the 10000 test images: 1.696\n",
      "[15,   100] loss: 1.723 acc: 44.17 time: 7.27\n",
      "[15,   200] loss: 1.745 acc: 42.27 time: 7.09\n",
      "[15,   300] loss: 1.738 acc: 42.80 time: 7.46\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 45.91 %\n",
      "Average loss on the 10000 test images: 1.689\n",
      "[16,   100] loss: 1.713 acc: 44.52 time: 7.35\n",
      "[16,   200] loss: 1.736 acc: 43.23 time: 7.04\n",
      "[16,   300] loss: 1.719 acc: 43.70 time: 7.08\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 45.73 %\n",
      "Average loss on the 10000 test images: 1.688\n",
      "[17,   100] loss: 1.722 acc: 43.52 time: 7.51\n",
      "[17,   200] loss: 1.712 acc: 43.95 time: 7.02\n",
      "[17,   300] loss: 1.729 acc: 43.41 time: 7.13\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 45.56 %\n",
      "Average loss on the 10000 test images: 1.690\n",
      "[18,   100] loss: 1.714 acc: 44.38 time: 7.48\n",
      "[18,   200] loss: 1.715 acc: 44.38 time: 7.27\n",
      "[18,   300] loss: 1.713 acc: 44.23 time: 7.47\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 45.99 %\n",
      "Average loss on the 10000 test images: 1.680\n",
      "[19,   100] loss: 1.711 acc: 44.54 time: 7.47\n",
      "[19,   200] loss: 1.709 acc: 44.61 time: 7.36\n",
      "[19,   300] loss: 1.717 acc: 43.50 time: 7.31\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 45.66 %\n",
      "Average loss on the 10000 test images: 1.682\n",
      "[20,   100] loss: 1.722 acc: 43.76 time: 7.73\n",
      "[20,   200] loss: 1.710 acc: 44.17 time: 7.05\n",
      "[20,   300] loss: 1.714 acc: 44.15 time: 6.89\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 45.78 %\n",
      "Average loss on the 10000 test images: 1.681\n",
      "[21,   100] loss: 1.711 acc: 44.38 time: 7.49\n",
      "[21,   200] loss: 1.706 acc: 44.77 time: 7.37\n",
      "[21,   300] loss: 1.700 acc: 44.85 time: 7.32\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 45.79 %\n",
      "Average loss on the 10000 test images: 1.679\n",
      "[22,   100] loss: 1.708 acc: 44.71 time: 7.11\n",
      "[22,   200] loss: 1.719 acc: 44.12 time: 6.99\n",
      "[22,   300] loss: 1.705 acc: 44.85 time: 7.16\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 46.06 %\n",
      "Average loss on the 10000 test images: 1.677\n",
      "[23,   100] loss: 1.705 acc: 44.78 time: 7.56\n",
      "[23,   200] loss: 1.702 acc: 45.03 time: 7.21\n",
      "[23,   300] loss: 1.701 acc: 44.99 time: 7.40\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 46.22 %\n",
      "Average loss on the 10000 test images: 1.675\n",
      "[24,   100] loss: 1.698 acc: 45.05 time: 7.67\n",
      "[24,   200] loss: 1.708 acc: 44.34 time: 7.38\n",
      "[24,   300] loss: 1.710 acc: 45.06 time: 7.31\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 46.20 %\n",
      "Average loss on the 10000 test images: 1.674\n",
      "[25,   100] loss: 1.698 acc: 45.02 time: 7.31\n",
      "[25,   200] loss: 1.696 acc: 45.21 time: 6.92\n",
      "[25,   300] loss: 1.709 acc: 44.55 time: 7.30\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 46.29 %\n",
      "Average loss on the 10000 test images: 1.674\n",
      "[26,   100] loss: 1.700 acc: 44.88 time: 7.55\n",
      "[26,   200] loss: 1.697 acc: 45.25 time: 7.27\n",
      "[26,   300] loss: 1.717 acc: 43.82 time: 7.22\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 46.41 %\n",
      "Average loss on the 10000 test images: 1.673\n",
      "[27,   100] loss: 1.702 acc: 44.77 time: 7.87\n",
      "[27,   200] loss: 1.699 acc: 45.47 time: 7.36\n",
      "[27,   300] loss: 1.702 acc: 44.72 time: 7.24\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 46.19 %\n",
      "Average loss on the 10000 test images: 1.671\n",
      "[28,   100] loss: 1.700 acc: 44.78 time: 7.48\n",
      "[28,   200] loss: 1.704 acc: 45.18 time: 7.13\n",
      "[28,   300] loss: 1.705 acc: 44.91 time: 7.45\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 46.30 %\n",
      "Average loss on the 10000 test images: 1.671\n",
      "[29,   100] loss: 1.700 acc: 44.51 time: 7.58\n",
      "[29,   200] loss: 1.698 acc: 44.98 time: 7.27\n",
      "[29,   300] loss: 1.703 acc: 44.98 time: 7.28\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 46.04 %\n",
      "Average loss on the 10000 test images: 1.672\n",
      "[30,   100] loss: 1.702 acc: 44.84 time: 7.40\n",
      "[30,   200] loss: 1.702 acc: 44.98 time: 7.37\n",
      "[30,   300] loss: 1.700 acc: 44.94 time: 7.36\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 46.31 %\n",
      "Average loss on the 10000 test images: 1.673\n",
      "[31,   100] loss: 1.705 acc: 44.30 time: 7.20\n",
      "[31,   200] loss: 1.699 acc: 44.39 time: 6.89\n",
      "[31,   300] loss: 1.699 acc: 44.55 time: 7.44\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 46.42 %\n",
      "Average loss on the 10000 test images: 1.672\n",
      "[32,   100] loss: 1.701 acc: 45.08 time: 7.33\n",
      "[32,   200] loss: 1.704 acc: 44.78 time: 7.15\n",
      "[32,   300] loss: 1.692 acc: 45.60 time: 7.20\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 46.10 %\n",
      "Average loss on the 10000 test images: 1.673\n",
      "[33,   100] loss: 1.698 acc: 44.98 time: 7.40\n",
      "[33,   200] loss: 1.701 acc: 45.09 time: 7.08\n",
      "[33,   300] loss: 1.702 acc: 44.70 time: 7.82\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 46.25 %\n",
      "Average loss on the 10000 test images: 1.672\n",
      "[34,   100] loss: 1.705 acc: 44.62 time: 7.33\n",
      "[34,   200] loss: 1.704 acc: 44.97 time: 7.25\n",
      "[34,   300] loss: 1.701 acc: 45.09 time: 7.07\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 46.37 %\n",
      "Average loss on the 10000 test images: 1.672\n",
      "[35,   100] loss: 1.695 acc: 45.30 time: 7.54\n",
      "[35,   200] loss: 1.694 acc: 45.12 time: 7.21\n",
      "[35,   300] loss: 1.701 acc: 44.93 time: 7.21\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 46.28 %\n",
      "Average loss on the 10000 test images: 1.671\n",
      "[36,   100] loss: 1.693 acc: 45.76 time: 7.59\n",
      "[36,   200] loss: 1.704 acc: 44.42 time: 7.07\n",
      "[36,   300] loss: 1.700 acc: 45.25 time: 7.52\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 46.25 %\n",
      "Average loss on the 10000 test images: 1.675\n",
      "[37,   100] loss: 1.700 acc: 44.85 time: 7.54\n",
      "[37,   200] loss: 1.688 acc: 45.50 time: 7.35\n",
      "[37,   300] loss: 1.705 acc: 44.96 time: 7.25\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 46.21 %\n",
      "Average loss on the 10000 test images: 1.671\n",
      "[38,   100] loss: 1.703 acc: 44.90 time: 7.37\n",
      "[38,   200] loss: 1.700 acc: 44.90 time: 7.26\n",
      "[38,   300] loss: 1.684 acc: 45.56 time: 7.05\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 46.23 %\n",
      "Average loss on the 10000 test images: 1.673\n",
      "[39,   100] loss: 1.689 acc: 45.34 time: 7.38\n",
      "[39,   200] loss: 1.709 acc: 44.66 time: 7.33\n",
      "[39,   300] loss: 1.707 acc: 44.26 time: 7.44\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 46.44 %\n",
      "Average loss on the 10000 test images: 1.672\n",
      "[40,   100] loss: 1.716 acc: 44.16 time: 7.55\n",
      "[40,   200] loss: 1.692 acc: 45.01 time: 7.12\n",
      "[40,   300] loss: 1.700 acc: 44.77 time: 7.25\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 46.39 %\n",
      "Average loss on the 10000 test images: 1.671\n",
      "[41,   100] loss: 1.698 acc: 44.95 time: 7.31\n",
      "[41,   200] loss: 1.702 acc: 44.98 time: 7.32\n",
      "[41,   300] loss: 1.690 acc: 45.84 time: 7.30\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 46.34 %\n",
      "Average loss on the 10000 test images: 1.672\n",
      "[42,   100] loss: 1.705 acc: 43.77 time: 7.63\n",
      "[42,   200] loss: 1.702 acc: 44.69 time: 7.12\n",
      "[42,   300] loss: 1.699 acc: 45.09 time: 7.21\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 46.25 %\n",
      "Average loss on the 10000 test images: 1.670\n",
      "[43,   100] loss: 1.703 acc: 44.77 time: 7.56\n",
      "[43,   200] loss: 1.701 acc: 45.35 time: 7.35\n",
      "[43,   300] loss: 1.694 acc: 45.33 time: 7.25\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 46.03 %\n",
      "Average loss on the 10000 test images: 1.673\n",
      "[44,   100] loss: 1.695 acc: 45.12 time: 7.45\n",
      "[44,   200] loss: 1.700 acc: 44.80 time: 7.11\n",
      "[44,   300] loss: 1.704 acc: 44.84 time: 7.62\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 46.14 %\n",
      "Average loss on the 10000 test images: 1.673\n",
      "[45,   100] loss: 1.696 acc: 44.54 time: 7.45\n",
      "[45,   200] loss: 1.695 acc: 45.27 time: 7.40\n",
      "[45,   300] loss: 1.693 acc: 45.27 time: 7.43\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 46.44 %\n",
      "Average loss on the 10000 test images: 1.670\n",
      "[46,   100] loss: 1.696 acc: 45.41 time: 7.59\n",
      "[46,   200] loss: 1.703 acc: 44.84 time: 7.30\n",
      "[46,   300] loss: 1.695 acc: 45.31 time: 7.21\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 46.18 %\n",
      "Average loss on the 10000 test images: 1.672\n",
      "[47,   100] loss: 1.692 acc: 45.37 time: 7.10\n",
      "[47,   200] loss: 1.709 acc: 44.02 time: 7.48\n",
      "[47,   300] loss: 1.691 acc: 45.54 time: 6.97\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 46.39 %\n",
      "Average loss on the 10000 test images: 1.671\n",
      "[48,   100] loss: 1.711 acc: 44.59 time: 7.37\n",
      "[48,   200] loss: 1.697 acc: 44.67 time: 7.39\n",
      "[48,   300] loss: 1.702 acc: 44.76 time: 6.97\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 46.47 %\n",
      "Average loss on the 10000 test images: 1.672\n",
      "[49,   100] loss: 1.690 acc: 45.21 time: 7.26\n",
      "[49,   200] loss: 1.696 acc: 44.91 time: 7.21\n",
      "[49,   300] loss: 1.709 acc: 44.38 time: 7.52\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 46.36 %\n",
      "Average loss on the 10000 test images: 1.671\n",
      "[50,   100] loss: 1.702 acc: 44.61 time: 7.18\n",
      "[50,   200] loss: 1.694 acc: 45.34 time: 6.96\n",
      "[50,   300] loss: 1.704 acc: 45.08 time: 7.88\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 46.42 %\n",
      "Average loss on the 10000 test images: 1.669\n",
      "Restored best model from epoch with validation accuracy: 46.47%\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "train(net, criterion, optimizer, num_epochs=50, decay_epochs=10, init_lr=0.01, task='classification', experiment_type='Fine-tuning Randomly Initialized Model')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-05T07:41:44.674424300Z",
     "start_time": "2023-11-05T07:14:04.231080500Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Supervised training on the pre-trained model (9 points)\n",
    "In this section, we will load the ResNet18 model pre-trained on the rotation task and re-train the whole model on the classification task.\n",
    "\n",
    "**Then we will use the trained model from rotation task as the pretrained weights. Notice, you should not use the pretrained weights from ImageNet.**"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torchvision.models import resnet18\n",
    "\n",
    "#####################################################\n",
    "#     TODO: Load the pre-trained ResNet18 model     #\n",
    "#####################################################\n",
    "# load the trained classifier weights\n",
    "net = resnet18(weights=None, num_classes=rotation_direction)\n",
    "ckpt = torch.load(f\"{experience_name}.pth\")\n",
    "net.load_state_dict(ckpt)\n",
    "\n",
    "# Adjusting the fully connected layer for 10 classes\n",
    "net.fc = nn.Linear(net.fc.in_features, 10)\n",
    "net = net.to(device)\n",
    "#####################################################\n",
    "#                End of your code                   #\n",
    "#####################################################"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-05T07:41:44.902256400Z",
     "start_time": "2023-11-05T07:41:44.668357Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "outputs": [
    {
     "data": {
      "text/plain": "CrossEntropyLoss()"
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO: Define criterion and optimizer\n",
    "criterion = nn.CrossEntropyLoss(label_smoothing=label_smoothing)\n",
    "\n",
    "# Optimizer: Update only the parameters of layer4 and fc\n",
    "optimizer = optim.Adam(lr=0.001, params=net.parameters())\n",
    "\n",
    "criterion.to(device)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-05T07:41:44.909283100Z",
     "start_time": "2023-11-05T07:41:44.902256400Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,   100] loss: 1.758 acc: 39.29 time: 15.96\n",
      "[1,   200] loss: 1.526 acc: 52.66 time: 7.85\n",
      "[1,   300] loss: 1.418 acc: 57.92 time: 7.65\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 61.93 %\n",
      "Average loss on the 10000 test images: 1.365\n",
      "[2,   100] loss: 1.304 acc: 63.69 time: 7.39\n",
      "[2,   200] loss: 1.279 acc: 65.43 time: 8.50\n",
      "[2,   300] loss: 1.239 acc: 66.66 time: 7.91\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 70.51 %\n",
      "Average loss on the 10000 test images: 1.166\n",
      "[3,   100] loss: 1.189 acc: 68.95 time: 8.02\n",
      "[3,   200] loss: 1.162 acc: 70.59 time: 8.14\n",
      "[3,   300] loss: 1.150 acc: 71.22 time: 8.53\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 72.73 %\n",
      "Average loss on the 10000 test images: 1.116\n",
      "[4,   100] loss: 1.102 acc: 73.48 time: 7.78\n",
      "[4,   200] loss: 1.112 acc: 72.99 time: 8.41\n",
      "[4,   300] loss: 1.093 acc: 73.81 time: 8.05\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 74.28 %\n",
      "Average loss on the 10000 test images: 1.083\n",
      "[5,   100] loss: 1.066 acc: 74.89 time: 8.28\n",
      "[5,   200] loss: 1.064 acc: 74.79 time: 7.42\n",
      "[5,   300] loss: 1.047 acc: 75.87 time: 8.51\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 75.04 %\n",
      "Average loss on the 10000 test images: 1.072\n",
      "[6,   100] loss: 1.023 acc: 76.66 time: 7.82\n",
      "[6,   200] loss: 1.019 acc: 77.29 time: 8.97\n",
      "[6,   300] loss: 1.021 acc: 76.95 time: 8.57\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 76.67 %\n",
      "Average loss on the 10000 test images: 1.031\n",
      "[7,   100] loss: 0.996 acc: 77.90 time: 7.84\n",
      "[7,   200] loss: 0.989 acc: 78.48 time: 8.67\n",
      "[7,   300] loss: 0.985 acc: 79.01 time: 8.26\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 76.83 %\n",
      "Average loss on the 10000 test images: 1.029\n",
      "[8,   100] loss: 0.966 acc: 79.57 time: 7.77\n",
      "[8,   200] loss: 0.976 acc: 78.77 time: 8.04\n",
      "[8,   300] loss: 0.974 acc: 79.27 time: 8.06\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 78.78 %\n",
      "Average loss on the 10000 test images: 0.990\n",
      "[9,   100] loss: 0.940 acc: 80.58 time: 7.78\n",
      "[9,   200] loss: 0.951 acc: 80.09 time: 8.31\n",
      "[9,   300] loss: 0.965 acc: 79.36 time: 8.47\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 78.25 %\n",
      "Average loss on the 10000 test images: 0.992\n",
      "[10,   100] loss: 0.923 acc: 81.41 time: 8.32\n",
      "[10,   200] loss: 0.944 acc: 80.21 time: 8.49\n",
      "[10,   300] loss: 0.927 acc: 81.13 time: 8.54\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 79.10 %\n",
      "Average loss on the 10000 test images: 0.978\n",
      "[11,   100] loss: 0.872 acc: 83.39 time: 7.90\n",
      "[11,   200] loss: 0.852 acc: 84.55 time: 9.12\n",
      "[11,   300] loss: 0.840 acc: 85.03 time: 8.81\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 82.81 %\n",
      "Average loss on the 10000 test images: 0.893\n",
      "[12,   100] loss: 0.828 acc: 85.57 time: 8.20\n",
      "[12,   200] loss: 0.832 acc: 85.36 time: 8.82\n",
      "[12,   300] loss: 0.835 acc: 84.97 time: 7.84\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 82.76 %\n",
      "Average loss on the 10000 test images: 0.888\n",
      "[13,   100] loss: 0.823 acc: 85.93 time: 8.57\n",
      "[13,   200] loss: 0.827 acc: 85.55 time: 9.01\n",
      "[13,   300] loss: 0.817 acc: 85.96 time: 8.43\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 82.92 %\n",
      "Average loss on the 10000 test images: 0.886\n",
      "[14,   100] loss: 0.809 acc: 86.28 time: 7.99\n",
      "[14,   200] loss: 0.803 acc: 86.52 time: 8.15\n",
      "[14,   300] loss: 0.821 acc: 85.91 time: 7.85\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 82.91 %\n",
      "Average loss on the 10000 test images: 0.883\n",
      "[15,   100] loss: 0.807 acc: 86.41 time: 7.93\n",
      "[15,   200] loss: 0.801 acc: 86.56 time: 9.09\n",
      "[15,   300] loss: 0.810 acc: 86.14 time: 8.14\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 82.96 %\n",
      "Average loss on the 10000 test images: 0.883\n",
      "[16,   100] loss: 0.793 acc: 87.18 time: 8.73\n",
      "[16,   200] loss: 0.807 acc: 86.08 time: 9.17\n",
      "[16,   300] loss: 0.799 acc: 87.11 time: 8.48\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 83.00 %\n",
      "Average loss on the 10000 test images: 0.882\n",
      "[17,   100] loss: 0.785 acc: 87.31 time: 8.28\n",
      "[17,   200] loss: 0.805 acc: 86.62 time: 9.09\n",
      "[17,   300] loss: 0.789 acc: 87.27 time: 7.87\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 83.45 %\n",
      "Average loss on the 10000 test images: 0.876\n",
      "[18,   100] loss: 0.789 acc: 87.59 time: 8.87\n",
      "[18,   200] loss: 0.782 acc: 87.57 time: 7.95\n",
      "[18,   300] loss: 0.797 acc: 86.85 time: 8.53\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 83.44 %\n",
      "Average loss on the 10000 test images: 0.873\n",
      "[19,   100] loss: 0.774 acc: 87.85 time: 8.04\n",
      "[19,   200] loss: 0.792 acc: 87.21 time: 8.13\n",
      "[19,   300] loss: 0.787 acc: 87.45 time: 9.17\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 83.38 %\n",
      "Average loss on the 10000 test images: 0.874\n",
      "[20,   100] loss: 0.790 acc: 86.91 time: 8.83\n",
      "[20,   200] loss: 0.784 acc: 87.73 time: 7.86\n",
      "[20,   300] loss: 0.788 acc: 87.45 time: 8.43\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 83.28 %\n",
      "Average loss on the 10000 test images: 0.875\n",
      "[21,   100] loss: 0.772 acc: 88.07 time: 8.26\n",
      "[21,   200] loss: 0.768 acc: 88.13 time: 8.61\n",
      "[21,   300] loss: 0.777 acc: 87.70 time: 8.49\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 83.54 %\n",
      "Average loss on the 10000 test images: 0.871\n",
      "[22,   100] loss: 0.764 acc: 88.46 time: 8.07\n",
      "[22,   200] loss: 0.772 acc: 88.30 time: 8.74\n",
      "[22,   300] loss: 0.775 acc: 87.85 time: 8.60\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 83.80 %\n",
      "Average loss on the 10000 test images: 0.870\n",
      "[23,   100] loss: 0.762 acc: 88.21 time: 8.50\n",
      "[23,   200] loss: 0.766 acc: 88.30 time: 8.69\n",
      "[23,   300] loss: 0.769 acc: 88.26 time: 7.82\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 83.75 %\n",
      "Average loss on the 10000 test images: 0.870\n",
      "[24,   100] loss: 0.763 acc: 88.48 time: 8.57\n",
      "[24,   200] loss: 0.763 acc: 88.47 time: 8.43\n",
      "[24,   300] loss: 0.777 acc: 87.93 time: 8.22\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 83.92 %\n",
      "Average loss on the 10000 test images: 0.868\n",
      "[25,   100] loss: 0.761 acc: 88.47 time: 8.92\n",
      "[25,   200] loss: 0.772 acc: 87.87 time: 8.54\n",
      "[25,   300] loss: 0.768 acc: 88.04 time: 8.89\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 83.80 %\n",
      "Average loss on the 10000 test images: 0.869\n",
      "[26,   100] loss: 0.763 acc: 88.39 time: 8.51\n",
      "[26,   200] loss: 0.759 acc: 88.52 time: 8.39\n",
      "[26,   300] loss: 0.769 acc: 88.05 time: 7.94\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 83.77 %\n",
      "Average loss on the 10000 test images: 0.868\n",
      "[27,   100] loss: 0.760 acc: 88.80 time: 8.45\n",
      "[27,   200] loss: 0.759 acc: 88.53 time: 8.24\n",
      "[27,   300] loss: 0.777 acc: 87.57 time: 8.79\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 83.85 %\n",
      "Average loss on the 10000 test images: 0.870\n",
      "[28,   100] loss: 0.768 acc: 88.23 time: 8.55\n",
      "[28,   200] loss: 0.757 acc: 88.90 time: 8.68\n",
      "[28,   300] loss: 0.767 acc: 88.14 time: 8.20\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 83.85 %\n",
      "Average loss on the 10000 test images: 0.870\n",
      "[29,   100] loss: 0.764 acc: 88.59 time: 8.41\n",
      "[29,   200] loss: 0.770 acc: 88.00 time: 8.62\n",
      "[29,   300] loss: 0.765 acc: 88.33 time: 8.45\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 83.97 %\n",
      "Average loss on the 10000 test images: 0.867\n",
      "[30,   100] loss: 0.765 acc: 88.23 time: 8.93\n",
      "[30,   200] loss: 0.762 acc: 88.31 time: 8.47\n",
      "[30,   300] loss: 0.764 acc: 88.22 time: 8.32\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 83.94 %\n",
      "Average loss on the 10000 test images: 0.868\n",
      "[31,   100] loss: 0.769 acc: 88.20 time: 8.78\n",
      "[31,   200] loss: 0.763 acc: 88.62 time: 8.54\n",
      "[31,   300] loss: 0.764 acc: 88.48 time: 7.96\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 83.95 %\n",
      "Average loss on the 10000 test images: 0.869\n",
      "[32,   100] loss: 0.760 acc: 88.52 time: 8.60\n",
      "[32,   200] loss: 0.765 acc: 88.41 time: 8.20\n",
      "[32,   300] loss: 0.765 acc: 88.02 time: 8.28\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 84.03 %\n",
      "Average loss on the 10000 test images: 0.867\n",
      "[33,   100] loss: 0.761 acc: 88.52 time: 8.44\n",
      "[33,   200] loss: 0.757 acc: 88.30 time: 8.76\n",
      "[33,   300] loss: 0.770 acc: 88.40 time: 8.02\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 83.94 %\n",
      "Average loss on the 10000 test images: 0.869\n",
      "[34,   100] loss: 0.767 acc: 88.19 time: 8.13\n",
      "[34,   200] loss: 0.752 acc: 88.98 time: 8.62\n",
      "[34,   300] loss: 0.753 acc: 88.84 time: 8.58\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 83.94 %\n",
      "Average loss on the 10000 test images: 0.868\n",
      "[35,   100] loss: 0.765 acc: 88.37 time: 8.33\n",
      "[35,   200] loss: 0.754 acc: 88.52 time: 8.49\n",
      "[35,   300] loss: 0.762 acc: 88.51 time: 8.12\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 83.92 %\n",
      "Average loss on the 10000 test images: 0.868\n",
      "[36,   100] loss: 0.760 acc: 88.38 time: 8.73\n",
      "[36,   200] loss: 0.757 acc: 88.43 time: 8.51\n",
      "[36,   300] loss: 0.762 acc: 88.37 time: 8.36\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 83.89 %\n",
      "Average loss on the 10000 test images: 0.869\n",
      "[37,   100] loss: 0.767 acc: 88.32 time: 8.39\n",
      "[37,   200] loss: 0.768 acc: 88.38 time: 7.91\n",
      "[37,   300] loss: 0.759 acc: 88.35 time: 8.28\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 83.91 %\n",
      "Average loss on the 10000 test images: 0.868\n",
      "[38,   100] loss: 0.752 acc: 88.84 time: 8.10\n",
      "[38,   200] loss: 0.761 acc: 88.63 time: 8.31\n",
      "[38,   300] loss: 0.768 acc: 87.95 time: 8.81\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 83.89 %\n",
      "Average loss on the 10000 test images: 0.868\n",
      "[39,   100] loss: 0.768 acc: 88.19 time: 9.17\n",
      "[39,   200] loss: 0.758 acc: 88.77 time: 8.19\n",
      "[39,   300] loss: 0.764 acc: 88.45 time: 8.33\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 84.05 %\n",
      "Average loss on the 10000 test images: 0.868\n",
      "[40,   100] loss: 0.754 acc: 88.90 time: 8.87\n",
      "[40,   200] loss: 0.764 acc: 88.21 time: 8.87\n",
      "[40,   300] loss: 0.755 acc: 88.66 time: 8.10\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 83.93 %\n",
      "Average loss on the 10000 test images: 0.868\n",
      "[41,   100] loss: 0.758 acc: 88.67 time: 8.29\n",
      "[41,   200] loss: 0.760 acc: 88.30 time: 8.41\n",
      "[41,   300] loss: 0.761 acc: 88.44 time: 8.01\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 83.84 %\n",
      "Average loss on the 10000 test images: 0.868\n",
      "[42,   100] loss: 0.765 acc: 88.41 time: 9.11\n",
      "[42,   200] loss: 0.763 acc: 88.59 time: 8.25\n",
      "[42,   300] loss: 0.755 acc: 89.04 time: 8.10\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 84.00 %\n",
      "Average loss on the 10000 test images: 0.868\n",
      "[43,   100] loss: 0.763 acc: 88.48 time: 9.01\n",
      "[43,   200] loss: 0.761 acc: 88.84 time: 8.59\n",
      "[43,   300] loss: 0.760 acc: 88.55 time: 8.52\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 84.02 %\n",
      "Average loss on the 10000 test images: 0.867\n",
      "[44,   100] loss: 0.758 acc: 88.79 time: 8.65\n",
      "[44,   200] loss: 0.767 acc: 88.09 time: 8.26\n",
      "[44,   300] loss: 0.764 acc: 88.62 time: 7.98\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 83.93 %\n",
      "Average loss on the 10000 test images: 0.868\n",
      "[45,   100] loss: 0.765 acc: 88.50 time: 8.66\n",
      "[45,   200] loss: 0.775 acc: 87.86 time: 7.81\n",
      "[45,   300] loss: 0.763 acc: 88.48 time: 8.63\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 84.00 %\n",
      "Average loss on the 10000 test images: 0.867\n",
      "[46,   100] loss: 0.759 acc: 88.73 time: 8.10\n",
      "[46,   200] loss: 0.763 acc: 88.02 time: 8.61\n",
      "[46,   300] loss: 0.759 acc: 88.60 time: 9.12\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 83.84 %\n",
      "Average loss on the 10000 test images: 0.869\n",
      "[47,   100] loss: 0.759 acc: 88.75 time: 8.05\n",
      "[47,   200] loss: 0.760 acc: 88.42 time: 7.87\n",
      "[47,   300] loss: 0.763 acc: 88.36 time: 8.44\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 83.86 %\n",
      "Average loss on the 10000 test images: 0.869\n",
      "[48,   100] loss: 0.765 acc: 88.08 time: 8.24\n",
      "[48,   200] loss: 0.761 acc: 88.36 time: 7.81\n",
      "[48,   300] loss: 0.756 acc: 88.76 time: 8.39\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 83.92 %\n",
      "Average loss on the 10000 test images: 0.867\n",
      "[49,   100] loss: 0.773 acc: 88.14 time: 9.18\n",
      "[49,   200] loss: 0.755 acc: 88.73 time: 8.29\n",
      "[49,   300] loss: 0.758 acc: 88.82 time: 8.02\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 84.01 %\n",
      "Average loss on the 10000 test images: 0.868\n",
      "[50,   100] loss: 0.764 acc: 88.10 time: 8.33\n",
      "[50,   200] loss: 0.756 acc: 88.93 time: 9.32\n",
      "[50,   300] loss: 0.766 acc: 88.40 time: 8.41\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 83.97 %\n",
      "Average loss on the 10000 test images: 0.868\n",
      "Restored best model from epoch with validation accuracy: 84.05%\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "train(net, criterion, optimizer, num_epochs=50, decay_epochs=10, init_lr=0.01, task='classification', experiment_type='Supervised Pre-trained Model')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-05T08:49:44.210012600Z",
     "start_time": "2023-11-05T08:18:40.612704300Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Supervised training on the randomly initialized model (9 points)\n",
    "In this section, we will randomly initialize a ResNet18 model and re-train the whole model on the classification task."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torchvision.models import resnet18\n",
    "\n",
    "#################################################\n",
    "# TODO: Randomly initialize a ResNet18 model    #\n",
    "#################################################\n",
    "net = resnet18(weights=None, num_classes=10)\n",
    "net = net.to(device)\n",
    "#################################################\n",
    "#              End of your code                 #\n",
    "#################################################"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-05T08:49:44.358636200Z",
     "start_time": "2023-11-05T08:49:44.203006100Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "outputs": [
    {
     "data": {
      "text/plain": "CrossEntropyLoss()"
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO: Define criterion and optimizer\n",
    "criterion = nn.CrossEntropyLoss(label_smoothing=label_smoothing)\n",
    "\n",
    "# Optimizer: Update only the parameters of layer4 and fc\n",
    "optimizer = optim.Adam(lr=0.001, params=net.parameters())\n",
    "\n",
    "criterion.to(device)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-05T08:49:44.366323300Z",
     "start_time": "2023-11-05T08:49:44.359638200Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,   100] loss: 2.313 acc: 22.95 time: 8.58\n",
      "[1,   200] loss: 1.950 acc: 32.47 time: 9.45\n",
      "[1,   300] loss: 1.886 acc: 35.87 time: 8.31\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 44.95 %\n",
      "Average loss on the 10000 test images: 1.671\n",
      "[2,   100] loss: 1.726 acc: 42.52 time: 8.81\n",
      "[2,   200] loss: 1.654 acc: 46.01 time: 8.24\n",
      "[2,   300] loss: 1.607 acc: 48.37 time: 8.63\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 52.38 %\n",
      "Average loss on the 10000 test images: 1.550\n",
      "[3,   100] loss: 1.492 acc: 54.04 time: 9.73\n",
      "[3,   200] loss: 1.459 acc: 56.47 time: 9.22\n",
      "[3,   300] loss: 1.416 acc: 58.34 time: 8.14\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 62.67 %\n",
      "Average loss on the 10000 test images: 1.340\n",
      "[4,   100] loss: 1.360 acc: 61.15 time: 9.08\n",
      "[4,   200] loss: 1.338 acc: 62.12 time: 8.20\n",
      "[4,   300] loss: 1.324 acc: 62.57 time: 8.06\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 64.43 %\n",
      "Average loss on the 10000 test images: 1.295\n",
      "[5,   100] loss: 1.279 acc: 64.84 time: 9.08\n",
      "[5,   200] loss: 1.273 acc: 64.54 time: 8.87\n",
      "[5,   300] loss: 1.249 acc: 66.41 time: 8.45\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 68.33 %\n",
      "Average loss on the 10000 test images: 1.205\n",
      "[6,   100] loss: 1.202 acc: 68.66 time: 8.45\n",
      "[6,   200] loss: 1.182 acc: 69.19 time: 8.49\n",
      "[6,   300] loss: 1.179 acc: 69.95 time: 8.46\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 71.19 %\n",
      "Average loss on the 10000 test images: 1.150\n",
      "[7,   100] loss: 1.146 acc: 71.30 time: 8.12\n",
      "[7,   200] loss: 1.158 acc: 70.38 time: 8.03\n",
      "[7,   300] loss: 1.135 acc: 71.75 time: 8.49\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 71.85 %\n",
      "Average loss on the 10000 test images: 1.153\n",
      "[8,   100] loss: 1.103 acc: 73.23 time: 8.06\n",
      "[8,   200] loss: 1.102 acc: 73.28 time: 8.29\n",
      "[8,   300] loss: 1.095 acc: 73.62 time: 8.11\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 72.62 %\n",
      "Average loss on the 10000 test images: 1.139\n",
      "[9,   100] loss: 1.076 acc: 74.73 time: 8.04\n",
      "[9,   200] loss: 1.080 acc: 74.16 time: 8.79\n",
      "[9,   300] loss: 1.070 acc: 75.26 time: 8.19\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 74.04 %\n",
      "Average loss on the 10000 test images: 1.107\n",
      "[10,   100] loss: 1.051 acc: 75.32 time: 8.42\n",
      "[10,   200] loss: 1.029 acc: 76.74 time: 8.75\n",
      "[10,   300] loss: 1.047 acc: 75.66 time: 7.95\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 76.41 %\n",
      "Average loss on the 10000 test images: 1.041\n",
      "[11,   100] loss: 0.979 acc: 78.88 time: 8.40\n",
      "[11,   200] loss: 0.941 acc: 80.27 time: 9.42\n",
      "[11,   300] loss: 0.941 acc: 80.28 time: 8.14\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 80.06 %\n",
      "Average loss on the 10000 test images: 0.951\n",
      "[12,   100] loss: 0.914 acc: 81.97 time: 8.62\n",
      "[12,   200] loss: 0.915 acc: 81.58 time: 8.38\n",
      "[12,   300] loss: 0.914 acc: 81.43 time: 8.40\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 80.63 %\n",
      "Average loss on the 10000 test images: 0.940\n",
      "[13,   100] loss: 0.895 acc: 82.34 time: 8.29\n",
      "[13,   200] loss: 0.911 acc: 81.53 time: 8.29\n",
      "[13,   300] loss: 0.893 acc: 82.48 time: 8.04\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 80.71 %\n",
      "Average loss on the 10000 test images: 0.931\n",
      "[14,   100] loss: 0.891 acc: 82.79 time: 8.64\n",
      "[14,   200] loss: 0.886 acc: 83.01 time: 9.10\n",
      "[14,   300] loss: 0.899 acc: 82.05 time: 8.08\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 81.23 %\n",
      "Average loss on the 10000 test images: 0.925\n",
      "[15,   100] loss: 0.875 acc: 83.11 time: 8.78\n",
      "[15,   200] loss: 0.878 acc: 83.10 time: 8.27\n",
      "[15,   300] loss: 0.878 acc: 83.09 time: 8.50\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 80.84 %\n",
      "Average loss on the 10000 test images: 0.926\n",
      "[16,   100] loss: 0.878 acc: 83.16 time: 8.86\n",
      "[16,   200] loss: 0.878 acc: 83.38 time: 8.63\n",
      "[16,   300] loss: 0.868 acc: 83.75 time: 8.22\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 81.33 %\n",
      "Average loss on the 10000 test images: 0.920\n",
      "[17,   100] loss: 0.859 acc: 84.10 time: 8.80\n",
      "[17,   200] loss: 0.868 acc: 83.73 time: 7.92\n",
      "[17,   300] loss: 0.862 acc: 83.86 time: 8.43\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 81.45 %\n",
      "Average loss on the 10000 test images: 0.919\n",
      "[18,   100] loss: 0.858 acc: 84.45 time: 8.88\n",
      "[18,   200] loss: 0.856 acc: 83.95 time: 8.85\n",
      "[18,   300] loss: 0.857 acc: 84.23 time: 8.46\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 81.70 %\n",
      "Average loss on the 10000 test images: 0.916\n",
      "[19,   100] loss: 0.855 acc: 84.15 time: 9.08\n",
      "[19,   200] loss: 0.846 acc: 84.55 time: 8.41\n",
      "[19,   300] loss: 0.851 acc: 84.39 time: 8.14\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 81.61 %\n",
      "Average loss on the 10000 test images: 0.915\n",
      "[20,   100] loss: 0.837 acc: 85.30 time: 9.52\n",
      "[20,   200] loss: 0.849 acc: 84.34 time: 8.36\n",
      "[20,   300] loss: 0.851 acc: 84.34 time: 8.32\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 81.99 %\n",
      "Average loss on the 10000 test images: 0.908\n",
      "[21,   100] loss: 0.828 acc: 85.36 time: 8.00\n",
      "[21,   200] loss: 0.823 acc: 85.67 time: 8.66\n",
      "[21,   300] loss: 0.828 acc: 85.34 time: 8.25\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 82.17 %\n",
      "Average loss on the 10000 test images: 0.904\n",
      "[22,   100] loss: 0.826 acc: 85.74 time: 8.86\n",
      "[22,   200] loss: 0.826 acc: 85.80 time: 9.24\n",
      "[22,   300] loss: 0.818 acc: 85.81 time: 9.00\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 82.24 %\n",
      "Average loss on the 10000 test images: 0.901\n",
      "[23,   100] loss: 0.831 acc: 85.53 time: 9.11\n",
      "[23,   200] loss: 0.831 acc: 85.38 time: 7.98\n",
      "[23,   300] loss: 0.819 acc: 85.71 time: 9.02\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 82.36 %\n",
      "Average loss on the 10000 test images: 0.901\n",
      "[24,   100] loss: 0.814 acc: 86.23 time: 8.63\n",
      "[24,   200] loss: 0.825 acc: 85.62 time: 8.24\n",
      "[24,   300] loss: 0.822 acc: 85.69 time: 8.20\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 82.41 %\n",
      "Average loss on the 10000 test images: 0.902\n",
      "[25,   100] loss: 0.817 acc: 86.11 time: 7.79\n",
      "[25,   200] loss: 0.815 acc: 86.18 time: 8.15\n",
      "[25,   300] loss: 0.815 acc: 86.17 time: 8.62\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 82.48 %\n",
      "Average loss on the 10000 test images: 0.900\n",
      "[26,   100] loss: 0.811 acc: 86.27 time: 8.87\n",
      "[26,   200] loss: 0.813 acc: 86.19 time: 8.91\n",
      "[26,   300] loss: 0.815 acc: 86.11 time: 8.74\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 82.70 %\n",
      "Average loss on the 10000 test images: 0.900\n",
      "[27,   100] loss: 0.809 acc: 86.39 time: 8.88\n",
      "[27,   200] loss: 0.823 acc: 85.79 time: 8.43\n",
      "[27,   300] loss: 0.812 acc: 86.14 time: 9.02\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 82.58 %\n",
      "Average loss on the 10000 test images: 0.901\n",
      "[28,   100] loss: 0.813 acc: 86.19 time: 9.09\n",
      "[28,   200] loss: 0.813 acc: 86.19 time: 9.17\n",
      "[28,   300] loss: 0.807 acc: 86.40 time: 9.01\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 82.43 %\n",
      "Average loss on the 10000 test images: 0.900\n",
      "[29,   100] loss: 0.811 acc: 86.36 time: 8.37\n",
      "[29,   200] loss: 0.817 acc: 86.02 time: 8.37\n",
      "[29,   300] loss: 0.809 acc: 86.18 time: 8.62\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 82.75 %\n",
      "Average loss on the 10000 test images: 0.899\n",
      "[30,   100] loss: 0.809 acc: 86.04 time: 8.90\n",
      "[30,   200] loss: 0.804 acc: 86.35 time: 8.43\n",
      "[30,   300] loss: 0.818 acc: 85.95 time: 8.67\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 82.59 %\n",
      "Average loss on the 10000 test images: 0.899\n",
      "[31,   100] loss: 0.801 acc: 86.75 time: 8.77\n",
      "[31,   200] loss: 0.810 acc: 86.47 time: 9.18\n",
      "[31,   300] loss: 0.819 acc: 85.82 time: 8.15\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 82.79 %\n",
      "Average loss on the 10000 test images: 0.899\n",
      "[32,   100] loss: 0.811 acc: 86.01 time: 8.84\n",
      "[32,   200] loss: 0.809 acc: 86.56 time: 8.06\n",
      "[32,   300] loss: 0.805 acc: 86.42 time: 8.64\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 82.52 %\n",
      "Average loss on the 10000 test images: 0.900\n",
      "[33,   100] loss: 0.817 acc: 86.20 time: 8.71\n",
      "[33,   200] loss: 0.810 acc: 86.21 time: 8.56\n",
      "[33,   300] loss: 0.808 acc: 86.54 time: 8.50\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 82.66 %\n",
      "Average loss on the 10000 test images: 0.900\n",
      "[34,   100] loss: 0.812 acc: 86.09 time: 8.01\n",
      "[34,   200] loss: 0.812 acc: 86.02 time: 8.65\n",
      "[34,   300] loss: 0.807 acc: 86.75 time: 8.08\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 82.60 %\n",
      "Average loss on the 10000 test images: 0.899\n",
      "[35,   100] loss: 0.806 acc: 86.39 time: 8.77\n",
      "[35,   200] loss: 0.811 acc: 86.09 time: 8.72\n",
      "[35,   300] loss: 0.809 acc: 86.38 time: 7.95\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 82.75 %\n",
      "Average loss on the 10000 test images: 0.899\n",
      "[36,   100] loss: 0.811 acc: 86.18 time: 8.34\n",
      "[36,   200] loss: 0.810 acc: 86.16 time: 8.48\n",
      "[36,   300] loss: 0.806 acc: 86.31 time: 9.74\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 82.66 %\n",
      "Average loss on the 10000 test images: 0.898\n",
      "[37,   100] loss: 0.807 acc: 86.55 time: 8.08\n",
      "[37,   200] loss: 0.816 acc: 86.07 time: 8.54\n",
      "[37,   300] loss: 0.806 acc: 86.24 time: 7.94\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 82.68 %\n",
      "Average loss on the 10000 test images: 0.899\n",
      "[38,   100] loss: 0.801 acc: 86.81 time: 8.63\n",
      "[38,   200] loss: 0.813 acc: 86.28 time: 9.08\n",
      "[38,   300] loss: 0.811 acc: 86.25 time: 8.35\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 82.64 %\n",
      "Average loss on the 10000 test images: 0.900\n",
      "[39,   100] loss: 0.812 acc: 86.07 time: 8.31\n",
      "[39,   200] loss: 0.808 acc: 86.55 time: 8.67\n",
      "[39,   300] loss: 0.814 acc: 86.07 time: 8.90\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 82.53 %\n",
      "Average loss on the 10000 test images: 0.899\n",
      "[40,   100] loss: 0.802 acc: 86.72 time: 9.02\n",
      "[40,   200] loss: 0.812 acc: 86.12 time: 9.18\n",
      "[40,   300] loss: 0.812 acc: 86.16 time: 8.00\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 82.68 %\n",
      "Average loss on the 10000 test images: 0.900\n",
      "[41,   100] loss: 0.807 acc: 86.43 time: 7.95\n",
      "[41,   200] loss: 0.811 acc: 86.27 time: 8.85\n",
      "[41,   300] loss: 0.804 acc: 86.45 time: 7.98\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 82.66 %\n",
      "Average loss on the 10000 test images: 0.899\n",
      "[42,   100] loss: 0.811 acc: 86.22 time: 8.99\n",
      "[42,   200] loss: 0.810 acc: 86.27 time: 9.07\n",
      "[42,   300] loss: 0.811 acc: 86.35 time: 9.22\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 82.42 %\n",
      "Average loss on the 10000 test images: 0.901\n",
      "[43,   100] loss: 0.815 acc: 85.98 time: 8.02\n",
      "[43,   200] loss: 0.809 acc: 86.46 time: 8.79\n",
      "[43,   300] loss: 0.802 acc: 86.52 time: 8.66\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 82.63 %\n",
      "Average loss on the 10000 test images: 0.897\n",
      "[44,   100] loss: 0.807 acc: 86.42 time: 9.07\n",
      "[44,   200] loss: 0.800 acc: 86.73 time: 8.71\n",
      "[44,   300] loss: 0.816 acc: 86.19 time: 8.15\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 82.70 %\n",
      "Average loss on the 10000 test images: 0.900\n",
      "[45,   100] loss: 0.800 acc: 86.92 time: 8.55\n",
      "[45,   200] loss: 0.811 acc: 86.52 time: 8.52\n",
      "[45,   300] loss: 0.799 acc: 86.75 time: 9.00\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 82.67 %\n",
      "Average loss on the 10000 test images: 0.899\n",
      "[46,   100] loss: 0.812 acc: 85.92 time: 8.50\n",
      "[46,   200] loss: 0.805 acc: 86.36 time: 8.46\n",
      "[46,   300] loss: 0.811 acc: 86.16 time: 8.01\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 82.83 %\n",
      "Average loss on the 10000 test images: 0.897\n",
      "[47,   100] loss: 0.812 acc: 86.35 time: 8.10\n",
      "[47,   200] loss: 0.805 acc: 86.30 time: 9.42\n",
      "[47,   300] loss: 0.815 acc: 86.13 time: 9.70\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 82.71 %\n",
      "Average loss on the 10000 test images: 0.899\n",
      "[48,   100] loss: 0.806 acc: 86.46 time: 8.14\n",
      "[48,   200] loss: 0.808 acc: 86.78 time: 8.48\n",
      "[48,   300] loss: 0.799 acc: 87.04 time: 8.35\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 82.65 %\n",
      "Average loss on the 10000 test images: 0.899\n",
      "[49,   100] loss: 0.807 acc: 86.23 time: 8.61\n",
      "[49,   200] loss: 0.807 acc: 86.20 time: 8.12\n",
      "[49,   300] loss: 0.808 acc: 86.36 time: 8.31\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 82.65 %\n",
      "Average loss on the 10000 test images: 0.899\n",
      "[50,   100] loss: 0.799 acc: 86.72 time: 8.13\n",
      "[50,   200] loss: 0.803 acc: 86.74 time: 7.95\n",
      "[50,   300] loss: 0.812 acc: 86.34 time: 7.62\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 82.72 %\n",
      "Average loss on the 10000 test images: 0.900\n",
      "Restored best model from epoch with validation accuracy: 82.83%\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "train(net, criterion, optimizer, num_epochs=50, decay_epochs=10, init_lr=0.01, task='classification', experiment_type='Supervised Randomly Initialized Model')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-05T09:21:21.484052Z",
     "start_time": "2023-11-05T08:49:44.365323Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Write report (37 points)\n",
    "\n",
    "本次作業主要有3個tasks需要大家完成，在A4.pdf中有希望大家達成的baseline **(不能低於baseline最多2%，沒有達到不會給全部分數)**，report的撰寫就希望大家可以透過去調整不同的訓練方法、損失函數、優化器，或者是調整凍結不同的層來進行這次的實驗，就請大家將嘗試的結果寫在report裡，祝大家順利！\n",
    "\n",
    "- Rotation task (13 points)\n",
    "- Fine-tuning the specified layers of the pre-trained model (12 points)\n",
    "- Fine-tuning the whole pre-trained model (12 points)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Extra Credit (13 points)\n",
    "\n",
    "上面基本的code跟report最高可以拿到87分，這個加分部分並沒有要求同學們一定要做，若同學們想要獲得更高的分數可以根據以下的加分要求來獲得加分。\n",
    "\n",
    "- In Figure 5(b) from the Gidaris et al. paper, the authors show a plot of CIFAR10 classification performance vs. number of training examples per category for a supervised CIFAR10 model vs. a RotNet model with the final layers fine-tuned on CIFAR10. The plot shows that pre-training on the Rotation task can be advantageous when only a small amount of labeled data is available. Using your RotNet fine-tuning code and supervised CIFAR10 training code from the main assignment, try to create a similar plot by performing supervised fine-tuning/training on only a subset of CIFAR10.\n",
    "- Use a more advanced model than ResNet18 to try to get higher accuracy on the rotation prediction task, as well as for transfer to supervised CIFAR10 classification.\n",
    "\n",
    "- If you have a good amount of compute at your disposal, try to train a rotation prediction model on the larger ImageNette dataset (still smaller than ImageNet, though).\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": [
    {
     "file_id": "1qQ3NEaCUln7yDSksrEOnDwrt3u9dYNr4",
     "timestamp": 1677623843954
    }
   ]
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3.8.13",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "aaa478f9632825e83f6a2247407c7a2930de96a6810af7910643e423346524f9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
