{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MIS 583 Assignment 4: Self-supervised and transfer learning on CIFAR10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we start, please put your name and SID in following format: <br>\n",
    ": LASTNAME Firstname, ?00000000   //   e.g.) 李晨愷 M114020035"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Your Answer:**    \n",
    "Hi I'm 鄔仁迪, B104020009."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "data": {
      "text/plain": "Empty DataFrame\nColumns: [Experiment Type, Epoch, Train Accuracy, Train Loss, Valid Accuracy, Valid Loss]\nIndex: []",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Experiment Type</th>\n      <th>Epoch</th>\n      <th>Train Accuracy</th>\n      <th>Train Loss</th>\n      <th>Valid Accuracy</th>\n      <th>Valid Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "experience_name = 'self_supervised_direction_4'\n",
    "label_smoothing = 0.1\n",
    "rotation_direction = 4\n",
    "\n",
    "# Define columns for the DataFrame\n",
    "columns = ['Experiment Type', 'Epoch', 'Train Accuracy', 'Train Loss', 'Valid Accuracy', 'Valid Loss']\n",
    "\n",
    "# Initialize an empty DataFrame with these columns\n",
    "experience_report = pd.DataFrame(columns=columns)\n",
    "\n",
    "experience_report"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-05T06:15:06.674576700Z",
     "start_time": "2023-11-05T06:15:05.555250Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "# Function to set the seed\n",
    "def set_seed(seed_value=42):\n",
    "    \"\"\"Set seed for reproducibility.\"\"\"\n",
    "    torch.manual_seed(seed_value)\n",
    "    torch.cuda.manual_seed(seed_value)\n",
    "    torch.cuda.manual_seed_all(seed_value)  # if you are using multi-GPU.\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    np.random.seed(seed_value)\n",
    "    random.seed(seed_value)\n",
    "\n",
    "set_seed()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-05T06:15:06.784579200Z",
     "start_time": "2023-11-05T06:15:05.631554800Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IWMWW8Ab_345"
   },
   "source": [
    "## Google Colab Setup\n",
    "Next we need to run a few commands to set up our environment on Google Colab. If you are running this notebook on a local machine you can skip this section.\n",
    "\n",
    "Run the following cell to mount your Google Drive. Follow the link, sign in to your Google account (the same account you used to store this notebook!) and copy the authorization code into the text box that appears below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "vH4wc4iD_6w_",
    "ExecuteTime": {
     "end_time": "2023-11-05T06:15:06.818583100Z",
     "start_time": "2023-11-05T06:15:05.767288Z"
    }
   },
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "XpNsPHZc_879",
    "ExecuteTime": {
     "end_time": "2023-11-05T06:15:06.818583100Z",
     "start_time": "2023-11-05T06:15:05.838573600Z"
    }
   },
   "outputs": [],
   "source": [
    "# fill in the path in your Google Drive in the string below. Note: do not escape slashes or spaces\n",
    "# import os\n",
    "# datadir = \"C:/Users/eddie/GitHub/Deep-Learning/PyTorch/Class/pytorch104\"\n",
    "# if not os.path.exists(datadir):\n",
    "#  !ln -s \"/content/drive/My Drive/Your/A4/path/\" $datadir # TODO: Fill your A3 path\n",
    "# os.chdir(datadir)\n",
    "# !pwd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Um5DJvBwb6xT"
   },
   "source": [
    "# Data Setup (5 points)\n",
    "\n",
    "The first thing to do is implement a dataset class to load rotated CIFAR10 images with matching labels. Since there is already a CIFAR10 dataset class implemented in `torchvision`, we will extend this class and modify the `__get_item__` method appropriately to load rotated images.\n",
    "\n",
    "Each rotation label should be an integer in the set {0, 1, 2, 3} which correspond to rotations of 0, 90, 180, or 270 degrees respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "oHkeNUOKiFbP",
    "ExecuteTime": {
     "end_time": "2023-11-05T06:15:06.823573200Z",
     "start_time": "2023-11-05T06:15:05.871573800Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "\n",
    "def rotate_img(img, rot):\n",
    "    \"\"\"\n",
    "    Rotates the image by a specified angle.\n",
    "\n",
    "    Parameters:\n",
    "    - img (PIL Image or Tensor): The image to be rotated.\n",
    "    - rot (int): The rotation label indicating the angle of rotation. Should be in the range [0, rotation_direction-1].\n",
    "\n",
    "    Returns:\n",
    "    - PIL Image or Tensor: The rotated image.\n",
    "    \"\"\"\n",
    "    angle = (360 / rotation_direction) * rot  # Calculate the rotation angle based on the label and the total directions\n",
    "\n",
    "    if not (0 <= rot < rotation_direction):\n",
    "        raise ValueError(f'rotation should be an integer in range [0, {rotation_direction - 1}]')\n",
    "\n",
    "    # Perform the rotation\n",
    "    return transforms.functional.rotate(img, angle)\n",
    "\n",
    "class CIFAR10Rotation(torchvision.datasets.CIFAR10):\n",
    "\n",
    "    def __init__(self, root, train, download, transform) -> None:\n",
    "        super().__init__(root=root, train=train, download=download, transform=transform)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, index: int):\n",
    "        image, cls_label = super().__getitem__(index)\n",
    "\n",
    "        # Randomly select image rotation based on the number of directions\n",
    "        rotation_label = random.randrange(rotation_direction)\n",
    "        image_rotated = rotate_img(image, rotation_label)\n",
    "\n",
    "        rotation_label = torch.tensor(rotation_label).long()\n",
    "        return image, image_rotated, rotation_label, torch.tensor(cls_label).long()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "CCBSpNWpb8uw",
    "ExecuteTime": {
     "end_time": "2023-11-05T06:15:08.565342Z",
     "start_time": "2023-11-05T06:15:05.894575400Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "transform_train = transforms.Compose([\n",
    "    transforms.RandomCrop(32, padding=4),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])\n",
    "\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])\n",
    "\n",
    "batch_size = 128\n",
    "\n",
    "trainset = CIFAR10Rotation(root='../data', train=True,\n",
    "                                        download=True, transform=transform_train)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,\n",
    "                                          shuffle=True, num_workers=0)\n",
    "\n",
    "testset = CIFAR10Rotation(root='../data', train=False,\n",
    "                                       download=True, transform=transform_test)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size,\n",
    "                                         shuffle=False, num_workers=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dOCWMyGhVOJB"
   },
   "source": [
    "Show some example images and rotated images with labels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "A9wN4BJWVMzB",
    "ExecuteTime": {
     "end_time": "2023-11-05T06:15:08.702978100Z",
     "start_time": "2023-11-05T06:15:07.945740500Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "data": {
      "text/plain": "<Figure size 640x480 with 1 Axes>",
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class labels:  frog  plane deer  car  \n"
     ]
    },
    {
     "data": {
      "text/plain": "<Figure size 640x480 with 1 Axes>",
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rotation labels:  0     0     180   90   \n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat',\n",
    "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "\n",
    "# Calculate the step size based on 360 degrees and the number of directions\n",
    "step_size = 360 // rotation_direction\n",
    "\n",
    "# Generate the rotation classes based on the number of directions\n",
    "rot_classes = tuple(str(i * step_size) for i in range(rotation_direction))\n",
    "\n",
    "\n",
    "def imshow(img):\n",
    "    # unnormalize\n",
    "    img = transforms.Normalize((0, 0, 0), (1/0.2023, 1/0.1994, 1/0.2010))(img)\n",
    "    img = transforms.Normalize((-0.4914, -0.4822, -0.4465), (1, 1, 1))(img)\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "dataiter = iter(trainloader)\n",
    "images, rot_images, rot_labels, labels = next(dataiter)\n",
    "\n",
    "# print images and rotated images\n",
    "img_grid = imshow(torchvision.utils.make_grid(images[:4], padding=0))\n",
    "print('Class labels: ', ' '.join(f'{classes[labels[j]]:5s}' for j in range(4)))\n",
    "img_grid = imshow(torchvision.utils.make_grid(rot_images[:4], padding=0))\n",
    "print('Rotation labels: ', ' '.join(f'{rot_classes[rot_labels[j]]:5s}' for j in range(4)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "unCucbHexG4W"
   },
   "source": [
    "# Evaluation code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "pptQRpqK0rOl",
    "ExecuteTime": {
     "end_time": "2023-11-05T06:15:08.702978100Z",
     "start_time": "2023-11-05T06:15:08.271832400Z"
    }
   },
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def run_test(net, testloader, criterion, task):\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    avg_test_loss = 0.0\n",
    "    # since we're not training, we don't need to calculate the gradients for our outputs\n",
    "    with torch.no_grad():\n",
    "        for images, images_rotated, labels, cls_labels in testloader:\n",
    "            if task == 'rotation':\n",
    "              images, labels = images_rotated.to(device), labels.to(device)\n",
    "            elif task == 'classification':\n",
    "              images, labels = images.to(device), cls_labels.to(device)\n",
    "            #######################################################################\n",
    "            # TODO: Calculate outputs by running images through the network       #\n",
    "            # The class with the highest energy is what we choose as prediction   #\n",
    "            #######################################################################\n",
    "            # Calculate outputs by running images through the network\n",
    "            outputs = net(images)\n",
    "\n",
    "            # The class with the highest score is what we choose as our prediction\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            #######################################################################\n",
    "            #                           End of your code                          #\n",
    "            #######################################################################\n",
    "            avg_test_loss += criterion(outputs, labels)  / len(testloader)\n",
    "    print('TESTING:')\n",
    "    print(f'Accuracy of the network on the 10000 test images: {100 * correct / total:.2f} %')\n",
    "    print(f'Average loss on the 10000 test images: {avg_test_loss:.3f}')\n",
    "\n",
    "    return avg_test_loss, 100 * correct / total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "hf698c16A9k5",
    "ExecuteTime": {
     "end_time": "2023-11-05T06:15:08.703977900Z",
     "start_time": "2023-11-05T06:15:08.279956400Z"
    }
   },
   "outputs": [],
   "source": [
    "def adjust_learning_rate(optimizer, epoch, init_lr, decay_epochs=30):\n",
    "    \"\"\"Sets the learning rate to the initial LR decayed by 10 every 30 epochs\"\"\"\n",
    "    lr = init_lr * (0.1 ** (epoch // decay_epochs))\n",
    "    for param_group in optimizer.param_groups:\n",
    "        param_group['lr'] = lr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3lYdnb1Wsta_"
   },
   "source": [
    "# Train a ResNet18 on the rotation task (9 points)\n",
    "\n",
    "In this section, we will train a ResNet18 model **from scratch** on the rotation task. The input is a rotated image and the model predicts the rotation label. See the Data Setup section for details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "knAiwdURvBHk",
    "ExecuteTime": {
     "end_time": "2023-11-05T06:15:08.703977900Z",
     "start_time": "2023-11-05T06:15:08.292347800Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "'cuda'"
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Notice: You should not use pretrained weights from ImageNet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "235MEIUgsv65",
    "ExecuteTime": {
     "end_time": "2023-11-05T06:15:08.744977200Z",
     "start_time": "2023-11-05T06:15:08.305347300Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torchvision.models import resnet18\n",
    "\n",
    "net = resnet18(weights = None, num_classes=rotation_direction) # Do not modify this line.\n",
    "net = net.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "Vuhiw0ZoszAd",
    "ExecuteTime": {
     "end_time": "2023-11-05T06:15:08.744977200Z",
     "start_time": "2023-11-05T06:15:08.577205300Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "################################################################################\n",
    "# TODO: Define loss and optmizer functions                                     #\n",
    "# Try any loss or optimizer function and learning rate to get better result    #\n",
    "# hint: torch.nn and torch.optim                                               #\n",
    "################################################################################\n",
    "# Loss and optimizer\n",
    "criterion = nn.CrossEntropyLoss(label_smoothing=label_smoothing)\n",
    "learning_rate = 0.001\n",
    "optimizer = optim.Adam(net.parameters(), lr=learning_rate)\n",
    "################################################################################\n",
    "#                               End of your code                               #\n",
    "################################################################################\n",
    "criterion = criterion.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "WleH-YBgs0rq",
    "ExecuteTime": {
     "end_time": "2023-11-05T06:15:08.745978600Z",
     "start_time": "2023-11-05T06:15:08.584719Z"
    }
   },
   "outputs": [],
   "source": [
    "# Both the self-supervised rotation task and supervised CIFAR10 classification are\n",
    "# trained with the CrossEntropyLoss, so we can use the training loop code.\n",
    "\n",
    "def train(net, criterion, optimizer, num_epochs, decay_epochs, init_lr, task, experiment_type=None):\n",
    "    global experience_report\n",
    "    best_valid_acc = 0.0  # Initialize best validation accuracy\n",
    "    best_model_state = None  # Initialize best model state\n",
    "\n",
    "    for epoch in range(num_epochs):  # loop over the dataset multiple times\n",
    "        # Initialize epoch variables\n",
    "        total_loss = 0.0\n",
    "        total_correct = 0.0\n",
    "        total_samples = 0.0\n",
    "\n",
    "        running_loss = 0.0\n",
    "        running_correct = 0.0\n",
    "        running_total = 0.0\n",
    "        start_time = time.time()\n",
    "\n",
    "        net.train()\n",
    "\n",
    "        for i, (imgs, imgs_rotated, rotation_label, cls_label) in enumerate(trainloader, 0):\n",
    "            adjust_learning_rate(optimizer, epoch, init_lr, decay_epochs)\n",
    "            ######################################################################################################\n",
    "            # TODO: Set the data to the correct device; Different task will use different inputs and labels      #  \n",
    "            # TODO: Zero the parameter gradients                                                                 #\n",
    "            # TODO: forward + backward + optimize                                                                #\n",
    "            # TODO: Get predicted results                                                                        #\n",
    "            ######################################################################################################\n",
    "            # Set data to the correct device\n",
    "            if task == 'rotation':\n",
    "                inputs, labels = imgs_rotated.to(device), rotation_label.to(device)\n",
    "            elif task == 'classification':\n",
    "                inputs, labels = imgs.to(device), cls_label.to(device)\n",
    "\n",
    "            optimizer.zero_grad()  # Zero the parameter gradients\n",
    "\n",
    "            # Forward + backward + optimize\n",
    "            outputs = net(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # Get predicted results for accuracy calculation\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            ######################################################################################################\n",
    "            #                               End of your code                                                     #\n",
    "            ######################################################################################################\n",
    "\n",
    "            # print statistics\n",
    "            print_freq = 100\n",
    "            running_loss += loss.item()\n",
    "\n",
    "            # calc acc\n",
    "            running_total += labels.size(0)\n",
    "            running_correct += (predicted == labels).sum().item()\n",
    "\n",
    "            # Update total counts for epoch averages\n",
    "            total_loss += loss.item()\n",
    "            total_samples += labels.size(0)\n",
    "            total_correct += (predicted == labels).sum().item()\n",
    "\n",
    "            if i % print_freq == (print_freq - 1):    # print every 2000 mini-batches\n",
    "                print(f'[{epoch + 1}, {i + 1:5d}] loss: {running_loss / print_freq:.3f} acc: {100*running_correct / running_total:.2f} time: {time.time() - start_time:.2f}')\n",
    "                running_loss, running_correct, running_total = 0.0, 0.0, 0.0\n",
    "                start_time = time.time()\n",
    "        ######################################################################################################\n",
    "        # TODO: Run the run_test() function after each epoch; Set the model to the evaluation mode.          #\n",
    "        ######################################################################################################\n",
    "        # Calculate average training loss and accuracy for the epoch\n",
    "        avg_train_loss = total_loss / len(trainloader)\n",
    "        avg_train_acc = 100 * total_correct / total_samples\n",
    "\n",
    "        # Evaluate the model after each epoch\n",
    "        net.eval()\n",
    "        test_loss, test_acc = run_test(net, testloader, criterion, task)\n",
    "\n",
    "        # Check if this is the best model so far\n",
    "        if test_acc > best_valid_acc:\n",
    "            best_valid_acc = test_acc\n",
    "            best_model_state = net.state_dict()  # Save the best model state\n",
    "\n",
    "        # Append the epoch's results to the report DataFrame\n",
    "        if experience_report is not None and experiment_type is not None:\n",
    "            new_row = pd.DataFrame({\n",
    "                'Experiment Type': [experiment_type],\n",
    "                'Epoch': [epoch + 1],\n",
    "                'Train Accuracy': [avg_train_acc.cpu().numpy()] if torch.is_tensor(avg_train_acc) else [avg_train_acc],\n",
    "                'Train Loss': [avg_train_loss.cpu().numpy()] if torch.is_tensor(avg_train_loss) else [avg_train_loss],\n",
    "                'Valid Accuracy': [test_acc.cpu().numpy()] if torch.is_tensor(test_acc) else [test_acc],\n",
    "                'Valid Loss': [test_loss.cpu().numpy()] if torch.is_tensor(test_loss) else [test_loss]\n",
    "            })\n",
    "            experience_report = pd.concat([experience_report, new_row], ignore_index=True)\n",
    "        ######################################################################################################\n",
    "        #                               End of your code                                                     #\n",
    "        ######################################################################################################\n",
    "    # Restore the best model state\n",
    "    if best_model_state:\n",
    "        net.load_state_dict(best_model_state)\n",
    "        print(f'Restored best model from epoch with validation accuracy: {best_valid_acc:.2f}%')\n",
    "\n",
    "    # Save the report DataFrame after the experiment\n",
    "    if experience_report is not None and experiment_type is not None:\n",
    "        experience_report.to_csv(f'{experience_name}.csv', index=False)\n",
    "\n",
    "    print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "2u4AsfAKtaQS",
    "ExecuteTime": {
     "end_time": "2023-11-05T06:46:18.971789Z",
     "start_time": "2023-11-05T06:15:08.593979100Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,   100] loss: 1.548 acc: 33.80 time: 14.37\n",
      "[1,   200] loss: 1.294 acc: 44.29 time: 8.85\n",
      "[1,   300] loss: 1.223 acc: 48.64 time: 10.46\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 51.03 %\n",
      "Average loss on the 10000 test images: 1.178\n",
      "[2,   100] loss: 1.168 acc: 52.00 time: 10.63\n",
      "[2,   200] loss: 1.159 acc: 53.21 time: 11.32\n",
      "[2,   300] loss: 1.141 acc: 54.03 time: 9.88\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 57.35 %\n",
      "Average loss on the 10000 test images: 1.096\n",
      "[3,   100] loss: 1.108 acc: 56.07 time: 8.52\n",
      "[3,   200] loss: 1.106 acc: 56.14 time: 8.45\n",
      "[3,   300] loss: 1.092 acc: 56.35 time: 8.34\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 57.72 %\n",
      "Average loss on the 10000 test images: 1.097\n",
      "[4,   100] loss: 1.074 acc: 58.66 time: 8.49\n",
      "[4,   200] loss: 1.064 acc: 59.02 time: 8.13\n",
      "[4,   300] loss: 1.053 acc: 60.00 time: 8.24\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 60.69 %\n",
      "Average loss on the 10000 test images: 1.035\n",
      "[5,   100] loss: 1.038 acc: 60.84 time: 8.57\n",
      "[5,   200] loss: 1.037 acc: 60.24 time: 8.66\n",
      "[5,   300] loss: 1.028 acc: 61.35 time: 8.05\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 60.83 %\n",
      "Average loss on the 10000 test images: 1.030\n",
      "[6,   100] loss: 1.012 acc: 62.47 time: 8.54\n",
      "[6,   200] loss: 1.012 acc: 62.30 time: 8.51\n",
      "[6,   300] loss: 1.007 acc: 62.88 time: 8.45\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 64.69 %\n",
      "Average loss on the 10000 test images: 0.981\n",
      "[7,   100] loss: 0.996 acc: 63.29 time: 8.02\n",
      "[7,   200] loss: 0.989 acc: 63.73 time: 8.76\n",
      "[7,   300] loss: 0.978 acc: 64.24 time: 8.16\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 63.95 %\n",
      "Average loss on the 10000 test images: 0.972\n",
      "[8,   100] loss: 0.985 acc: 64.02 time: 8.00\n",
      "[8,   200] loss: 0.967 acc: 65.26 time: 8.23\n",
      "[8,   300] loss: 0.966 acc: 64.86 time: 7.99\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 65.23 %\n",
      "Average loss on the 10000 test images: 0.968\n",
      "[9,   100] loss: 0.959 acc: 65.59 time: 7.91\n",
      "[9,   200] loss: 0.963 acc: 65.64 time: 8.65\n",
      "[9,   300] loss: 0.955 acc: 66.05 time: 7.77\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 67.32 %\n",
      "Average loss on the 10000 test images: 0.935\n",
      "[10,   100] loss: 0.945 acc: 66.46 time: 7.94\n",
      "[10,   200] loss: 0.948 acc: 66.52 time: 8.12\n",
      "[10,   300] loss: 0.940 acc: 67.08 time: 9.17\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 67.97 %\n",
      "Average loss on the 10000 test images: 0.918\n",
      "[11,   100] loss: 0.939 acc: 66.86 time: 7.85\n",
      "[11,   200] loss: 0.934 acc: 67.24 time: 7.82\n",
      "[11,   300] loss: 0.931 acc: 67.44 time: 9.02\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 68.09 %\n",
      "Average loss on the 10000 test images: 0.921\n",
      "[12,   100] loss: 0.922 acc: 67.95 time: 8.36\n",
      "[12,   200] loss: 0.918 acc: 68.26 time: 8.94\n",
      "[12,   300] loss: 0.917 acc: 68.70 time: 9.13\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 66.77 %\n",
      "Average loss on the 10000 test images: 0.952\n",
      "[13,   100] loss: 0.919 acc: 68.55 time: 7.95\n",
      "[13,   200] loss: 0.900 acc: 69.18 time: 9.52\n",
      "[13,   300] loss: 0.907 acc: 69.06 time: 8.86\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 69.70 %\n",
      "Average loss on the 10000 test images: 0.897\n",
      "[14,   100] loss: 0.899 acc: 70.01 time: 7.87\n",
      "[14,   200] loss: 0.891 acc: 69.77 time: 7.93\n",
      "[14,   300] loss: 0.890 acc: 70.47 time: 7.68\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 71.67 %\n",
      "Average loss on the 10000 test images: 0.859\n",
      "[15,   100] loss: 0.873 acc: 71.23 time: 7.94\n",
      "[15,   200] loss: 0.879 acc: 70.90 time: 7.74\n",
      "[15,   300] loss: 0.890 acc: 70.19 time: 8.28\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 71.53 %\n",
      "Average loss on the 10000 test images: 0.867\n",
      "[16,   100] loss: 0.842 acc: 72.99 time: 8.01\n",
      "[16,   200] loss: 0.829 acc: 73.83 time: 8.11\n",
      "[16,   300] loss: 0.817 acc: 74.70 time: 8.36\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 75.56 %\n",
      "Average loss on the 10000 test images: 0.798\n",
      "[17,   100] loss: 0.815 acc: 74.31 time: 7.88\n",
      "[17,   200] loss: 0.814 acc: 74.57 time: 8.59\n",
      "[17,   300] loss: 0.820 acc: 74.53 time: 8.61\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 75.84 %\n",
      "Average loss on the 10000 test images: 0.789\n",
      "[18,   100] loss: 0.808 acc: 74.88 time: 8.18\n",
      "[18,   200] loss: 0.804 acc: 75.17 time: 8.45\n",
      "[18,   300] loss: 0.807 acc: 75.07 time: 8.71\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 76.39 %\n",
      "Average loss on the 10000 test images: 0.783\n",
      "[19,   100] loss: 0.805 acc: 74.96 time: 7.89\n",
      "[19,   200] loss: 0.800 acc: 75.30 time: 7.96\n",
      "[19,   300] loss: 0.791 acc: 75.88 time: 8.00\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 76.18 %\n",
      "Average loss on the 10000 test images: 0.779\n",
      "[20,   100] loss: 0.785 acc: 76.12 time: 8.14\n",
      "[20,   200] loss: 0.801 acc: 75.10 time: 8.58\n",
      "[20,   300] loss: 0.794 acc: 75.50 time: 8.57\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 76.33 %\n",
      "Average loss on the 10000 test images: 0.775\n",
      "[21,   100] loss: 0.787 acc: 76.13 time: 8.01\n",
      "[21,   200] loss: 0.781 acc: 76.38 time: 8.45\n",
      "[21,   300] loss: 0.783 acc: 76.53 time: 7.98\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 76.95 %\n",
      "Average loss on the 10000 test images: 0.770\n",
      "[22,   100] loss: 0.778 acc: 76.78 time: 8.20\n",
      "[22,   200] loss: 0.784 acc: 76.34 time: 8.42\n",
      "[22,   300] loss: 0.779 acc: 76.57 time: 8.43\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 77.07 %\n",
      "Average loss on the 10000 test images: 0.767\n",
      "[23,   100] loss: 0.779 acc: 76.56 time: 8.52\n",
      "[23,   200] loss: 0.779 acc: 76.25 time: 8.25\n",
      "[23,   300] loss: 0.780 acc: 76.40 time: 8.79\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 77.04 %\n",
      "Average loss on the 10000 test images: 0.762\n",
      "[24,   100] loss: 0.777 acc: 76.91 time: 8.31\n",
      "[24,   200] loss: 0.773 acc: 76.69 time: 7.98\n",
      "[24,   300] loss: 0.775 acc: 77.14 time: 8.25\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 76.94 %\n",
      "Average loss on the 10000 test images: 0.773\n",
      "[25,   100] loss: 0.765 acc: 77.42 time: 8.64\n",
      "[25,   200] loss: 0.770 acc: 77.17 time: 7.93\n",
      "[25,   300] loss: 0.773 acc: 77.06 time: 8.42\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 77.75 %\n",
      "Average loss on the 10000 test images: 0.761\n",
      "[26,   100] loss: 0.765 acc: 77.41 time: 8.04\n",
      "[26,   200] loss: 0.778 acc: 76.61 time: 7.96\n",
      "[26,   300] loss: 0.763 acc: 77.62 time: 8.11\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 77.17 %\n",
      "Average loss on the 10000 test images: 0.763\n",
      "[27,   100] loss: 0.765 acc: 77.62 time: 8.14\n",
      "[27,   200] loss: 0.769 acc: 76.86 time: 8.30\n",
      "[27,   300] loss: 0.761 acc: 77.99 time: 9.03\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 77.53 %\n",
      "Average loss on the 10000 test images: 0.761\n",
      "[28,   100] loss: 0.754 acc: 77.85 time: 8.08\n",
      "[28,   200] loss: 0.768 acc: 77.20 time: 8.35\n",
      "[28,   300] loss: 0.759 acc: 77.78 time: 9.04\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 78.08 %\n",
      "Average loss on the 10000 test images: 0.749\n",
      "[29,   100] loss: 0.759 acc: 77.69 time: 8.09\n",
      "[29,   200] loss: 0.754 acc: 77.98 time: 8.46\n",
      "[29,   300] loss: 0.762 acc: 77.39 time: 8.25\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 77.78 %\n",
      "Average loss on the 10000 test images: 0.752\n",
      "[30,   100] loss: 0.745 acc: 78.60 time: 7.95\n",
      "[30,   200] loss: 0.754 acc: 78.11 time: 8.12\n",
      "[30,   300] loss: 0.764 acc: 77.52 time: 8.38\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 77.76 %\n",
      "Average loss on the 10000 test images: 0.751\n",
      "[31,   100] loss: 0.751 acc: 78.30 time: 8.04\n",
      "[31,   200] loss: 0.753 acc: 77.59 time: 8.54\n",
      "[31,   300] loss: 0.743 acc: 78.45 time: 7.86\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 78.32 %\n",
      "Average loss on the 10000 test images: 0.747\n",
      "[32,   100] loss: 0.747 acc: 78.79 time: 8.69\n",
      "[32,   200] loss: 0.750 acc: 78.38 time: 8.19\n",
      "[32,   300] loss: 0.745 acc: 78.68 time: 8.09\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 78.63 %\n",
      "Average loss on the 10000 test images: 0.737\n",
      "[33,   100] loss: 0.742 acc: 78.68 time: 8.91\n",
      "[33,   200] loss: 0.746 acc: 78.67 time: 8.16\n",
      "[33,   300] loss: 0.745 acc: 78.51 time: 8.30\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 78.47 %\n",
      "Average loss on the 10000 test images: 0.739\n",
      "[34,   100] loss: 0.750 acc: 78.12 time: 8.02\n",
      "[34,   200] loss: 0.743 acc: 78.60 time: 8.39\n",
      "[34,   300] loss: 0.744 acc: 78.77 time: 8.51\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 78.84 %\n",
      "Average loss on the 10000 test images: 0.738\n",
      "[35,   100] loss: 0.736 acc: 79.05 time: 7.88\n",
      "[35,   200] loss: 0.750 acc: 78.46 time: 8.03\n",
      "[35,   300] loss: 0.743 acc: 78.81 time: 8.20\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 78.49 %\n",
      "Average loss on the 10000 test images: 0.740\n",
      "[36,   100] loss: 0.750 acc: 78.20 time: 7.99\n",
      "[36,   200] loss: 0.735 acc: 79.20 time: 8.19\n",
      "[36,   300] loss: 0.745 acc: 78.35 time: 8.51\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 78.86 %\n",
      "Average loss on the 10000 test images: 0.740\n",
      "[37,   100] loss: 0.737 acc: 79.30 time: 8.29\n",
      "[37,   200] loss: 0.732 acc: 79.23 time: 7.87\n",
      "[37,   300] loss: 0.742 acc: 78.66 time: 8.72\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 78.76 %\n",
      "Average loss on the 10000 test images: 0.741\n",
      "[38,   100] loss: 0.744 acc: 78.74 time: 7.96\n",
      "[38,   200] loss: 0.742 acc: 78.77 time: 8.39\n",
      "[38,   300] loss: 0.738 acc: 78.88 time: 8.08\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 79.07 %\n",
      "Average loss on the 10000 test images: 0.741\n",
      "[39,   100] loss: 0.750 acc: 78.34 time: 8.05\n",
      "[39,   200] loss: 0.732 acc: 79.36 time: 8.19\n",
      "[39,   300] loss: 0.731 acc: 79.20 time: 7.92\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 78.80 %\n",
      "Average loss on the 10000 test images: 0.740\n",
      "[40,   100] loss: 0.734 acc: 79.56 time: 8.70\n",
      "[40,   200] loss: 0.745 acc: 78.55 time: 7.89\n",
      "[40,   300] loss: 0.733 acc: 79.25 time: 7.93\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 78.60 %\n",
      "Average loss on the 10000 test images: 0.736\n",
      "[41,   100] loss: 0.740 acc: 78.89 time: 8.97\n",
      "[41,   200] loss: 0.741 acc: 78.63 time: 8.15\n",
      "[41,   300] loss: 0.743 acc: 78.63 time: 8.48\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 78.56 %\n",
      "Average loss on the 10000 test images: 0.736\n",
      "[42,   100] loss: 0.742 acc: 78.59 time: 8.95\n",
      "[42,   200] loss: 0.737 acc: 79.02 time: 8.32\n",
      "[42,   300] loss: 0.736 acc: 79.16 time: 8.78\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 79.01 %\n",
      "Average loss on the 10000 test images: 0.733\n",
      "[43,   100] loss: 0.738 acc: 78.93 time: 8.08\n",
      "[43,   200] loss: 0.740 acc: 78.83 time: 8.05\n",
      "[43,   300] loss: 0.729 acc: 79.14 time: 7.89\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 78.51 %\n",
      "Average loss on the 10000 test images: 0.739\n",
      "[44,   100] loss: 0.735 acc: 78.84 time: 8.14\n",
      "[44,   200] loss: 0.736 acc: 78.91 time: 9.19\n",
      "[44,   300] loss: 0.729 acc: 79.41 time: 7.95\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 78.63 %\n",
      "Average loss on the 10000 test images: 0.741\n",
      "[45,   100] loss: 0.738 acc: 79.14 time: 8.59\n",
      "[45,   200] loss: 0.731 acc: 79.65 time: 8.61\n",
      "[45,   300] loss: 0.734 acc: 79.40 time: 8.38\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 78.50 %\n",
      "Average loss on the 10000 test images: 0.739\n",
      "[46,   100] loss: 0.730 acc: 79.17 time: 8.41\n",
      "[46,   200] loss: 0.738 acc: 79.09 time: 8.13\n",
      "[46,   300] loss: 0.742 acc: 78.62 time: 8.01\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 79.18 %\n",
      "Average loss on the 10000 test images: 0.735\n",
      "[47,   100] loss: 0.732 acc: 79.05 time: 8.15\n",
      "[47,   200] loss: 0.735 acc: 79.12 time: 8.10\n",
      "[47,   300] loss: 0.734 acc: 79.28 time: 8.15\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 78.82 %\n",
      "Average loss on the 10000 test images: 0.737\n",
      "[48,   100] loss: 0.735 acc: 79.43 time: 8.14\n",
      "[48,   200] loss: 0.735 acc: 79.20 time: 8.41\n",
      "[48,   300] loss: 0.734 acc: 79.09 time: 8.56\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 78.87 %\n",
      "Average loss on the 10000 test images: 0.735\n",
      "[49,   100] loss: 0.740 acc: 79.00 time: 8.48\n",
      "[49,   200] loss: 0.742 acc: 78.41 time: 8.93\n",
      "[49,   300] loss: 0.736 acc: 79.01 time: 8.47\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 78.86 %\n",
      "Average loss on the 10000 test images: 0.738\n",
      "[50,   100] loss: 0.731 acc: 79.48 time: 8.65\n",
      "[50,   200] loss: 0.725 acc: 79.58 time: 9.03\n",
      "[50,   300] loss: 0.732 acc: 78.96 time: 8.63\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 78.77 %\n",
      "Average loss on the 10000 test images: 0.735\n",
      "Restored best model from epoch with validation accuracy: 79.18%\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "train(net, criterion, optimizer, num_epochs=50, decay_epochs=15, init_lr=0.01, task='rotation', experiment_type='Self-Supervise Rotation Model')\n",
    "################################\n",
    "#     TODO: Save the model     #  \n",
    "################################\n",
    "# Get current date and time\n",
    "# Save the model\n",
    "model_path = f\"{experience_name}.pth\"\n",
    "torch.save(net.state_dict(), model_path)\n",
    "################################\n",
    "#      End of your code        #  \n",
    "################################"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Fine-tuning on the pre-trained model (9 points)\n",
    "\n",
    "In this section, we will load the ResNet18 model pre-trained on the rotation task and fine-tune on the classification task. We will freeze all previous layers except for the 'layer4' block and 'fc' layer.\n",
    "\n",
    "**Then we will use the trained model from rotation task as the pretrained weights. Notice, you should not use the pretrained weights from ImageNet.**"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [
    {
     "data": {
      "text/plain": "<All keys matched successfully>"
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torchvision.models import resnet18\n",
    "\n",
    "#####################################################\n",
    "#     TODO: Load the pre-trained ResNet18 model     #\n",
    "#####################################################\n",
    "# load the trained classifier weights\n",
    "ckpt = torch.load(f\"{experience_name}.pth\")\n",
    "net.load_state_dict(ckpt)\n",
    "####################################################\n",
    "#                End of your code                  #\n",
    "####################################################"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-05T06:46:19.058898700Z",
     "start_time": "2023-11-05T06:46:18.967789400Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [
    {
     "data": {
      "text/plain": "ResNet(\n  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  (relu): ReLU(inplace=True)\n  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n  (layer1): Sequential(\n    (0): BasicBlock(\n      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n    (1): BasicBlock(\n      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n  )\n  (layer2): Sequential(\n    (0): BasicBlock(\n      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (downsample): Sequential(\n        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (1): BasicBlock(\n      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n  )\n  (layer3): Sequential(\n    (0): BasicBlock(\n      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (downsample): Sequential(\n        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (1): BasicBlock(\n      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n  )\n  (layer4): Sequential(\n    (0): BasicBlock(\n      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (downsample): Sequential(\n        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (1): BasicBlock(\n      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n  )\n  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n  (fc): Linear(in_features=512, out_features=10, bias=True)\n)"
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#################################################################################################\n",
    "#   TODO: Freeze all previous layers; only keep the 'layer4' block and 'fc' layer trainable     #\n",
    "#################################################################################################\n",
    "# Freeze all parameters\n",
    "net.requires_grad_(False)\n",
    "\n",
    "# Adjusting the fully connected layer to have 10 outputs for 10 classes\n",
    "net.fc = nn.Linear(net.fc.in_features, 10)  # Re-define the fc layer\n",
    "\n",
    "# Unfreeze the last block (layer4) and the fully connected (fc) layer\n",
    "net.layer4.requires_grad_(True)\n",
    "net.fc.requires_grad_(True)\n",
    "\n",
    "# Make sure to move the model to the device after modifying it\n",
    "net.to(device)\n",
    "#################################################################################################\n",
    "#                                          End of your code                                     #\n",
    "#################################################################################################"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-05T06:46:19.065416300Z",
     "start_time": "2023-11-05T06:46:19.054899600Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Params to learn:\n",
      "\t layer4.0.conv1.weight\n",
      "\t layer4.0.bn1.weight\n",
      "\t layer4.0.bn1.bias\n",
      "\t layer4.0.conv2.weight\n",
      "\t layer4.0.bn2.weight\n",
      "\t layer4.0.bn2.bias\n",
      "\t layer4.0.downsample.0.weight\n",
      "\t layer4.0.downsample.1.weight\n",
      "\t layer4.0.downsample.1.bias\n",
      "\t layer4.1.conv1.weight\n",
      "\t layer4.1.bn1.weight\n",
      "\t layer4.1.bn1.bias\n",
      "\t layer4.1.conv2.weight\n",
      "\t layer4.1.bn2.weight\n",
      "\t layer4.1.bn2.bias\n",
      "\t fc.weight\n",
      "\t fc.bias\n"
     ]
    }
   ],
   "source": [
    "# Print all the trainable parameters\n",
    "params_to_update = net.parameters()\n",
    "print(\"Params to learn:\")\n",
    "params_to_update = []\n",
    "for name,param in net.named_parameters():\n",
    "    if param.requires_grad == True:\n",
    "        params_to_update.append(param)\n",
    "        print(\"\\t\",name)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-05T06:46:19.071063800Z",
     "start_time": "2023-11-05T06:46:19.062414800Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [
    {
     "data": {
      "text/plain": "CrossEntropyLoss()"
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO: Define criterion and optimizer\n",
    "# Note that your optimizer only needs to update the parameters that are trainable.\n",
    "criterion = nn.CrossEntropyLoss(label_smoothing=label_smoothing)\n",
    "\n",
    "# Optimizer: Update only the parameters of layer4 and fc\n",
    "optimizer = optim.Adam([\n",
    "    {'params': net.layer4.parameters()},\n",
    "    {'params': net.fc.parameters()}\n",
    "], lr=0.001)\n",
    "\n",
    "criterion.to(device)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-05T06:46:19.155033900Z",
     "start_time": "2023-11-05T06:46:19.070069700Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,   100] loss: 1.856 acc: 36.19 time: 7.53\n",
      "[1,   200] loss: 1.655 acc: 46.13 time: 7.61\n",
      "[1,   300] loss: 1.599 acc: 49.24 time: 7.69\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 51.21 %\n",
      "Average loss on the 10000 test images: 1.579\n",
      "[2,   100] loss: 1.555 acc: 51.09 time: 8.42\n",
      "[2,   200] loss: 1.537 acc: 52.25 time: 7.48\n",
      "[2,   300] loss: 1.540 acc: 52.49 time: 7.87\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 54.82 %\n",
      "Average loss on the 10000 test images: 1.487\n",
      "[3,   100] loss: 1.508 acc: 53.20 time: 7.64\n",
      "[3,   200] loss: 1.490 acc: 54.36 time: 7.36\n",
      "[3,   300] loss: 1.502 acc: 53.92 time: 7.27\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 55.53 %\n",
      "Average loss on the 10000 test images: 1.482\n",
      "[4,   100] loss: 1.473 acc: 55.40 time: 7.44\n",
      "[4,   200] loss: 1.488 acc: 54.18 time: 7.60\n",
      "[4,   300] loss: 1.494 acc: 55.02 time: 7.58\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 57.72 %\n",
      "Average loss on the 10000 test images: 1.428\n",
      "[5,   100] loss: 1.462 acc: 55.58 time: 7.59\n",
      "[5,   200] loss: 1.454 acc: 55.88 time: 7.28\n",
      "[5,   300] loss: 1.466 acc: 55.41 time: 7.52\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 57.70 %\n",
      "Average loss on the 10000 test images: 1.425\n",
      "[6,   100] loss: 1.451 acc: 56.48 time: 7.57\n",
      "[6,   200] loss: 1.441 acc: 57.20 time: 7.43\n",
      "[6,   300] loss: 1.438 acc: 56.80 time: 7.37\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 58.38 %\n",
      "Average loss on the 10000 test images: 1.407\n",
      "[7,   100] loss: 1.437 acc: 57.05 time: 7.72\n",
      "[7,   200] loss: 1.443 acc: 56.21 time: 7.14\n",
      "[7,   300] loss: 1.440 acc: 56.64 time: 7.41\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 59.05 %\n",
      "Average loss on the 10000 test images: 1.393\n",
      "[8,   100] loss: 1.418 acc: 57.43 time: 7.05\n",
      "[8,   200] loss: 1.432 acc: 57.57 time: 7.37\n",
      "[8,   300] loss: 1.429 acc: 57.45 time: 7.16\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 58.52 %\n",
      "Average loss on the 10000 test images: 1.400\n",
      "[9,   100] loss: 1.417 acc: 57.80 time: 7.34\n",
      "[9,   200] loss: 1.422 acc: 57.67 time: 7.37\n",
      "[9,   300] loss: 1.416 acc: 58.02 time: 7.42\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 60.57 %\n",
      "Average loss on the 10000 test images: 1.362\n",
      "[10,   100] loss: 1.409 acc: 58.23 time: 7.24\n",
      "[10,   200] loss: 1.414 acc: 57.89 time: 7.01\n",
      "[10,   300] loss: 1.422 acc: 57.64 time: 7.09\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 59.96 %\n",
      "Average loss on the 10000 test images: 1.374\n",
      "[11,   100] loss: 1.371 acc: 60.11 time: 7.22\n",
      "[11,   200] loss: 1.371 acc: 60.05 time: 7.13\n",
      "[11,   300] loss: 1.370 acc: 60.08 time: 7.34\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 62.15 %\n",
      "Average loss on the 10000 test images: 1.330\n",
      "[12,   100] loss: 1.338 acc: 61.44 time: 7.54\n",
      "[12,   200] loss: 1.348 acc: 61.19 time: 7.19\n",
      "[12,   300] loss: 1.361 acc: 60.31 time: 7.37\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 62.17 %\n",
      "Average loss on the 10000 test images: 1.325\n",
      "[13,   100] loss: 1.336 acc: 61.59 time: 7.13\n",
      "[13,   200] loss: 1.343 acc: 61.11 time: 7.22\n",
      "[13,   300] loss: 1.346 acc: 61.19 time: 7.13\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 62.09 %\n",
      "Average loss on the 10000 test images: 1.326\n",
      "[14,   100] loss: 1.336 acc: 62.09 time: 7.66\n",
      "[14,   200] loss: 1.337 acc: 61.56 time: 7.60\n",
      "[14,   300] loss: 1.342 acc: 60.98 time: 7.39\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 62.85 %\n",
      "Average loss on the 10000 test images: 1.317\n",
      "[15,   100] loss: 1.329 acc: 62.02 time: 7.22\n",
      "[15,   200] loss: 1.345 acc: 61.45 time: 7.05\n",
      "[15,   300] loss: 1.343 acc: 61.15 time: 7.22\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 62.51 %\n",
      "Average loss on the 10000 test images: 1.321\n",
      "[16,   100] loss: 1.343 acc: 60.91 time: 7.52\n",
      "[16,   200] loss: 1.337 acc: 60.88 time: 7.32\n",
      "[16,   300] loss: 1.336 acc: 61.30 time: 7.41\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 62.85 %\n",
      "Average loss on the 10000 test images: 1.315\n",
      "[17,   100] loss: 1.322 acc: 62.24 time: 7.31\n",
      "[17,   200] loss: 1.326 acc: 62.01 time: 7.20\n",
      "[17,   300] loss: 1.343 acc: 60.50 time: 7.42\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 62.36 %\n",
      "Average loss on the 10000 test images: 1.317\n",
      "[18,   100] loss: 1.330 acc: 61.80 time: 7.36\n",
      "[18,   200] loss: 1.337 acc: 61.44 time: 7.11\n",
      "[18,   300] loss: 1.326 acc: 62.01 time: 7.17\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 62.60 %\n",
      "Average loss on the 10000 test images: 1.317\n",
      "[19,   100] loss: 1.331 acc: 61.62 time: 7.42\n",
      "[19,   200] loss: 1.333 acc: 61.67 time: 7.04\n",
      "[19,   300] loss: 1.327 acc: 61.71 time: 7.30\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 62.92 %\n",
      "Average loss on the 10000 test images: 1.312\n",
      "[20,   100] loss: 1.329 acc: 62.17 time: 7.23\n",
      "[20,   200] loss: 1.330 acc: 62.02 time: 7.00\n",
      "[20,   300] loss: 1.324 acc: 62.09 time: 7.44\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 62.80 %\n",
      "Average loss on the 10000 test images: 1.314\n",
      "[21,   100] loss: 1.320 acc: 62.16 time: 7.32\n",
      "[21,   200] loss: 1.316 acc: 62.92 time: 7.18\n",
      "[21,   300] loss: 1.326 acc: 62.40 time: 7.07\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 63.26 %\n",
      "Average loss on the 10000 test images: 1.308\n",
      "[22,   100] loss: 1.302 acc: 63.21 time: 7.14\n",
      "[22,   200] loss: 1.321 acc: 62.04 time: 7.18\n",
      "[22,   300] loss: 1.332 acc: 61.66 time: 7.22\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 63.12 %\n",
      "Average loss on the 10000 test images: 1.309\n",
      "[23,   100] loss: 1.324 acc: 61.98 time: 7.34\n",
      "[23,   200] loss: 1.327 acc: 61.72 time: 7.36\n",
      "[23,   300] loss: 1.307 acc: 62.77 time: 7.49\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 63.18 %\n",
      "Average loss on the 10000 test images: 1.308\n",
      "[24,   100] loss: 1.316 acc: 62.40 time: 7.38\n",
      "[24,   200] loss: 1.320 acc: 61.95 time: 7.25\n",
      "[24,   300] loss: 1.327 acc: 62.09 time: 7.20\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 63.22 %\n",
      "Average loss on the 10000 test images: 1.307\n",
      "[25,   100] loss: 1.323 acc: 61.81 time: 7.29\n",
      "[25,   200] loss: 1.330 acc: 61.91 time: 7.18\n",
      "[25,   300] loss: 1.308 acc: 62.50 time: 7.11\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 63.07 %\n",
      "Average loss on the 10000 test images: 1.307\n",
      "[26,   100] loss: 1.303 acc: 63.37 time: 7.25\n",
      "[26,   200] loss: 1.333 acc: 61.36 time: 7.10\n",
      "[26,   300] loss: 1.324 acc: 62.12 time: 7.21\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 63.16 %\n",
      "Average loss on the 10000 test images: 1.308\n",
      "[27,   100] loss: 1.312 acc: 62.45 time: 7.38\n",
      "[27,   200] loss: 1.311 acc: 62.65 time: 6.93\n",
      "[27,   300] loss: 1.318 acc: 62.20 time: 7.19\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 63.38 %\n",
      "Average loss on the 10000 test images: 1.310\n",
      "[28,   100] loss: 1.319 acc: 62.35 time: 7.20\n",
      "[28,   200] loss: 1.324 acc: 62.09 time: 7.09\n",
      "[28,   300] loss: 1.319 acc: 61.77 time: 6.96\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 62.93 %\n",
      "Average loss on the 10000 test images: 1.307\n",
      "[29,   100] loss: 1.320 acc: 62.03 time: 7.41\n",
      "[29,   200] loss: 1.317 acc: 62.31 time: 7.42\n",
      "[29,   300] loss: 1.319 acc: 62.14 time: 7.67\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 63.03 %\n",
      "Average loss on the 10000 test images: 1.306\n",
      "[30,   100] loss: 1.324 acc: 61.88 time: 7.46\n",
      "[30,   200] loss: 1.307 acc: 62.84 time: 7.18\n",
      "[30,   300] loss: 1.317 acc: 62.70 time: 7.11\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 63.31 %\n",
      "Average loss on the 10000 test images: 1.304\n",
      "[31,   100] loss: 1.317 acc: 62.37 time: 7.13\n",
      "[31,   200] loss: 1.315 acc: 61.69 time: 7.44\n",
      "[31,   300] loss: 1.318 acc: 62.46 time: 7.27\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 63.26 %\n",
      "Average loss on the 10000 test images: 1.306\n",
      "[32,   100] loss: 1.319 acc: 62.31 time: 7.31\n",
      "[32,   200] loss: 1.313 acc: 62.56 time: 7.35\n",
      "[32,   300] loss: 1.310 acc: 62.88 time: 6.97\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 63.38 %\n",
      "Average loss on the 10000 test images: 1.304\n",
      "[33,   100] loss: 1.312 acc: 62.18 time: 7.32\n",
      "[33,   200] loss: 1.324 acc: 62.06 time: 7.50\n",
      "[33,   300] loss: 1.312 acc: 62.46 time: 7.17\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 63.35 %\n",
      "Average loss on the 10000 test images: 1.305\n",
      "[34,   100] loss: 1.320 acc: 62.45 time: 7.35\n",
      "[34,   200] loss: 1.306 acc: 62.94 time: 6.98\n",
      "[34,   300] loss: 1.329 acc: 61.59 time: 7.52\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 62.97 %\n",
      "Average loss on the 10000 test images: 1.310\n",
      "[35,   100] loss: 1.323 acc: 61.80 time: 7.03\n",
      "[35,   200] loss: 1.314 acc: 62.87 time: 7.05\n",
      "[35,   300] loss: 1.311 acc: 62.98 time: 7.48\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 62.90 %\n",
      "Average loss on the 10000 test images: 1.309\n",
      "[36,   100] loss: 1.316 acc: 62.28 time: 7.41\n",
      "[36,   200] loss: 1.323 acc: 61.94 time: 7.39\n",
      "[36,   300] loss: 1.311 acc: 62.60 time: 7.56\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 63.17 %\n",
      "Average loss on the 10000 test images: 1.306\n",
      "[37,   100] loss: 1.323 acc: 61.96 time: 7.14\n",
      "[37,   200] loss: 1.323 acc: 61.95 time: 7.00\n",
      "[37,   300] loss: 1.298 acc: 63.50 time: 7.22\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 63.35 %\n",
      "Average loss on the 10000 test images: 1.305\n",
      "[38,   100] loss: 1.314 acc: 62.60 time: 7.54\n",
      "[38,   200] loss: 1.322 acc: 61.96 time: 7.20\n",
      "[38,   300] loss: 1.320 acc: 62.73 time: 7.27\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 63.36 %\n",
      "Average loss on the 10000 test images: 1.305\n",
      "[39,   100] loss: 1.321 acc: 62.34 time: 7.23\n",
      "[39,   200] loss: 1.309 acc: 62.49 time: 6.98\n",
      "[39,   300] loss: 1.311 acc: 62.29 time: 7.18\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 63.12 %\n",
      "Average loss on the 10000 test images: 1.306\n",
      "[40,   100] loss: 1.311 acc: 62.83 time: 7.41\n",
      "[40,   200] loss: 1.317 acc: 62.25 time: 7.09\n",
      "[40,   300] loss: 1.318 acc: 62.30 time: 7.32\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 63.19 %\n",
      "Average loss on the 10000 test images: 1.308\n",
      "[41,   100] loss: 1.322 acc: 61.52 time: 7.29\n",
      "[41,   200] loss: 1.299 acc: 63.56 time: 6.95\n",
      "[41,   300] loss: 1.323 acc: 62.04 time: 7.25\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 63.01 %\n",
      "Average loss on the 10000 test images: 1.307\n",
      "[42,   100] loss: 1.312 acc: 63.17 time: 7.03\n",
      "[42,   200] loss: 1.317 acc: 62.04 time: 7.22\n",
      "[42,   300] loss: 1.328 acc: 61.68 time: 7.66\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 62.91 %\n",
      "Average loss on the 10000 test images: 1.306\n",
      "[43,   100] loss: 1.319 acc: 62.32 time: 6.97\n",
      "[43,   200] loss: 1.313 acc: 62.63 time: 7.24\n",
      "[43,   300] loss: 1.323 acc: 61.83 time: 6.88\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 63.10 %\n",
      "Average loss on the 10000 test images: 1.306\n",
      "[44,   100] loss: 1.314 acc: 62.03 time: 7.31\n",
      "[44,   200] loss: 1.314 acc: 62.02 time: 7.03\n",
      "[44,   300] loss: 1.313 acc: 62.14 time: 7.49\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 63.09 %\n",
      "Average loss on the 10000 test images: 1.308\n",
      "[45,   100] loss: 1.310 acc: 62.59 time: 7.03\n",
      "[45,   200] loss: 1.319 acc: 61.95 time: 7.29\n",
      "[45,   300] loss: 1.302 acc: 63.88 time: 7.37\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 63.27 %\n",
      "Average loss on the 10000 test images: 1.306\n",
      "[46,   100] loss: 1.327 acc: 61.80 time: 7.24\n",
      "[46,   200] loss: 1.323 acc: 61.70 time: 7.51\n",
      "[46,   300] loss: 1.313 acc: 62.38 time: 7.40\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 62.93 %\n",
      "Average loss on the 10000 test images: 1.307\n",
      "[47,   100] loss: 1.315 acc: 62.66 time: 7.38\n",
      "[47,   200] loss: 1.312 acc: 62.86 time: 7.12\n",
      "[47,   300] loss: 1.311 acc: 62.74 time: 7.00\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 62.97 %\n",
      "Average loss on the 10000 test images: 1.306\n",
      "[48,   100] loss: 1.315 acc: 62.92 time: 7.19\n",
      "[48,   200] loss: 1.304 acc: 62.95 time: 7.30\n",
      "[48,   300] loss: 1.323 acc: 62.20 time: 7.02\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 63.30 %\n",
      "Average loss on the 10000 test images: 1.304\n",
      "[49,   100] loss: 1.326 acc: 62.34 time: 7.27\n",
      "[49,   200] loss: 1.317 acc: 62.33 time: 7.75\n",
      "[49,   300] loss: 1.309 acc: 62.97 time: 7.36\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 63.29 %\n",
      "Average loss on the 10000 test images: 1.308\n",
      "[50,   100] loss: 1.317 acc: 61.94 time: 7.22\n",
      "[50,   200] loss: 1.313 acc: 62.82 time: 7.16\n",
      "[50,   300] loss: 1.330 acc: 61.98 time: 6.90\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 63.38 %\n",
      "Average loss on the 10000 test images: 1.305\n",
      "Restored best model from epoch with validation accuracy: 63.38%\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "train(net, criterion, optimizer, num_epochs=50, decay_epochs=10, init_lr=0.01, task='classification', experiment_type='Fine-tuning Pre-trained Model')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-05T07:13:34.753421300Z",
     "start_time": "2023-11-05T06:46:19.080030800Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Fine-tuning on the randomly initialized model (9 points)\n",
    "In this section, we will randomly initialize a ResNet18 model and fine-tune on the classification task. We will freeze all previous layers except for the 'layer4' block and 'fc' layer."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torchvision.models import resnet18\n",
    "#################################################\n",
    "# TODO: Randomly initialize a ResNet18 model    #\n",
    "#################################################\n",
    "# Randomly initialize a ResNet18 model\n",
    "net = resnet18(pretrained=False)\n",
    "#################################################\n",
    "#              End of your code                 #\n",
    "#################################################"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-05T07:13:34.876807500Z",
     "start_time": "2023-11-05T07:13:34.751421200Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [
    {
     "data": {
      "text/plain": "ResNet(\n  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  (relu): ReLU(inplace=True)\n  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n  (layer1): Sequential(\n    (0): BasicBlock(\n      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n    (1): BasicBlock(\n      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n  )\n  (layer2): Sequential(\n    (0): BasicBlock(\n      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (downsample): Sequential(\n        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (1): BasicBlock(\n      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n  )\n  (layer3): Sequential(\n    (0): BasicBlock(\n      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (downsample): Sequential(\n        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (1): BasicBlock(\n      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n  )\n  (layer4): Sequential(\n    (0): BasicBlock(\n      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (downsample): Sequential(\n        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (1): BasicBlock(\n      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n  )\n  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n  (fc): Linear(in_features=512, out_features=10, bias=True)\n)"
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#################################################################################################\n",
    "# TODO: Freeze all previous layers; only keep the 'layer4' block and 'fc' layer trainable       #\n",
    "# To do this, you should set requires_grad=False for the frozen layers.                         #\n",
    "#################################################################################################\n",
    "# Adjusting the fully connected layer for 10 classes\n",
    "net.fc = nn.Linear(net.fc.in_features, 10)\n",
    "\n",
    "# Freeze all layers in the randomly initialized model\n",
    "net.requires_grad_(False)\n",
    "\n",
    "# Unfreeze the last block (layer4) and the fully connected (fc) layer\n",
    "net.layer4.requires_grad_(True)\n",
    "net.fc.requires_grad_(True)\n",
    "\n",
    "# Move the model to the device\n",
    "net.to(device)\n",
    "#################################################################################################\n",
    "#                                          End of your code                                     #\n",
    "#################################################################################################"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-05T07:13:34.926911500Z",
     "start_time": "2023-11-05T07:13:34.877807900Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Params to learn:\n",
      "\t layer4.0.conv1.weight\n",
      "\t layer4.0.bn1.weight\n",
      "\t layer4.0.bn1.bias\n",
      "\t layer4.0.conv2.weight\n",
      "\t layer4.0.bn2.weight\n",
      "\t layer4.0.bn2.bias\n",
      "\t layer4.0.downsample.0.weight\n",
      "\t layer4.0.downsample.1.weight\n",
      "\t layer4.0.downsample.1.bias\n",
      "\t layer4.1.conv1.weight\n",
      "\t layer4.1.bn1.weight\n",
      "\t layer4.1.bn1.bias\n",
      "\t layer4.1.conv2.weight\n",
      "\t layer4.1.bn2.weight\n",
      "\t layer4.1.bn2.bias\n",
      "\t fc.weight\n",
      "\t fc.bias\n"
     ]
    }
   ],
   "source": [
    "# Print all the trainable parameters\n",
    "params_to_update = net.parameters()\n",
    "print(\"Params to learn:\")\n",
    "params_to_update = []\n",
    "for name,param in net.named_parameters():\n",
    "    if param.requires_grad == True:\n",
    "        params_to_update.append(param)\n",
    "        print(\"\\t\",name)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-05T07:13:34.952021Z",
     "start_time": "2023-11-05T07:13:34.926085400Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [
    {
     "data": {
      "text/plain": "CrossEntropyLoss()"
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO: Define criterion and optimizer\n",
    "# Note that your optimizer only needs to update the parameters that are trainable.\n",
    "criterion = nn.CrossEntropyLoss(label_smoothing=label_smoothing)\n",
    "\n",
    "# Optimizer: Update only the parameters of layer4 and fc\n",
    "optimizer = optim.Adam([\n",
    "    {'params': net.layer4.parameters()},\n",
    "    {'params': net.fc.parameters()}\n",
    "], lr=0.001)\n",
    "\n",
    "criterion.to(device)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-05T07:13:34.952021Z",
     "start_time": "2023-11-05T07:13:34.930434100Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,   100] loss: 2.317 acc: 24.79 time: 7.16\n",
      "[1,   200] loss: 2.017 acc: 30.29 time: 7.18\n",
      "[1,   300] loss: 1.967 acc: 32.02 time: 7.16\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 37.46 %\n",
      "Average loss on the 10000 test images: 1.845\n",
      "[2,   100] loss: 1.910 acc: 34.12 time: 7.22\n",
      "[2,   200] loss: 1.901 acc: 34.66 time: 7.00\n",
      "[2,   300] loss: 1.872 acc: 36.76 time: 7.11\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 39.82 %\n",
      "Average loss on the 10000 test images: 1.804\n",
      "[3,   100] loss: 1.872 acc: 35.68 time: 7.20\n",
      "[3,   200] loss: 1.874 acc: 36.43 time: 7.25\n",
      "[3,   300] loss: 1.847 acc: 37.98 time: 7.19\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 39.07 %\n",
      "Average loss on the 10000 test images: 1.814\n",
      "[4,   100] loss: 1.836 acc: 38.20 time: 7.57\n",
      "[4,   200] loss: 1.849 acc: 37.68 time: 7.25\n",
      "[4,   300] loss: 1.845 acc: 38.11 time: 7.40\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 41.47 %\n",
      "Average loss on the 10000 test images: 1.762\n",
      "[5,   100] loss: 1.826 acc: 38.64 time: 7.39\n",
      "[5,   200] loss: 1.827 acc: 38.52 time: 7.55\n",
      "[5,   300] loss: 1.833 acc: 38.23 time: 7.15\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 40.67 %\n",
      "Average loss on the 10000 test images: 1.791\n",
      "[6,   100] loss: 1.809 acc: 39.59 time: 7.10\n",
      "[6,   200] loss: 1.828 acc: 38.52 time: 7.32\n",
      "[6,   300] loss: 1.809 acc: 39.75 time: 7.17\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 41.34 %\n",
      "Average loss on the 10000 test images: 1.769\n",
      "[7,   100] loss: 1.798 acc: 39.94 time: 7.29\n",
      "[7,   200] loss: 1.821 acc: 39.43 time: 7.10\n",
      "[7,   300] loss: 1.805 acc: 39.84 time: 7.36\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 42.75 %\n",
      "Average loss on the 10000 test images: 1.739\n",
      "[8,   100] loss: 1.805 acc: 39.18 time: 6.84\n",
      "[8,   200] loss: 1.804 acc: 39.71 time: 7.14\n",
      "[8,   300] loss: 1.787 acc: 40.32 time: 7.30\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 42.85 %\n",
      "Average loss on the 10000 test images: 1.753\n",
      "[9,   100] loss: 1.785 acc: 40.71 time: 7.40\n",
      "[9,   200] loss: 1.784 acc: 40.85 time: 7.02\n",
      "[9,   300] loss: 1.785 acc: 40.23 time: 7.37\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 43.03 %\n",
      "Average loss on the 10000 test images: 1.739\n",
      "[10,   100] loss: 1.782 acc: 41.05 time: 7.29\n",
      "[10,   200] loss: 1.781 acc: 41.27 time: 7.16\n",
      "[10,   300] loss: 1.772 acc: 41.63 time: 7.61\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 42.82 %\n",
      "Average loss on the 10000 test images: 1.745\n",
      "[11,   100] loss: 1.765 acc: 42.37 time: 7.25\n",
      "[11,   200] loss: 1.741 acc: 42.41 time: 7.05\n",
      "[11,   300] loss: 1.748 acc: 42.53 time: 6.98\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 44.68 %\n",
      "Average loss on the 10000 test images: 1.705\n",
      "[12,   100] loss: 1.727 acc: 43.44 time: 7.47\n",
      "[12,   200] loss: 1.742 acc: 43.09 time: 7.24\n",
      "[12,   300] loss: 1.719 acc: 43.77 time: 7.02\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 44.89 %\n",
      "Average loss on the 10000 test images: 1.699\n",
      "[13,   100] loss: 1.730 acc: 43.46 time: 7.63\n",
      "[13,   200] loss: 1.729 acc: 43.77 time: 7.31\n",
      "[13,   300] loss: 1.720 acc: 43.90 time: 7.46\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 44.85 %\n",
      "Average loss on the 10000 test images: 1.698\n",
      "[14,   100] loss: 1.732 acc: 42.95 time: 7.25\n",
      "[14,   200] loss: 1.725 acc: 43.43 time: 7.37\n",
      "[14,   300] loss: 1.706 acc: 44.11 time: 7.08\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 45.52 %\n",
      "Average loss on the 10000 test images: 1.688\n",
      "[15,   100] loss: 1.713 acc: 44.17 time: 7.16\n",
      "[15,   200] loss: 1.714 acc: 43.95 time: 7.31\n",
      "[15,   300] loss: 1.713 acc: 44.09 time: 7.07\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 45.71 %\n",
      "Average loss on the 10000 test images: 1.686\n",
      "[16,   100] loss: 1.711 acc: 43.66 time: 7.15\n",
      "[16,   200] loss: 1.716 acc: 44.38 time: 7.10\n",
      "[16,   300] loss: 1.714 acc: 44.09 time: 7.27\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 45.83 %\n",
      "Average loss on the 10000 test images: 1.685\n",
      "[17,   100] loss: 1.703 acc: 44.46 time: 7.09\n",
      "[17,   200] loss: 1.709 acc: 44.15 time: 7.27\n",
      "[17,   300] loss: 1.706 acc: 44.96 time: 6.97\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 45.68 %\n",
      "Average loss on the 10000 test images: 1.682\n",
      "[18,   100] loss: 1.694 acc: 45.12 time: 7.69\n",
      "[18,   200] loss: 1.698 acc: 45.12 time: 7.34\n",
      "[18,   300] loss: 1.705 acc: 44.59 time: 6.97\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 46.13 %\n",
      "Average loss on the 10000 test images: 1.675\n",
      "[19,   100] loss: 1.697 acc: 44.69 time: 7.64\n",
      "[19,   200] loss: 1.703 acc: 44.62 time: 7.10\n",
      "[19,   300] loss: 1.713 acc: 44.47 time: 7.28\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 45.82 %\n",
      "Average loss on the 10000 test images: 1.679\n",
      "[20,   100] loss: 1.696 acc: 44.57 time: 7.38\n",
      "[20,   200] loss: 1.700 acc: 44.48 time: 7.22\n",
      "[20,   300] loss: 1.706 acc: 44.50 time: 7.52\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 46.18 %\n",
      "Average loss on the 10000 test images: 1.680\n",
      "[21,   100] loss: 1.686 acc: 45.25 time: 7.59\n",
      "[21,   200] loss: 1.697 acc: 45.16 time: 7.29\n",
      "[21,   300] loss: 1.695 acc: 45.04 time: 7.06\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 46.50 %\n",
      "Average loss on the 10000 test images: 1.672\n",
      "[22,   100] loss: 1.693 acc: 45.11 time: 7.25\n",
      "[22,   200] loss: 1.688 acc: 45.29 time: 7.49\n",
      "[22,   300] loss: 1.690 acc: 45.60 time: 7.29\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 46.29 %\n",
      "Average loss on the 10000 test images: 1.674\n",
      "[23,   100] loss: 1.684 acc: 45.70 time: 7.23\n",
      "[23,   200] loss: 1.694 acc: 44.96 time: 6.93\n",
      "[23,   300] loss: 1.699 acc: 44.80 time: 7.17\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 46.22 %\n",
      "Average loss on the 10000 test images: 1.675\n",
      "[24,   100] loss: 1.691 acc: 45.40 time: 7.44\n",
      "[24,   200] loss: 1.682 acc: 45.73 time: 7.22\n",
      "[24,   300] loss: 1.695 acc: 44.96 time: 7.14\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 46.41 %\n",
      "Average loss on the 10000 test images: 1.672\n",
      "[25,   100] loss: 1.691 acc: 45.26 time: 7.48\n",
      "[25,   200] loss: 1.681 acc: 45.97 time: 7.28\n",
      "[25,   300] loss: 1.677 acc: 45.89 time: 7.25\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 46.16 %\n",
      "Average loss on the 10000 test images: 1.673\n",
      "[26,   100] loss: 1.693 acc: 45.22 time: 7.22\n",
      "[26,   200] loss: 1.693 acc: 45.36 time: 7.15\n",
      "[26,   300] loss: 1.689 acc: 45.71 time: 7.17\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 46.44 %\n",
      "Average loss on the 10000 test images: 1.671\n",
      "[27,   100] loss: 1.695 acc: 44.70 time: 7.15\n",
      "[27,   200] loss: 1.683 acc: 45.60 time: 7.35\n",
      "[27,   300] loss: 1.687 acc: 45.66 time: 7.31\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 46.40 %\n",
      "Average loss on the 10000 test images: 1.673\n",
      "[28,   100] loss: 1.690 acc: 45.48 time: 7.62\n",
      "[28,   200] loss: 1.676 acc: 45.80 time: 7.51\n",
      "[28,   300] loss: 1.690 acc: 45.12 time: 7.07\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 46.63 %\n",
      "Average loss on the 10000 test images: 1.668\n",
      "[29,   100] loss: 1.687 acc: 45.22 time: 7.29\n",
      "[29,   200] loss: 1.680 acc: 46.43 time: 7.28\n",
      "[29,   300] loss: 1.682 acc: 45.93 time: 6.98\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 46.64 %\n",
      "Average loss on the 10000 test images: 1.668\n",
      "[30,   100] loss: 1.685 acc: 44.92 time: 7.25\n",
      "[30,   200] loss: 1.692 acc: 45.18 time: 7.30\n",
      "[30,   300] loss: 1.682 acc: 45.16 time: 7.07\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 46.57 %\n",
      "Average loss on the 10000 test images: 1.665\n",
      "[31,   100] loss: 1.677 acc: 46.10 time: 7.50\n",
      "[31,   200] loss: 1.667 acc: 46.66 time: 7.35\n",
      "[31,   300] loss: 1.700 acc: 44.65 time: 7.12\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 46.52 %\n",
      "Average loss on the 10000 test images: 1.668\n",
      "[32,   100] loss: 1.672 acc: 45.75 time: 7.06\n",
      "[32,   200] loss: 1.684 acc: 45.03 time: 7.12\n",
      "[32,   300] loss: 1.690 acc: 44.48 time: 6.96\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 46.34 %\n",
      "Average loss on the 10000 test images: 1.671\n",
      "[33,   100] loss: 1.681 acc: 45.90 time: 7.19\n",
      "[33,   200] loss: 1.683 acc: 45.75 time: 7.24\n",
      "[33,   300] loss: 1.687 acc: 45.67 time: 6.96\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 46.58 %\n",
      "Average loss on the 10000 test images: 1.669\n",
      "[34,   100] loss: 1.677 acc: 45.73 time: 7.17\n",
      "[34,   200] loss: 1.691 acc: 45.33 time: 7.46\n",
      "[34,   300] loss: 1.682 acc: 45.79 time: 7.17\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 46.60 %\n",
      "Average loss on the 10000 test images: 1.667\n",
      "[35,   100] loss: 1.687 acc: 45.79 time: 7.19\n",
      "[35,   200] loss: 1.682 acc: 45.51 time: 7.07\n",
      "[35,   300] loss: 1.686 acc: 45.34 time: 7.00\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 46.31 %\n",
      "Average loss on the 10000 test images: 1.674\n",
      "[36,   100] loss: 1.678 acc: 46.07 time: 7.39\n",
      "[36,   200] loss: 1.684 acc: 45.49 time: 7.27\n",
      "[36,   300] loss: 1.700 acc: 44.91 time: 7.19\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 46.60 %\n",
      "Average loss on the 10000 test images: 1.670\n",
      "[37,   100] loss: 1.675 acc: 46.28 time: 7.16\n",
      "[37,   200] loss: 1.682 acc: 45.95 time: 7.44\n",
      "[37,   300] loss: 1.700 acc: 44.92 time: 7.09\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 46.52 %\n",
      "Average loss on the 10000 test images: 1.669\n",
      "[38,   100] loss: 1.672 acc: 46.15 time: 7.33\n",
      "[38,   200] loss: 1.689 acc: 45.41 time: 7.43\n",
      "[38,   300] loss: 1.688 acc: 45.14 time: 7.29\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 46.29 %\n",
      "Average loss on the 10000 test images: 1.669\n",
      "[39,   100] loss: 1.688 acc: 45.55 time: 7.37\n",
      "[39,   200] loss: 1.691 acc: 45.04 time: 7.56\n",
      "[39,   300] loss: 1.679 acc: 45.80 time: 7.11\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 46.69 %\n",
      "Average loss on the 10000 test images: 1.667\n",
      "[40,   100] loss: 1.695 acc: 45.37 time: 7.31\n",
      "[40,   200] loss: 1.692 acc: 45.35 time: 7.30\n",
      "[40,   300] loss: 1.677 acc: 45.27 time: 7.12\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 46.34 %\n",
      "Average loss on the 10000 test images: 1.672\n",
      "[41,   100] loss: 1.692 acc: 45.40 time: 7.34\n",
      "[41,   200] loss: 1.683 acc: 45.38 time: 7.42\n",
      "[41,   300] loss: 1.686 acc: 44.92 time: 7.13\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 46.44 %\n",
      "Average loss on the 10000 test images: 1.672\n",
      "[42,   100] loss: 1.698 acc: 45.12 time: 7.11\n",
      "[42,   200] loss: 1.685 acc: 45.31 time: 7.14\n",
      "[42,   300] loss: 1.676 acc: 45.67 time: 7.30\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 46.60 %\n",
      "Average loss on the 10000 test images: 1.667\n",
      "[43,   100] loss: 1.686 acc: 45.25 time: 7.38\n",
      "[43,   200] loss: 1.694 acc: 45.20 time: 7.39\n",
      "[43,   300] loss: 1.674 acc: 46.10 time: 7.12\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 46.33 %\n",
      "Average loss on the 10000 test images: 1.668\n",
      "[44,   100] loss: 1.688 acc: 45.12 time: 7.32\n",
      "[44,   200] loss: 1.691 acc: 45.69 time: 7.59\n",
      "[44,   300] loss: 1.687 acc: 45.24 time: 7.08\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 46.57 %\n",
      "Average loss on the 10000 test images: 1.668\n",
      "[45,   100] loss: 1.689 acc: 45.33 time: 7.43\n",
      "[45,   200] loss: 1.697 acc: 44.73 time: 7.12\n",
      "[45,   300] loss: 1.675 acc: 45.97 time: 7.15\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 46.35 %\n",
      "Average loss on the 10000 test images: 1.671\n",
      "[46,   100] loss: 1.684 acc: 45.80 time: 7.49\n",
      "[46,   200] loss: 1.688 acc: 45.37 time: 7.06\n",
      "[46,   300] loss: 1.682 acc: 45.88 time: 7.53\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 46.42 %\n",
      "Average loss on the 10000 test images: 1.666\n",
      "[47,   100] loss: 1.686 acc: 45.31 time: 7.66\n",
      "[47,   200] loss: 1.683 acc: 45.45 time: 7.10\n",
      "[47,   300] loss: 1.681 acc: 45.59 time: 7.47\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 46.39 %\n",
      "Average loss on the 10000 test images: 1.670\n",
      "[48,   100] loss: 1.689 acc: 44.91 time: 7.51\n",
      "[48,   200] loss: 1.688 acc: 45.35 time: 7.07\n",
      "[48,   300] loss: 1.677 acc: 45.75 time: 7.30\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 46.43 %\n",
      "Average loss on the 10000 test images: 1.672\n",
      "[49,   100] loss: 1.678 acc: 45.25 time: 7.10\n",
      "[49,   200] loss: 1.687 acc: 45.23 time: 7.05\n",
      "[49,   300] loss: 1.704 acc: 44.48 time: 7.32\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 46.48 %\n",
      "Average loss on the 10000 test images: 1.669\n",
      "[50,   100] loss: 1.683 acc: 45.70 time: 7.37\n",
      "[50,   200] loss: 1.699 acc: 44.98 time: 7.17\n",
      "[50,   300] loss: 1.688 acc: 45.59 time: 7.30\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 46.37 %\n",
      "Average loss on the 10000 test images: 1.669\n",
      "Restored best model from epoch with validation accuracy: 46.69%\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "train(net, criterion, optimizer, num_epochs=50, decay_epochs=10, init_lr=0.01, task='classification', experiment_type='Fine-tuning Randomly Initialized Model')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-05T07:40:42.719614700Z",
     "start_time": "2023-11-05T07:13:34.941942400Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Supervised training on the pre-trained model (9 points)\n",
    "In this section, we will load the ResNet18 model pre-trained on the rotation task and re-train the whole model on the classification task.\n",
    "\n",
    "**Then we will use the trained model from rotation task as the pretrained weights. Notice, you should not use the pretrained weights from ImageNet.**"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torchvision.models import resnet18\n",
    "\n",
    "#####################################################\n",
    "#     TODO: Load the pre-trained ResNet18 model     #\n",
    "#####################################################\n",
    "# load the trained classifier weights\n",
    "net = resnet18(weights=None, num_classes=rotation_direction)\n",
    "ckpt = torch.load(f\"{experience_name}.pth\")\n",
    "net.load_state_dict(ckpt)\n",
    "\n",
    "# Adjusting the fully connected layer for 10 classes\n",
    "net.fc = nn.Linear(net.fc.in_features, 10)\n",
    "net = net.to(device)\n",
    "#####################################################\n",
    "#                End of your code                   #\n",
    "#####################################################"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-05T07:40:42.984717700Z",
     "start_time": "2023-11-05T07:40:42.717614700Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "outputs": [
    {
     "data": {
      "text/plain": "CrossEntropyLoss()"
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO: Define criterion and optimizer\n",
    "criterion = nn.CrossEntropyLoss(label_smoothing=label_smoothing)\n",
    "\n",
    "# Optimizer: Update only the parameters of layer4 and fc\n",
    "optimizer = optim.Adam(lr=0.001, params=net.parameters())\n",
    "\n",
    "criterion.to(device)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-05T07:40:42.985715200Z",
     "start_time": "2023-11-05T07:40:42.978705800Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,   100] loss: 1.616 acc: 47.92 time: 17.78\n",
      "[1,   200] loss: 1.387 acc: 59.47 time: 11.18\n",
      "[1,   300] loss: 1.309 acc: 63.37 time: 7.45\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 65.54 %\n",
      "Average loss on the 10000 test images: 1.273\n",
      "[2,   100] loss: 1.215 acc: 68.35 time: 7.31\n",
      "[2,   200] loss: 1.199 acc: 69.30 time: 7.88\n",
      "[2,   300] loss: 1.182 acc: 69.50 time: 8.06\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 68.95 %\n",
      "Average loss on the 10000 test images: 1.194\n",
      "[3,   100] loss: 1.128 acc: 72.26 time: 7.43\n",
      "[3,   200] loss: 1.106 acc: 73.06 time: 8.32\n",
      "[3,   300] loss: 1.117 acc: 72.48 time: 8.29\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 74.18 %\n",
      "Average loss on the 10000 test images: 1.087\n",
      "[4,   100] loss: 1.075 acc: 74.24 time: 7.76\n",
      "[4,   200] loss: 1.077 acc: 74.73 time: 8.09\n",
      "[4,   300] loss: 1.060 acc: 75.20 time: 8.31\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 75.47 %\n",
      "Average loss on the 10000 test images: 1.057\n",
      "[5,   100] loss: 1.034 acc: 76.46 time: 8.14\n",
      "[5,   200] loss: 1.028 acc: 76.62 time: 7.66\n",
      "[5,   300] loss: 1.015 acc: 77.16 time: 7.92\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 77.05 %\n",
      "Average loss on the 10000 test images: 1.016\n",
      "[6,   100] loss: 0.989 acc: 78.46 time: 7.72\n",
      "[6,   200] loss: 1.002 acc: 77.33 time: 8.45\n",
      "[6,   300] loss: 0.989 acc: 78.51 time: 9.13\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 78.20 %\n",
      "Average loss on the 10000 test images: 0.999\n",
      "[7,   100] loss: 0.965 acc: 79.59 time: 7.72\n",
      "[7,   200] loss: 0.979 acc: 78.96 time: 7.82\n",
      "[7,   300] loss: 0.963 acc: 80.02 time: 8.61\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 77.46 %\n",
      "Average loss on the 10000 test images: 1.023\n",
      "[8,   100] loss: 0.948 acc: 80.67 time: 7.81\n",
      "[8,   200] loss: 0.954 acc: 80.09 time: 7.76\n",
      "[8,   300] loss: 0.949 acc: 80.14 time: 7.89\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 79.62 %\n",
      "Average loss on the 10000 test images: 0.967\n",
      "[9,   100] loss: 0.928 acc: 81.16 time: 7.82\n",
      "[9,   200] loss: 0.937 acc: 80.60 time: 7.76\n",
      "[9,   300] loss: 0.924 acc: 81.24 time: 8.57\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 79.44 %\n",
      "Average loss on the 10000 test images: 0.966\n",
      "[10,   100] loss: 0.910 acc: 82.03 time: 8.21\n",
      "[10,   200] loss: 0.916 acc: 81.79 time: 8.21\n",
      "[10,   300] loss: 0.910 acc: 82.11 time: 8.01\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 79.67 %\n",
      "Average loss on the 10000 test images: 0.961\n",
      "[11,   100] loss: 0.864 acc: 84.02 time: 7.87\n",
      "[11,   200] loss: 0.824 acc: 85.51 time: 8.10\n",
      "[11,   300] loss: 0.828 acc: 85.27 time: 8.89\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 82.90 %\n",
      "Average loss on the 10000 test images: 0.881\n",
      "[12,   100] loss: 0.819 acc: 85.84 time: 8.15\n",
      "[12,   200] loss: 0.807 acc: 86.29 time: 8.09\n",
      "[12,   300] loss: 0.810 acc: 86.48 time: 8.69\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 83.59 %\n",
      "Average loss on the 10000 test images: 0.875\n",
      "[13,   100] loss: 0.799 acc: 86.60 time: 8.10\n",
      "[13,   200] loss: 0.801 acc: 87.00 time: 8.36\n",
      "[13,   300] loss: 0.799 acc: 86.34 time: 8.81\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 83.68 %\n",
      "Average loss on the 10000 test images: 0.872\n",
      "[14,   100] loss: 0.791 acc: 87.13 time: 7.86\n",
      "[14,   200] loss: 0.786 acc: 87.26 time: 7.97\n",
      "[14,   300] loss: 0.798 acc: 86.81 time: 8.16\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 83.65 %\n",
      "Average loss on the 10000 test images: 0.868\n",
      "[15,   100] loss: 0.787 acc: 87.04 time: 8.01\n",
      "[15,   200] loss: 0.793 acc: 86.90 time: 7.84\n",
      "[15,   300] loss: 0.785 acc: 87.52 time: 9.12\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 83.70 %\n",
      "Average loss on the 10000 test images: 0.864\n",
      "[16,   100] loss: 0.783 acc: 87.79 time: 8.55\n",
      "[16,   200] loss: 0.782 acc: 87.45 time: 8.84\n",
      "[16,   300] loss: 0.784 acc: 87.42 time: 8.99\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 83.74 %\n",
      "Average loss on the 10000 test images: 0.867\n",
      "[17,   100] loss: 0.766 acc: 88.27 time: 8.17\n",
      "[17,   200] loss: 0.783 acc: 87.16 time: 8.07\n",
      "[17,   300] loss: 0.792 acc: 86.92 time: 8.76\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 83.70 %\n",
      "Average loss on the 10000 test images: 0.865\n",
      "[18,   100] loss: 0.771 acc: 88.20 time: 8.59\n",
      "[18,   200] loss: 0.762 acc: 88.59 time: 8.90\n",
      "[18,   300] loss: 0.782 acc: 87.54 time: 7.76\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 83.59 %\n",
      "Average loss on the 10000 test images: 0.866\n",
      "[19,   100] loss: 0.768 acc: 88.19 time: 8.02\n",
      "[19,   200] loss: 0.762 acc: 88.41 time: 8.09\n",
      "[19,   300] loss: 0.775 acc: 87.72 time: 8.10\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 83.82 %\n",
      "Average loss on the 10000 test images: 0.866\n",
      "[20,   100] loss: 0.765 acc: 88.27 time: 8.30\n",
      "[20,   200] loss: 0.768 acc: 88.24 time: 8.74\n",
      "[20,   300] loss: 0.757 acc: 88.73 time: 7.80\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 84.48 %\n",
      "Average loss on the 10000 test images: 0.860\n",
      "[21,   100] loss: 0.756 acc: 88.25 time: 7.92\n",
      "[21,   200] loss: 0.754 acc: 88.89 time: 8.32\n",
      "[21,   300] loss: 0.754 acc: 89.01 time: 8.47\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 84.64 %\n",
      "Average loss on the 10000 test images: 0.855\n",
      "[22,   100] loss: 0.760 acc: 88.54 time: 8.15\n",
      "[22,   200] loss: 0.740 acc: 89.51 time: 8.03\n",
      "[22,   300] loss: 0.751 acc: 89.10 time: 8.77\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 84.64 %\n",
      "Average loss on the 10000 test images: 0.854\n",
      "[23,   100] loss: 0.749 acc: 88.99 time: 7.95\n",
      "[23,   200] loss: 0.745 acc: 89.24 time: 8.23\n",
      "[23,   300] loss: 0.752 acc: 88.87 time: 8.53\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 84.40 %\n",
      "Average loss on the 10000 test images: 0.856\n",
      "[24,   100] loss: 0.745 acc: 89.30 time: 8.04\n",
      "[24,   200] loss: 0.749 acc: 89.05 time: 8.44\n",
      "[24,   300] loss: 0.754 acc: 88.72 time: 8.58\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 84.52 %\n",
      "Average loss on the 10000 test images: 0.856\n",
      "[25,   100] loss: 0.742 acc: 89.41 time: 8.26\n",
      "[25,   200] loss: 0.749 acc: 89.16 time: 8.78\n",
      "[25,   300] loss: 0.750 acc: 88.95 time: 8.28\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 84.51 %\n",
      "Average loss on the 10000 test images: 0.855\n",
      "[26,   100] loss: 0.739 acc: 89.56 time: 8.68\n",
      "[26,   200] loss: 0.747 acc: 89.27 time: 8.51\n",
      "[26,   300] loss: 0.741 acc: 89.48 time: 8.10\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 84.46 %\n",
      "Average loss on the 10000 test images: 0.856\n",
      "[27,   100] loss: 0.749 acc: 89.16 time: 8.09\n",
      "[27,   200] loss: 0.743 acc: 89.15 time: 8.38\n",
      "[27,   300] loss: 0.750 acc: 88.94 time: 8.00\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 84.54 %\n",
      "Average loss on the 10000 test images: 0.856\n",
      "[28,   100] loss: 0.732 acc: 89.77 time: 9.19\n",
      "[28,   200] loss: 0.744 acc: 89.20 time: 8.60\n",
      "[28,   300] loss: 0.742 acc: 89.20 time: 7.86\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 84.53 %\n",
      "Average loss on the 10000 test images: 0.855\n",
      "[29,   100] loss: 0.748 acc: 89.00 time: 9.36\n",
      "[29,   200] loss: 0.748 acc: 89.05 time: 8.04\n",
      "[29,   300] loss: 0.744 acc: 89.23 time: 8.18\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 84.34 %\n",
      "Average loss on the 10000 test images: 0.856\n",
      "[30,   100] loss: 0.753 acc: 89.11 time: 8.53\n",
      "[30,   200] loss: 0.744 acc: 89.17 time: 7.93\n",
      "[30,   300] loss: 0.742 acc: 89.34 time: 8.99\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 84.41 %\n",
      "Average loss on the 10000 test images: 0.855\n",
      "[31,   100] loss: 0.738 acc: 89.62 time: 8.34\n",
      "[31,   200] loss: 0.744 acc: 89.22 time: 8.14\n",
      "[31,   300] loss: 0.753 acc: 88.91 time: 8.85\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 84.64 %\n",
      "Average loss on the 10000 test images: 0.856\n",
      "[32,   100] loss: 0.730 acc: 89.55 time: 8.40\n",
      "[32,   200] loss: 0.733 acc: 89.59 time: 8.18\n",
      "[32,   300] loss: 0.748 acc: 89.24 time: 8.41\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 84.43 %\n",
      "Average loss on the 10000 test images: 0.857\n",
      "[33,   100] loss: 0.751 acc: 88.96 time: 8.66\n",
      "[33,   200] loss: 0.738 acc: 89.45 time: 8.11\n",
      "[33,   300] loss: 0.748 acc: 89.05 time: 8.33\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 84.53 %\n",
      "Average loss on the 10000 test images: 0.855\n",
      "[34,   100] loss: 0.747 acc: 89.23 time: 8.70\n",
      "[34,   200] loss: 0.736 acc: 89.78 time: 8.41\n",
      "[34,   300] loss: 0.744 acc: 89.22 time: 8.06\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 84.56 %\n",
      "Average loss on the 10000 test images: 0.855\n",
      "[35,   100] loss: 0.745 acc: 89.19 time: 8.92\n",
      "[35,   200] loss: 0.740 acc: 89.41 time: 8.34\n",
      "[35,   300] loss: 0.739 acc: 89.52 time: 8.16\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 84.44 %\n",
      "Average loss on the 10000 test images: 0.854\n",
      "[36,   100] loss: 0.744 acc: 89.45 time: 7.97\n",
      "[36,   200] loss: 0.740 acc: 89.37 time: 8.08\n",
      "[36,   300] loss: 0.748 acc: 89.04 time: 8.85\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 84.52 %\n",
      "Average loss on the 10000 test images: 0.854\n",
      "[37,   100] loss: 0.745 acc: 89.18 time: 8.83\n",
      "[37,   200] loss: 0.744 acc: 89.23 time: 8.39\n",
      "[37,   300] loss: 0.734 acc: 89.61 time: 8.38\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 84.38 %\n",
      "Average loss on the 10000 test images: 0.855\n",
      "[38,   100] loss: 0.736 acc: 89.45 time: 8.56\n",
      "[38,   200] loss: 0.743 acc: 89.23 time: 8.36\n",
      "[38,   300] loss: 0.740 acc: 89.32 time: 8.20\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 84.61 %\n",
      "Average loss on the 10000 test images: 0.856\n",
      "[39,   100] loss: 0.741 acc: 89.55 time: 9.12\n",
      "[39,   200] loss: 0.740 acc: 89.40 time: 8.30\n",
      "[39,   300] loss: 0.741 acc: 89.61 time: 8.76\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 84.58 %\n",
      "Average loss on the 10000 test images: 0.855\n",
      "[40,   100] loss: 0.744 acc: 89.16 time: 8.16\n",
      "[40,   200] loss: 0.740 acc: 89.66 time: 8.01\n",
      "[40,   300] loss: 0.744 acc: 89.25 time: 9.15\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 84.49 %\n",
      "Average loss on the 10000 test images: 0.856\n",
      "[41,   100] loss: 0.750 acc: 88.96 time: 8.70\n",
      "[41,   200] loss: 0.740 acc: 89.27 time: 8.68\n",
      "[41,   300] loss: 0.743 acc: 89.45 time: 8.39\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 84.42 %\n",
      "Average loss on the 10000 test images: 0.856\n",
      "[42,   100] loss: 0.738 acc: 89.55 time: 8.64\n",
      "[42,   200] loss: 0.748 acc: 89.17 time: 8.62\n",
      "[42,   300] loss: 0.740 acc: 89.48 time: 8.64\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 84.53 %\n",
      "Average loss on the 10000 test images: 0.856\n",
      "[43,   100] loss: 0.747 acc: 89.12 time: 8.62\n",
      "[43,   200] loss: 0.745 acc: 89.38 time: 8.09\n",
      "[43,   300] loss: 0.742 acc: 89.23 time: 9.38\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 84.45 %\n",
      "Average loss on the 10000 test images: 0.855\n",
      "[44,   100] loss: 0.741 acc: 89.41 time: 8.17\n",
      "[44,   200] loss: 0.745 acc: 88.94 time: 8.11\n",
      "[44,   300] loss: 0.741 acc: 89.44 time: 8.68\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 84.59 %\n",
      "Average loss on the 10000 test images: 0.854\n",
      "[45,   100] loss: 0.741 acc: 89.38 time: 8.87\n",
      "[45,   200] loss: 0.739 acc: 89.41 time: 8.29\n",
      "[45,   300] loss: 0.741 acc: 89.58 time: 8.35\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 84.53 %\n",
      "Average loss on the 10000 test images: 0.855\n",
      "[46,   100] loss: 0.739 acc: 89.59 time: 8.75\n",
      "[46,   200] loss: 0.736 acc: 89.74 time: 8.39\n",
      "[46,   300] loss: 0.743 acc: 89.38 time: 8.07\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 84.58 %\n",
      "Average loss on the 10000 test images: 0.855\n",
      "[47,   100] loss: 0.746 acc: 89.05 time: 9.27\n",
      "[47,   200] loss: 0.751 acc: 89.09 time: 8.37\n",
      "[47,   300] loss: 0.732 acc: 90.02 time: 7.99\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 84.61 %\n",
      "Average loss on the 10000 test images: 0.855\n",
      "[48,   100] loss: 0.732 acc: 89.88 time: 8.66\n",
      "[48,   200] loss: 0.746 acc: 89.12 time: 8.41\n",
      "[48,   300] loss: 0.753 acc: 88.80 time: 8.12\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 84.59 %\n",
      "Average loss on the 10000 test images: 0.856\n",
      "[49,   100] loss: 0.734 acc: 89.66 time: 8.22\n",
      "[49,   200] loss: 0.748 acc: 89.23 time: 7.97\n",
      "[49,   300] loss: 0.736 acc: 89.47 time: 9.01\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 84.62 %\n",
      "Average loss on the 10000 test images: 0.855\n",
      "[50,   100] loss: 0.740 acc: 89.19 time: 8.25\n",
      "[50,   200] loss: 0.741 acc: 89.27 time: 8.67\n",
      "[50,   300] loss: 0.755 acc: 88.88 time: 8.45\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 84.47 %\n",
      "Average loss on the 10000 test images: 0.855\n",
      "Restored best model from epoch with validation accuracy: 84.64%\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "train(net, criterion, optimizer, num_epochs=50, decay_epochs=10, init_lr=0.01, task='classification', experiment_type='Supervised Pre-trained Model')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-05T08:49:27.335143100Z",
     "start_time": "2023-11-05T08:18:32.524812600Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Supervised training on the randomly initialized model (9 points)\n",
    "In this section, we will randomly initialize a ResNet18 model and re-train the whole model on the classification task."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torchvision.models import resnet18\n",
    "\n",
    "#################################################\n",
    "# TODO: Randomly initialize a ResNet18 model    #\n",
    "#################################################\n",
    "net = resnet18(weights=None, num_classes=10)\n",
    "net = net.to(device)\n",
    "#################################################\n",
    "#              End of your code                 #\n",
    "#################################################"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-05T08:49:27.531056200Z",
     "start_time": "2023-11-05T08:49:27.332143600Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "outputs": [
    {
     "data": {
      "text/plain": "CrossEntropyLoss()"
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO: Define criterion and optimizer\n",
    "criterion = nn.CrossEntropyLoss(label_smoothing=label_smoothing)\n",
    "\n",
    "# Optimizer: Update only the parameters of layer4 and fc\n",
    "optimizer = optim.Adam(lr=0.001, params=net.parameters())\n",
    "\n",
    "criterion.to(device)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-05T08:49:27.532051200Z",
     "start_time": "2023-11-05T08:49:27.525128600Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,   100] loss: 2.243 acc: 25.22 time: 8.82\n",
      "[1,   200] loss: 1.950 acc: 34.40 time: 7.67\n",
      "[1,   300] loss: 1.863 acc: 36.67 time: 8.48\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 43.68 %\n",
      "Average loss on the 10000 test images: 1.743\n",
      "[2,   100] loss: 1.697 acc: 44.10 time: 8.29\n",
      "[2,   200] loss: 1.619 acc: 47.81 time: 8.89\n",
      "[2,   300] loss: 1.573 acc: 50.45 time: 8.75\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 53.01 %\n",
      "Average loss on the 10000 test images: 1.572\n",
      "[3,   100] loss: 1.489 acc: 54.59 time: 9.11\n",
      "[3,   200] loss: 1.436 acc: 56.90 time: 8.24\n",
      "[3,   300] loss: 1.398 acc: 58.92 time: 9.24\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 61.14 %\n",
      "Average loss on the 10000 test images: 1.347\n",
      "[4,   100] loss: 1.355 acc: 60.91 time: 8.36\n",
      "[4,   200] loss: 1.319 acc: 62.94 time: 8.71\n",
      "[4,   300] loss: 1.292 acc: 64.23 time: 8.95\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 65.85 %\n",
      "Average loss on the 10000 test images: 1.272\n",
      "[5,   100] loss: 1.251 acc: 66.12 time: 8.24\n",
      "[5,   200] loss: 1.237 acc: 66.73 time: 7.98\n",
      "[5,   300] loss: 1.221 acc: 67.42 time: 8.29\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 68.40 %\n",
      "Average loss on the 10000 test images: 1.207\n",
      "[6,   100] loss: 1.193 acc: 68.62 time: 8.66\n",
      "[6,   200] loss: 1.177 acc: 69.92 time: 8.77\n",
      "[6,   300] loss: 1.171 acc: 70.33 time: 8.46\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 70.54 %\n",
      "Average loss on the 10000 test images: 1.176\n",
      "[7,   100] loss: 1.131 acc: 71.68 time: 8.65\n",
      "[7,   200] loss: 1.130 acc: 71.92 time: 9.49\n",
      "[7,   300] loss: 1.116 acc: 72.55 time: 7.97\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 73.30 %\n",
      "Average loss on the 10000 test images: 1.097\n",
      "[8,   100] loss: 1.089 acc: 73.81 time: 8.75\n",
      "[8,   200] loss: 1.097 acc: 73.53 time: 9.09\n",
      "[8,   300] loss: 1.102 acc: 73.43 time: 7.99\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 72.77 %\n",
      "Average loss on the 10000 test images: 1.120\n",
      "[9,   100] loss: 1.078 acc: 74.52 time: 7.98\n",
      "[9,   200] loss: 1.049 acc: 75.67 time: 8.17\n",
      "[9,   300] loss: 1.053 acc: 75.40 time: 8.11\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 76.47 %\n",
      "Average loss on the 10000 test images: 1.030\n",
      "[10,   100] loss: 1.017 acc: 77.08 time: 8.08\n",
      "[10,   200] loss: 1.045 acc: 76.16 time: 8.21\n",
      "[10,   300] loss: 1.034 acc: 76.41 time: 8.05\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 75.40 %\n",
      "Average loss on the 10000 test images: 1.052\n",
      "[11,   100] loss: 0.970 acc: 79.07 time: 8.04\n",
      "[11,   200] loss: 0.918 acc: 81.73 time: 9.39\n",
      "[11,   300] loss: 0.927 acc: 81.10 time: 7.92\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 80.69 %\n",
      "Average loss on the 10000 test images: 0.935\n",
      "[12,   100] loss: 0.900 acc: 81.82 time: 8.13\n",
      "[12,   200] loss: 0.893 acc: 82.70 time: 9.07\n",
      "[12,   300] loss: 0.901 acc: 82.04 time: 8.65\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 80.85 %\n",
      "Average loss on the 10000 test images: 0.929\n",
      "[13,   100] loss: 0.885 acc: 83.02 time: 8.29\n",
      "[13,   200] loss: 0.890 acc: 82.79 time: 8.39\n",
      "[13,   300] loss: 0.878 acc: 83.37 time: 8.16\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 81.49 %\n",
      "Average loss on the 10000 test images: 0.914\n",
      "[14,   100] loss: 0.874 acc: 83.56 time: 7.98\n",
      "[14,   200] loss: 0.876 acc: 83.38 time: 8.57\n",
      "[14,   300] loss: 0.878 acc: 83.13 time: 8.50\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 81.94 %\n",
      "Average loss on the 10000 test images: 0.911\n",
      "[15,   100] loss: 0.865 acc: 83.70 time: 8.17\n",
      "[15,   200] loss: 0.863 acc: 83.79 time: 9.17\n",
      "[15,   300] loss: 0.867 acc: 83.83 time: 8.52\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 81.92 %\n",
      "Average loss on the 10000 test images: 0.909\n",
      "[16,   100] loss: 0.854 acc: 84.54 time: 8.35\n",
      "[16,   200] loss: 0.860 acc: 84.20 time: 9.39\n",
      "[16,   300] loss: 0.846 acc: 84.73 time: 8.81\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 82.04 %\n",
      "Average loss on the 10000 test images: 0.902\n",
      "[17,   100] loss: 0.845 acc: 84.96 time: 8.11\n",
      "[17,   200] loss: 0.845 acc: 84.63 time: 8.92\n",
      "[17,   300] loss: 0.844 acc: 84.67 time: 8.43\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 82.43 %\n",
      "Average loss on the 10000 test images: 0.902\n",
      "[18,   100] loss: 0.842 acc: 84.78 time: 8.32\n",
      "[18,   200] loss: 0.836 acc: 84.94 time: 7.93\n",
      "[18,   300] loss: 0.836 acc: 85.12 time: 8.10\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 82.34 %\n",
      "Average loss on the 10000 test images: 0.899\n",
      "[19,   100] loss: 0.832 acc: 85.20 time: 8.50\n",
      "[19,   200] loss: 0.834 acc: 85.07 time: 8.42\n",
      "[19,   300] loss: 0.833 acc: 85.45 time: 8.75\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 82.32 %\n",
      "Average loss on the 10000 test images: 0.900\n",
      "[20,   100] loss: 0.806 acc: 86.47 time: 8.42\n",
      "[20,   200] loss: 0.826 acc: 85.58 time: 8.98\n",
      "[20,   300] loss: 0.825 acc: 85.97 time: 8.25\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 82.55 %\n",
      "Average loss on the 10000 test images: 0.897\n",
      "[21,   100] loss: 0.802 acc: 86.70 time: 8.42\n",
      "[21,   200] loss: 0.798 acc: 86.73 time: 8.06\n",
      "[21,   300] loss: 0.803 acc: 86.89 time: 8.32\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 83.05 %\n",
      "Average loss on the 10000 test images: 0.890\n",
      "[22,   100] loss: 0.811 acc: 86.16 time: 8.46\n",
      "[22,   200] loss: 0.794 acc: 87.04 time: 8.54\n",
      "[22,   300] loss: 0.799 acc: 86.66 time: 8.64\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 83.09 %\n",
      "Average loss on the 10000 test images: 0.889\n",
      "[23,   100] loss: 0.803 acc: 86.80 time: 9.30\n",
      "[23,   200] loss: 0.796 acc: 86.66 time: 8.71\n",
      "[23,   300] loss: 0.795 acc: 87.28 time: 8.80\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 83.13 %\n",
      "Average loss on the 10000 test images: 0.889\n",
      "[24,   100] loss: 0.799 acc: 86.64 time: 8.92\n",
      "[24,   200] loss: 0.789 acc: 87.35 time: 7.95\n",
      "[24,   300] loss: 0.798 acc: 86.88 time: 8.42\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 83.21 %\n",
      "Average loss on the 10000 test images: 0.888\n",
      "[25,   100] loss: 0.793 acc: 86.99 time: 8.10\n",
      "[25,   200] loss: 0.800 acc: 86.70 time: 8.10\n",
      "[25,   300] loss: 0.792 acc: 87.16 time: 8.32\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 83.17 %\n",
      "Average loss on the 10000 test images: 0.888\n",
      "[26,   100] loss: 0.796 acc: 86.88 time: 8.16\n",
      "[26,   200] loss: 0.796 acc: 86.99 time: 8.35\n",
      "[26,   300] loss: 0.795 acc: 87.20 time: 8.69\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 83.18 %\n",
      "Average loss on the 10000 test images: 0.887\n",
      "[27,   100] loss: 0.804 acc: 86.57 time: 9.20\n",
      "[27,   200] loss: 0.790 acc: 87.06 time: 8.26\n",
      "[27,   300] loss: 0.798 acc: 86.81 time: 8.37\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 83.35 %\n",
      "Average loss on the 10000 test images: 0.887\n",
      "[28,   100] loss: 0.795 acc: 87.01 time: 8.79\n",
      "[28,   200] loss: 0.794 acc: 87.05 time: 8.31\n",
      "[28,   300] loss: 0.794 acc: 86.80 time: 8.37\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 83.25 %\n",
      "Average loss on the 10000 test images: 0.885\n",
      "[29,   100] loss: 0.784 acc: 87.61 time: 9.53\n",
      "[29,   200] loss: 0.790 acc: 87.28 time: 8.03\n",
      "[29,   300] loss: 0.793 acc: 86.72 time: 8.22\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 83.38 %\n",
      "Average loss on the 10000 test images: 0.884\n",
      "[30,   100] loss: 0.784 acc: 87.68 time: 8.72\n",
      "[30,   200] loss: 0.789 acc: 87.23 time: 8.19\n",
      "[30,   300] loss: 0.786 acc: 87.05 time: 8.17\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 83.43 %\n",
      "Average loss on the 10000 test images: 0.886\n",
      "[31,   100] loss: 0.783 acc: 87.40 time: 8.73\n",
      "[31,   200] loss: 0.795 acc: 87.02 time: 8.43\n",
      "[31,   300] loss: 0.777 acc: 87.79 time: 8.39\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 83.28 %\n",
      "Average loss on the 10000 test images: 0.885\n",
      "[32,   100] loss: 0.782 acc: 87.80 time: 8.86\n",
      "[32,   200] loss: 0.785 acc: 87.17 time: 8.07\n",
      "[32,   300] loss: 0.790 acc: 87.02 time: 8.43\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 83.36 %\n",
      "Average loss on the 10000 test images: 0.884\n",
      "[33,   100] loss: 0.788 acc: 87.15 time: 8.37\n",
      "[33,   200] loss: 0.783 acc: 87.53 time: 8.67\n",
      "[33,   300] loss: 0.788 acc: 87.30 time: 8.19\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 83.36 %\n",
      "Average loss on the 10000 test images: 0.884\n",
      "[34,   100] loss: 0.788 acc: 87.22 time: 8.56\n",
      "[34,   200] loss: 0.789 acc: 87.21 time: 8.79\n",
      "[34,   300] loss: 0.786 acc: 87.34 time: 8.11\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 83.32 %\n",
      "Average loss on the 10000 test images: 0.884\n",
      "[35,   100] loss: 0.780 acc: 87.87 time: 8.58\n",
      "[35,   200] loss: 0.796 acc: 86.90 time: 7.99\n",
      "[35,   300] loss: 0.776 acc: 87.99 time: 8.77\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 83.39 %\n",
      "Average loss on the 10000 test images: 0.884\n",
      "[36,   100] loss: 0.785 acc: 87.32 time: 8.73\n",
      "[36,   200] loss: 0.787 acc: 87.13 time: 8.29\n",
      "[36,   300] loss: 0.773 acc: 87.86 time: 8.12\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 83.24 %\n",
      "Average loss on the 10000 test images: 0.884\n",
      "[37,   100] loss: 0.780 acc: 87.96 time: 8.76\n",
      "[37,   200] loss: 0.791 acc: 86.99 time: 9.49\n",
      "[37,   300] loss: 0.783 acc: 87.04 time: 8.07\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 83.40 %\n",
      "Average loss on the 10000 test images: 0.883\n",
      "[38,   100] loss: 0.772 acc: 87.97 time: 8.53\n",
      "[38,   200] loss: 0.782 acc: 87.62 time: 7.92\n",
      "[38,   300] loss: 0.784 acc: 87.34 time: 8.20\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 83.09 %\n",
      "Average loss on the 10000 test images: 0.885\n",
      "[39,   100] loss: 0.781 acc: 87.83 time: 8.84\n",
      "[39,   200] loss: 0.778 acc: 87.66 time: 8.82\n",
      "[39,   300] loss: 0.788 acc: 87.09 time: 8.09\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 83.20 %\n",
      "Average loss on the 10000 test images: 0.885\n",
      "[40,   100] loss: 0.781 acc: 87.60 time: 8.63\n",
      "[40,   200] loss: 0.780 acc: 87.60 time: 8.86\n",
      "[40,   300] loss: 0.779 acc: 87.73 time: 8.10\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 83.36 %\n",
      "Average loss on the 10000 test images: 0.884\n",
      "[41,   100] loss: 0.782 acc: 87.53 time: 9.13\n",
      "[41,   200] loss: 0.784 acc: 87.61 time: 7.85\n",
      "[41,   300] loss: 0.785 acc: 87.24 time: 8.16\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 83.47 %\n",
      "Average loss on the 10000 test images: 0.886\n",
      "[42,   100] loss: 0.784 acc: 87.36 time: 9.03\n",
      "[42,   200] loss: 0.781 acc: 87.52 time: 7.97\n",
      "[42,   300] loss: 0.784 acc: 87.50 time: 8.20\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 83.38 %\n",
      "Average loss on the 10000 test images: 0.884\n",
      "[43,   100] loss: 0.781 acc: 87.84 time: 9.05\n",
      "[43,   200] loss: 0.786 acc: 87.44 time: 9.10\n",
      "[43,   300] loss: 0.781 acc: 87.61 time: 8.40\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 83.39 %\n",
      "Average loss on the 10000 test images: 0.884\n",
      "[44,   100] loss: 0.779 acc: 87.91 time: 9.05\n",
      "[44,   200] loss: 0.778 acc: 87.70 time: 8.84\n",
      "[44,   300] loss: 0.785 acc: 87.63 time: 8.80\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 83.26 %\n",
      "Average loss on the 10000 test images: 0.884\n",
      "[45,   100] loss: 0.781 acc: 87.70 time: 8.84\n",
      "[45,   200] loss: 0.786 acc: 87.62 time: 8.34\n",
      "[45,   300] loss: 0.784 acc: 87.39 time: 9.06\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 83.40 %\n",
      "Average loss on the 10000 test images: 0.884\n",
      "[46,   100] loss: 0.783 acc: 87.52 time: 8.78\n",
      "[46,   200] loss: 0.781 acc: 87.66 time: 9.13\n",
      "[46,   300] loss: 0.795 acc: 87.12 time: 8.51\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 83.48 %\n",
      "Average loss on the 10000 test images: 0.884\n",
      "[47,   100] loss: 0.787 acc: 86.98 time: 8.42\n",
      "[47,   200] loss: 0.776 acc: 87.81 time: 8.02\n",
      "[47,   300] loss: 0.780 acc: 87.77 time: 8.40\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 83.38 %\n",
      "Average loss on the 10000 test images: 0.884\n",
      "[48,   100] loss: 0.784 acc: 87.41 time: 9.22\n",
      "[48,   200] loss: 0.775 acc: 87.55 time: 9.71\n",
      "[48,   300] loss: 0.797 acc: 86.84 time: 8.43\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 83.32 %\n",
      "Average loss on the 10000 test images: 0.885\n",
      "[49,   100] loss: 0.788 acc: 87.31 time: 8.56\n",
      "[49,   200] loss: 0.784 acc: 87.58 time: 8.25\n",
      "[49,   300] loss: 0.777 acc: 87.76 time: 8.51\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 83.28 %\n",
      "Average loss on the 10000 test images: 0.884\n",
      "[50,   100] loss: 0.782 acc: 87.45 time: 8.17\n",
      "[50,   200] loss: 0.782 acc: 87.50 time: 8.27\n",
      "[50,   300] loss: 0.781 acc: 87.60 time: 8.33\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 83.50 %\n",
      "Average loss on the 10000 test images: 0.884\n",
      "Restored best model from epoch with validation accuracy: 83.50%\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "train(net, criterion, optimizer, num_epochs=50, decay_epochs=10, init_lr=0.01, task='classification', experiment_type='Supervised Randomly Initialized Model')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-05T09:20:54.895135100Z",
     "start_time": "2023-11-05T08:49:27.532051200Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Write report (37 points)\n",
    "\n",
    "本次作業主要有3個tasks需要大家完成，在A4.pdf中有希望大家達成的baseline **(不能低於baseline最多2%，沒有達到不會給全部分數)**，report的撰寫就希望大家可以透過去調整不同的訓練方法、損失函數、優化器，或者是調整凍結不同的層來進行這次的實驗，就請大家將嘗試的結果寫在report裡，祝大家順利！\n",
    "\n",
    "- Rotation task (13 points)\n",
    "- Fine-tuning the specified layers of the pre-trained model (12 points)\n",
    "- Fine-tuning the whole pre-trained model (12 points)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Extra Credit (13 points)\n",
    "\n",
    "上面基本的code跟report最高可以拿到87分，這個加分部分並沒有要求同學們一定要做，若同學們想要獲得更高的分數可以根據以下的加分要求來獲得加分。\n",
    "\n",
    "- In Figure 5(b) from the Gidaris et al. paper, the authors show a plot of CIFAR10 classification performance vs. number of training examples per category for a supervised CIFAR10 model vs. a RotNet model with the final layers fine-tuned on CIFAR10. The plot shows that pre-training on the Rotation task can be advantageous when only a small amount of labeled data is available. Using your RotNet fine-tuning code and supervised CIFAR10 training code from the main assignment, try to create a similar plot by performing supervised fine-tuning/training on only a subset of CIFAR10.\n",
    "- Use a more advanced model than ResNet18 to try to get higher accuracy on the rotation prediction task, as well as for transfer to supervised CIFAR10 classification.\n",
    "\n",
    "- If you have a good amount of compute at your disposal, try to train a rotation prediction model on the larger ImageNette dataset (still smaller than ImageNet, though).\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": [
    {
     "file_id": "1qQ3NEaCUln7yDSksrEOnDwrt3u9dYNr4",
     "timestamp": 1677623843954
    }
   ]
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3.8.13",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "aaa478f9632825e83f6a2247407c7a2930de96a6810af7910643e423346524f9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
