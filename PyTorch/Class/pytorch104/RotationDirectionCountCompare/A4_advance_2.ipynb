{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MIS 583 Assignment 4: Self-supervised and transfer learning on CIFAR10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we start, please put your name and SID in following format: <br>\n",
    ": LASTNAME Firstname, ?00000000   //   e.g.) 李晨愷 M114020035"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Your Answer:**    \n",
    "Hi I'm 鄔仁迪, B104020009."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "data": {
      "text/plain": "Empty DataFrame\nColumns: [Experiment Type, Epoch, Train Accuracy, Train Loss, Valid Accuracy, Valid Loss]\nIndex: []",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Experiment Type</th>\n      <th>Epoch</th>\n      <th>Train Accuracy</th>\n      <th>Train Loss</th>\n      <th>Valid Accuracy</th>\n      <th>Valid Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "experience_name = 'self_supervised_direction_8'\n",
    "label_smoothing = 0.1\n",
    "rotation_direction = 8\n",
    "\n",
    "# Define columns for the DataFrame\n",
    "columns = ['Experiment Type', 'Epoch', 'Train Accuracy', 'Train Loss', 'Valid Accuracy', 'Valid Loss']\n",
    "\n",
    "# Initialize an empty DataFrame with these columns\n",
    "experience_report = pd.DataFrame(columns=columns)\n",
    "\n",
    "experience_report"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-05T06:15:09.705600400Z",
     "start_time": "2023-11-05T06:15:09.033099900Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "# Function to set the seed\n",
    "def set_seed(seed_value=42):\n",
    "    \"\"\"Set seed for reproducibility.\"\"\"\n",
    "    torch.manual_seed(seed_value)\n",
    "    torch.cuda.manual_seed(seed_value)\n",
    "    torch.cuda.manual_seed_all(seed_value)  # if you are using multi-GPU.\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    np.random.seed(seed_value)\n",
    "    random.seed(seed_value)\n",
    "\n",
    "set_seed()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-05T06:15:09.705600400Z",
     "start_time": "2023-11-05T06:15:09.044311600Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IWMWW8Ab_345"
   },
   "source": [
    "## Google Colab Setup\n",
    "Next we need to run a few commands to set up our environment on Google Colab. If you are running this notebook on a local machine you can skip this section.\n",
    "\n",
    "Run the following cell to mount your Google Drive. Follow the link, sign in to your Google account (the same account you used to store this notebook!) and copy the authorization code into the text box that appears below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "vH4wc4iD_6w_",
    "ExecuteTime": {
     "end_time": "2023-11-05T06:15:09.887611500Z",
     "start_time": "2023-11-05T06:15:09.069997600Z"
    }
   },
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "XpNsPHZc_879",
    "ExecuteTime": {
     "end_time": "2023-11-05T06:15:09.887611500Z",
     "start_time": "2023-11-05T06:15:09.072509900Z"
    }
   },
   "outputs": [],
   "source": [
    "# fill in the path in your Google Drive in the string below. Note: do not escape slashes or spaces\n",
    "# import os\n",
    "# datadir = \"C:/Users/eddie/GitHub/Deep-Learning/PyTorch/Class/pytorch104\"\n",
    "# if not os.path.exists(datadir):\n",
    "#  !ln -s \"/content/drive/My Drive/Your/A4/path/\" $datadir # TODO: Fill your A3 path\n",
    "# os.chdir(datadir)\n",
    "# !pwd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Um5DJvBwb6xT"
   },
   "source": [
    "# Data Setup (5 points)\n",
    "\n",
    "The first thing to do is implement a dataset class to load rotated CIFAR10 images with matching labels. Since there is already a CIFAR10 dataset class implemented in `torchvision`, we will extend this class and modify the `__get_item__` method appropriately to load rotated images.\n",
    "\n",
    "Each rotation label should be an integer in the set {0, 1, 2, 3} which correspond to rotations of 0, 90, 180, or 270 degrees respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "oHkeNUOKiFbP",
    "ExecuteTime": {
     "end_time": "2023-11-05T06:15:09.946600600Z",
     "start_time": "2023-11-05T06:15:09.105860900Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "\n",
    "def rotate_img(img, rot):\n",
    "    \"\"\"\n",
    "    Rotates the image by a specified angle.\n",
    "\n",
    "    Parameters:\n",
    "    - img (PIL Image or Tensor): The image to be rotated.\n",
    "    - rot (int): The rotation label indicating the angle of rotation. Should be in the range [0, rotation_direction-1].\n",
    "\n",
    "    Returns:\n",
    "    - PIL Image or Tensor: The rotated image.\n",
    "    \"\"\"\n",
    "    angle = (360 / rotation_direction) * rot  # Calculate the rotation angle based on the label and the total directions\n",
    "\n",
    "    if not (0 <= rot < rotation_direction):\n",
    "        raise ValueError(f'rotation should be an integer in range [0, {rotation_direction - 1}]')\n",
    "\n",
    "    # Perform the rotation\n",
    "    return transforms.functional.rotate(img, angle)\n",
    "\n",
    "class CIFAR10Rotation(torchvision.datasets.CIFAR10):\n",
    "\n",
    "    def __init__(self, root, train, download, transform) -> None:\n",
    "        super().__init__(root=root, train=train, download=download, transform=transform)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, index: int):\n",
    "        image, cls_label = super().__getitem__(index)\n",
    "\n",
    "        # Randomly select image rotation based on the number of directions\n",
    "        rotation_label = random.randrange(rotation_direction)\n",
    "        image_rotated = rotate_img(image, rotation_label)\n",
    "\n",
    "        rotation_label = torch.tensor(rotation_label).long()\n",
    "        return image, image_rotated, rotation_label, torch.tensor(cls_label).long()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "CCBSpNWpb8uw",
    "ExecuteTime": {
     "end_time": "2023-11-05T06:15:10.974000500Z",
     "start_time": "2023-11-05T06:15:09.108921700Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "transform_train = transforms.Compose([\n",
    "    transforms.RandomCrop(32, padding=4),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])\n",
    "\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])\n",
    "\n",
    "batch_size = 128\n",
    "\n",
    "trainset = CIFAR10Rotation(root='../data', train=True,\n",
    "                                        download=True, transform=transform_train)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,\n",
    "                                          shuffle=True, num_workers=0)\n",
    "\n",
    "testset = CIFAR10Rotation(root='../data', train=False,\n",
    "                                       download=True, transform=transform_test)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size,\n",
    "                                         shuffle=False, num_workers=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dOCWMyGhVOJB"
   },
   "source": [
    "Show some example images and rotated images with labels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "A9wN4BJWVMzB",
    "ExecuteTime": {
     "end_time": "2023-11-05T06:15:11.338840Z",
     "start_time": "2023-11-05T06:15:10.971034900Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "data": {
      "text/plain": "<Figure size 640x480 with 1 Axes>",
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class labels:  frog  plane deer  car  \n"
     ]
    },
    {
     "data": {
      "text/plain": "<Figure size 640x480 with 1 Axes>",
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rotation labels:  45    0     180   135  \n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat',\n",
    "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "\n",
    "# Calculate the step size based on 360 degrees and the number of directions\n",
    "step_size = 360 // rotation_direction\n",
    "\n",
    "# Generate the rotation classes based on the number of directions\n",
    "rot_classes = tuple(str(i * step_size) for i in range(rotation_direction))\n",
    "\n",
    "\n",
    "def imshow(img):\n",
    "    # unnormalize\n",
    "    img = transforms.Normalize((0, 0, 0), (1/0.2023, 1/0.1994, 1/0.2010))(img)\n",
    "    img = transforms.Normalize((-0.4914, -0.4822, -0.4465), (1, 1, 1))(img)\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "dataiter = iter(trainloader)\n",
    "images, rot_images, rot_labels, labels = next(dataiter)\n",
    "\n",
    "# print images and rotated images\n",
    "img_grid = imshow(torchvision.utils.make_grid(images[:4], padding=0))\n",
    "print('Class labels: ', ' '.join(f'{classes[labels[j]]:5s}' for j in range(4)))\n",
    "img_grid = imshow(torchvision.utils.make_grid(rot_images[:4], padding=0))\n",
    "print('Rotation labels: ', ' '.join(f'{rot_classes[rot_labels[j]]:5s}' for j in range(4)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "unCucbHexG4W"
   },
   "source": [
    "# Evaluation code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "pptQRpqK0rOl",
    "ExecuteTime": {
     "end_time": "2023-11-05T06:15:11.340839700Z",
     "start_time": "2023-11-05T06:15:11.296608100Z"
    }
   },
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def run_test(net, testloader, criterion, task):\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    avg_test_loss = 0.0\n",
    "    # since we're not training, we don't need to calculate the gradients for our outputs\n",
    "    with torch.no_grad():\n",
    "        for images, images_rotated, labels, cls_labels in testloader:\n",
    "            if task == 'rotation':\n",
    "              images, labels = images_rotated.to(device), labels.to(device)\n",
    "            elif task == 'classification':\n",
    "              images, labels = images.to(device), cls_labels.to(device)\n",
    "            #######################################################################\n",
    "            # TODO: Calculate outputs by running images through the network       #\n",
    "            # The class with the highest energy is what we choose as prediction   #\n",
    "            #######################################################################\n",
    "            # Calculate outputs by running images through the network\n",
    "            outputs = net(images)\n",
    "\n",
    "            # The class with the highest score is what we choose as our prediction\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            #######################################################################\n",
    "            #                           End of your code                          #\n",
    "            #######################################################################\n",
    "            avg_test_loss += criterion(outputs, labels)  / len(testloader)\n",
    "    print('TESTING:')\n",
    "    print(f'Accuracy of the network on the 10000 test images: {100 * correct / total:.2f} %')\n",
    "    print(f'Average loss on the 10000 test images: {avg_test_loss:.3f}')\n",
    "\n",
    "    return avg_test_loss, 100 * correct / total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "hf698c16A9k5",
    "ExecuteTime": {
     "end_time": "2023-11-05T06:15:11.340839700Z",
     "start_time": "2023-11-05T06:15:11.320819400Z"
    }
   },
   "outputs": [],
   "source": [
    "def adjust_learning_rate(optimizer, epoch, init_lr, decay_epochs=30):\n",
    "    \"\"\"Sets the learning rate to the initial LR decayed by 10 every 30 epochs\"\"\"\n",
    "    lr = init_lr * (0.1 ** (epoch // decay_epochs))\n",
    "    for param_group in optimizer.param_groups:\n",
    "        param_group['lr'] = lr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3lYdnb1Wsta_"
   },
   "source": [
    "# Train a ResNet18 on the rotation task (9 points)\n",
    "\n",
    "In this section, we will train a ResNet18 model **from scratch** on the rotation task. The input is a rotated image and the model predicts the rotation label. See the Data Setup section for details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "knAiwdURvBHk",
    "ExecuteTime": {
     "end_time": "2023-11-05T06:15:11.377018700Z",
     "start_time": "2023-11-05T06:15:11.329839300Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "'cuda'"
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Notice: You should not use pretrained weights from ImageNet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "235MEIUgsv65",
    "ExecuteTime": {
     "end_time": "2023-11-05T06:15:11.572701500Z",
     "start_time": "2023-11-05T06:15:11.348014800Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torchvision.models import resnet18\n",
    "\n",
    "net = resnet18(weights = None, num_classes=rotation_direction) # Do not modify this line.\n",
    "net = net.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "Vuhiw0ZoszAd",
    "ExecuteTime": {
     "end_time": "2023-11-05T06:15:11.574701Z",
     "start_time": "2023-11-05T06:15:11.561031Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "################################################################################\n",
    "# TODO: Define loss and optmizer functions                                     #\n",
    "# Try any loss or optimizer function and learning rate to get better result    #\n",
    "# hint: torch.nn and torch.optim                                               #\n",
    "################################################################################\n",
    "# Loss and optimizer\n",
    "criterion = nn.CrossEntropyLoss(label_smoothing=label_smoothing)\n",
    "learning_rate = 0.001\n",
    "optimizer = optim.Adam(net.parameters(), lr=learning_rate)\n",
    "################################################################################\n",
    "#                               End of your code                               #\n",
    "################################################################################\n",
    "criterion = criterion.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "WleH-YBgs0rq",
    "ExecuteTime": {
     "end_time": "2023-11-05T06:15:11.652209300Z",
     "start_time": "2023-11-05T06:15:11.572701500Z"
    }
   },
   "outputs": [],
   "source": [
    "# Both the self-supervised rotation task and supervised CIFAR10 classification are\n",
    "# trained with the CrossEntropyLoss, so we can use the training loop code.\n",
    "\n",
    "def train(net, criterion, optimizer, num_epochs, decay_epochs, init_lr, task, experiment_type=None):\n",
    "    global experience_report\n",
    "    best_valid_acc = 0.0  # Initialize best validation accuracy\n",
    "    best_model_state = None  # Initialize best model state\n",
    "\n",
    "    for epoch in range(num_epochs):  # loop over the dataset multiple times\n",
    "        # Initialize epoch variables\n",
    "        total_loss = 0.0\n",
    "        total_correct = 0.0\n",
    "        total_samples = 0.0\n",
    "\n",
    "        running_loss = 0.0\n",
    "        running_correct = 0.0\n",
    "        running_total = 0.0\n",
    "        start_time = time.time()\n",
    "\n",
    "        net.train()\n",
    "\n",
    "        for i, (imgs, imgs_rotated, rotation_label, cls_label) in enumerate(trainloader, 0):\n",
    "            adjust_learning_rate(optimizer, epoch, init_lr, decay_epochs)\n",
    "            ######################################################################################################\n",
    "            # TODO: Set the data to the correct device; Different task will use different inputs and labels      #  \n",
    "            # TODO: Zero the parameter gradients                                                                 #\n",
    "            # TODO: forward + backward + optimize                                                                #\n",
    "            # TODO: Get predicted results                                                                        #\n",
    "            ######################################################################################################\n",
    "            # Set data to the correct device\n",
    "            if task == 'rotation':\n",
    "                inputs, labels = imgs_rotated.to(device), rotation_label.to(device)\n",
    "            elif task == 'classification':\n",
    "                inputs, labels = imgs.to(device), cls_label.to(device)\n",
    "\n",
    "            optimizer.zero_grad()  # Zero the parameter gradients\n",
    "\n",
    "            # Forward + backward + optimize\n",
    "            outputs = net(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # Get predicted results for accuracy calculation\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            ######################################################################################################\n",
    "            #                               End of your code                                                     #\n",
    "            ######################################################################################################\n",
    "\n",
    "            # print statistics\n",
    "            print_freq = 100\n",
    "            running_loss += loss.item()\n",
    "\n",
    "            # calc acc\n",
    "            running_total += labels.size(0)\n",
    "            running_correct += (predicted == labels).sum().item()\n",
    "\n",
    "            # Update total counts for epoch averages\n",
    "            total_loss += loss.item()\n",
    "            total_samples += labels.size(0)\n",
    "            total_correct += (predicted == labels).sum().item()\n",
    "\n",
    "            if i % print_freq == (print_freq - 1):    # print every 2000 mini-batches\n",
    "                print(f'[{epoch + 1}, {i + 1:5d}] loss: {running_loss / print_freq:.3f} acc: {100*running_correct / running_total:.2f} time: {time.time() - start_time:.2f}')\n",
    "                running_loss, running_correct, running_total = 0.0, 0.0, 0.0\n",
    "                start_time = time.time()\n",
    "        ######################################################################################################\n",
    "        # TODO: Run the run_test() function after each epoch; Set the model to the evaluation mode.          #\n",
    "        ######################################################################################################\n",
    "        # Calculate average training loss and accuracy for the epoch\n",
    "        avg_train_loss = total_loss / len(trainloader)\n",
    "        avg_train_acc = 100 * total_correct / total_samples\n",
    "\n",
    "        # Evaluate the model after each epoch\n",
    "        net.eval()\n",
    "        test_loss, test_acc = run_test(net, testloader, criterion, task)\n",
    "\n",
    "        # Check if this is the best model so far\n",
    "        if test_acc > best_valid_acc:\n",
    "            best_valid_acc = test_acc\n",
    "            best_model_state = net.state_dict()  # Save the best model state\n",
    "\n",
    "        # Append the epoch's results to the report DataFrame\n",
    "        if experience_report is not None and experiment_type is not None:\n",
    "            new_row = pd.DataFrame({\n",
    "                'Experiment Type': [experiment_type],\n",
    "                'Epoch': [epoch + 1],\n",
    "                'Train Accuracy': [avg_train_acc.cpu().numpy()] if torch.is_tensor(avg_train_acc) else [avg_train_acc],\n",
    "                'Train Loss': [avg_train_loss.cpu().numpy()] if torch.is_tensor(avg_train_loss) else [avg_train_loss],\n",
    "                'Valid Accuracy': [test_acc.cpu().numpy()] if torch.is_tensor(test_acc) else [test_acc],\n",
    "                'Valid Loss': [test_loss.cpu().numpy()] if torch.is_tensor(test_loss) else [test_loss]\n",
    "            })\n",
    "            experience_report = pd.concat([experience_report, new_row], ignore_index=True)\n",
    "        ######################################################################################################\n",
    "        #                               End of your code                                                     #\n",
    "        ######################################################################################################\n",
    "    # Restore the best model state\n",
    "    if best_model_state:\n",
    "        net.load_state_dict(best_model_state)\n",
    "        print(f'Restored best model from epoch with validation accuracy: {best_valid_acc:.2f}%')\n",
    "\n",
    "    # Save the report DataFrame after the experiment\n",
    "    if experience_report is not None and experiment_type is not None:\n",
    "        experience_report.to_csv(f'{experience_name}.csv', index=False)\n",
    "\n",
    "    print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "2u4AsfAKtaQS",
    "ExecuteTime": {
     "end_time": "2023-11-05T06:46:46.939136300Z",
     "start_time": "2023-11-05T06:15:11.637193900Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,   100] loss: 1.892 acc: 30.48 time: 14.97\n",
      "[1,   200] loss: 1.557 acc: 42.55 time: 8.73\n",
      "[1,   300] loss: 1.487 acc: 44.88 time: 10.43\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 49.14 %\n",
      "Average loss on the 10000 test images: 1.657\n",
      "[2,   100] loss: 1.423 acc: 47.85 time: 10.53\n",
      "[2,   200] loss: 1.387 acc: 49.77 time: 11.40\n",
      "[2,   300] loss: 1.369 acc: 50.57 time: 9.04\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 51.99 %\n",
      "Average loss on the 10000 test images: 1.415\n",
      "[3,   100] loss: 1.342 acc: 52.12 time: 8.58\n",
      "[3,   200] loss: 1.337 acc: 53.02 time: 8.64\n",
      "[3,   300] loss: 1.335 acc: 53.24 time: 8.61\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 55.14 %\n",
      "Average loss on the 10000 test images: 1.342\n",
      "[4,   100] loss: 1.307 acc: 54.88 time: 8.46\n",
      "[4,   200] loss: 1.305 acc: 54.91 time: 8.23\n",
      "[4,   300] loss: 1.302 acc: 55.21 time: 8.32\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 57.41 %\n",
      "Average loss on the 10000 test images: 1.303\n",
      "[5,   100] loss: 1.288 acc: 56.29 time: 9.07\n",
      "[5,   200] loss: 1.285 acc: 56.58 time: 8.63\n",
      "[5,   300] loss: 1.278 acc: 57.36 time: 8.23\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 59.58 %\n",
      "Average loss on the 10000 test images: 1.288\n",
      "[6,   100] loss: 1.265 acc: 57.55 time: 8.71\n",
      "[6,   200] loss: 1.257 acc: 58.21 time: 8.46\n",
      "[6,   300] loss: 1.251 acc: 58.94 time: 8.86\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 60.58 %\n",
      "Average loss on the 10000 test images: 1.222\n",
      "[7,   100] loss: 1.244 acc: 59.20 time: 8.69\n",
      "[7,   200] loss: 1.228 acc: 60.07 time: 8.38\n",
      "[7,   300] loss: 1.231 acc: 59.72 time: 8.47\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 60.46 %\n",
      "Average loss on the 10000 test images: 1.247\n",
      "[8,   100] loss: 1.229 acc: 59.91 time: 8.15\n",
      "[8,   200] loss: 1.214 acc: 61.21 time: 8.15\n",
      "[8,   300] loss: 1.213 acc: 60.44 time: 8.71\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 62.56 %\n",
      "Average loss on the 10000 test images: 1.209\n",
      "[9,   100] loss: 1.201 acc: 61.88 time: 8.93\n",
      "[9,   200] loss: 1.188 acc: 62.15 time: 7.67\n",
      "[9,   300] loss: 1.196 acc: 62.05 time: 8.55\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 62.95 %\n",
      "Average loss on the 10000 test images: 1.197\n",
      "[10,   100] loss: 1.190 acc: 62.71 time: 8.26\n",
      "[10,   200] loss: 1.173 acc: 63.30 time: 9.05\n",
      "[10,   300] loss: 1.180 acc: 63.17 time: 8.86\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 65.36 %\n",
      "Average loss on the 10000 test images: 1.147\n",
      "[11,   100] loss: 1.160 acc: 64.40 time: 7.92\n",
      "[11,   200] loss: 1.160 acc: 64.30 time: 8.99\n",
      "[11,   300] loss: 1.156 acc: 64.44 time: 8.12\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 65.13 %\n",
      "Average loss on the 10000 test images: 1.155\n",
      "[12,   100] loss: 1.151 acc: 64.89 time: 9.19\n",
      "[12,   200] loss: 1.129 acc: 65.82 time: 8.82\n",
      "[12,   300] loss: 1.125 acc: 66.15 time: 8.08\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 67.40 %\n",
      "Average loss on the 10000 test images: 1.107\n",
      "[13,   100] loss: 1.120 acc: 66.63 time: 9.52\n",
      "[13,   200] loss: 1.116 acc: 66.75 time: 9.03\n",
      "[13,   300] loss: 1.119 acc: 66.29 time: 9.06\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 68.42 %\n",
      "Average loss on the 10000 test images: 1.086\n",
      "[14,   100] loss: 1.098 acc: 67.62 time: 8.02\n",
      "[14,   200] loss: 1.091 acc: 68.24 time: 7.79\n",
      "[14,   300] loss: 1.082 acc: 68.84 time: 8.55\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 69.69 %\n",
      "Average loss on the 10000 test images: 1.059\n",
      "[15,   100] loss: 1.081 acc: 68.95 time: 7.82\n",
      "[15,   200] loss: 1.083 acc: 68.59 time: 8.79\n",
      "[15,   300] loss: 1.060 acc: 70.18 time: 8.72\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 69.93 %\n",
      "Average loss on the 10000 test images: 1.054\n",
      "[16,   100] loss: 1.031 acc: 71.70 time: 8.64\n",
      "[16,   200] loss: 1.012 acc: 72.34 time: 8.12\n",
      "[16,   300] loss: 0.997 acc: 73.46 time: 8.14\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 74.64 %\n",
      "Average loss on the 10000 test images: 0.965\n",
      "[17,   100] loss: 0.989 acc: 73.88 time: 8.69\n",
      "[17,   200] loss: 0.990 acc: 73.60 time: 9.01\n",
      "[17,   300] loss: 0.989 acc: 73.97 time: 9.07\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 75.96 %\n",
      "Average loss on the 10000 test images: 0.946\n",
      "[18,   100] loss: 0.982 acc: 73.76 time: 8.99\n",
      "[18,   200] loss: 0.962 acc: 75.06 time: 8.93\n",
      "[18,   300] loss: 0.980 acc: 74.44 time: 8.67\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 75.61 %\n",
      "Average loss on the 10000 test images: 0.952\n",
      "[19,   100] loss: 0.982 acc: 74.00 time: 8.25\n",
      "[19,   200] loss: 0.966 acc: 74.63 time: 7.89\n",
      "[19,   300] loss: 0.969 acc: 74.78 time: 7.66\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 76.64 %\n",
      "Average loss on the 10000 test images: 0.938\n",
      "[20,   100] loss: 0.972 acc: 74.44 time: 8.82\n",
      "[20,   200] loss: 0.966 acc: 75.04 time: 9.08\n",
      "[20,   300] loss: 0.973 acc: 74.42 time: 8.63\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 76.42 %\n",
      "Average loss on the 10000 test images: 0.935\n",
      "[21,   100] loss: 0.960 acc: 75.27 time: 8.52\n",
      "[21,   200] loss: 0.952 acc: 75.77 time: 8.49\n",
      "[21,   300] loss: 0.958 acc: 75.07 time: 8.67\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 76.73 %\n",
      "Average loss on the 10000 test images: 0.936\n",
      "[22,   100] loss: 0.955 acc: 75.45 time: 8.62\n",
      "[22,   200] loss: 0.960 acc: 75.37 time: 8.52\n",
      "[22,   300] loss: 0.959 acc: 75.15 time: 8.23\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 76.76 %\n",
      "Average loss on the 10000 test images: 0.928\n",
      "[23,   100] loss: 0.961 acc: 75.19 time: 8.95\n",
      "[23,   200] loss: 0.953 acc: 75.45 time: 9.41\n",
      "[23,   300] loss: 0.946 acc: 75.96 time: 8.63\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 76.98 %\n",
      "Average loss on the 10000 test images: 0.930\n",
      "[24,   100] loss: 0.956 acc: 75.66 time: 8.05\n",
      "[24,   200] loss: 0.946 acc: 76.28 time: 9.36\n",
      "[24,   300] loss: 0.942 acc: 75.97 time: 7.89\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 77.39 %\n",
      "Average loss on the 10000 test images: 0.918\n",
      "[25,   100] loss: 0.946 acc: 76.00 time: 8.09\n",
      "[25,   200] loss: 0.939 acc: 76.50 time: 8.88\n",
      "[25,   300] loss: 0.936 acc: 76.36 time: 8.24\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 77.74 %\n",
      "Average loss on the 10000 test images: 0.910\n",
      "[26,   100] loss: 0.944 acc: 75.96 time: 7.97\n",
      "[26,   200] loss: 0.942 acc: 76.10 time: 8.73\n",
      "[26,   300] loss: 0.937 acc: 76.84 time: 8.49\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 77.95 %\n",
      "Average loss on the 10000 test images: 0.909\n",
      "[27,   100] loss: 0.933 acc: 76.32 time: 8.66\n",
      "[27,   200] loss: 0.942 acc: 76.30 time: 8.66\n",
      "[27,   300] loss: 0.936 acc: 76.51 time: 8.16\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 78.82 %\n",
      "Average loss on the 10000 test images: 0.900\n",
      "[28,   100] loss: 0.927 acc: 77.14 time: 9.38\n",
      "[28,   200] loss: 0.943 acc: 76.14 time: 8.62\n",
      "[28,   300] loss: 0.926 acc: 76.85 time: 8.28\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 77.95 %\n",
      "Average loss on the 10000 test images: 0.905\n",
      "[29,   100] loss: 0.931 acc: 76.83 time: 8.58\n",
      "[29,   200] loss: 0.925 acc: 77.02 time: 8.98\n",
      "[29,   300] loss: 0.926 acc: 77.38 time: 8.30\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 78.37 %\n",
      "Average loss on the 10000 test images: 0.901\n",
      "[30,   100] loss: 0.919 acc: 77.56 time: 8.44\n",
      "[30,   200] loss: 0.924 acc: 76.94 time: 8.44\n",
      "[30,   300] loss: 0.920 acc: 77.36 time: 8.20\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 78.63 %\n",
      "Average loss on the 10000 test images: 0.896\n",
      "[31,   100] loss: 0.923 acc: 77.42 time: 7.95\n",
      "[31,   200] loss: 0.918 acc: 77.16 time: 8.66\n",
      "[31,   300] loss: 0.919 acc: 77.20 time: 8.64\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 79.22 %\n",
      "Average loss on the 10000 test images: 0.886\n",
      "[32,   100] loss: 0.906 acc: 78.20 time: 8.33\n",
      "[32,   200] loss: 0.917 acc: 77.64 time: 8.30\n",
      "[32,   300] loss: 0.909 acc: 78.16 time: 9.10\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 79.24 %\n",
      "Average loss on the 10000 test images: 0.886\n",
      "[33,   100] loss: 0.913 acc: 77.74 time: 8.69\n",
      "[33,   200] loss: 0.921 acc: 77.29 time: 8.67\n",
      "[33,   300] loss: 0.899 acc: 78.39 time: 8.09\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 79.05 %\n",
      "Average loss on the 10000 test images: 0.883\n",
      "[34,   100] loss: 0.912 acc: 78.10 time: 8.91\n",
      "[34,   200] loss: 0.917 acc: 77.30 time: 8.68\n",
      "[34,   300] loss: 0.906 acc: 78.15 time: 8.09\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 79.04 %\n",
      "Average loss on the 10000 test images: 0.889\n",
      "[35,   100] loss: 0.907 acc: 77.89 time: 8.37\n",
      "[35,   200] loss: 0.913 acc: 77.92 time: 8.51\n",
      "[35,   300] loss: 0.918 acc: 77.24 time: 8.08\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 78.81 %\n",
      "Average loss on the 10000 test images: 0.888\n",
      "[36,   100] loss: 0.905 acc: 78.41 time: 9.50\n",
      "[36,   200] loss: 0.909 acc: 77.98 time: 8.83\n",
      "[36,   300] loss: 0.913 acc: 77.99 time: 8.33\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 78.86 %\n",
      "Average loss on the 10000 test images: 0.886\n",
      "[37,   100] loss: 0.918 acc: 77.67 time: 8.85\n",
      "[37,   200] loss: 0.908 acc: 77.83 time: 8.63\n",
      "[37,   300] loss: 0.911 acc: 77.74 time: 8.05\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 79.69 %\n",
      "Average loss on the 10000 test images: 0.880\n",
      "[38,   100] loss: 0.906 acc: 78.22 time: 8.24\n",
      "[38,   200] loss: 0.916 acc: 77.50 time: 8.12\n",
      "[38,   300] loss: 0.909 acc: 77.99 time: 8.10\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 79.73 %\n",
      "Average loss on the 10000 test images: 0.885\n",
      "[39,   100] loss: 0.908 acc: 78.05 time: 7.99\n",
      "[39,   200] loss: 0.906 acc: 78.37 time: 8.27\n",
      "[39,   300] loss: 0.912 acc: 77.63 time: 8.70\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 79.25 %\n",
      "Average loss on the 10000 test images: 0.884\n",
      "[40,   100] loss: 0.900 acc: 78.59 time: 8.16\n",
      "[40,   200] loss: 0.912 acc: 77.82 time: 8.60\n",
      "[40,   300] loss: 0.911 acc: 78.01 time: 8.46\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 79.77 %\n",
      "Average loss on the 10000 test images: 0.877\n",
      "[41,   100] loss: 0.905 acc: 78.34 time: 9.03\n",
      "[41,   200] loss: 0.902 acc: 78.39 time: 8.87\n",
      "[41,   300] loss: 0.911 acc: 77.33 time: 8.48\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 79.55 %\n",
      "Average loss on the 10000 test images: 0.882\n",
      "[42,   100] loss: 0.912 acc: 77.82 time: 8.22\n",
      "[42,   200] loss: 0.912 acc: 77.83 time: 8.15\n",
      "[42,   300] loss: 0.907 acc: 77.95 time: 8.07\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 79.69 %\n",
      "Average loss on the 10000 test images: 0.877\n",
      "[43,   100] loss: 0.899 acc: 78.55 time: 8.72\n",
      "[43,   200] loss: 0.901 acc: 78.21 time: 8.24\n",
      "[43,   300] loss: 0.900 acc: 78.15 time: 8.59\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 79.60 %\n",
      "Average loss on the 10000 test images: 0.877\n",
      "[44,   100] loss: 0.913 acc: 77.76 time: 9.35\n",
      "[44,   200] loss: 0.907 acc: 77.80 time: 8.82\n",
      "[44,   300] loss: 0.913 acc: 77.65 time: 7.98\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 79.43 %\n",
      "Average loss on the 10000 test images: 0.889\n",
      "[45,   100] loss: 0.902 acc: 78.20 time: 7.96\n",
      "[45,   200] loss: 0.918 acc: 77.30 time: 8.08\n",
      "[45,   300] loss: 0.897 acc: 78.84 time: 8.51\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 79.45 %\n",
      "Average loss on the 10000 test images: 0.881\n",
      "[46,   100] loss: 0.895 acc: 78.70 time: 8.35\n",
      "[46,   200] loss: 0.901 acc: 78.53 time: 8.08\n",
      "[46,   300] loss: 0.911 acc: 77.90 time: 8.25\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 79.47 %\n",
      "Average loss on the 10000 test images: 0.880\n",
      "[47,   100] loss: 0.906 acc: 78.10 time: 8.19\n",
      "[47,   200] loss: 0.898 acc: 78.38 time: 8.00\n",
      "[47,   300] loss: 0.909 acc: 77.80 time: 8.39\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 79.51 %\n",
      "Average loss on the 10000 test images: 0.879\n",
      "[48,   100] loss: 0.909 acc: 77.83 time: 8.67\n",
      "[48,   200] loss: 0.901 acc: 78.60 time: 8.38\n",
      "[48,   300] loss: 0.902 acc: 78.38 time: 8.91\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 79.87 %\n",
      "Average loss on the 10000 test images: 0.881\n",
      "[49,   100] loss: 0.898 acc: 78.50 time: 8.54\n",
      "[49,   200] loss: 0.909 acc: 77.80 time: 8.79\n",
      "[49,   300] loss: 0.909 acc: 77.85 time: 8.94\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 79.51 %\n",
      "Average loss on the 10000 test images: 0.878\n",
      "[50,   100] loss: 0.896 acc: 78.16 time: 8.44\n",
      "[50,   200] loss: 0.909 acc: 77.61 time: 8.17\n",
      "[50,   300] loss: 0.897 acc: 78.51 time: 8.20\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 79.47 %\n",
      "Average loss on the 10000 test images: 0.877\n",
      "Restored best model from epoch with validation accuracy: 79.87%\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "train(net, criterion, optimizer, num_epochs=50, decay_epochs=15, init_lr=0.01, task='rotation', experiment_type='Self-Supervise Rotation Model')\n",
    "################################\n",
    "#     TODO: Save the model     #  \n",
    "################################\n",
    "# Get current date and time\n",
    "# Save the model\n",
    "model_path = f\"{experience_name}.pth\"\n",
    "torch.save(net.state_dict(), model_path)\n",
    "################################\n",
    "#      End of your code        #  \n",
    "################################"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Fine-tuning on the pre-trained model (9 points)\n",
    "\n",
    "In this section, we will load the ResNet18 model pre-trained on the rotation task and fine-tune on the classification task. We will freeze all previous layers except for the 'layer4' block and 'fc' layer.\n",
    "\n",
    "**Then we will use the trained model from rotation task as the pretrained weights. Notice, you should not use the pretrained weights from ImageNet.**"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [
    {
     "data": {
      "text/plain": "<All keys matched successfully>"
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torchvision.models import resnet18\n",
    "\n",
    "#####################################################\n",
    "#     TODO: Load the pre-trained ResNet18 model     #\n",
    "#####################################################\n",
    "# load the trained classifier weights\n",
    "ckpt = torch.load(f\"{experience_name}.pth\")\n",
    "net.load_state_dict(ckpt)\n",
    "####################################################\n",
    "#                End of your code                  #\n",
    "####################################################"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-05T06:46:47.019109400Z",
     "start_time": "2023-11-05T06:46:46.936135200Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [
    {
     "data": {
      "text/plain": "ResNet(\n  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  (relu): ReLU(inplace=True)\n  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n  (layer1): Sequential(\n    (0): BasicBlock(\n      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n    (1): BasicBlock(\n      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n  )\n  (layer2): Sequential(\n    (0): BasicBlock(\n      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (downsample): Sequential(\n        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (1): BasicBlock(\n      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n  )\n  (layer3): Sequential(\n    (0): BasicBlock(\n      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (downsample): Sequential(\n        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (1): BasicBlock(\n      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n  )\n  (layer4): Sequential(\n    (0): BasicBlock(\n      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (downsample): Sequential(\n        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (1): BasicBlock(\n      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n  )\n  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n  (fc): Linear(in_features=512, out_features=10, bias=True)\n)"
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#################################################################################################\n",
    "#   TODO: Freeze all previous layers; only keep the 'layer4' block and 'fc' layer trainable     #\n",
    "#################################################################################################\n",
    "# Freeze all parameters\n",
    "net.requires_grad_(False)\n",
    "\n",
    "# Adjusting the fully connected layer to have 10 outputs for 10 classes\n",
    "net.fc = nn.Linear(net.fc.in_features, 10)  # Re-define the fc layer\n",
    "\n",
    "# Unfreeze the last block (layer4) and the fully connected (fc) layer\n",
    "net.layer4.requires_grad_(True)\n",
    "net.fc.requires_grad_(True)\n",
    "\n",
    "# Make sure to move the model to the device after modifying it\n",
    "net.to(device)\n",
    "#################################################################################################\n",
    "#                                          End of your code                                     #\n",
    "#################################################################################################"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-05T06:46:47.028442800Z",
     "start_time": "2023-11-05T06:46:47.014103800Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Params to learn:\n",
      "\t layer4.0.conv1.weight\n",
      "\t layer4.0.bn1.weight\n",
      "\t layer4.0.bn1.bias\n",
      "\t layer4.0.conv2.weight\n",
      "\t layer4.0.bn2.weight\n",
      "\t layer4.0.bn2.bias\n",
      "\t layer4.0.downsample.0.weight\n",
      "\t layer4.0.downsample.1.weight\n",
      "\t layer4.0.downsample.1.bias\n",
      "\t layer4.1.conv1.weight\n",
      "\t layer4.1.bn1.weight\n",
      "\t layer4.1.bn1.bias\n",
      "\t layer4.1.conv2.weight\n",
      "\t layer4.1.bn2.weight\n",
      "\t layer4.1.bn2.bias\n",
      "\t fc.weight\n",
      "\t fc.bias\n"
     ]
    }
   ],
   "source": [
    "# Print all the trainable parameters\n",
    "params_to_update = net.parameters()\n",
    "print(\"Params to learn:\")\n",
    "params_to_update = []\n",
    "for name,param in net.named_parameters():\n",
    "    if param.requires_grad == True:\n",
    "        params_to_update.append(param)\n",
    "        print(\"\\t\",name)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-05T06:46:47.037452400Z",
     "start_time": "2023-11-05T06:46:47.023768200Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [
    {
     "data": {
      "text/plain": "CrossEntropyLoss()"
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO: Define criterion and optimizer\n",
    "# Note that your optimizer only needs to update the parameters that are trainable.\n",
    "criterion = nn.CrossEntropyLoss(label_smoothing=label_smoothing)\n",
    "\n",
    "# Optimizer: Update only the parameters of layer4 and fc\n",
    "optimizer = optim.Adam([\n",
    "    {'params': net.layer4.parameters()},\n",
    "    {'params': net.fc.parameters()}\n",
    "], lr=0.001)\n",
    "\n",
    "criterion.to(device)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-05T06:46:47.045400Z",
     "start_time": "2023-11-05T06:46:47.033452300Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,   100] loss: 1.937 acc: 32.07 time: 8.43\n",
      "[1,   200] loss: 1.736 acc: 42.10 time: 8.33\n",
      "[1,   300] loss: 1.676 acc: 45.42 time: 7.75\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 48.29 %\n",
      "Average loss on the 10000 test images: 1.614\n",
      "[2,   100] loss: 1.630 acc: 48.09 time: 7.72\n",
      "[2,   200] loss: 1.616 acc: 48.94 time: 7.64\n",
      "[2,   300] loss: 1.597 acc: 49.21 time: 7.52\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 51.95 %\n",
      "Average loss on the 10000 test images: 1.538\n",
      "[3,   100] loss: 1.582 acc: 49.64 time: 7.28\n",
      "[3,   200] loss: 1.556 acc: 51.26 time: 8.13\n",
      "[3,   300] loss: 1.573 acc: 50.68 time: 7.75\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 53.93 %\n",
      "Average loss on the 10000 test images: 1.513\n",
      "[4,   100] loss: 1.552 acc: 51.32 time: 7.57\n",
      "[4,   200] loss: 1.542 acc: 52.55 time: 7.42\n",
      "[4,   300] loss: 1.537 acc: 52.48 time: 7.46\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 54.22 %\n",
      "Average loss on the 10000 test images: 1.504\n",
      "[5,   100] loss: 1.525 acc: 53.05 time: 7.67\n",
      "[5,   200] loss: 1.521 acc: 52.66 time: 7.58\n",
      "[5,   300] loss: 1.536 acc: 52.02 time: 7.42\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 54.16 %\n",
      "Average loss on the 10000 test images: 1.495\n",
      "[6,   100] loss: 1.515 acc: 53.16 time: 7.78\n",
      "[6,   200] loss: 1.512 acc: 53.45 time: 7.49\n",
      "[6,   300] loss: 1.519 acc: 53.53 time: 7.39\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 55.99 %\n",
      "Average loss on the 10000 test images: 1.469\n",
      "[7,   100] loss: 1.508 acc: 53.62 time: 7.14\n",
      "[7,   200] loss: 1.509 acc: 54.23 time: 7.32\n",
      "[7,   300] loss: 1.496 acc: 53.80 time: 7.36\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 55.56 %\n",
      "Average loss on the 10000 test images: 1.473\n",
      "[8,   100] loss: 1.496 acc: 54.34 time: 7.65\n",
      "[8,   200] loss: 1.484 acc: 54.83 time: 7.54\n",
      "[8,   300] loss: 1.487 acc: 54.61 time: 7.55\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 55.52 %\n",
      "Average loss on the 10000 test images: 1.481\n",
      "[9,   100] loss: 1.492 acc: 54.04 time: 7.45\n",
      "[9,   200] loss: 1.477 acc: 55.31 time: 7.13\n",
      "[9,   300] loss: 1.489 acc: 54.74 time: 7.30\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 56.10 %\n",
      "Average loss on the 10000 test images: 1.471\n",
      "[10,   100] loss: 1.489 acc: 54.98 time: 7.32\n",
      "[10,   200] loss: 1.473 acc: 54.97 time: 7.19\n",
      "[10,   300] loss: 1.469 acc: 55.88 time: 7.52\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 56.93 %\n",
      "Average loss on the 10000 test images: 1.444\n",
      "[11,   100] loss: 1.452 acc: 56.32 time: 7.76\n",
      "[11,   200] loss: 1.437 acc: 56.92 time: 7.42\n",
      "[11,   300] loss: 1.433 acc: 56.79 time: 7.37\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 59.25 %\n",
      "Average loss on the 10000 test images: 1.404\n",
      "[12,   100] loss: 1.431 acc: 57.80 time: 7.18\n",
      "[12,   200] loss: 1.426 acc: 57.33 time: 7.22\n",
      "[12,   300] loss: 1.411 acc: 58.34 time: 7.33\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 59.00 %\n",
      "Average loss on the 10000 test images: 1.399\n",
      "[13,   100] loss: 1.420 acc: 57.62 time: 7.71\n",
      "[13,   200] loss: 1.415 acc: 58.00 time: 7.59\n",
      "[13,   300] loss: 1.422 acc: 58.12 time: 7.45\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 59.19 %\n",
      "Average loss on the 10000 test images: 1.395\n",
      "[14,   100] loss: 1.410 acc: 58.45 time: 7.32\n",
      "[14,   200] loss: 1.420 acc: 57.70 time: 7.39\n",
      "[14,   300] loss: 1.411 acc: 57.62 time: 7.32\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 59.47 %\n",
      "Average loss on the 10000 test images: 1.389\n",
      "[15,   100] loss: 1.414 acc: 58.26 time: 7.36\n",
      "[15,   200] loss: 1.419 acc: 57.91 time: 7.39\n",
      "[15,   300] loss: 1.401 acc: 59.20 time: 7.69\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 59.34 %\n",
      "Average loss on the 10000 test images: 1.390\n",
      "[16,   100] loss: 1.414 acc: 58.20 time: 7.60\n",
      "[16,   200] loss: 1.404 acc: 58.77 time: 7.05\n",
      "[16,   300] loss: 1.411 acc: 58.14 time: 7.63\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 59.69 %\n",
      "Average loss on the 10000 test images: 1.389\n",
      "[17,   100] loss: 1.408 acc: 58.27 time: 7.41\n",
      "[17,   200] loss: 1.417 acc: 57.23 time: 7.30\n",
      "[17,   300] loss: 1.405 acc: 58.72 time: 7.38\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 59.95 %\n",
      "Average loss on the 10000 test images: 1.387\n",
      "[18,   100] loss: 1.396 acc: 58.65 time: 7.40\n",
      "[18,   200] loss: 1.410 acc: 58.39 time: 7.26\n",
      "[18,   300] loss: 1.406 acc: 58.51 time: 7.63\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 59.79 %\n",
      "Average loss on the 10000 test images: 1.386\n",
      "[19,   100] loss: 1.407 acc: 58.47 time: 7.04\n",
      "[19,   200] loss: 1.403 acc: 58.74 time: 7.54\n",
      "[19,   300] loss: 1.399 acc: 58.95 time: 7.54\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 59.95 %\n",
      "Average loss on the 10000 test images: 1.386\n",
      "[20,   100] loss: 1.411 acc: 58.30 time: 7.36\n",
      "[20,   200] loss: 1.403 acc: 58.79 time: 7.48\n",
      "[20,   300] loss: 1.402 acc: 58.80 time: 7.27\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 59.94 %\n",
      "Average loss on the 10000 test images: 1.384\n",
      "[21,   100] loss: 1.393 acc: 59.11 time: 7.33\n",
      "[21,   200] loss: 1.396 acc: 58.62 time: 7.27\n",
      "[21,   300] loss: 1.399 acc: 58.63 time: 7.74\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 60.27 %\n",
      "Average loss on the 10000 test images: 1.379\n",
      "[22,   100] loss: 1.386 acc: 59.18 time: 7.73\n",
      "[22,   200] loss: 1.393 acc: 58.39 time: 7.62\n",
      "[22,   300] loss: 1.394 acc: 59.05 time: 7.40\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 60.27 %\n",
      "Average loss on the 10000 test images: 1.381\n",
      "[23,   100] loss: 1.401 acc: 58.91 time: 7.54\n",
      "[23,   200] loss: 1.409 acc: 58.45 time: 7.43\n",
      "[23,   300] loss: 1.383 acc: 59.51 time: 7.49\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 60.13 %\n",
      "Average loss on the 10000 test images: 1.380\n",
      "[24,   100] loss: 1.398 acc: 59.12 time: 7.45\n",
      "[24,   200] loss: 1.381 acc: 59.78 time: 7.25\n",
      "[24,   300] loss: 1.399 acc: 58.90 time: 7.36\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 60.13 %\n",
      "Average loss on the 10000 test images: 1.380\n",
      "[25,   100] loss: 1.388 acc: 59.52 time: 7.49\n",
      "[25,   200] loss: 1.394 acc: 58.83 time: 7.45\n",
      "[25,   300] loss: 1.400 acc: 59.01 time: 7.42\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 59.90 %\n",
      "Average loss on the 10000 test images: 1.378\n",
      "[26,   100] loss: 1.391 acc: 59.68 time: 7.24\n",
      "[26,   200] loss: 1.390 acc: 59.16 time: 7.42\n",
      "[26,   300] loss: 1.406 acc: 58.66 time: 7.56\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 60.17 %\n",
      "Average loss on the 10000 test images: 1.380\n",
      "[27,   100] loss: 1.391 acc: 59.35 time: 7.58\n",
      "[27,   200] loss: 1.389 acc: 59.44 time: 7.32\n",
      "[27,   300] loss: 1.395 acc: 58.91 time: 7.30\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 60.27 %\n",
      "Average loss on the 10000 test images: 1.378\n",
      "[28,   100] loss: 1.394 acc: 58.93 time: 7.82\n",
      "[28,   200] loss: 1.396 acc: 58.75 time: 7.58\n",
      "[28,   300] loss: 1.384 acc: 59.48 time: 7.56\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 59.98 %\n",
      "Average loss on the 10000 test images: 1.379\n",
      "[29,   100] loss: 1.387 acc: 59.71 time: 7.27\n",
      "[29,   200] loss: 1.402 acc: 58.69 time: 7.21\n",
      "[29,   300] loss: 1.390 acc: 59.52 time: 7.49\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 60.27 %\n",
      "Average loss on the 10000 test images: 1.380\n",
      "[30,   100] loss: 1.391 acc: 59.18 time: 7.65\n",
      "[30,   200] loss: 1.391 acc: 59.52 time: 7.59\n",
      "[30,   300] loss: 1.389 acc: 59.05 time: 7.26\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 60.23 %\n",
      "Average loss on the 10000 test images: 1.377\n",
      "[31,   100] loss: 1.389 acc: 59.12 time: 7.26\n",
      "[31,   200] loss: 1.383 acc: 59.85 time: 7.24\n",
      "[31,   300] loss: 1.402 acc: 58.70 time: 7.24\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 60.19 %\n",
      "Average loss on the 10000 test images: 1.379\n",
      "[32,   100] loss: 1.389 acc: 59.37 time: 7.25\n",
      "[32,   200] loss: 1.397 acc: 58.78 time: 7.49\n",
      "[32,   300] loss: 1.385 acc: 58.89 time: 7.27\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 60.28 %\n",
      "Average loss on the 10000 test images: 1.379\n",
      "[33,   100] loss: 1.387 acc: 59.21 time: 7.67\n",
      "[33,   200] loss: 1.380 acc: 59.55 time: 7.37\n",
      "[33,   300] loss: 1.396 acc: 58.64 time: 7.08\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 60.37 %\n",
      "Average loss on the 10000 test images: 1.378\n",
      "[34,   100] loss: 1.397 acc: 58.93 time: 7.51\n",
      "[34,   200] loss: 1.389 acc: 59.55 time: 7.19\n",
      "[34,   300] loss: 1.382 acc: 59.74 time: 7.18\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 60.29 %\n",
      "Average loss on the 10000 test images: 1.380\n",
      "[35,   100] loss: 1.395 acc: 59.33 time: 7.38\n",
      "[35,   200] loss: 1.379 acc: 59.91 time: 7.33\n",
      "[35,   300] loss: 1.393 acc: 59.15 time: 7.26\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 60.46 %\n",
      "Average loss on the 10000 test images: 1.376\n",
      "[36,   100] loss: 1.394 acc: 58.74 time: 7.26\n",
      "[36,   200] loss: 1.391 acc: 58.96 time: 7.63\n",
      "[36,   300] loss: 1.388 acc: 59.43 time: 7.92\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 60.36 %\n",
      "Average loss on the 10000 test images: 1.379\n",
      "[37,   100] loss: 1.385 acc: 59.80 time: 7.42\n",
      "[37,   200] loss: 1.396 acc: 58.77 time: 7.35\n",
      "[37,   300] loss: 1.389 acc: 59.13 time: 7.30\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 60.09 %\n",
      "Average loss on the 10000 test images: 1.379\n",
      "[38,   100] loss: 1.406 acc: 58.61 time: 7.33\n",
      "[38,   200] loss: 1.382 acc: 60.02 time: 7.25\n",
      "[38,   300] loss: 1.391 acc: 58.84 time: 7.72\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 60.31 %\n",
      "Average loss on the 10000 test images: 1.380\n",
      "[39,   100] loss: 1.380 acc: 59.85 time: 7.32\n",
      "[39,   200] loss: 1.382 acc: 59.45 time: 7.27\n",
      "[39,   300] loss: 1.397 acc: 58.42 time: 7.29\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 60.21 %\n",
      "Average loss on the 10000 test images: 1.377\n",
      "[40,   100] loss: 1.389 acc: 59.00 time: 7.32\n",
      "[40,   200] loss: 1.390 acc: 59.26 time: 7.16\n",
      "[40,   300] loss: 1.396 acc: 58.94 time: 7.11\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 60.20 %\n",
      "Average loss on the 10000 test images: 1.378\n",
      "[41,   100] loss: 1.376 acc: 59.86 time: 7.95\n",
      "[41,   200] loss: 1.388 acc: 59.76 time: 7.43\n",
      "[41,   300] loss: 1.399 acc: 58.61 time: 7.35\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 60.37 %\n",
      "Average loss on the 10000 test images: 1.377\n",
      "[42,   100] loss: 1.394 acc: 58.61 time: 7.12\n",
      "[42,   200] loss: 1.389 acc: 59.12 time: 7.87\n",
      "[42,   300] loss: 1.390 acc: 59.65 time: 7.14\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 60.25 %\n",
      "Average loss on the 10000 test images: 1.382\n",
      "[43,   100] loss: 1.386 acc: 58.99 time: 7.75\n",
      "[43,   200] loss: 1.402 acc: 58.83 time: 7.46\n",
      "[43,   300] loss: 1.391 acc: 59.30 time: 7.20\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 60.41 %\n",
      "Average loss on the 10000 test images: 1.378\n",
      "[44,   100] loss: 1.395 acc: 59.16 time: 7.33\n",
      "[44,   200] loss: 1.391 acc: 59.29 time: 7.11\n",
      "[44,   300] loss: 1.383 acc: 59.20 time: 7.21\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 60.32 %\n",
      "Average loss on the 10000 test images: 1.376\n",
      "[45,   100] loss: 1.397 acc: 58.65 time: 7.41\n",
      "[45,   200] loss: 1.401 acc: 58.55 time: 7.25\n",
      "[45,   300] loss: 1.386 acc: 59.42 time: 7.24\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 60.17 %\n",
      "Average loss on the 10000 test images: 1.376\n",
      "[46,   100] loss: 1.386 acc: 59.14 time: 7.16\n",
      "[46,   200] loss: 1.396 acc: 58.77 time: 6.95\n",
      "[46,   300] loss: 1.386 acc: 59.90 time: 7.54\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 60.11 %\n",
      "Average loss on the 10000 test images: 1.378\n",
      "[47,   100] loss: 1.394 acc: 58.69 time: 7.61\n",
      "[47,   200] loss: 1.400 acc: 58.28 time: 7.41\n",
      "[47,   300] loss: 1.394 acc: 59.39 time: 7.53\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 60.29 %\n",
      "Average loss on the 10000 test images: 1.376\n",
      "[48,   100] loss: 1.399 acc: 59.09 time: 7.14\n",
      "[48,   200] loss: 1.400 acc: 58.48 time: 7.30\n",
      "[48,   300] loss: 1.383 acc: 59.71 time: 7.24\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 59.91 %\n",
      "Average loss on the 10000 test images: 1.379\n",
      "[49,   100] loss: 1.383 acc: 58.97 time: 7.44\n",
      "[49,   200] loss: 1.398 acc: 58.55 time: 7.43\n",
      "[49,   300] loss: 1.398 acc: 58.95 time: 7.02\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 60.22 %\n",
      "Average loss on the 10000 test images: 1.379\n",
      "[50,   100] loss: 1.397 acc: 58.96 time: 7.79\n",
      "[50,   200] loss: 1.390 acc: 59.02 time: 7.17\n",
      "[50,   300] loss: 1.392 acc: 59.53 time: 7.20\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 60.18 %\n",
      "Average loss on the 10000 test images: 1.379\n",
      "Restored best model from epoch with validation accuracy: 60.46%\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "train(net, criterion, optimizer, num_epochs=50, decay_epochs=10, init_lr=0.01, task='classification', experiment_type='Fine-tuning Pre-trained Model')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-05T07:14:31.022862100Z",
     "start_time": "2023-11-05T06:46:47.042400600Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Fine-tuning on the randomly initialized model (9 points)\n",
    "In this section, we will randomly initialize a ResNet18 model and fine-tune on the classification task. We will freeze all previous layers except for the 'layer4' block and 'fc' layer."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torchvision.models import resnet18\n",
    "#################################################\n",
    "# TODO: Randomly initialize a ResNet18 model    #\n",
    "#################################################\n",
    "# Randomly initialize a ResNet18 model\n",
    "net = resnet18(pretrained=False)\n",
    "#################################################\n",
    "#              End of your code                 #\n",
    "#################################################"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-05T07:14:31.154551700Z",
     "start_time": "2023-11-05T07:14:31.018129800Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [
    {
     "data": {
      "text/plain": "ResNet(\n  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  (relu): ReLU(inplace=True)\n  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n  (layer1): Sequential(\n    (0): BasicBlock(\n      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n    (1): BasicBlock(\n      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n  )\n  (layer2): Sequential(\n    (0): BasicBlock(\n      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (downsample): Sequential(\n        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (1): BasicBlock(\n      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n  )\n  (layer3): Sequential(\n    (0): BasicBlock(\n      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (downsample): Sequential(\n        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (1): BasicBlock(\n      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n  )\n  (layer4): Sequential(\n    (0): BasicBlock(\n      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (downsample): Sequential(\n        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (1): BasicBlock(\n      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n  )\n  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n  (fc): Linear(in_features=512, out_features=10, bias=True)\n)"
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#################################################################################################\n",
    "# TODO: Freeze all previous layers; only keep the 'layer4' block and 'fc' layer trainable       #\n",
    "# To do this, you should set requires_grad=False for the frozen layers.                         #\n",
    "#################################################################################################\n",
    "# Adjusting the fully connected layer for 10 classes\n",
    "net.fc = nn.Linear(net.fc.in_features, 10)\n",
    "\n",
    "# Freeze all layers in the randomly initialized model\n",
    "net.requires_grad_(False)\n",
    "\n",
    "# Unfreeze the last block (layer4) and the fully connected (fc) layer\n",
    "net.layer4.requires_grad_(True)\n",
    "net.fc.requires_grad_(True)\n",
    "\n",
    "# Move the model to the device\n",
    "net.to(device)\n",
    "#################################################################################################\n",
    "#                                          End of your code                                     #\n",
    "#################################################################################################"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-05T07:14:31.189714400Z",
     "start_time": "2023-11-05T07:14:31.156544Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Params to learn:\n",
      "\t layer4.0.conv1.weight\n",
      "\t layer4.0.bn1.weight\n",
      "\t layer4.0.bn1.bias\n",
      "\t layer4.0.conv2.weight\n",
      "\t layer4.0.bn2.weight\n",
      "\t layer4.0.bn2.bias\n",
      "\t layer4.0.downsample.0.weight\n",
      "\t layer4.0.downsample.1.weight\n",
      "\t layer4.0.downsample.1.bias\n",
      "\t layer4.1.conv1.weight\n",
      "\t layer4.1.bn1.weight\n",
      "\t layer4.1.bn1.bias\n",
      "\t layer4.1.conv2.weight\n",
      "\t layer4.1.bn2.weight\n",
      "\t layer4.1.bn2.bias\n",
      "\t fc.weight\n",
      "\t fc.bias\n"
     ]
    }
   ],
   "source": [
    "# Print all the trainable parameters\n",
    "params_to_update = net.parameters()\n",
    "print(\"Params to learn:\")\n",
    "params_to_update = []\n",
    "for name,param in net.named_parameters():\n",
    "    if param.requires_grad == True:\n",
    "        params_to_update.append(param)\n",
    "        print(\"\\t\",name)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-05T07:14:31.190804500Z",
     "start_time": "2023-11-05T07:14:31.184699100Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [
    {
     "data": {
      "text/plain": "CrossEntropyLoss()"
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO: Define criterion and optimizer\n",
    "# Note that your optimizer only needs to update the parameters that are trainable.\n",
    "criterion = nn.CrossEntropyLoss(label_smoothing=label_smoothing)\n",
    "\n",
    "# Optimizer: Update only the parameters of layer4 and fc\n",
    "optimizer = optim.Adam([\n",
    "    {'params': net.layer4.parameters()},\n",
    "    {'params': net.fc.parameters()}\n",
    "], lr=0.001)\n",
    "\n",
    "criterion.to(device)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-05T07:14:31.251365200Z",
     "start_time": "2023-11-05T07:14:31.188714800Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,   100] loss: 2.299 acc: 24.25 time: 7.36\n",
      "[1,   200] loss: 2.056 acc: 29.04 time: 7.23\n",
      "[1,   300] loss: 1.987 acc: 30.97 time: 7.33\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 36.40 %\n",
      "Average loss on the 10000 test images: 1.879\n",
      "[2,   100] loss: 1.935 acc: 34.36 time: 8.27\n",
      "[2,   200] loss: 1.904 acc: 34.68 time: 7.74\n",
      "[2,   300] loss: 1.907 acc: 34.78 time: 7.46\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 37.87 %\n",
      "Average loss on the 10000 test images: 1.847\n",
      "[3,   100] loss: 1.882 acc: 35.83 time: 7.67\n",
      "[3,   200] loss: 1.882 acc: 35.99 time: 7.43\n",
      "[3,   300] loss: 1.877 acc: 36.38 time: 7.68\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 40.28 %\n",
      "Average loss on the 10000 test images: 1.809\n",
      "[4,   100] loss: 1.850 acc: 37.96 time: 7.37\n",
      "[4,   200] loss: 1.864 acc: 36.92 time: 7.31\n",
      "[4,   300] loss: 1.866 acc: 36.35 time: 7.34\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 40.65 %\n",
      "Average loss on the 10000 test images: 1.798\n",
      "[5,   100] loss: 1.841 acc: 38.41 time: 7.31\n",
      "[5,   200] loss: 1.839 acc: 38.05 time: 7.44\n",
      "[5,   300] loss: 1.832 acc: 39.02 time: 7.19\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 40.48 %\n",
      "Average loss on the 10000 test images: 1.803\n",
      "[6,   100] loss: 1.833 acc: 38.47 time: 7.47\n",
      "[6,   200] loss: 1.830 acc: 38.72 time: 6.94\n",
      "[6,   300] loss: 1.828 acc: 39.11 time: 7.49\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 41.54 %\n",
      "Average loss on the 10000 test images: 1.771\n",
      "[7,   100] loss: 1.831 acc: 38.74 time: 7.60\n",
      "[7,   200] loss: 1.819 acc: 39.27 time: 7.23\n",
      "[7,   300] loss: 1.810 acc: 39.41 time: 7.21\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 42.04 %\n",
      "Average loss on the 10000 test images: 1.765\n",
      "[8,   100] loss: 1.818 acc: 38.99 time: 7.34\n",
      "[8,   200] loss: 1.812 acc: 40.05 time: 7.16\n",
      "[8,   300] loss: 1.810 acc: 39.45 time: 7.50\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 41.81 %\n",
      "Average loss on the 10000 test images: 1.765\n",
      "[9,   100] loss: 1.814 acc: 39.41 time: 7.47\n",
      "[9,   200] loss: 1.804 acc: 40.62 time: 7.50\n",
      "[9,   300] loss: 1.805 acc: 40.23 time: 7.26\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 41.32 %\n",
      "Average loss on the 10000 test images: 1.775\n",
      "[10,   100] loss: 1.803 acc: 40.31 time: 7.51\n",
      "[10,   200] loss: 1.789 acc: 40.39 time: 7.27\n",
      "[10,   300] loss: 1.791 acc: 40.41 time: 7.32\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 42.45 %\n",
      "Average loss on the 10000 test images: 1.754\n",
      "[11,   100] loss: 1.777 acc: 41.59 time: 7.72\n",
      "[11,   200] loss: 1.766 acc: 41.96 time: 7.35\n",
      "[11,   300] loss: 1.763 acc: 42.21 time: 7.42\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 44.03 %\n",
      "Average loss on the 10000 test images: 1.724\n",
      "[12,   100] loss: 1.752 acc: 42.18 time: 7.45\n",
      "[12,   200] loss: 1.740 acc: 43.36 time: 7.64\n",
      "[12,   300] loss: 1.753 acc: 42.13 time: 7.19\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 44.50 %\n",
      "Average loss on the 10000 test images: 1.716\n",
      "[13,   100] loss: 1.741 acc: 42.64 time: 7.25\n",
      "[13,   200] loss: 1.752 acc: 42.52 time: 7.54\n",
      "[13,   300] loss: 1.747 acc: 42.67 time: 7.08\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 44.77 %\n",
      "Average loss on the 10000 test images: 1.710\n",
      "[14,   100] loss: 1.740 acc: 42.89 time: 7.33\n",
      "[14,   200] loss: 1.732 acc: 44.29 time: 7.30\n",
      "[14,   300] loss: 1.748 acc: 42.85 time: 7.49\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 44.89 %\n",
      "Average loss on the 10000 test images: 1.706\n",
      "[15,   100] loss: 1.738 acc: 43.51 time: 7.59\n",
      "[15,   200] loss: 1.730 acc: 43.30 time: 7.50\n",
      "[15,   300] loss: 1.721 acc: 43.77 time: 7.11\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 44.92 %\n",
      "Average loss on the 10000 test images: 1.707\n",
      "[16,   100] loss: 1.727 acc: 43.74 time: 7.79\n",
      "[16,   200] loss: 1.726 acc: 44.09 time: 7.28\n",
      "[16,   300] loss: 1.732 acc: 44.10 time: 7.18\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 45.55 %\n",
      "Average loss on the 10000 test images: 1.697\n",
      "[17,   100] loss: 1.726 acc: 43.98 time: 7.66\n",
      "[17,   200] loss: 1.726 acc: 43.98 time: 7.26\n",
      "[17,   300] loss: 1.715 acc: 43.78 time: 7.50\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 45.46 %\n",
      "Average loss on the 10000 test images: 1.697\n",
      "[18,   100] loss: 1.722 acc: 43.55 time: 7.60\n",
      "[18,   200] loss: 1.719 acc: 44.44 time: 7.72\n",
      "[18,   300] loss: 1.719 acc: 43.88 time: 7.48\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 45.70 %\n",
      "Average loss on the 10000 test images: 1.694\n",
      "[19,   100] loss: 1.712 acc: 44.48 time: 7.70\n",
      "[19,   200] loss: 1.716 acc: 43.67 time: 7.05\n",
      "[19,   300] loss: 1.719 acc: 43.66 time: 7.02\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 45.63 %\n",
      "Average loss on the 10000 test images: 1.692\n",
      "[20,   100] loss: 1.716 acc: 44.04 time: 7.33\n",
      "[20,   200] loss: 1.717 acc: 44.05 time: 7.24\n",
      "[20,   300] loss: 1.715 acc: 44.36 time: 7.28\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 45.93 %\n",
      "Average loss on the 10000 test images: 1.686\n",
      "[21,   100] loss: 1.713 acc: 44.12 time: 7.20\n",
      "[21,   200] loss: 1.712 acc: 44.82 time: 7.06\n",
      "[21,   300] loss: 1.712 acc: 44.36 time: 7.39\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 46.08 %\n",
      "Average loss on the 10000 test images: 1.685\n",
      "[22,   100] loss: 1.710 acc: 44.55 time: 7.62\n",
      "[22,   200] loss: 1.699 acc: 44.82 time: 7.25\n",
      "[22,   300] loss: 1.712 acc: 44.57 time: 7.29\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 46.11 %\n",
      "Average loss on the 10000 test images: 1.688\n",
      "[23,   100] loss: 1.711 acc: 44.79 time: 7.59\n",
      "[23,   200] loss: 1.710 acc: 44.94 time: 7.69\n",
      "[23,   300] loss: 1.704 acc: 45.41 time: 7.30\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 45.97 %\n",
      "Average loss on the 10000 test images: 1.687\n",
      "[24,   100] loss: 1.695 acc: 45.13 time: 7.26\n",
      "[24,   200] loss: 1.715 acc: 44.17 time: 7.19\n",
      "[24,   300] loss: 1.710 acc: 44.59 time: 7.28\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 45.95 %\n",
      "Average loss on the 10000 test images: 1.685\n",
      "[25,   100] loss: 1.699 acc: 44.55 time: 7.68\n",
      "[25,   200] loss: 1.703 acc: 44.95 time: 7.42\n",
      "[25,   300] loss: 1.700 acc: 44.77 time: 7.07\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 46.01 %\n",
      "Average loss on the 10000 test images: 1.687\n",
      "[26,   100] loss: 1.712 acc: 44.54 time: 7.82\n",
      "[26,   200] loss: 1.708 acc: 44.34 time: 7.30\n",
      "[26,   300] loss: 1.707 acc: 45.26 time: 7.35\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 46.22 %\n",
      "Average loss on the 10000 test images: 1.685\n",
      "[27,   100] loss: 1.710 acc: 44.40 time: 7.51\n",
      "[27,   200] loss: 1.698 acc: 45.27 time: 7.17\n",
      "[27,   300] loss: 1.702 acc: 44.87 time: 7.31\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 45.87 %\n",
      "Average loss on the 10000 test images: 1.682\n",
      "[28,   100] loss: 1.705 acc: 44.63 time: 7.46\n",
      "[28,   200] loss: 1.699 acc: 45.23 time: 7.22\n",
      "[28,   300] loss: 1.711 acc: 44.45 time: 7.39\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 46.36 %\n",
      "Average loss on the 10000 test images: 1.682\n",
      "[29,   100] loss: 1.702 acc: 44.64 time: 7.24\n",
      "[29,   200] loss: 1.704 acc: 45.33 time: 7.21\n",
      "[29,   300] loss: 1.717 acc: 43.80 time: 7.51\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 46.20 %\n",
      "Average loss on the 10000 test images: 1.680\n",
      "[30,   100] loss: 1.703 acc: 44.53 time: 7.08\n",
      "[30,   200] loss: 1.708 acc: 44.61 time: 7.00\n",
      "[30,   300] loss: 1.717 acc: 44.30 time: 7.31\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 46.16 %\n",
      "Average loss on the 10000 test images: 1.683\n",
      "[31,   100] loss: 1.689 acc: 44.73 time: 7.32\n",
      "[31,   200] loss: 1.698 acc: 45.02 time: 6.93\n",
      "[31,   300] loss: 1.708 acc: 44.44 time: 7.26\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 46.18 %\n",
      "Average loss on the 10000 test images: 1.684\n",
      "[32,   100] loss: 1.698 acc: 44.89 time: 7.54\n",
      "[32,   200] loss: 1.699 acc: 44.80 time: 7.19\n",
      "[32,   300] loss: 1.703 acc: 44.81 time: 7.53\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 46.37 %\n",
      "Average loss on the 10000 test images: 1.683\n",
      "[33,   100] loss: 1.702 acc: 44.83 time: 7.31\n",
      "[33,   200] loss: 1.702 acc: 44.96 time: 7.27\n",
      "[33,   300] loss: 1.694 acc: 45.15 time: 7.24\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 46.34 %\n",
      "Average loss on the 10000 test images: 1.681\n",
      "[34,   100] loss: 1.703 acc: 44.57 time: 7.20\n",
      "[34,   200] loss: 1.712 acc: 44.54 time: 7.22\n",
      "[34,   300] loss: 1.695 acc: 45.34 time: 6.96\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 46.33 %\n",
      "Average loss on the 10000 test images: 1.681\n",
      "[35,   100] loss: 1.708 acc: 44.74 time: 7.57\n",
      "[35,   200] loss: 1.708 acc: 44.42 time: 7.56\n",
      "[35,   300] loss: 1.699 acc: 45.41 time: 7.41\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 46.09 %\n",
      "Average loss on the 10000 test images: 1.683\n",
      "[36,   100] loss: 1.705 acc: 44.33 time: 7.45\n",
      "[36,   200] loss: 1.703 acc: 44.41 time: 7.14\n",
      "[36,   300] loss: 1.703 acc: 45.20 time: 7.35\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 46.16 %\n",
      "Average loss on the 10000 test images: 1.684\n",
      "[37,   100] loss: 1.703 acc: 45.20 time: 7.48\n",
      "[37,   200] loss: 1.705 acc: 45.24 time: 7.31\n",
      "[37,   300] loss: 1.712 acc: 44.60 time: 7.15\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 45.98 %\n",
      "Average loss on the 10000 test images: 1.684\n",
      "[38,   100] loss: 1.710 acc: 44.38 time: 7.29\n",
      "[38,   200] loss: 1.696 acc: 45.05 time: 7.50\n",
      "[38,   300] loss: 1.706 acc: 44.48 time: 7.55\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 46.17 %\n",
      "Average loss on the 10000 test images: 1.682\n",
      "[39,   100] loss: 1.709 acc: 44.64 time: 7.38\n",
      "[39,   200] loss: 1.701 acc: 45.28 time: 7.23\n",
      "[39,   300] loss: 1.697 acc: 44.55 time: 7.30\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 46.20 %\n",
      "Average loss on the 10000 test images: 1.681\n",
      "[40,   100] loss: 1.698 acc: 45.14 time: 7.25\n",
      "[40,   200] loss: 1.709 acc: 44.69 time: 7.36\n",
      "[40,   300] loss: 1.699 acc: 44.77 time: 7.46\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 45.99 %\n",
      "Average loss on the 10000 test images: 1.683\n",
      "[41,   100] loss: 1.692 acc: 45.56 time: 7.22\n",
      "[41,   200] loss: 1.701 acc: 45.28 time: 7.39\n",
      "[41,   300] loss: 1.705 acc: 44.81 time: 7.28\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 46.39 %\n",
      "Average loss on the 10000 test images: 1.679\n",
      "[42,   100] loss: 1.706 acc: 44.96 time: 7.28\n",
      "[42,   200] loss: 1.708 acc: 44.59 time: 7.46\n",
      "[42,   300] loss: 1.702 acc: 44.64 time: 7.19\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 46.29 %\n",
      "Average loss on the 10000 test images: 1.683\n",
      "[43,   100] loss: 1.691 acc: 46.04 time: 7.45\n",
      "[43,   200] loss: 1.700 acc: 45.02 time: 7.13\n",
      "[43,   300] loss: 1.708 acc: 44.54 time: 7.87\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 46.30 %\n",
      "Average loss on the 10000 test images: 1.681\n",
      "[44,   100] loss: 1.700 acc: 45.14 time: 7.76\n",
      "[44,   200] loss: 1.694 acc: 45.29 time: 7.61\n",
      "[44,   300] loss: 1.703 acc: 45.08 time: 7.34\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 45.99 %\n",
      "Average loss on the 10000 test images: 1.685\n",
      "[45,   100] loss: 1.714 acc: 44.55 time: 7.53\n",
      "[45,   200] loss: 1.704 acc: 44.64 time: 7.32\n",
      "[45,   300] loss: 1.706 acc: 44.19 time: 7.43\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 46.25 %\n",
      "Average loss on the 10000 test images: 1.681\n",
      "[46,   100] loss: 1.687 acc: 45.96 time: 7.25\n",
      "[46,   200] loss: 1.702 acc: 45.01 time: 7.10\n",
      "[46,   300] loss: 1.702 acc: 45.02 time: 7.12\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 46.27 %\n",
      "Average loss on the 10000 test images: 1.682\n",
      "[47,   100] loss: 1.689 acc: 45.62 time: 7.81\n",
      "[47,   200] loss: 1.718 acc: 44.08 time: 7.00\n",
      "[47,   300] loss: 1.700 acc: 44.86 time: 7.31\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 46.15 %\n",
      "Average loss on the 10000 test images: 1.681\n",
      "[48,   100] loss: 1.706 acc: 44.94 time: 7.46\n",
      "[48,   200] loss: 1.699 acc: 44.84 time: 7.12\n",
      "[48,   300] loss: 1.704 acc: 45.20 time: 16.31\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 46.23 %\n",
      "Average loss on the 10000 test images: 1.682\n",
      "[49,   100] loss: 1.708 acc: 44.88 time: 6.99\n",
      "[49,   200] loss: 1.707 acc: 44.85 time: 7.41\n",
      "[49,   300] loss: 1.687 acc: 45.30 time: 8.18\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 45.97 %\n",
      "Average loss on the 10000 test images: 1.684\n",
      "[50,   100] loss: 1.702 acc: 45.42 time: 7.67\n",
      "[50,   200] loss: 1.709 acc: 44.26 time: 8.27\n",
      "[50,   300] loss: 1.696 acc: 45.41 time: 8.18\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 46.33 %\n",
      "Average loss on the 10000 test images: 1.680\n",
      "Restored best model from epoch with validation accuracy: 46.39%\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "train(net, criterion, optimizer, num_epochs=50, decay_epochs=10, init_lr=0.01, task='classification', experiment_type='Fine-tuning Randomly Initialized Model')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-05T07:42:27.811622900Z",
     "start_time": "2023-11-05T07:14:31.198361500Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Supervised training on the pre-trained model (9 points)\n",
    "In this section, we will load the ResNet18 model pre-trained on the rotation task and re-train the whole model on the classification task.\n",
    "\n",
    "**Then we will use the trained model from rotation task as the pretrained weights. Notice, you should not use the pretrained weights from ImageNet.**"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torchvision.models import resnet18\n",
    "\n",
    "#####################################################\n",
    "#     TODO: Load the pre-trained ResNet18 model     #\n",
    "#####################################################\n",
    "# load the trained classifier weights\n",
    "net = resnet18(weights=None, num_classes=rotation_direction)\n",
    "ckpt = torch.load(f\"{experience_name}.pth\")\n",
    "net.load_state_dict(ckpt)\n",
    "\n",
    "# Adjusting the fully connected layer for 10 classes\n",
    "net.fc = nn.Linear(net.fc.in_features, 10)\n",
    "net = net.to(device)\n",
    "#####################################################\n",
    "#                End of your code                   #\n",
    "#####################################################"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-05T07:42:28.031564400Z",
     "start_time": "2023-11-05T07:42:27.808601Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "outputs": [
    {
     "data": {
      "text/plain": "CrossEntropyLoss()"
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO: Define criterion and optimizer\n",
    "criterion = nn.CrossEntropyLoss(label_smoothing=label_smoothing)\n",
    "\n",
    "# Optimizer: Update only the parameters of layer4 and fc\n",
    "optimizer = optim.Adam(lr=0.001, params=net.parameters())\n",
    "\n",
    "criterion.to(device)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-05T07:42:28.039558300Z",
     "start_time": "2023-11-05T07:42:28.034557700Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,   100] loss: 1.676 acc: 45.73 time: 12.37\n",
      "[1,   200] loss: 1.452 acc: 56.37 time: 7.80\n",
      "[1,   300] loss: 1.338 acc: 61.99 time: 7.29\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 63.50 %\n",
      "Average loss on the 10000 test images: 1.308\n",
      "[2,   100] loss: 1.264 acc: 65.98 time: 7.93\n",
      "[2,   200] loss: 1.223 acc: 67.38 time: 8.40\n",
      "[2,   300] loss: 1.205 acc: 68.38 time: 7.85\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 71.91 %\n",
      "Average loss on the 10000 test images: 1.128\n",
      "[3,   100] loss: 1.143 acc: 71.32 time: 8.62\n",
      "[3,   200] loss: 1.125 acc: 72.29 time: 8.28\n",
      "[3,   300] loss: 1.123 acc: 72.54 time: 8.39\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 72.00 %\n",
      "Average loss on the 10000 test images: 1.136\n",
      "[4,   100] loss: 1.081 acc: 74.05 time: 8.52\n",
      "[4,   200] loss: 1.075 acc: 74.86 time: 8.18\n",
      "[4,   300] loss: 1.066 acc: 74.48 time: 8.39\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 74.57 %\n",
      "Average loss on the 10000 test images: 1.080\n",
      "[5,   100] loss: 1.032 acc: 76.39 time: 7.62\n",
      "[5,   200] loss: 1.036 acc: 76.36 time: 8.39\n",
      "[5,   300] loss: 1.041 acc: 75.95 time: 7.99\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 76.07 %\n",
      "Average loss on the 10000 test images: 1.041\n",
      "[6,   100] loss: 0.999 acc: 78.10 time: 8.74\n",
      "[6,   200] loss: 1.013 acc: 77.52 time: 9.17\n",
      "[6,   300] loss: 1.000 acc: 78.09 time: 8.58\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 76.53 %\n",
      "Average loss on the 10000 test images: 1.034\n",
      "[7,   100] loss: 0.984 acc: 78.80 time: 8.43\n",
      "[7,   200] loss: 0.974 acc: 79.23 time: 8.55\n",
      "[7,   300] loss: 0.976 acc: 79.11 time: 8.01\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 78.02 %\n",
      "Average loss on the 10000 test images: 0.998\n",
      "[8,   100] loss: 0.953 acc: 80.24 time: 8.08\n",
      "[8,   200] loss: 0.946 acc: 80.37 time: 8.12\n",
      "[8,   300] loss: 0.960 acc: 79.41 time: 8.48\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 79.01 %\n",
      "Average loss on the 10000 test images: 0.975\n",
      "[9,   100] loss: 0.930 acc: 81.32 time: 8.34\n",
      "[9,   200] loss: 0.932 acc: 80.91 time: 8.67\n",
      "[9,   300] loss: 0.939 acc: 80.69 time: 7.97\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 78.94 %\n",
      "Average loss on the 10000 test images: 0.966\n",
      "[10,   100] loss: 0.896 acc: 83.03 time: 8.53\n",
      "[10,   200] loss: 0.920 acc: 81.54 time: 8.66\n",
      "[10,   300] loss: 0.928 acc: 81.05 time: 8.17\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 79.68 %\n",
      "Average loss on the 10000 test images: 0.964\n",
      "[11,   100] loss: 0.866 acc: 83.97 time: 9.20\n",
      "[11,   200] loss: 0.833 acc: 85.31 time: 8.86\n",
      "[11,   300] loss: 0.834 acc: 84.88 time: 8.14\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 83.06 %\n",
      "Average loss on the 10000 test images: 0.885\n",
      "[12,   100] loss: 0.819 acc: 85.94 time: 8.85\n",
      "[12,   200] loss: 0.813 acc: 86.27 time: 7.91\n",
      "[12,   300] loss: 0.805 acc: 86.53 time: 8.35\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 83.33 %\n",
      "Average loss on the 10000 test images: 0.880\n",
      "[13,   100] loss: 0.802 acc: 86.49 time: 9.06\n",
      "[13,   200] loss: 0.805 acc: 86.28 time: 8.55\n",
      "[13,   300] loss: 0.808 acc: 86.19 time: 7.93\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 83.44 %\n",
      "Average loss on the 10000 test images: 0.881\n",
      "[14,   100] loss: 0.788 acc: 87.28 time: 8.30\n",
      "[14,   200] loss: 0.798 acc: 86.73 time: 7.91\n",
      "[14,   300] loss: 0.802 acc: 86.80 time: 8.11\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 83.59 %\n",
      "Average loss on the 10000 test images: 0.876\n",
      "[15,   100] loss: 0.785 acc: 87.54 time: 9.22\n",
      "[15,   200] loss: 0.791 acc: 87.03 time: 8.16\n",
      "[15,   300] loss: 0.798 acc: 86.65 time: 8.47\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 83.54 %\n",
      "Average loss on the 10000 test images: 0.877\n",
      "[16,   100] loss: 0.777 acc: 87.74 time: 9.60\n",
      "[16,   200] loss: 0.785 acc: 87.45 time: 8.30\n",
      "[16,   300] loss: 0.792 acc: 87.22 time: 8.11\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 83.70 %\n",
      "Average loss on the 10000 test images: 0.871\n",
      "[17,   100] loss: 0.780 acc: 87.48 time: 9.11\n",
      "[17,   200] loss: 0.786 acc: 87.59 time: 7.90\n",
      "[17,   300] loss: 0.779 acc: 87.37 time: 8.70\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 84.18 %\n",
      "Average loss on the 10000 test images: 0.869\n",
      "[18,   100] loss: 0.777 acc: 88.15 time: 8.06\n",
      "[18,   200] loss: 0.778 acc: 87.58 time: 8.30\n",
      "[18,   300] loss: 0.781 acc: 87.55 time: 8.13\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 83.87 %\n",
      "Average loss on the 10000 test images: 0.870\n",
      "[19,   100] loss: 0.766 acc: 88.36 time: 8.66\n",
      "[19,   200] loss: 0.770 acc: 88.09 time: 8.99\n",
      "[19,   300] loss: 0.776 acc: 87.76 time: 8.46\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 84.09 %\n",
      "Average loss on the 10000 test images: 0.866\n",
      "[20,   100] loss: 0.770 acc: 88.33 time: 8.06\n",
      "[20,   200] loss: 0.766 acc: 88.29 time: 8.31\n",
      "[20,   300] loss: 0.770 acc: 88.13 time: 7.94\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 84.44 %\n",
      "Average loss on the 10000 test images: 0.869\n",
      "[21,   100] loss: 0.756 acc: 88.77 time: 8.54\n",
      "[21,   200] loss: 0.762 acc: 88.16 time: 8.52\n",
      "[21,   300] loss: 0.760 acc: 88.67 time: 8.13\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 84.38 %\n",
      "Average loss on the 10000 test images: 0.864\n",
      "[22,   100] loss: 0.758 acc: 88.98 time: 9.17\n",
      "[22,   200] loss: 0.753 acc: 88.88 time: 8.37\n",
      "[22,   300] loss: 0.759 acc: 88.96 time: 8.10\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 84.39 %\n",
      "Average loss on the 10000 test images: 0.865\n",
      "[23,   100] loss: 0.750 acc: 88.97 time: 8.63\n",
      "[23,   200] loss: 0.759 acc: 88.56 time: 7.95\n",
      "[23,   300] loss: 0.750 acc: 88.76 time: 8.10\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 84.37 %\n",
      "Average loss on the 10000 test images: 0.864\n",
      "[24,   100] loss: 0.758 acc: 88.61 time: 8.45\n",
      "[24,   200] loss: 0.758 acc: 88.71 time: 8.44\n",
      "[24,   300] loss: 0.754 acc: 88.72 time: 8.21\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 84.40 %\n",
      "Average loss on the 10000 test images: 0.864\n",
      "[25,   100] loss: 0.751 acc: 88.99 time: 9.16\n",
      "[25,   200] loss: 0.767 acc: 88.20 time: 8.42\n",
      "[25,   300] loss: 0.753 acc: 88.78 time: 8.80\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 84.37 %\n",
      "Average loss on the 10000 test images: 0.864\n",
      "[26,   100] loss: 0.748 acc: 89.16 time: 8.28\n",
      "[26,   200] loss: 0.756 acc: 88.72 time: 8.36\n",
      "[26,   300] loss: 0.750 acc: 89.05 time: 8.16\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 84.34 %\n",
      "Average loss on the 10000 test images: 0.864\n",
      "[27,   100] loss: 0.755 acc: 88.95 time: 8.50\n",
      "[27,   200] loss: 0.748 acc: 89.28 time: 9.03\n",
      "[27,   300] loss: 0.743 acc: 89.46 time: 8.82\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 84.33 %\n",
      "Average loss on the 10000 test images: 0.864\n",
      "[28,   100] loss: 0.755 acc: 89.08 time: 8.92\n",
      "[28,   200] loss: 0.751 acc: 88.77 time: 9.03\n",
      "[28,   300] loss: 0.751 acc: 88.90 time: 8.85\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 84.38 %\n",
      "Average loss on the 10000 test images: 0.863\n",
      "[29,   100] loss: 0.754 acc: 89.05 time: 8.92\n",
      "[29,   200] loss: 0.749 acc: 89.20 time: 8.30\n",
      "[29,   300] loss: 0.739 acc: 89.41 time: 8.24\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 84.36 %\n",
      "Average loss on the 10000 test images: 0.864\n",
      "[30,   100] loss: 0.749 acc: 88.90 time: 8.61\n",
      "[30,   200] loss: 0.751 acc: 88.95 time: 8.20\n",
      "[30,   300] loss: 0.752 acc: 89.13 time: 8.47\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 84.39 %\n",
      "Average loss on the 10000 test images: 0.864\n",
      "[31,   100] loss: 0.754 acc: 88.88 time: 8.23\n",
      "[31,   200] loss: 0.753 acc: 89.13 time: 8.43\n",
      "[31,   300] loss: 0.751 acc: 88.80 time: 8.11\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 84.33 %\n",
      "Average loss on the 10000 test images: 0.864\n",
      "[32,   100] loss: 0.744 acc: 89.45 time: 8.37\n",
      "[32,   200] loss: 0.746 acc: 89.30 time: 8.53\n",
      "[32,   300] loss: 0.751 acc: 89.01 time: 8.37\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 84.45 %\n",
      "Average loss on the 10000 test images: 0.864\n",
      "[33,   100] loss: 0.747 acc: 89.18 time: 8.51\n",
      "[33,   200] loss: 0.746 acc: 89.12 time: 8.50\n",
      "[33,   300] loss: 0.749 acc: 89.16 time: 8.75\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 84.42 %\n",
      "Average loss on the 10000 test images: 0.865\n",
      "[34,   100] loss: 0.740 acc: 89.37 time: 9.08\n",
      "[34,   200] loss: 0.757 acc: 88.65 time: 8.94\n",
      "[34,   300] loss: 0.748 acc: 89.28 time: 8.43\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 84.41 %\n",
      "Average loss on the 10000 test images: 0.865\n",
      "[35,   100] loss: 0.744 acc: 89.42 time: 8.65\n",
      "[35,   200] loss: 0.745 acc: 89.04 time: 8.19\n",
      "[35,   300] loss: 0.752 acc: 88.89 time: 8.22\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 84.45 %\n",
      "Average loss on the 10000 test images: 0.863\n",
      "[36,   100] loss: 0.745 acc: 89.22 time: 8.23\n",
      "[36,   200] loss: 0.754 acc: 88.72 time: 8.92\n",
      "[36,   300] loss: 0.748 acc: 89.17 time: 8.53\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 84.50 %\n",
      "Average loss on the 10000 test images: 0.863\n",
      "[37,   100] loss: 0.755 acc: 88.38 time: 8.23\n",
      "[37,   200] loss: 0.746 acc: 89.32 time: 8.51\n",
      "[37,   300] loss: 0.742 acc: 89.12 time: 8.01\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 84.39 %\n",
      "Average loss on the 10000 test images: 0.863\n",
      "[38,   100] loss: 0.754 acc: 88.88 time: 8.86\n",
      "[38,   200] loss: 0.744 acc: 89.20 time: 8.72\n",
      "[38,   300] loss: 0.749 acc: 89.12 time: 8.90\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 84.40 %\n",
      "Average loss on the 10000 test images: 0.863\n",
      "[39,   100] loss: 0.740 acc: 89.41 time: 8.40\n",
      "[39,   200] loss: 0.750 acc: 88.88 time: 7.95\n",
      "[39,   300] loss: 0.756 acc: 88.83 time: 8.35\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 84.58 %\n",
      "Average loss on the 10000 test images: 0.862\n",
      "[40,   100] loss: 0.745 acc: 89.26 time: 8.16\n",
      "[40,   200] loss: 0.750 acc: 89.01 time: 8.92\n",
      "[40,   300] loss: 0.745 acc: 89.19 time: 8.46\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 84.42 %\n",
      "Average loss on the 10000 test images: 0.864\n",
      "[41,   100] loss: 0.754 acc: 88.86 time: 8.01\n",
      "[41,   200] loss: 0.751 acc: 88.91 time: 9.17\n",
      "[41,   300] loss: 0.758 acc: 88.60 time: 9.03\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 84.31 %\n",
      "Average loss on the 10000 test images: 0.864\n",
      "[42,   100] loss: 0.750 acc: 89.12 time: 8.30\n",
      "[42,   200] loss: 0.741 acc: 89.52 time: 8.59\n",
      "[42,   300] loss: 0.753 acc: 88.95 time: 8.32\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 84.39 %\n",
      "Average loss on the 10000 test images: 0.862\n",
      "[43,   100] loss: 0.748 acc: 88.89 time: 8.57\n",
      "[43,   200] loss: 0.747 acc: 89.30 time: 8.01\n",
      "[43,   300] loss: 0.744 acc: 89.45 time: 8.87\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 84.36 %\n",
      "Average loss on the 10000 test images: 0.863\n",
      "[44,   100] loss: 0.749 acc: 88.81 time: 8.28\n",
      "[44,   200] loss: 0.753 acc: 89.01 time: 8.77\n",
      "[44,   300] loss: 0.745 acc: 89.17 time: 8.61\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 84.42 %\n",
      "Average loss on the 10000 test images: 0.864\n",
      "[45,   100] loss: 0.751 acc: 88.80 time: 8.91\n",
      "[45,   200] loss: 0.746 acc: 89.10 time: 8.40\n",
      "[45,   300] loss: 0.743 acc: 89.34 time: 7.95\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 84.34 %\n",
      "Average loss on the 10000 test images: 0.864\n",
      "[46,   100] loss: 0.751 acc: 89.02 time: 9.08\n",
      "[46,   200] loss: 0.747 acc: 89.39 time: 9.00\n",
      "[46,   300] loss: 0.751 acc: 88.52 time: 7.79\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 84.42 %\n",
      "Average loss on the 10000 test images: 0.864\n",
      "[47,   100] loss: 0.747 acc: 89.16 time: 8.74\n",
      "[47,   200] loss: 0.748 acc: 89.22 time: 8.27\n",
      "[47,   300] loss: 0.755 acc: 88.95 time: 8.54\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 84.41 %\n",
      "Average loss on the 10000 test images: 0.864\n",
      "[48,   100] loss: 0.735 acc: 89.67 time: 8.40\n",
      "[48,   200] loss: 0.746 acc: 89.20 time: 8.09\n",
      "[48,   300] loss: 0.751 acc: 89.12 time: 8.82\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 84.45 %\n",
      "Average loss on the 10000 test images: 0.862\n",
      "[49,   100] loss: 0.745 acc: 89.20 time: 8.31\n",
      "[49,   200] loss: 0.752 acc: 88.93 time: 8.91\n",
      "[49,   300] loss: 0.751 acc: 88.83 time: 8.40\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 84.57 %\n",
      "Average loss on the 10000 test images: 0.863\n",
      "[50,   100] loss: 0.750 acc: 89.08 time: 8.75\n",
      "[50,   200] loss: 0.751 acc: 89.00 time: 7.77\n",
      "[50,   300] loss: 0.752 acc: 88.89 time: 8.45\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 84.42 %\n",
      "Average loss on the 10000 test images: 0.863\n",
      "Restored best model from epoch with validation accuracy: 84.58%\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "train(net, criterion, optimizer, num_epochs=50, decay_epochs=10, init_lr=0.01, task='classification', experiment_type='Supervised Pre-trained Model')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-05T08:50:05.528598700Z",
     "start_time": "2023-11-05T08:18:47.898179400Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Supervised training on the randomly initialized model (9 points)\n",
    "In this section, we will randomly initialize a ResNet18 model and re-train the whole model on the classification task."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torchvision.models import resnet18\n",
    "\n",
    "#################################################\n",
    "# TODO: Randomly initialize a ResNet18 model    #\n",
    "#################################################\n",
    "net = resnet18(weights=None, num_classes=10)\n",
    "net = net.to(device)\n",
    "#################################################\n",
    "#              End of your code                 #\n",
    "#################################################"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-05T08:50:05.714685400Z",
     "start_time": "2023-11-05T08:50:05.525599200Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "outputs": [
    {
     "data": {
      "text/plain": "CrossEntropyLoss()"
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO: Define criterion and optimizer\n",
    "criterion = nn.CrossEntropyLoss(label_smoothing=label_smoothing)\n",
    "\n",
    "# Optimizer: Update only the parameters of layer4 and fc\n",
    "optimizer = optim.Adam(lr=0.001, params=net.parameters())\n",
    "\n",
    "criterion.to(device)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-05T08:50:05.723687900Z",
     "start_time": "2023-11-05T08:50:05.716687900Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,   100] loss: 2.276 acc: 23.34 time: 8.64\n",
      "[1,   200] loss: 1.958 acc: 34.40 time: 8.85\n",
      "[1,   300] loss: 1.816 acc: 38.49 time: 8.96\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 47.75 %\n",
      "Average loss on the 10000 test images: 1.666\n",
      "[2,   100] loss: 1.681 acc: 44.85 time: 9.28\n",
      "[2,   200] loss: 1.630 acc: 47.84 time: 8.39\n",
      "[2,   300] loss: 1.568 acc: 50.59 time: 9.72\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 54.21 %\n",
      "Average loss on the 10000 test images: 1.520\n",
      "[3,   100] loss: 1.476 acc: 54.47 time: 8.61\n",
      "[3,   200] loss: 1.438 acc: 57.66 time: 8.43\n",
      "[3,   300] loss: 1.408 acc: 59.01 time: 9.08\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 62.70 %\n",
      "Average loss on the 10000 test images: 1.336\n",
      "[4,   100] loss: 1.323 acc: 63.67 time: 8.28\n",
      "[4,   200] loss: 1.325 acc: 62.66 time: 8.23\n",
      "[4,   300] loss: 1.280 acc: 64.93 time: 9.25\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 67.50 %\n",
      "Average loss on the 10000 test images: 1.243\n",
      "[5,   100] loss: 1.240 acc: 66.77 time: 9.39\n",
      "[5,   200] loss: 1.229 acc: 66.99 time: 8.62\n",
      "[5,   300] loss: 1.228 acc: 67.26 time: 8.87\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 69.68 %\n",
      "Average loss on the 10000 test images: 1.175\n",
      "[6,   100] loss: 1.182 acc: 69.37 time: 9.67\n",
      "[6,   200] loss: 1.172 acc: 69.78 time: 8.36\n",
      "[6,   300] loss: 1.160 acc: 70.76 time: 8.11\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 69.34 %\n",
      "Average loss on the 10000 test images: 1.190\n",
      "[7,   100] loss: 1.133 acc: 72.07 time: 9.35\n",
      "[7,   200] loss: 1.133 acc: 71.45 time: 8.65\n",
      "[7,   300] loss: 1.114 acc: 72.93 time: 8.26\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 71.37 %\n",
      "Average loss on the 10000 test images: 1.125\n",
      "[8,   100] loss: 1.099 acc: 73.91 time: 8.31\n",
      "[8,   200] loss: 1.084 acc: 73.77 time: 8.06\n",
      "[8,   300] loss: 1.080 acc: 74.10 time: 8.27\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 71.92 %\n",
      "Average loss on the 10000 test images: 1.141\n",
      "[9,   100] loss: 1.058 acc: 75.29 time: 8.29\n",
      "[9,   200] loss: 1.055 acc: 75.55 time: 8.09\n",
      "[9,   300] loss: 1.057 acc: 75.36 time: 8.58\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 71.07 %\n",
      "Average loss on the 10000 test images: 1.195\n",
      "[10,   100] loss: 1.037 acc: 76.23 time: 9.19\n",
      "[10,   200] loss: 1.031 acc: 76.59 time: 8.43\n",
      "[10,   300] loss: 1.035 acc: 76.19 time: 9.03\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 75.17 %\n",
      "Average loss on the 10000 test images: 1.067\n",
      "[11,   100] loss: 0.961 acc: 79.43 time: 9.27\n",
      "[11,   200] loss: 0.933 acc: 80.77 time: 8.55\n",
      "[11,   300] loss: 0.932 acc: 80.67 time: 8.43\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 80.16 %\n",
      "Average loss on the 10000 test images: 0.955\n",
      "[12,   100] loss: 0.919 acc: 81.45 time: 8.43\n",
      "[12,   200] loss: 0.920 acc: 81.46 time: 8.35\n",
      "[12,   300] loss: 0.899 acc: 82.45 time: 8.54\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 80.89 %\n",
      "Average loss on the 10000 test images: 0.930\n",
      "[13,   100] loss: 0.886 acc: 83.02 time: 8.79\n",
      "[13,   200] loss: 0.881 acc: 83.13 time: 8.50\n",
      "[13,   300] loss: 0.886 acc: 82.61 time: 8.74\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 81.04 %\n",
      "Average loss on the 10000 test images: 0.928\n",
      "[14,   100] loss: 0.883 acc: 83.09 time: 9.27\n",
      "[14,   200] loss: 0.885 acc: 82.74 time: 8.80\n",
      "[14,   300] loss: 0.874 acc: 83.66 time: 8.68\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 81.45 %\n",
      "Average loss on the 10000 test images: 0.915\n",
      "[15,   100] loss: 0.866 acc: 84.12 time: 9.34\n",
      "[15,   200] loss: 0.881 acc: 83.29 time: 9.10\n",
      "[15,   300] loss: 0.866 acc: 83.84 time: 8.85\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 81.68 %\n",
      "Average loss on the 10000 test images: 0.916\n",
      "[16,   100] loss: 0.857 acc: 84.34 time: 9.07\n",
      "[16,   200] loss: 0.857 acc: 84.16 time: 8.63\n",
      "[16,   300] loss: 0.866 acc: 83.89 time: 8.44\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 81.78 %\n",
      "Average loss on the 10000 test images: 0.911\n",
      "[17,   100] loss: 0.847 acc: 84.62 time: 8.29\n",
      "[17,   200] loss: 0.859 acc: 84.27 time: 8.33\n",
      "[17,   300] loss: 0.854 acc: 84.51 time: 9.22\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 81.82 %\n",
      "Average loss on the 10000 test images: 0.908\n",
      "[18,   100] loss: 0.843 acc: 84.90 time: 8.83\n",
      "[18,   200] loss: 0.843 acc: 84.91 time: 8.75\n",
      "[18,   300] loss: 0.836 acc: 85.04 time: 8.73\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 81.97 %\n",
      "Average loss on the 10000 test images: 0.905\n",
      "[19,   100] loss: 0.841 acc: 84.91 time: 9.11\n",
      "[19,   200] loss: 0.834 acc: 84.97 time: 9.03\n",
      "[19,   300] loss: 0.840 acc: 84.95 time: 8.67\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 82.36 %\n",
      "Average loss on the 10000 test images: 0.898\n",
      "[20,   100] loss: 0.833 acc: 84.98 time: 8.55\n",
      "[20,   200] loss: 0.832 acc: 85.09 time: 7.96\n",
      "[20,   300] loss: 0.837 acc: 84.85 time: 8.49\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 82.38 %\n",
      "Average loss on the 10000 test images: 0.897\n",
      "[21,   100] loss: 0.810 acc: 86.33 time: 9.10\n",
      "[21,   200] loss: 0.815 acc: 86.31 time: 8.60\n",
      "[21,   300] loss: 0.812 acc: 86.23 time: 9.16\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 82.39 %\n",
      "Average loss on the 10000 test images: 0.892\n",
      "[22,   100] loss: 0.814 acc: 85.86 time: 9.02\n",
      "[22,   200] loss: 0.809 acc: 86.21 time: 8.72\n",
      "[22,   300] loss: 0.826 acc: 85.51 time: 8.29\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 82.65 %\n",
      "Average loss on the 10000 test images: 0.892\n",
      "[23,   100] loss: 0.810 acc: 86.53 time: 8.45\n",
      "[23,   200] loss: 0.811 acc: 86.27 time: 8.62\n",
      "[23,   300] loss: 0.810 acc: 86.10 time: 8.39\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 82.81 %\n",
      "Average loss on the 10000 test images: 0.891\n",
      "[24,   100] loss: 0.812 acc: 86.23 time: 8.62\n",
      "[24,   200] loss: 0.805 acc: 86.60 time: 8.01\n",
      "[24,   300] loss: 0.807 acc: 86.22 time: 8.19\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 82.88 %\n",
      "Average loss on the 10000 test images: 0.890\n",
      "[25,   100] loss: 0.805 acc: 86.59 time: 8.46\n",
      "[25,   200] loss: 0.812 acc: 86.14 time: 8.84\n",
      "[25,   300] loss: 0.807 acc: 86.77 time: 8.95\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 82.89 %\n",
      "Average loss on the 10000 test images: 0.890\n",
      "[26,   100] loss: 0.808 acc: 86.56 time: 8.56\n",
      "[26,   200] loss: 0.801 acc: 86.72 time: 8.75\n",
      "[26,   300] loss: 0.805 acc: 86.48 time: 8.53\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 82.77 %\n",
      "Average loss on the 10000 test images: 0.891\n",
      "[27,   100] loss: 0.795 acc: 86.91 time: 8.59\n",
      "[27,   200] loss: 0.805 acc: 86.54 time: 9.20\n",
      "[27,   300] loss: 0.802 acc: 86.80 time: 9.21\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 83.08 %\n",
      "Average loss on the 10000 test images: 0.889\n",
      "[28,   100] loss: 0.795 acc: 87.08 time: 8.46\n",
      "[28,   200] loss: 0.799 acc: 86.88 time: 8.49\n",
      "[28,   300] loss: 0.797 acc: 87.02 time: 8.59\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 82.71 %\n",
      "Average loss on the 10000 test images: 0.889\n",
      "[29,   100] loss: 0.804 acc: 86.79 time: 8.22\n",
      "[29,   200] loss: 0.792 acc: 87.31 time: 8.42\n",
      "[29,   300] loss: 0.802 acc: 86.62 time: 8.56\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 82.91 %\n",
      "Average loss on the 10000 test images: 0.888\n",
      "[30,   100] loss: 0.794 acc: 87.03 time: 8.72\n",
      "[30,   200] loss: 0.796 acc: 86.77 time: 8.96\n",
      "[30,   300] loss: 0.803 acc: 86.77 time: 9.05\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 82.90 %\n",
      "Average loss on the 10000 test images: 0.890\n",
      "[31,   100] loss: 0.801 acc: 86.62 time: 8.57\n",
      "[31,   200] loss: 0.800 acc: 86.79 time: 8.87\n",
      "[31,   300] loss: 0.796 acc: 86.75 time: 8.51\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 83.10 %\n",
      "Average loss on the 10000 test images: 0.888\n",
      "[32,   100] loss: 0.798 acc: 86.91 time: 8.14\n",
      "[32,   200] loss: 0.795 acc: 86.85 time: 8.52\n",
      "[32,   300] loss: 0.798 acc: 86.91 time: 8.63\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 82.82 %\n",
      "Average loss on the 10000 test images: 0.889\n",
      "[33,   100] loss: 0.807 acc: 86.46 time: 8.15\n",
      "[33,   200] loss: 0.785 acc: 87.04 time: 8.14\n",
      "[33,   300] loss: 0.790 acc: 87.05 time: 8.58\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 83.02 %\n",
      "Average loss on the 10000 test images: 0.887\n",
      "[34,   100] loss: 0.794 acc: 86.93 time: 8.89\n",
      "[34,   200] loss: 0.801 acc: 86.85 time: 8.44\n",
      "[34,   300] loss: 0.798 acc: 86.88 time: 8.66\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 83.06 %\n",
      "Average loss on the 10000 test images: 0.889\n",
      "[35,   100] loss: 0.791 acc: 87.09 time: 8.49\n",
      "[35,   200] loss: 0.797 acc: 86.97 time: 8.38\n",
      "[35,   300] loss: 0.798 acc: 86.83 time: 8.78\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 82.86 %\n",
      "Average loss on the 10000 test images: 0.890\n",
      "[36,   100] loss: 0.785 acc: 87.55 time: 8.43\n",
      "[36,   200] loss: 0.790 acc: 87.09 time: 8.04\n",
      "[36,   300] loss: 0.810 acc: 86.43 time: 8.60\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 82.95 %\n",
      "Average loss on the 10000 test images: 0.889\n",
      "[37,   100] loss: 0.807 acc: 86.32 time: 8.87\n",
      "[37,   200] loss: 0.796 acc: 87.26 time: 8.38\n",
      "[37,   300] loss: 0.792 acc: 87.14 time: 8.78\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 82.91 %\n",
      "Average loss on the 10000 test images: 0.890\n",
      "[38,   100] loss: 0.796 acc: 86.80 time: 8.32\n",
      "[38,   200] loss: 0.798 acc: 87.14 time: 8.67\n",
      "[38,   300] loss: 0.800 acc: 86.89 time: 8.32\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 82.93 %\n",
      "Average loss on the 10000 test images: 0.888\n",
      "[39,   100] loss: 0.801 acc: 86.57 time: 9.01\n",
      "[39,   200] loss: 0.794 acc: 86.91 time: 9.16\n",
      "[39,   300] loss: 0.794 acc: 86.99 time: 8.50\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 83.05 %\n",
      "Average loss on the 10000 test images: 0.886\n",
      "[40,   100] loss: 0.798 acc: 86.66 time: 8.21\n",
      "[40,   200] loss: 0.804 acc: 86.62 time: 8.17\n",
      "[40,   300] loss: 0.794 acc: 86.87 time: 8.82\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 83.10 %\n",
      "Average loss on the 10000 test images: 0.888\n",
      "[41,   100] loss: 0.788 acc: 87.11 time: 8.86\n",
      "[41,   200] loss: 0.800 acc: 86.79 time: 9.01\n",
      "[41,   300] loss: 0.796 acc: 86.92 time: 9.12\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 82.98 %\n",
      "Average loss on the 10000 test images: 0.889\n",
      "[42,   100] loss: 0.791 acc: 87.34 time: 8.30\n",
      "[42,   200] loss: 0.799 acc: 86.70 time: 8.54\n",
      "[42,   300] loss: 0.787 acc: 87.38 time: 8.97\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 82.98 %\n",
      "Average loss on the 10000 test images: 0.887\n",
      "[43,   100] loss: 0.794 acc: 86.99 time: 9.55\n",
      "[43,   200] loss: 0.794 acc: 86.99 time: 7.93\n",
      "[43,   300] loss: 0.794 acc: 87.06 time: 8.89\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 82.80 %\n",
      "Average loss on the 10000 test images: 0.890\n",
      "[44,   100] loss: 0.796 acc: 87.08 time: 8.39\n",
      "[44,   200] loss: 0.791 acc: 87.35 time: 8.56\n",
      "[44,   300] loss: 0.789 acc: 87.16 time: 9.10\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 83.04 %\n",
      "Average loss on the 10000 test images: 0.888\n",
      "[45,   100] loss: 0.805 acc: 86.73 time: 8.75\n",
      "[45,   200] loss: 0.796 acc: 86.53 time: 8.49\n",
      "[45,   300] loss: 0.780 acc: 87.73 time: 8.23\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 82.99 %\n",
      "Average loss on the 10000 test images: 0.888\n",
      "[46,   100] loss: 0.795 acc: 86.86 time: 8.13\n",
      "[46,   200] loss: 0.796 acc: 87.05 time: 9.07\n",
      "[46,   300] loss: 0.796 acc: 86.83 time: 9.67\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 82.89 %\n",
      "Average loss on the 10000 test images: 0.889\n",
      "[47,   100] loss: 0.804 acc: 86.41 time: 8.35\n",
      "[47,   200] loss: 0.792 acc: 86.95 time: 8.56\n",
      "[47,   300] loss: 0.796 acc: 87.16 time: 8.53\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 82.91 %\n",
      "Average loss on the 10000 test images: 0.889\n",
      "[48,   100] loss: 0.800 acc: 86.81 time: 8.77\n",
      "[48,   200] loss: 0.792 acc: 87.12 time: 8.25\n",
      "[48,   300] loss: 0.797 acc: 87.03 time: 8.18\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 82.78 %\n",
      "Average loss on the 10000 test images: 0.890\n",
      "[49,   100] loss: 0.796 acc: 86.84 time: 8.07\n",
      "[49,   200] loss: 0.791 acc: 87.38 time: 8.27\n",
      "[49,   300] loss: 0.797 acc: 86.86 time: 7.62\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 82.99 %\n",
      "Average loss on the 10000 test images: 0.889\n",
      "[50,   100] loss: 0.802 acc: 86.91 time: 8.65\n",
      "[50,   200] loss: 0.792 acc: 86.97 time: 8.68\n",
      "[50,   300] loss: 0.794 acc: 87.01 time: 8.81\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 83.07 %\n",
      "Average loss on the 10000 test images: 0.888\n",
      "Restored best model from epoch with validation accuracy: 83.10%\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "train(net, criterion, optimizer, num_epochs=50, decay_epochs=10, init_lr=0.01, task='classification', experiment_type='Supervised Randomly Initialized Model')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-05T09:21:59.516883Z",
     "start_time": "2023-11-05T08:50:05.722687300Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Write report (37 points)\n",
    "\n",
    "本次作業主要有3個tasks需要大家完成，在A4.pdf中有希望大家達成的baseline **(不能低於baseline最多2%，沒有達到不會給全部分數)**，report的撰寫就希望大家可以透過去調整不同的訓練方法、損失函數、優化器，或者是調整凍結不同的層來進行這次的實驗，就請大家將嘗試的結果寫在report裡，祝大家順利！\n",
    "\n",
    "- Rotation task (13 points)\n",
    "- Fine-tuning the specified layers of the pre-trained model (12 points)\n",
    "- Fine-tuning the whole pre-trained model (12 points)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Extra Credit (13 points)\n",
    "\n",
    "上面基本的code跟report最高可以拿到87分，這個加分部分並沒有要求同學們一定要做，若同學們想要獲得更高的分數可以根據以下的加分要求來獲得加分。\n",
    "\n",
    "- In Figure 5(b) from the Gidaris et al. paper, the authors show a plot of CIFAR10 classification performance vs. number of training examples per category for a supervised CIFAR10 model vs. a RotNet model with the final layers fine-tuned on CIFAR10. The plot shows that pre-training on the Rotation task can be advantageous when only a small amount of labeled data is available. Using your RotNet fine-tuning code and supervised CIFAR10 training code from the main assignment, try to create a similar plot by performing supervised fine-tuning/training on only a subset of CIFAR10.\n",
    "- Use a more advanced model than ResNet18 to try to get higher accuracy on the rotation prediction task, as well as for transfer to supervised CIFAR10 classification.\n",
    "\n",
    "- If you have a good amount of compute at your disposal, try to train a rotation prediction model on the larger ImageNette dataset (still smaller than ImageNet, though).\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": [
    {
     "file_id": "1qQ3NEaCUln7yDSksrEOnDwrt3u9dYNr4",
     "timestamp": 1677623843954
    }
   ]
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3.8.13",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "aaa478f9632825e83f6a2247407c7a2930de96a6810af7910643e423346524f9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
