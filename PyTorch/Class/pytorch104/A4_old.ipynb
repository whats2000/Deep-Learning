{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MIS 583 Assignment 4: Self-supervised and transfer learning on CIFAR10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we start, please put your name and SID in following format: <br>\n",
    ": LASTNAME Firstname, ?00000000   //   e.g.) 李晨愷 M114020035"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Your Answer:**    \n",
    "Hi I'm Ren-Di Wu, B104020009."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IWMWW8Ab_345"
   },
   "source": [
    "## Google Colab Setup\n",
    "Next we need to run a few commands to set up our environment on Google Colab. If you are running this notebook on a local machine you can skip this section.\n",
    "\n",
    "Run the following cell to mount your Google Drive. Follow the link, sign in to your Google account (the same account you used to store this notebook!) and copy the authorization code into the text box that appears below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-04T16:00:44.266326Z",
     "start_time": "2023-11-04T16:00:44.226657100Z"
    },
    "id": "vH4wc4iD_6w_"
   },
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-02T14:34:35.454618300Z",
     "start_time": "2023-11-02T14:34:35.450610Z"
    },
    "id": "XpNsPHZc_879"
   },
   "outputs": [],
   "source": [
    "# fill in the path in your Google Drive in the string below. Note: do not escape slashes or spaces\n",
    "# import os\n",
    "# datadir = \"C:/Users/eddie/GitHub/Deep-Learning/PyTorch/Class/pytorch104\"\n",
    "# if not os.path.exists(datadir):\n",
    "#  !ln -s \"/content/drive/My Drive/Your/A4/path/\" $datadir # TODO: Fill your A3 path\n",
    "# os.chdir(datadir)\n",
    "# !pwd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Um5DJvBwb6xT"
   },
   "source": [
    "# Data Setup (5 points)\n",
    "\n",
    "The first thing to do is implement a dataset class to load rotated CIFAR10 images with matching labels. Since there is already a CIFAR10 dataset class implemented in `torchvision`, we will extend this class and modify the `__get_item__` method appropriately to load rotated images.\n",
    "\n",
    "Each rotation label should be an integer in the set {0, 1, 2, 3} which correspond to rotations of 0, 90, 180, or 270 degrees respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-11-04T15:36:08.670812800Z"
    },
    "id": "oHkeNUOKiFbP",
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "\n",
    "def rotate_img(img, rot):\n",
    "    if rot == 0: # 0 degrees rotation\n",
    "        return img\n",
    "    #######################################################################\n",
    "    #        TODO: Implement rotate_img() - return the rotated img        #                           \n",
    "    #######################################################################\n",
    "    angles = {0: 0, 1: 90, 2: 180, 3: 270}\n",
    "    if rot in angles:\n",
    "        return transforms.functional.rotate(img, angles[rot])\n",
    "    else:\n",
    "        raise ValueError('rotation should be 0, 90, 180, or 270 degrees')\n",
    "\n",
    "    #######################################################################\n",
    "    #                           End of your code                          #\n",
    "    #######################################################################\n",
    "\n",
    "class CIFAR10Rotation(torchvision.datasets.CIFAR10):\n",
    "\n",
    "    def __init__(self, root, train, download, transform) -> None:\n",
    "        super().__init__(root=root, train=train, download=download, transform=transform)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, index: int):\n",
    "        image, cls_label = super().__getitem__(index)\n",
    "\n",
    "        # randomly select image rotation\n",
    "        rotation_label = random.choice([0, 1, 2, 3])\n",
    "        image_rotated = rotate_img(image, rotation_label)\n",
    "\n",
    "        rotation_label = torch.tensor(rotation_label).long()\n",
    "        return image, image_rotated, rotation_label, torch.tensor(cls_label).long()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-02T15:49:38.877797700Z",
     "start_time": "2023-11-02T15:49:37.119072500Z"
    },
    "id": "CCBSpNWpb8uw"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "transform_train = transforms.Compose([\n",
    "    transforms.RandomCrop(32, padding=4),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])\n",
    "\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])\n",
    "\n",
    "batch_size = 128\n",
    "\n",
    "trainset = CIFAR10Rotation(root='data', train=True,\n",
    "                                        download=True, transform=transform_train)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,\n",
    "                                          shuffle=True, num_workers=0)\n",
    "\n",
    "testset = CIFAR10Rotation(root='data', train=False,\n",
    "                                       download=True, transform=transform_test)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size,\n",
    "                                         shuffle=False, num_workers=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dOCWMyGhVOJB"
   },
   "source": [
    "Show some example images and rotated images with labels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-02T15:49:41.735831500Z",
     "start_time": "2023-11-02T15:49:41.039673800Z"
    },
    "id": "A9wN4BJWVMzB"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class labels:  truck plane plane bird \n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAh8AAACrCAYAAADGmf6bAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAABAaElEQVR4nO2de3Rc1X3vf+cxT81oRm9ZlmUL29jGxjxsbBTyIEQNoSwChdUmlBYn4TaL1E4Br9sQJ4WupKXmtusmJL2ErPam0K6Gkvg2kIY0UGLzCImfwuZlsA1+CduSLEujkUaa1zn7/kEz53x/x5rxIHkky7/PWlprfrPPY5999tmzdX7f/ftpSilFgiAIgiAIFUKf6goIgiAIgnB+IZMPQRAEQRAqikw+BEEQBEGoKDL5EARBEAShosjkQxAEQRCEiiKTD0EQBEEQKopMPgRBEARBqCgy+RAEQRAEoaLI5EMQBEEQhIoikw9BEARBECrKWZt8PPzwwzRv3jwKBoO0evVq2rFjx9k6lSAIgiAI5xDa2cjt8qMf/Yhuv/12+v73v0+rV6+mhx56iDZt2kT79u2jxsbGovvatk3Hjx+naDRKmqZNdtUEQRAEQTgLKKVoeHiYWlpaSNdLvNtQZ4FVq1aptWvXFmzLslRLS4vauHFjyX27u7sVEcmf/Mmf/Mmf/MnfOfjX3d1d8rfepEkmm81SV1cXbdiwofCdruvU2dlJW7du9WyfyWQok8kUbDXBFzGL7vgvrE//QbC1/v1g+9QY2LlADdhG6+VgV4Vngx3Q0oXP+SoflMXMJNgfrf0N2B31v8a6qQzYhjVCiAVWVsUKn/1GHsoODuIbpm/913ywe9WFYDeOvgX23OMv45mjNti5urrCZ18Q28Q0sS5Vftz32us+CfZg9DKwj7z2Eth7X3sOj+9q8wB7OaYIu3ROhcGub1sG9vLLPwJ2ODYL7CxFwbaVUfhsaHg/NMK+y1/cKcIvSvk88/zFn3K+MGxWpmGba1oQbJtwB01Pg03Kz7bnx3eujT+jhoFtvv6mNr63IBT4xtfuANvO4RishZxnLpfDffOjw2D7THwGY3VxsIdH2DOpAnhuP9qpjNPzR5ODUHai+yjYyZEE2O1z54FdXYt1ITZe5MZGwT747oHC5xrX+EpEZJohtu2bYLe0LQS7rhHrUlvTArbhx/FB6c7YonscDuw3WeEG7vEgk07T//rGX1I0iuPm6Zj0yUd/fz9ZlkVNTU3wfVNTE7399tue7Tdu3Ejf+MY3Ju38hr8KbN2HN00zsbMZCodZ28SbYvjDzI6AbepOE6oATj5M9mAEg3jsqjA2v6ZwezNvUDEyrrmjn93JcBrrYrDr1lWoaLlPx3NrButwpnNCnw9/uEwTf1Z9PmzjcBjbdCyMbRoIYt1MH16Lz/VD6/P8wPvYF2j7A3gPgmHsL6EwPjQGVYNtuSYfpmfywX7ged00bBe9xDw7z2cn7smHxco0HKU1DdvQ1vjkg7cTG5R5ZWDygaWG4eNbC8K4BINsoquz58hVbrAhMGfhvn42xoaC2I9zedbvS0w+8q7nxMrguXw+HGRNEyvn9+NzEAjg/nzyodv4zPp8zvH4sUyT22yMLXFu/tvjnXw4x/N6S9hAZfPJh2e0OCPJxKRPPsplw4YNtH79+oKdTCZpzpw5H/h4efYjqgXxx0WxycPwMHvbEGKTlwDayUAWbMvVyEqxG+zDWXr3SeysTxyeh3Uz8U1HW/UQ2GYG/7tNZJ265W3878EXwza0dfyPXrfZ5ETHruBjP/iBEHamsYBzLZlcCsryFpvhp/C/7MGBBJbHsI3nXfIxsFPsP4TDb79Q+GwRayONDQjsR7fv0Atg/ybxDtixhkvAXrL8d8CO1LUWPmfZmww+8eFvQkzFB0K0lWcixUZe16CgsQHbZiOGbbO3E8QmJ4R9yfYMBcUnvhPh73fif5Qae2vD//NymwabFvFtdXa/dXYP+Pbeq2QDqWt3lcc2DGrYL9/81Raw92zfDvaVq5aCXRfHfp9hg7plOe3Cr3tkFJ+pUAgnm5EIjnP8x8Cy8XgWuzbT1VDKwvvzP75wF02EahPPnczjc5N19cV8Ds89ksV9I+xHeHQMx6Kh4QTYFtWCHYqgreWdcfTou/g2uPvIu1hPhXXLpPvAXn7RRWDHq+vB1tk/bYuWXFr4nBjG+7t/L77piFY3gD134SqwQ2F8g8/HIlVkgsHnEvxNp83HLVd53vZORMZj0icf9fX1ZBgG9fb2wve9vb3U3Nzs2T4QCFAgEPB8LwiCIAjCzGTSl9r6/X5asWIFbd68ufCdbdu0efNm6ujomOzTCYIgCIJwjnFW3C7r16+nNWvW0MqVK2nVqlX00EMPUSqVos9//vNn43SCIAiCIJxDnJXJx2c+8xk6efIk3X///dTT00OXXnopPfPMMx4R6tnA1FCTQQbzV5loW0zkGWDCHu4QyrIVJyY5fjtlMdEm82Unx/DYW/fiipRYHM/Vvhpvj53Fa+sdcjzWAxn06TYEUdRpMS0EXx3BRUNaCT1DKuVs769CkWYoiG0cr2IiXabDGuVaCRP9lUsu7wTbthxf+5G3XoCyILu/lEdNj49d50jfcbD3vXUI7P17d4O94ipnpc4Fy3ClDPn4ypgSLxaZPsGzgEVx27n/p/oOQ1mK+bpnNbIVJ3n0IRusYwfYKq40E7S6q6Ix4axHWVsCvr/3eLwvjn8qfmadbcC1Dt47wnU4WGrZTkNwgbDBnqGqKD5z/mgc7NEcHoBHPPK0ovsLrvmzx/e7E5UW/JW6ZbD/JMdbSikUcSfZlVtZZ9zT/DhuhaqZuDmHz29i4BTYKo+6nHQWnxNNx8HIvSKtbhY+E4NDPWCPplG7FA3jsUb7UfNn4anJF0KNYL9LG5cY5X0rBvbsuQvwYGyhRC6HvxWe56bIc8T7jkfzwfqe7dZ88OVJRThrgtN169bRunXrztbhBUEQBEE4R5HcLoIgCIIgVBSZfAiCIAiCUFGmPM7HZDPK4nzYBs6vTBZ0SqvGSHKZEDYJi61FJvPju49vsgilfhZbYYzFv9BsdAK2xRNgVxGP/Id+wFktjpZC62dOehY1ME/cF4fbVzG7PocagSCbptbFHX3DSAbjk9gZPNZgCiO9nmTLsKsw+J5Hb6JH8B4tXXVd4XM6hdd57OArYPsMvCe5YWyHoRT6bUdTeE/6e3Ftf3+PE4XwD2tQm9K0YCXYqSz2Ne/6eKbyMLHvhVhQo3TC8W+/te1nUDY8gtfR74pHQkS0eH472MtWYF0HWfyEMexqRFyX4S4at2Q8uJiFmVwTAroMrhfhleF6ERbfgEehLVpPonzGeQ509vzqIRb1l8WjGcuwvjbGnlGuT/GGdivAwrZ8AI0HP1dxbYz7+FqpHB1l0pvh8U2wXQzNPaaysUBj+jGmdTDtBNjxKnwOkiP4fHf3dIPd2OQMRjUsYnVbK4aKUDnUePlMrJudxef3ZALrFstjO2Rzzv1vaJoLZdU1OAbyIIE5prVQPN6NJ4YQArefRxlnfaOY3ojXoxjy5kMQBEEQhIoikw9BEARBECqKTD4EQRAEQagoM07zYVjoA6xNo3+qdoz5EKPotx9hicdGbFy7bVg8UZ3j7+JxPXw5PFcmh/qD5Reg/3FpO8u3keN+WTApR44/WuOSjyzOK7OE9SbmM8xbuC48nEX/de1hzFtgnzhR+Hwij230ZhbzrQywhHuXrrwCbNNmGVmZjznN/NP+sOOXXXHlzVCWS6O+pOdEF9jDedSnDLO8M4r59eMBXF8fds3X39y+GcqMAMYviM3CzMGazRLLsal/Oot1S/Zhmw8de73wOTeI8UhqWCbhhWHMI1Gfx/gHDRF89FkKDK9TGIqK56QpzcQyVxdjolXhGhHL1R/GWCyVKpZJ2rbQ351jz+QIy83E243noXFfTd4ev15E72cOLw82DvL9XXqkSQ7zQTkmbdGYjs79nGhMrMBtZbPxmD2vozbqKkaYDqc6yO7hsKNHs7I4XkfZ/+qDKLOiLNMAjWUGwO7rwzgh4QuWgN3Q7GQe1yJxPDiLR6Kz8dvK8b5VXPuksWSQiX6nbjxhXqQGxxI7j30PNB+srBjy5kMQBEEQhIoikw9BEARBECqKTD4EQRAEQagoM07zEVL9YN+QRw3AR2oxDohiyRz2pTFuxLMhdOwdw/QNRLqjETF15mcz0GefHcVjD7yH/staAw9uB9FPHw6g32/EcrbP5nEemTPRF2qp4jlrcizOR5JNS2MsZU5uwGnXHgvbcCCM7dDcOg/sOEtiY3OfMot/wcIAkO3KUxMMo483FEQfr5ZHX2iY5ZmxcqzN83iPchm8cNPlKz159B0o27Xl38Fe/fHrwTaCqAnpOX4E7KE+jCkymsAYBKMDxwqf4zGMMXDl4svBbh5A/Uj2+FGw80zTk7exXXQNh4ac6znh90vTxo9PcTpK5pnwxKRwaQB4LAxPnA/P2dAqHsKANCbECISd/hSO4DMV1TB3RySEz2d1FerH0qOoGclptWB78tK4dB6WhddtWcXjfPAYMobBy/m5xg8EUSqGSNnwGCU8roSLvMJ+GNBxMMizmEKWjvqEbB41Hn4f00oQ3rMTPScLn1Mj+AxZY2ibBvYHk52rbwDH/0gty+XVjLE8AiHneEmei4vdf8XOpRtcT8Z0NAYeL9GLY8sp1/gwe95CKOOxO4pqPnI8QND4yJsPQRAEQRAqikw+BEEQBEGoKDPO7RLHlZNUX4Ov2Rrn46uvKuaeoKO4vOq5FL6uymtsyZPrlbNh8uVQ+NqVuw/qm/G1bbQB7YY6PLep8PgHDjuvcfN6HMrY20hi0bMpytwsEfZaLsWW9h2KoTvDXOCkm967F90Fg2lsQzOBrqtsFl0ZAfZaN89eKY4msV2MgFO33a/gctfDB3bjudl1BIN4nb5qFp45gA6pLAszP+RaX2eypdP5HqznKy+jndOwL46OoOsjaOG5dBv3b53lLDG+6uM3QFks3AB26MABsN879CrYr766C+vix/DrkfplYOfdzehxk5X3P0ypUN/Fttc84dX5kkIqbvNz8+WubDl0wPX62lbokjvJXl0bCu/nrCZ0CZ44hc9Bjq05DbLllKQ5z4mtWGoGVnGdL0HlofsJ+31JR4oqdsMnBg8NXwzdk5IAf7KCzN1g53CZv1/D59tiMQkGRnGsMauccW64H93ew2P4fM6e2wZ2dQzDNiytRddozkRb+dHOu8PzB9EdrJhL3+Oqtvkzhduf6j8Bdn/PYbCbmpzxPBjCc+d56HZ2/5RrjLUtWWorCIIgCMI0RSYfgiAIgiBUFJl8CIIgCIJQUWac5iPFwkxTEv20gQT66UN+9OP5B9Fvq5votzUtbDLDteQtaKCPcH5sD9hXLEE/vJ+wbtxbpp3Ec2ka1rU95Fyrvxb1BDuP49FsDa/LYkvOfClstywLsXuS1ZWyTl0iLHS7j81pgz7Ui/iCTGfDME2WLnokAfb+t52Q6d3vPI/n8mM9o0HUQjTOmg12NoO+0vdO4PJZP1te6Teda7HyeD9MH0uh3ncQbN3Hlw2iP1pjj+OihcvBvuoj1zrbhjC9d18e961tx2P3nDwO9slDeJ2+APZd28Z7EG5yNCFZi+uecNvSeGKao+lZ2jm+RsCrAeFblLcM2HMm9+GZtmVwCDU53cdwaWUghH2PCNt4bBS1T6EI+to1zT1WsaWzfCllCV2GzbRP/Dr50ky3637Sl9ryUN8eHY5je1LB874SRp1FlC2HHWNL7ftZ3w3X4fhe7dLZHO0+DGWzWi8Au6ENw6Mb7Hn25XDZb/LUSbDTKdQAVbuWaptcR8WXs7MbmLdx7Bk8iaHcB5g+qbZpFtiROse2bN47WN8pqtkpQ89zxlsKgiAIgiBMAjL5EARBEAShosjkQxAEQRCEijLjNB9+Df2o+0fQ5zeyFX1fVgb9sJaBa6/TC9Gvp1gq45zLL6vZGMr9whimVL5iDtqajfqEtA91GsEsS3vP1vrnXaGGB9KoTdjZPYcQDO0dsNGHGE2z8Os6+p9H+lEzkD7paEjsHM5hRxW2eZzFTjAzLFQ0qyn3Z8eqMfT3/pNOmPEA68EhFsK4be7FYC9esgrsTArPPrh5E9jJ5DGwQwGnfygWyt3KYd/jMQp0dMuSxeJCLLhwKdgfu/o6sFXQifPRm8L7NeRDf/OYH+OVxJdfDXbq6CtgD5xgod5HXgZ7vksDFKpH37ftCTpQAo3rFXisjvE1H8XKiLzxLbxxPjyVKWpi+gWmg6lBv7kZwnDpqQzqy1IpvO7ECGqG4lH+JDjb5/NYsUyexb8olXqe+em5W5+HdnfH+Tjbmg8uIbBdY5MnTDjbd0xjsTOCGHvDZiKRqiocJ20WxjyXdTQjSy7/OJSZTLtms5/PPNOmnTqFGqBTfZjiIBZl96zG0QjZfrxurqTIZple0EL9UaIf9SUN9RjHp7YRn+Gc67elVByWYo9QOV1F3nwIgiAIglBRZPIhCIIgCEJFkcmHIAiCIAgVZcZpPloDqKt4uw51GEeZn62G4mAnWarqk36WS97E+ZphOPqGCIvzUBPCY+mEPmDL4H5bphHQ+dpu5rd1fc6yevPcLnmWN2I4gP7mrIH7z2ZxQFpY3pqetHOt6QCW+VhugGyQ6W5MbAfc2utzNFlckOZWR4cz0ov1rK1Dv3vbRSvw4BFMYx1GNy7Vt+wBe3gYcyKYru6TZVqWvIV2LovX7fOhf1mxNNmGH3UbOQ0rN5RxrnXYRB0M99KOMV1FIDYf7MY2bLfhYdSfDPRiTJr9bzgXvuBS9LNH6tAuBY/N4c1zz033F8W35bE4eO6XEhIPr6bEpT9QrE0tHt8mwDQBY6gn6x/EsaT7eC/YrS0Ys0JznS+Vwn2HhtHHP3tOE9uXEKZ9KKnjgPKzm9ulWJwPbw4bfn+ZFsaHbegV8TDT8ww6fTkaYDlO0jhmJnoxVs7IqUNgp5kGJBJEHZbfwOMnk07cDz8bM1MpvN+ajgP8yHAK7FB1C9jxZtQA8ug3PldfY92cVBlCDktyuwiCIAiCMF2RyYcgCIIgCBWl7MnHSy+9RDfccAO1tLSQpmn01FNPQblSiu6//36aNWsWhUIh6uzspAMsvbcgCIIgCOcvZWs+UqkUXXLJJfSFL3yBbr75Zk/53/7t39J3v/td+ud//mdqb2+n++67j6699lrau3cvBYPB0xxxcgmw2BlWP8YvWLoQ1+bPa0SNwEtHMQ5IRkdfq8a0Ee64IvEAbhsx0A/nI/Sr53Vsfo9vjbureblr/xzTH2Rs1BdYGtNlKMyB4B9DbUxtDut+QRP6UiPVTjsGY1jmr8c29UWxvKkK/dMYcYK8C/+Z3qR90RWFz6N1uF69KoZ+d4PVLZXDRj353mG0B1Hj4feh79WynHbKW9jGLGQAKeaXHRhl+XGYf3TXK6+CbUTw2hZc4cT9yLC+47exnjb7vyKtsA2jEYyHMGdRB9jZTD/Ymbyj07Es1Oxo2pn7ef97h/K2L3Yo4noBfir+/1WpXC9cj+Aq4XoBFt8km8ENRlL4DPGrPnECYzHkc4vB9hnOHnkL9WRppj8oFZuB49FZeMrH33ayKabr4PFHdHY/da4X4vePxTux2f3n+7vvqc1iqaQG8bchN3gY7LAPjxVvqgPbZ6DOyjMmu7RyJ/tYHqDhBJ6bjWO2gXGc5rZcCLZmsDxhrJ0M3Rm8eJuVio3jvn+qDM1H2ZOP6667jq677rrTliml6KGHHqK/+Iu/oBtvvJGIiP7lX/6Fmpqa6KmnnqLPfvaz5Z5OEARBEIQZxqRqPg4dOkQ9PT3U2dlZ+C4Wi9Hq1atp69atp90nk8lQMpmEP0EQBEEQZi6TOvno6Xk/jW9TE75Wb2pqKpRxNm7cSLFYrPA3Zw4PCy4IgiAIwkxiyuN8bNiwgdavX1+wk8nkhCYgRzLo4z/eMwj2vEZ0zF9y2UKwY7345sWXRr9cnvsIXXEEqgLo0w/70DdOGo/rwfyVBvOXmdzJjHVx++ly3P+sMwGCif5GQ6H+JsVc4X0BXJPex/QL13Z+tPC5rq4ZyiwTzx2fjWvO+0dQb+IJ88B8jD7ucww5a/HDs1huB3as7Bj6xt/c9lOw331zN9iZUfTDx0N48tGMo63QQ9hG0TA+TgE/7jtms1gNQ9gOeZbro2vn83i8+tmFzw0LP4L7svtnMN+2yXIe5Vg8jEANPgdtl/0h2JrmXFs4Wg9l5aztJ5rsqBHFD84VAZ5z80eMb+/WfLCEKLkc6mxiUfTxJ5Kom9F0jNXQ358A+9QpHKviUSeOiG3huTIsb4yn45cJ113A4SZ4bA7XcXh1O47N43rwvE86DxnDbzDfn/+/rXPNh2OPDuP9UKn3wI76mW6CjZnBKMbiMXQs10wcg5Ou5//ECcwLk88znRWL2zRnIcYvilbHcXueT8mjjRq/zbnNcZeXo/mY1Dcfzc3v/wj19mLwnN7e3kIZJxAIUHV1NfwJgiAIgjBzmdTJR3t7OzU3N9PmzZsL3yWTSdq+fTt1dHQU2VMQBEEQhPOFst0uIyMj9M47TljZQ4cO0Z49e6i2tpba2tro7rvvpr/+67+mhQsXFpbatrS00E033TSZ9RYEQRAE4Ryl7MnHrl276OMf/3jB/q1eY82aNfTYY4/RV77yFUqlUvTFL36REokEffjDH6ZnnnmmIjE+iIgGdfS7GgHUgERjqBHIshaobUXfWfAQ+vXGWBwR5crPUh1GH2GIaTwsxXNgML88y89isZgiZLPcAK58DVkW12OY5YUxmLBCZ/7rpI7XlWrAdstEUYfzkwPOmvfgUdTJROoxlsoFGubASA2i+DiyFEyvD9jG/W1Xuc5iTAR1jIfQd/RdsHdt3wL2MIvrMauuAc/FtDFts5x2CTIxSs8A5hXysfgkrXG8/1oK2zyHVaf8GPanF37+48Ln1Z14v+csuAyPbZR4tJnP1yI8XlV8Htju3mLZWNGJCsdKxuoY5/P7X7C4Dp5jlzi351zj+8YNngdEoZ3Po64mn2Zxf1ACQIcPJsA+9C7mBsllnLhAe985CGXz5mKcFp3dP00xm6lZylFxTK7ig8g0WcwJpk9zl5tMq2YauK1u4A3UeYwK3rdYXbidzzptnhk6CmVhk8XSYc+YL4B1C7PfvNEc9q2DhzFuyNGjx51j5/EZqw7j2B+I4aKO+ib83TKZ7s4TIkrn96BIbJUS+XTc5bZdKo6Oq45nvOV/c/XVVxcNaKNpGn3zm9+kb37zm+UeWhAEQRCE8wDJ7SIIgiAIQkWRyYcgCIIgCBVlyuN8TD7o67p42cVgr7wMffp+k60DN/k6ZeYzZOuYI6bjt28J4VrsIMuBoSs8VpDFWiAb/ZuaQh9jTmfHcx3OYv7oPPMvmha30aeYyWHemVffeh3sNEtcsqDFiTnR3tqOxzrJtArP/yfYRxOo+Vjzv/+YimFzh6XL6xc08Lqzg+gbf+uVn4MdNPG6my+YB3ZTLcawmNeCWpf2Jqf/DDGNR8ZEu2cI28FIHQPbT6yvBcJoslAtR7vfKnze8uQ/QtlNt/1PsBvmLgM7y+JE8JgzGtMf2RaPUeP0H086jYkygcAf3KfvqRrTZfCulM5gbJV8FtvJfa1WDjUcw2Oo2cn6WRyHEGp8TB/Gdclk8XhRFheibckC59hYbY9fnnvCeQ4UUtjXbLaDJ56GS1vBzzVR/D7UQmn83C6dB9d4mDwGhcFjUpSn+eBxQ9LDTj4eXWGrByNxsEdHMY4LqyodOnQc7ANH0U6z/lTlev6jtTEos2zUj8ydfwnY1TEct4iwH7NmgRhRRBgHxBvno4QGxFVuW2c+pZA3H4IgCIIgVBSZfAiCIAiCUFFk8iEIgiAIQkWZgZoP9PGOjqJf9t2DqAmYMxdjUgwPoyYgb2G8C43Qr1utO3675ij6j/1h5hNmMSl0Dc8VYH55xfzuOcU9v3GnnlnUC2g5lmeAtYuWxrr4fOhT1H3oEwwlUc/w2VlOLpDVc1GrkvdVgf0LlD7Qu30YW4PDl3IrDdvV7YLWWNlbe18Gu/fYHrAXzML7PX8e5jSZ1dQKdpBdSzbj1M3Htl3chqkBwscPg/3ar/4dj8XyM0SjeK5cBvtPkJxrHTm1H8qOHNgFdsNs1OHYGt4jnf3foTNtBDHNANyRCUoAeJyAyUSxOAO8Lxks/kFqBLVOQ4PYWTXX/tk03o/+k/hMDI+xNg2iH35s9AjY2Qw+z2NjKbAbXLF2Fi9eBGXHj+EzxK/TK5PiX/Dti/v1JxOfJ84H13w4NtdkeGyDaxfGzxND5NWA8DghySFHxzE2hrl4IuFasPM53Pfd91DT9V4/3k/NwDG5Jopjrt8VNyQYRs1HvBnvf0MLjj08dwux591g5SZ//l3t6u0LrA15ehxXuTLOvN/Imw9BEARBECqKTD4EQRAEQagoMvkQBEEQBKGizDzNB/P5vnsAfeOtJvqvolH0u+dyqJ1gIfApb6AOozri6DQWLpwHZY0xnNuN8DXQGp473Yc+xlM9mOvhWH8vHm/Q8eu9sh+vu68H16CP2ljvbGII7IULMTdA7CL0pR7e0QX2UM65lncH0G/ut9GXvbgB8+1suOvLYJ+k4vAYFJrmnDubxTa2CP2o8xfheviFzReAHa9BDYjlw/s/6sPYC6YrDojmR41H1EDNTvAk+vjNAPp8ozVxsDWWb4f7wuOutf8RFtGi5/gbYCcGV4AdbkRtCwv74JFxTHYoj2JwP3yxs5dSi3hiEPBy5rBuaEBdRn1dnO3v1GVwAHMY9Qzi/T41ij7+KparycdiCuVZnI90Fp9Ry9UffEzbUBXGfEdcC1EkA8b75cWLYYtSxyoXn4/rj/Auma4YFBrTEGisHfh1l9J8ePsH0wgOO+NiyI/n8rG6DA7h/Uum8VjBID7vfLxXPB+PKxdUdTVqOubOQ82H6WfHsvlNYtoYrvnQxm83Txt64nywM7nKDVPifAiCIAiCME2RyYcgCIIgCBVlxrldDIVLLy+8AN0Jly7DJUwXX4bh1w/8ElOw8zznfvaqrNa1EreuFl+VUbgRTDOPr2l/swvDLf/4qTfBjgWxrqlhXOp3uNtxERwcxWVgoyydc1pH24jja9vDLM29L3EK7CwLHfz/RpxX0A1RTO9dH8G6XNCCr1ljEXTDlETh/soVhl5jrzKXXvJJsE0bl0NqWXyFmDPRzWJGcGm17cflryOuVOX5Mbx/J9/F5a77u34JdkjH17RGCI+tWBpt3cBrMwLOddt+7m5Cl11/zz6w5zXOw+01vP+T/Wq9OHxZLzM9yyPHhy8p1aj4a3WbLylmNn+lPJp0nrndO3ZA2f5uXJZrEfbrUBU+rwG2zLe+Bp+TwWHsTyNpxw0TYCHJw0G0eb2Vp9HY0soSMfJteI0/uZ3DZ3K3C+J2uxB3u5RYestdBF63C94DZeMz527XoI3PyPAQPmO6n7tNmOsri+3Gw6nnbaxbTV1T4fOFiy+HsmAVC7eusN6ee6SwbjxEPnfDgNuFHZm3Oe9r7n1NQ9wugiAIgiBMU2TyIQiCIAhCRZHJhyAIgiAIFWXGaT6UicsfjxGGmX58Vx/Y9q7tYI9puPQuXMt1G+ivnBVzfIQBHZec5vPoh8vmUV+w8zXUVWzdjctf5zegDziRwKV+g6OOZmDMj0tC7RTzZYbYctUAbj+SwWVh4TzaoSq25DTsXHdimOlD0qi76evHdknuRF/5jYs+S8Xwhg52rkXxZWBVDWxbpi8pkkqaiCjLxA82XwboMk8dfwfK3tqJGg8jg+0SDOH9D1ejvsSwWMr2BOpVDM2pu+XDR9fOYxsffvsVsJtaLgW7qm4+2BnWjgZfi1vE7c9De09nSi3q5f2h96izXPrYa9ugLDGAS2PHAjjWpAL4PGtJfC5IR03BWBqPZ7v6g8nCgFdVoV6o3HDonltWwVsYYLoArstwh0z3LI0tsXS21Pbc5pcdDDnaODXCl76z1Bs5XFqt2yxlhZ/Vlf3c5pkwZ277ssLnunr8HcoxvaBGqPnh4qdSuqlyUhyUalM3ebYUuuhxz3hLQRAEQRCESUAmH4IgCIIgVBSZfAiCIAiCUFFmnObD9rM4DY2o2Rjg6dmJ+WEVNompMy2EiX7c+hqXn9bClMojI7jOf0yfA3aahcRNEZ7r2CjWpaoe42n4dSdOgGGh1iGALkKyMu+BbWS6cYMxDMdus3Xkpg/90/kx59pqQ6hNSZ04DnYiidoFfxSPVT6udmPxCrgPN6+4D7JEavFi5yIi0+X3TSYwJoxtY99oaMC1+Q0tGNp94fIPgX3iBIbP3/3rF8HWdafNw1zrwmKGJEcTYO97HY+1rCMONvnxObFZu+g8Nsc0xeuP5gEwWFwPpvEYy7DxIOBoyGrnLYOiIR8+M91vYb/PhDAuhJVGXc6pQSxf2M5iObhStmfSqAcqx2d/OrhOx2J6BTzZhE7lgYdX51RS86Gz1POBgDM2HT+Kz3MkgtsGeUj7COriMqxJM0Fs85bZS8BeuGipUy92bH+JNvPcolKxcor0n5Ih6YtpPvI8/sj4yJsPQRAEQRAqikw+BEEQBEGoKDL5EARBEAShosw4zYfXl8VyAfBLZj5fm+1v6+gjzmvoe83lHHGFPcoUBxmmJ/CjBsRnYNyO1MDbeOxjeC6bxfKwqh1/dMO8K6GsNoAxJU68txPsoI2J7P3M1x0gFnOAtcuQa427GsV6qmH0badOoW/8WA/zq59FNE8Oi/Ic2Dzde9aVnyEQwrX28y68COzGeBzsC5dgmnsthrmA6iMYe6MdpTR06PWXCp9VDgt9TJsUYdm8e7q78FyteK6WBR8HW022o98N90czHYYnJoFLd+O9nzynBdOqaKWOjeXZDPblrCveSeuFi6EsH8A4LpaBMYYGTr6FdgrvWWsb6mzaZzeDPTbqnPudQxhTZlYTxoEoN84Hh8f9cPv1Fc+HM0G45oPrTyam+eCajvJywzQ1OvdgfxferxwOiVTFnv+szYR27LenpQXjwCy9GMfsqojTfywW16NULJ1S2pZS2xcr423qibvkIpcrrk2B457xloIgCIIgCJOATD4EQRAEQagoZU0+Nm7cSFdccQVFo1FqbGykm266ifbtw9Td6XSa1q5dS3V1dRSJROiWW26h3t7ecY4oCIIgCML5RlmajxdffJHWrl1LV1xxBeXzefra175Gn/zkJ2nv3r2FXAP33HMP/fznP6dNmzZRLBajdevW0c0330y//vWvz8oFeMHF1Rqx9fEsfgV3pelc88HsTB51Fz3HnfnbWDv6RquNWrDzeYzFoNkYF4AI6zZqsHXkzL8diTixPfQoxhDJjWHegeAY5lOJ2yyuh83iH/jw3NYYtqs+6jhAMz7c1xrFc/uZX7Vl9myqGBPOWcF0O5rzyNQ1LIKycAj98A31TWBbvhawE8MYgyTH8rVcsPxjYGfTjmao+62XoIxYOJNAENs8yDQiB9/8Dda1Ca8lGMW6u7vHRFO5lFKTaLzN3ZqPImVE5InjwWHua09dYlF8vmPVjp0bRS1TNIhxOfwG1qWvHo/e0IqakeypN8G+YD7G8WmqdZ5vH8vNZGostw97fktpI3i/5poCd7vyY08Uo0T+D91VbpbQaHDpArf1ErmcDJPXxRmD4zUsHpHNhTGoy7BYXI857ZeBvfTiVWBHo9h/lOv4/DpLaj48X5Sp+dDcH3lOGx4rZ3x9iWme+ZSirMnHM888A/Zjjz1GjY2N1NXVRR/96EdpaGiIfvCDH9Djjz9O11xzDRERPfroo7RkyRLatm0bXXnllac7rCAIgiAI5xET0nwMDb0fAa629v3/8Lu6uiiXy1FnZ2dhm8WLF1NbWxtt3br1tMfIZDKUTCbhTxAEQRCEmcsHnnzYtk133303XXXVVbRs2fthh3t6esjv91OcLTFsamqinp6e0x5n48aNFIvFCn9z5sw57XaCIAiCIMwMPnCcj7Vr19Ibb7xBL7/88oQqsGHDBlq/fn3BTiaTE5uAMKcuc0+RUtxXytaJM++ZxXyEeR11Gz09jt2fwHXf1VH0ldoWxrfIZdFnqFlRrGwA/ZEmWx8fCMYLn9M+jOuRzqLGw9DQX63l0UFpM98nj9DPY3lUuaoejuB1+5l24YZPXAf2pb/7SbB3FUkrMd3QjWDhc87A+2WFWd+qZhoPG4NvKO77Zq5128Q8RQsuvbrweSyNGo6TPW+AHc3h/aoOoJYhmewD+8jbmPvlwstvwMpo7rpXOM+L+5GcYE6TknDtg0tDwk/tYz7/lghuEI/g/evGR5KODOD9HxnDQBKn3nyt8Ll/CO/X4kWYZ8aj2SjRTjx3j+YN9OH6OLmLIrnmo5g+hWsfuM3lCN4wT/iFP4A6DiuDbX7y+KHC5xGWH8k0cF/eLIEq1Pgtv5TFXqrFuC65LD6j7lcB/H6W0nyUizcuiNvgfYnpbIjrbiqg+fgt69ato6effppeeuklam11AiU1NzdTNpulRCIBbz96e3upubn5NEciCgQCFAgETlsmCIIgCMLMo6wprVKK1q1bR08++SRt2bKF2tsxYtuKFSvI5/PR5s2bC9/t27ePjh49Sh0dHZNTY0EQBEEQzmnKevOxdu1aevzxx+mnP/0pRaPRgo4jFotRKBSiWCxGd9xxB61fv55qa2upurqavvzlL1NHR4esdBEEQRAEgYjKnHw88sgjRER09dVXw/ePPvoofe5znyMiom9/+9uk6zrdcsstlMlk6Nprr6Xvfe97k1LZScHjO+NxArhmhOV6MNHP25t2dBhv9aJPzyL006ZpGOzRPPrOwyHmQ54dBzsYQr1JznTqOqyzxAMG13CgXsSdk4aIiGcl8LP9eXyErMtf6bfRF1ptogZk8fyFYF84H/OK7NpPlaOU67SEpMB9x3xVqPmwLZbrgWs6dJbDwmaxU1iwjrzCF5NmlRP34aLV10LZK9tRA5J4D/MENQbx/ocNPHfPod1g189GTUH9rAsLn3NMo6OKh22YMO78Op64HmXi2ZvH+fFoJxybvyY2WUyheBDLZwWwM6V6MJ/S/r5jaNMA2KMJ555GatE17c1pUtzmKIvFBeFaOVc7TLbKhud24RTTfPA4TJ5cLvyyWflwAu9Bfzfm3xkeOFL4rJmYq8diMaJyGTz2BUsxt1NNTR3YvB2L5bjhsVXK1XyU0gBNRPOha+Nrds6a5uNMGiAYDNLDDz9MDz/8cDmHFgRBEAThPEFyuwiCIAiCUFFk8iEIgiAIQkX5wHE+pi3cNcRsvr6db24zf5eeR7+crtCxe9K19vvHe3Fdf807aIeZj3jfYdb8viNgVtVg7P/hwSHc3nB8wqFarGeW1dNg/kt/gAUd4DlxSviQ3TFH8jn0hXanUNvyf/9jE9gX9uF1xq+8C89dwj85EWyen4FR6tzu3QNB1OAECGOt8DQjGtcTeU7O/PAsL5Hl2sHHYogsvfx6sF9JsZgR/e+AHQujPkVL47kPv74F7Npqpy/rAcz7ki/TH60Rv87JjWFQDrxneeICuevG84Yw37fPRF2GoWNcnzGW82j5wnlgr1yGWiif63yDaYz8HPLjudiwRVqJfm7wWA38/1DljAfWJId1MTz/8o4/1hgeTUcpu/j/0zZLwBJkui0z5MTqsPI4RvoDTDcVw3hUCxdhLpcgjynCzl1M18Gvo5Tkody4IDxGiXuc48+Ed0wcP84Hvx/FkDcfgiAIgiBUFJl8CIIgCIJQUWTyIQiCIAhCRZl5mg/mR+NyAd3jXy7uG/OxYh+LiJE2nQ0OqziUncziOu86VpekxjL4Vi/A7ds/jMVN/WAf7Xc0ICkqnjckw/QDAXYdpg/noT4WkyLHBAya3+k6wSjLG5JADcgLr+0B+7lX0f4603ycuzBfaCktxAS0LMx9TNW188C+5AqMA7LnV6jDSY1ivINwAOue7MH4Bye7nTwjzQs/gnVh+qLSTJ3GYyJwXzfPUZJl4og8E2KkWS6n1gbMBRKtRs1QbtTR7VglhBc8bofyCiuwnMc34Ru4rlUpHgVoYnAdh6cuRTQE3C6l0eLaicYm1Eqpptlgh2NOrKZg5BVWT/y5bJ3PYuE04LHLrRvXgEwEjSs3PKIgpm10bc739WjuuAl5gETzIQiCIAjCNEUmH4IgCIIgVBSZfAiCIAiCUFFmnObDtlBvoOvlXaLXZ8X8cMx1ZliO39dkfle/gb5Sw8DyYBXqNPxhXBdexWL/18zFOABU78T5OHgK4zbYKZZXwmYJOELoX7bzqAlRLO8Mj38wnHeuzWfgdazo+CjYS5dfDHZDQz3YCTqHKOrSnNz8C+WQs/H+1zQvAXv5qk+B/dpvngZ7lGlAqqPY944feb3w2V8zF7dtWVxeZT1OY2Z6mmF6aER0ncX1YM9nivns83k+duD/euEqltuD6bCUcvvScRzz+PRL4I37UDwuhGFo45ZNFK/WAcvxOShP41HKVjy2Bjt+06x5hc91jRjHQ7HYKT4f9geb5Wri25d6vicznpHiz0yxXC78i5JStfHjfJTTL+XNhyAIgiAIFUUmH4IgCIIgVBSZfAiCIAiCUFFmnOYjx/1sPI9ECZeUzsQNOk/QwXyGhivggpnH5mQqC7JZXWobUfsQMjEXRMDPYopkMS5ILtVX+FxlY6yNYA3qMALzF6GdxrwxUZa3wLRRAzI2nADb3Uos5AQtuXQl2J/+zI1g8/QLT3cV940qfg/GrclpcnUU2fN0lNoefJp87Xy5J+N5RDy+9fGvzevBx215bp/GuZh3YtHYKNh7u/4L7EwO85BkRhy7/1QflMVmo76kNCXyVJRROIlu8t8e8YyLdJPFxmEagEyG9WuFz1QVy8/CT+Aeivh/iR6fPo+d4dmen8qT3IOZ7lgbk/s/qsG0M5o2/vPPY4J4YmVMUAPC8wop29EMmiyOC0vl49F4eOJj8HQ5Hvng+J2Zl5U7rnl6cZHYHHwDT66lEnoR3P7MB0F58yEIgiAIQkWRyYcgCIIgCBVlxrlddJVhNrtExdMYY7Gm+HyMv2Nir9os5/gGf+Vk474WejYoHMKU7LG5uLTLZ+AOPj8e78Ja53xVAQzlHgujS6c6Ng/PbeAr4IjJlvJl8bW7yo6A7XctxctkcXlzXX0N2MSXHOqlXs3xZYDjvwrnr2y5+6EUxR0dxfeY8ArEUkvaeDsUSXutE94DxR7tMeaWm72wA+xMBvtDf/c+sFsXLC98rm7Bpbb5PJ67NONf1/v2+Jvzp9PrjphITU7XNV2vwnlfYyc32Wv5RI4vvcc2jodweTQ/oOVyaJr8lT4Ln87bzPtKn5WXsN1w98JEMVjddfYgud08E11aW3p5K1826nzmzzcfW3iod+94wP107LdDje/OKHWsUi7aiSyP1g0uGOAU6VvcFV3sPGe8pSAIgiAIwiQgkw9BEARBECqKTD4EQRAEQagoM07zceD/XDXVVRAE4TzAuwQV/e7psTGw/QHUeAQCuBza8gjQxj8XD/XOKeXz9yzFLaJvKDeUeyUpqW3whFNHJjOkeUlKhLgvvmt5Gg5vuILJO1exch5Svhjy5kMQBEEQhIoikw9BEARBECqKTD4EQRAEQagoM07zIQiCcDbwqAM88SlYiPssxvUIBlHjweNdWEyf4NZamCwOjzctfbEUBF48Gg9ul4zF88G54Ybrz9qxhXMHefMhCIIgCEJFKWvy8cgjj9Dy5cupurqaqqurqaOjg37xi18UytPpNK1du5bq6uooEonQLbfcQr29vZNeaUEQBEEQzl3Kmny0trbSgw8+SF1dXbRr1y665ppr6MYbb6Q333yTiIjuuece+tnPfkabNm2iF198kY4fP04333zzWam4IAiCIAjnJmVpPm644QawH3jgAXrkkUdo27Zt1NraSj/4wQ/o8ccfp2uuuYaIiB599FFasmQJbdu2ja688srJq7UgCDMHFhugSLZvni6JeKwETWPah1JhHDy5KNjx3Pk3WD3t/CjYlpUGO5/DnDfBEOZqsnmuDwvrbrvqwq9b57leSgTu0ErkIeF5a9waklzZuXsEoTQfWPNhWRY98cQTlEqlqKOjg7q6uiiXy1FnZ2dhm8WLF1NbWxtt3bp13ONkMhlKJpPwJwiCIAjCzKXsycfrr79OkUiEAoEA3XnnnfTkk0/SRRddRD09PeT3+ykej8P2TU1N1NPTM+7xNm7cSLFYrPA3Z86ccbcVBEEQBOHcp+zJx6JFi2jPnj20fft2+tKXvkRr1qyhvXv3fuAKbNiwgYaGhgp/3d3dH/hYgiAIgiBMf8qO8+H3+2nBggVERLRixQrauXMnfec736HPfOYzlM1mKZFIwNuP3t5eam5uHvd4gUCAAoFA+TUXBOG8h0e3KJ7xhMiTT8OTp8Iet5znODE0PBsL60Eqh8cOR3F7S+XZDux/QeWuC9NwEKNEPg5vfhZPMhesm+XoUWyrvBgignAmTDjOh23blMlkaMWKFeTz+Wjz5s2Fsn379tHRo0epo6NjoqcRBEEQBGGGUNabjw0bNtB1111HbW1tNDw8TI8//ji98MIL9Oyzz1IsFqM77riD1q9fT7W1tVRdXU1f/vKXqaOjQ1a6CIIgCIJQoKzJR19fH91+++104sQJisVitHz5cnr22Wfpd37nd4iI6Nvf/jbpuk633HILZTIZuvbaa+l73/teWRUqN3WwIAjnFmMjxVe0Gdr4tu5ZU4ouAZ1w+aruWaLKl9KyEOnseJpreS0suyWisdQI2OkxXHqbyeDS20wa3S5jo8ydkWfHz7mWu2YzUGawuvDw6xwejj1fIvW55mqHzFi6yJaC4OVMfsc1Nc1+7d977z1Z8SIIgiAI5yjd3d3U2tpadJtpN/mwbZuOHz9OSilqa2uj7u5uqq6unupqnTMkk0maM2eOtFsZSJt9MKTdykfa7IMh7VY+U9FmSikaHh6mlpYWz9s2zrTLaqvrOrW2thaCjf02j4xQHtJu5SNt9sGQdisfabMPhrRb+VS6zWKx2BltJ1ltBUEQBEGoKDL5EARBEAShokzbyUcgEKC//Mu/lABkZSLtVj7SZh8MabfykTb7YEi7lc90b7NpJzgVBEEQBGFmM23ffAiCIAiCMDORyYcgCIIgCBVFJh+CIAiCIFQUmXwIgiAIglBRpu3k4+GHH6Z58+ZRMBik1atX044dO6a6StOGjRs30hVXXEHRaJQaGxvppptuon379sE26XSa1q5dS3V1dRSJROiWW26h3t7eKarx9OPBBx8kTdPo7rvvLnwnbXZ6jh07Rn/0R39EdXV1FAqF6OKLL6Zdu3YVypVSdP/999OsWbMoFApRZ2cnHThwYAprPLVYlkX33Xcftbe3UygUovnz59Nf/dVfQb4LaTOil156iW644QZqaWkhTdPoqaeegvIzaaOBgQG67bbbqLq6muLxON1xxx00MoI5d2Yaxdotl8vRvffeSxdffDFVVVVRS0sL3X777XT8+HE4xrRoNzUNeeKJJ5Tf71f/9E//pN588031J3/yJyoej6ve3t6prtq04Nprr1WPPvqoeuONN9SePXvU7/7u76q2tjY1MjJS2ObOO+9Uc+bMUZs3b1a7du1SV155pfrQhz40hbWePuzYsUPNmzdPLV++XN11112F76XNvAwMDKi5c+eqz33uc2r79u3q4MGD6tlnn1XvvPNOYZsHH3xQxWIx9dRTT6lXX31VffrTn1bt7e1qbGxsCms+dTzwwAOqrq5OPf300+rQoUNq06ZNKhKJqO985zuFbaTNlPrP//xP9fWvf1395Cc/UUSknnzySSg/kzb61Kc+pS655BK1bds29atf/UotWLBA3XrrrRW+kspSrN0SiYTq7OxUP/rRj9Tbb7+ttm7dqlatWqVWrFgBx5gO7TYtJx+rVq1Sa9euLdiWZamWlha1cePGKazV9KWvr08RkXrxxReVUu93QJ/PpzZt2lTY5q233lJEpLZu3TpV1ZwWDA8Pq4ULF6rnnntOfexjHytMPqTNTs+9996rPvzhD49bbtu2am5uVn/3d39X+C6RSKhAIKD+7d/+rRJVnHZcf/316gtf+AJ8d/PNN6vbbrtNKSVtdjr4j+iZtNHevXsVEamdO3cWtvnFL36hNE1Tx44dq1jdp5LTTdo4O3bsUESkjhw5opSaPu027dwu2WyWurq6qLOzs/CdruvU2dlJW7duncKaTV+GhoaIiKi2tpaIiLq6uiiXy0EbLl68mNra2s77Nly7di1df/310DZE0mbj8R//8R+0cuVK+v3f/31qbGykyy67jP7xH/+xUH7o0CHq6emBdovFYrR69erztt0+9KEP0ebNm2n//v1ERPTqq6/Syy+/TNdddx0RSZudCWfSRlu3bqV4PE4rV64sbNPZ2Um6rtP27dsrXufpytDQEGmaRvF4nIimT7tNu8Ry/f39ZFkWNTU1wfdNTU309ttvT1Gtpi+2bdPdd99NV111FS1btoyIiHp6esjv9xc6229pamqinp6eKajl9OCJJ56gV155hXbu3OkpkzY7PQcPHqRHHnmE1q9fT1/72tdo586d9Gd/9mfk9/tpzZo1hbY53fN6vrbbV7/6VUomk7R48WIyDIMsy6IHHniAbrvtNiIiabMz4EzaqKenhxobG6HcNE2qra2Vdvxv0uk03XvvvXTrrbcWkstNl3abdpMPoTzWrl1Lb7zxBr388stTXZVpTXd3N91111303HPPUTAYnOrqnDPYtk0rV66kv/mbvyEiossuu4zeeOMN+v73v09r1qyZ4tpNT3784x/TD3/4Q3r88cdp6dKltGfPHrr77ruppaVF2kyoGLlcjv7gD/6AlFL0yCOPTHV1PEw7t0t9fT0ZhuFZZdDb20vNzc1TVKvpybp16+jpp5+m559/nlpbWwvfNzc3UzabpUQiAdufz23Y1dVFfX19dPnll5NpmmSaJr344ov03e9+l0zTpKamJmmz0zBr1iy66KKL4LslS5bQ0aNHiYgKbSPPq8Of//mf01e/+lX67Gc/SxdffDH98R//Md1zzz20ceNGIpI2OxPOpI2am5upr68PyvP5PA0MDJz37fjbiceRI0foueeeK7z1IJo+7TbtJh9+v59WrFhBmzdvLnxn2zZt3ryZOjo6prBm0welFK1bt46efPJJ2rJlC7W3t0P5ihUryOfzQRvu27ePjh49et624Sc+8Ql6/fXXac+ePYW/lStX0m233Vb4LG3m5aqrrvIs496/fz/NnTuXiIja29upubkZ2i2ZTNL27dvP23YbHR0lXceh1TAMsm2biKTNzoQzaaOOjg5KJBLU1dVV2GbLli1k2zatXr264nWeLvx24nHgwAH65S9/SXV1dVA+bdqtYtLWMnjiiSdUIBBQjz32mNq7d6/64he/qOLxuOrp6Znqqk0LvvSlL6lYLKZeeOEFdeLEicLf6OhoYZs777xTtbW1qS1btqhdu3apjo4O1dHRMYW1nn64V7soJW12Onbs2KFM01QPPPCAOnDggPrhD3+owuGw+td//dfCNg8++KCKx+Pqpz/9qXrttdfUjTfeeN4tG3WzZs0aNXv27MJS25/85Ceqvr5efeUrXylsI232/sqz3bt3q927dysiUt/61rfU7t27C6syzqSNPvWpT6nLLrtMbd++Xb388stq4cKFM36pbbF2y2az6tOf/rRqbW1Ve/bsgd+HTCZTOMZ0aLdpOflQSqm///u/V21tbcrv96tVq1apbdu2TXWVpg1EdNq/Rx99tLDN2NiY+tM//VNVU1OjwuGw+r3f+z114sSJqav0NIRPPqTNTs/PfvYztWzZMhUIBNTixYvVP/zDP0C5bdvqvvvuU01NTSoQCKhPfOITat++fVNU26knmUyqu+66S7W1talgMKguuOAC9fWvfx0Gf2kzpZ5//vnTjmNr1qxRSp1ZG506dUrdeuutKhKJqOrqavX5z39eDQ8PT8HVVI5i7Xbo0KFxfx+ef/75wjGmQ7tpSrnC7gmCIAiCIJxlpp3mQxAEQRCEmY1MPgRBEARBqCgy+RAEQRAEoaLI5EMQBEEQhIoikw9BEARBECqKTD4EQRAEQagoMvkQBEEQBKGiyORDEARBEISKIpMPQRAEQRAqikw+BEEQBEGoKDL5EARBEAShosjkQxAEQRCEivL/ATBdxyaeHFVzAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rotation labels:  90    180   90    180  \n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat',\n",
    "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "\n",
    "rot_classes = ('0', '90', '180', '270')\n",
    "\n",
    "\n",
    "def imshow(img):\n",
    "    # unnormalize\n",
    "    img = transforms.Normalize((0, 0, 0), (1/0.2023, 1/0.1994, 1/0.2010))(img)\n",
    "    img = transforms.Normalize((-0.4914, -0.4822, -0.4465), (1, 1, 1))(img)\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "dataiter = iter(trainloader)\n",
    "images, rot_images, rot_labels, labels = next(dataiter)\n",
    "\n",
    "# print images and rotated images\n",
    "img_grid = imshow(torchvision.utils.make_grid(images[:4], padding=0))\n",
    "print('Class labels: ', ' '.join(f'{classes[labels[j]]:5s}' for j in range(4)))\n",
    "img_grid = imshow(torchvision.utils.make_grid(rot_images[:4], padding=0))\n",
    "print('Rotation labels: ', ' '.join(f'{rot_classes[rot_labels[j]]:5s}' for j in range(4)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "unCucbHexG4W"
   },
   "source": [
    "# Evaluation code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-02T15:49:50.088155300Z",
     "start_time": "2023-11-02T15:49:50.078122800Z"
    },
    "id": "pptQRpqK0rOl"
   },
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def run_test(net, testloader, criterion, task):\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    avg_test_loss = 0.0\n",
    "    # since we're not training, we don't need to calculate the gradients for our outputs\n",
    "    with torch.no_grad():\n",
    "        for images, images_rotated, labels, cls_labels in testloader:\n",
    "            if task == 'rotation':\n",
    "              images, labels = images_rotated.to(device), labels.to(device)\n",
    "            elif task == 'classification':\n",
    "              images, labels = images.to(device), cls_labels.to(device)\n",
    "            #######################################################################\n",
    "            # TODO: Calculate outputs by running images through the network       #\n",
    "            # The class with the highest energy is what we choose as prediction   #\n",
    "            #######################################################################\n",
    "            # Calculate outputs by running images through the network\n",
    "            outputs = net(images)\n",
    "\n",
    "            # The class with the highest score is what we choose as our prediction\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            #######################################################################\n",
    "            #                           End of your code                          #\n",
    "            #######################################################################\n",
    "            avg_test_loss += criterion(outputs, labels)  / len(testloader)\n",
    "    print('TESTING:')\n",
    "    print(f'Accuracy of the network on the 10000 test images: {100 * correct / total:.2f} %')\n",
    "    print(f'Average loss on the 10000 test images: {avg_test_loss:.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-02T15:49:50.594406Z",
     "start_time": "2023-11-02T15:49:50.591327100Z"
    },
    "id": "hf698c16A9k5"
   },
   "outputs": [],
   "source": [
    "def adjust_learning_rate(optimizer, epoch, init_lr, decay_epochs=30):\n",
    "    \"\"\"Sets the learning rate to the initial LR decayed by 10 every 30 epochs\"\"\"\n",
    "    lr = init_lr * (0.1 ** (epoch // decay_epochs))\n",
    "    for param_group in optimizer.param_groups:\n",
    "        param_group['lr'] = lr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3lYdnb1Wsta_"
   },
   "source": [
    "# Train a ResNet18 on the rotation task (9 points)\n",
    "\n",
    "In this section, we will train a ResNet18 model **from scratch** on the rotation task. The input is a rotated image and the model predicts the rotation label. See the Data Setup section for details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-02T15:49:55.700856700Z",
     "start_time": "2023-11-02T15:49:54.470610600Z"
    },
    "id": "knAiwdURvBHk"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Notice: You should not use pretrained weights from ImageNet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-02T15:49:58.847070100Z",
     "start_time": "2023-11-02T15:49:57.944718200Z"
    },
    "id": "235MEIUgsv65"
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torchvision.models import resnet18\n",
    "\n",
    "net = resnet18(weights = None, num_classes=4) # Do not modify this line.\n",
    "net = net.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-02T15:50:04.193980200Z",
     "start_time": "2023-11-02T15:50:04.185317700Z"
    },
    "id": "Vuhiw0ZoszAd"
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "################################################################################\n",
    "# TODO: Define loss and optmizer functions                                     #\n",
    "# Try any loss or optimizer function and learning rate to get better result    #\n",
    "# hint: torch.nn and torch.optim                                               #\n",
    "################################################################################\n",
    "# Loss and optimizer\n",
    "criterion = nn.CrossEntropyLoss(label_smoothing=0.1)\n",
    "learning_rate = 0.001\n",
    "optimizer = optim.Adam(net.parameters(), lr=learning_rate)\n",
    "################################################################################\n",
    "#                               End of your code                               #\n",
    "################################################################################\n",
    "criterion = criterion.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-02T15:50:05.708537500Z",
     "start_time": "2023-11-02T15:50:05.693344500Z"
    },
    "id": "WleH-YBgs0rq"
   },
   "outputs": [],
   "source": [
    "# Both the self-supervised rotation task and supervised CIFAR10 classification are\n",
    "# trained with the CrossEntropyLoss, so we can use the training loop code.\n",
    "\n",
    "def train(net, criterion, optimizer, num_epochs, decay_epochs, init_lr, task):\n",
    "\n",
    "    for epoch in range(num_epochs):  # loop over the dataset multiple times\n",
    "\n",
    "        running_loss = 0.0\n",
    "        running_correct = 0.0\n",
    "        running_total = 0.0\n",
    "        start_time = time.time()\n",
    "\n",
    "        net.train()\n",
    "\n",
    "        for i, (imgs, imgs_rotated, rotation_label, cls_label) in enumerate(trainloader, 0):\n",
    "            adjust_learning_rate(optimizer, epoch, init_lr, decay_epochs)\n",
    "            ######################################################################################################\n",
    "            # TODO: Set the data to the correct device; Different task will use different inputs and labels      #  \n",
    "            # TODO: Zero the parameter gradients                                                                 #\n",
    "            # TODO: forward + backward + optimize                                                                #\n",
    "            # TODO: Get predicted results                                                                        #\n",
    "            ######################################################################################################\n",
    "            # Set data to the correct device\n",
    "            if task == 'rotation':\n",
    "                inputs, labels = imgs_rotated.to(device), rotation_label.to(device)\n",
    "            elif task == 'classification':\n",
    "                inputs, labels = imgs.to(device), cls_label.to(device)\n",
    "\n",
    "            optimizer.zero_grad()  # Zero the parameter gradients\n",
    "\n",
    "            # Forward + backward + optimize\n",
    "            outputs = net(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # Get predicted results for accuracy calculation\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            ######################################################################################################\n",
    "            #                               End of your code                                                     #\n",
    "            ######################################################################################################\n",
    "\n",
    "            # print statistics\n",
    "            print_freq = 100\n",
    "            running_loss += loss.item()\n",
    "\n",
    "            # calc acc\n",
    "            running_total += labels.size(0)\n",
    "            running_correct += (predicted == labels).sum().item()\n",
    "\n",
    "            if i % print_freq == (print_freq - 1):    # print every 2000 mini-batches\n",
    "                print(f'[{epoch + 1}, {i + 1:5d}] loss: {running_loss / print_freq:.3f} acc: {100*running_correct / running_total:.2f} time: {time.time() - start_time:.2f}')\n",
    "                running_loss, running_correct, running_total = 0.0, 0.0, 0.0\n",
    "                start_time = time.time()\n",
    "        ######################################################################################################\n",
    "        # TODO: Run the run_test() function after each epoch; Set the model to the evaluation mode.          #\n",
    "        ######################################################################################################\n",
    "        # Evaluate the model after each epoch\n",
    "        net.eval()\n",
    "        run_test(net, testloader, criterion, task)\n",
    "        ######################################################################################################\n",
    "        #                               End of your code                                                     #\n",
    "        ######################################################################################################  \n",
    "\n",
    "    print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-02T15:22:09.753158600Z",
     "start_time": "2023-11-02T14:53:56.137263100Z"
    },
    "id": "2u4AsfAKtaQS"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,   100] loss: 1.098 acc: 56.41 time: 8.39\n",
      "[1,   200] loss: 1.085 acc: 57.01 time: 8.80\n",
      "[1,   300] loss: 1.081 acc: 58.02 time: 9.22\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 58.36 %\n",
      "Average loss on the 10000 test images: 1.072\n",
      "[2,   100] loss: 1.058 acc: 59.49 time: 7.70\n",
      "[2,   200] loss: 1.049 acc: 60.07 time: 7.99\n",
      "[2,   300] loss: 1.047 acc: 59.55 time: 8.07\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 62.01 %\n",
      "Average loss on the 10000 test images: 1.011\n",
      "[3,   100] loss: 1.029 acc: 61.00 time: 8.20\n",
      "[3,   200] loss: 1.017 acc: 61.88 time: 8.63\n",
      "[3,   300] loss: 1.022 acc: 61.95 time: 8.72\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 62.54 %\n",
      "Average loss on the 10000 test images: 1.018\n",
      "[4,   100] loss: 1.012 acc: 62.79 time: 9.12\n",
      "[4,   200] loss: 0.998 acc: 63.11 time: 10.51\n",
      "[4,   300] loss: 1.008 acc: 62.76 time: 9.68\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 64.89 %\n",
      "Average loss on the 10000 test images: 0.986\n",
      "[5,   100] loss: 0.987 acc: 63.90 time: 8.15\n",
      "[5,   200] loss: 0.995 acc: 63.55 time: 8.08\n",
      "[5,   300] loss: 0.979 acc: 64.11 time: 8.13\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 65.32 %\n",
      "Average loss on the 10000 test images: 0.968\n",
      "[6,   100] loss: 0.974 acc: 65.07 time: 8.02\n",
      "[6,   200] loss: 0.971 acc: 64.71 time: 8.04\n",
      "[6,   300] loss: 0.974 acc: 64.75 time: 8.06\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 66.70 %\n",
      "Average loss on the 10000 test images: 0.939\n",
      "[7,   100] loss: 0.957 acc: 65.59 time: 7.97\n",
      "[7,   200] loss: 0.950 acc: 65.99 time: 8.16\n",
      "[7,   300] loss: 0.953 acc: 65.79 time: 9.09\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 65.62 %\n",
      "Average loss on the 10000 test images: 0.970\n",
      "[8,   100] loss: 0.944 acc: 66.61 time: 7.61\n",
      "[8,   200] loss: 0.941 acc: 66.38 time: 8.08\n",
      "[8,   300] loss: 0.938 acc: 67.26 time: 9.44\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 65.09 %\n",
      "Average loss on the 10000 test images: 0.978\n",
      "[9,   100] loss: 0.926 acc: 67.72 time: 8.01\n",
      "[9,   200] loss: 0.928 acc: 67.89 time: 8.68\n",
      "[9,   300] loss: 0.930 acc: 67.62 time: 8.56\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 68.89 %\n",
      "Average loss on the 10000 test images: 0.910\n",
      "[10,   100] loss: 0.912 acc: 68.64 time: 8.26\n",
      "[10,   200] loss: 0.902 acc: 68.89 time: 8.10\n",
      "[10,   300] loss: 0.909 acc: 68.84 time: 8.20\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 70.11 %\n",
      "Average loss on the 10000 test images: 0.884\n",
      "[11,   100] loss: 0.904 acc: 69.67 time: 8.29\n",
      "[11,   200] loss: 0.898 acc: 69.63 time: 8.39\n",
      "[11,   300] loss: 0.896 acc: 69.78 time: 8.31\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 70.70 %\n",
      "Average loss on the 10000 test images: 0.872\n",
      "[12,   100] loss: 0.884 acc: 70.47 time: 8.65\n",
      "[12,   200] loss: 0.885 acc: 70.51 time: 8.88\n",
      "[12,   300] loss: 0.891 acc: 70.21 time: 9.23\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 69.61 %\n",
      "Average loss on the 10000 test images: 0.898\n",
      "[13,   100] loss: 0.871 acc: 71.62 time: 8.27\n",
      "[13,   200] loss: 0.872 acc: 71.17 time: 8.25\n",
      "[13,   300] loss: 0.863 acc: 72.04 time: 8.19\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 72.23 %\n",
      "Average loss on the 10000 test images: 0.847\n",
      "[14,   100] loss: 0.856 acc: 72.16 time: 8.15\n",
      "[14,   200] loss: 0.851 acc: 72.20 time: 8.09\n",
      "[14,   300] loss: 0.862 acc: 71.86 time: 8.08\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 73.81 %\n",
      "Average loss on the 10000 test images: 0.834\n",
      "[15,   100] loss: 0.848 acc: 73.02 time: 11.87\n",
      "[15,   200] loss: 0.834 acc: 73.82 time: 8.78\n",
      "[15,   300] loss: 0.845 acc: 72.84 time: 7.98\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 73.40 %\n",
      "Average loss on the 10000 test images: 0.842\n",
      "[16,   100] loss: 0.814 acc: 74.55 time: 8.21\n",
      "[16,   200] loss: 0.784 acc: 76.40 time: 8.13\n",
      "[16,   300] loss: 0.791 acc: 75.83 time: 8.49\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 77.13 %\n",
      "Average loss on the 10000 test images: 0.765\n",
      "[17,   100] loss: 0.777 acc: 77.02 time: 7.83\n",
      "[17,   200] loss: 0.779 acc: 76.77 time: 8.19\n",
      "[17,   300] loss: 0.778 acc: 76.98 time: 9.98\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 77.53 %\n",
      "Average loss on the 10000 test images: 0.758\n",
      "[18,   100] loss: 0.775 acc: 77.11 time: 8.65\n",
      "[18,   200] loss: 0.778 acc: 76.58 time: 15.68\n",
      "[18,   300] loss: 0.773 acc: 77.02 time: 9.56\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 77.73 %\n",
      "Average loss on the 10000 test images: 0.758\n",
      "[19,   100] loss: 0.768 acc: 77.22 time: 8.02\n",
      "[19,   200] loss: 0.772 acc: 77.06 time: 8.08\n",
      "[19,   300] loss: 0.758 acc: 77.69 time: 8.10\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 77.64 %\n",
      "Average loss on the 10000 test images: 0.754\n",
      "[20,   100] loss: 0.769 acc: 77.35 time: 7.86\n",
      "[20,   200] loss: 0.762 acc: 77.62 time: 8.26\n",
      "[20,   300] loss: 0.757 acc: 77.49 time: 9.07\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 77.72 %\n",
      "Average loss on the 10000 test images: 0.754\n",
      "[21,   100] loss: 0.763 acc: 77.41 time: 8.69\n",
      "[21,   200] loss: 0.756 acc: 77.84 time: 8.63\n",
      "[21,   300] loss: 0.762 acc: 77.62 time: 8.79\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 77.96 %\n",
      "Average loss on the 10000 test images: 0.751\n",
      "[22,   100] loss: 0.756 acc: 77.94 time: 7.77\n",
      "[22,   200] loss: 0.758 acc: 77.93 time: 8.06\n",
      "[22,   300] loss: 0.750 acc: 78.50 time: 8.14\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 78.56 %\n",
      "Average loss on the 10000 test images: 0.747\n",
      "[23,   100] loss: 0.755 acc: 77.98 time: 8.27\n",
      "[23,   200] loss: 0.756 acc: 77.95 time: 8.08\n",
      "[23,   300] loss: 0.756 acc: 77.99 time: 8.38\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 78.84 %\n",
      "Average loss on the 10000 test images: 0.747\n",
      "[24,   100] loss: 0.740 acc: 79.12 time: 7.89\n",
      "[24,   200] loss: 0.750 acc: 78.44 time: 8.15\n",
      "[24,   300] loss: 0.746 acc: 78.45 time: 8.22\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 79.03 %\n",
      "Average loss on the 10000 test images: 0.732\n",
      "[25,   100] loss: 0.744 acc: 78.05 time: 7.96\n",
      "[25,   200] loss: 0.754 acc: 78.24 time: 8.16\n",
      "[25,   300] loss: 0.757 acc: 77.85 time: 8.07\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 78.82 %\n",
      "Average loss on the 10000 test images: 0.740\n",
      "[26,   100] loss: 0.737 acc: 78.89 time: 7.90\n",
      "[26,   200] loss: 0.745 acc: 78.93 time: 8.15\n",
      "[26,   300] loss: 0.736 acc: 79.26 time: 8.32\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 78.61 %\n",
      "Average loss on the 10000 test images: 0.741\n",
      "[27,   100] loss: 0.743 acc: 78.66 time: 8.48\n",
      "[27,   200] loss: 0.740 acc: 79.23 time: 8.16\n",
      "[27,   300] loss: 0.744 acc: 78.72 time: 8.19\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 78.98 %\n",
      "Average loss on the 10000 test images: 0.735\n",
      "[28,   100] loss: 0.742 acc: 78.77 time: 7.94\n",
      "[28,   200] loss: 0.740 acc: 79.27 time: 8.15\n",
      "[28,   300] loss: 0.726 acc: 79.55 time: 15.27\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 79.25 %\n",
      "Average loss on the 10000 test images: 0.736\n",
      "[29,   100] loss: 0.739 acc: 79.33 time: 8.04\n",
      "[29,   200] loss: 0.736 acc: 79.00 time: 8.14\n",
      "[29,   300] loss: 0.735 acc: 79.25 time: 8.25\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 79.25 %\n",
      "Average loss on the 10000 test images: 0.732\n",
      "[30,   100] loss: 0.738 acc: 79.19 time: 8.00\n",
      "[30,   200] loss: 0.726 acc: 79.80 time: 8.21\n",
      "[30,   300] loss: 0.729 acc: 79.32 time: 8.18\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 79.28 %\n",
      "Average loss on the 10000 test images: 0.727\n",
      "[31,   100] loss: 0.725 acc: 79.83 time: 8.06\n",
      "[31,   200] loss: 0.730 acc: 79.48 time: 8.19\n",
      "[31,   300] loss: 0.728 acc: 79.62 time: 8.16\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 79.12 %\n",
      "Average loss on the 10000 test images: 0.727\n",
      "[32,   100] loss: 0.724 acc: 80.12 time: 8.01\n",
      "[32,   200] loss: 0.723 acc: 79.84 time: 8.14\n",
      "[32,   300] loss: 0.732 acc: 79.38 time: 8.31\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 79.42 %\n",
      "Average loss on the 10000 test images: 0.722\n",
      "[33,   100] loss: 0.724 acc: 79.62 time: 8.05\n",
      "[33,   200] loss: 0.722 acc: 80.00 time: 8.20\n",
      "[33,   300] loss: 0.719 acc: 79.98 time: 8.17\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 79.52 %\n",
      "Average loss on the 10000 test images: 0.722\n",
      "[34,   100] loss: 0.724 acc: 79.85 time: 10.25\n",
      "[34,   200] loss: 0.717 acc: 80.23 time: 8.23\n",
      "[34,   300] loss: 0.738 acc: 79.16 time: 8.19\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 79.52 %\n",
      "Average loss on the 10000 test images: 0.726\n",
      "[35,   100] loss: 0.724 acc: 79.83 time: 8.05\n",
      "[35,   200] loss: 0.729 acc: 79.56 time: 8.29\n",
      "[35,   300] loss: 0.714 acc: 80.28 time: 8.14\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 79.56 %\n",
      "Average loss on the 10000 test images: 0.723\n",
      "[36,   100] loss: 0.726 acc: 79.33 time: 8.02\n",
      "[36,   200] loss: 0.714 acc: 80.30 time: 8.26\n",
      "[36,   300] loss: 0.718 acc: 80.24 time: 8.45\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 79.31 %\n",
      "Average loss on the 10000 test images: 0.724\n",
      "[37,   100] loss: 0.720 acc: 79.84 time: 8.12\n",
      "[37,   200] loss: 0.719 acc: 80.11 time: 8.17\n",
      "[37,   300] loss: 0.725 acc: 79.53 time: 8.22\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 79.61 %\n",
      "Average loss on the 10000 test images: 0.720\n",
      "[38,   100] loss: 0.723 acc: 79.62 time: 8.15\n",
      "[38,   200] loss: 0.713 acc: 80.39 time: 8.13\n",
      "[38,   300] loss: 0.727 acc: 79.89 time: 8.18\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 79.95 %\n",
      "Average loss on the 10000 test images: 0.720\n",
      "[39,   100] loss: 0.720 acc: 80.20 time: 7.99\n",
      "[39,   200] loss: 0.723 acc: 79.75 time: 8.09\n",
      "[39,   300] loss: 0.717 acc: 80.27 time: 8.31\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 79.28 %\n",
      "Average loss on the 10000 test images: 0.726\n",
      "[40,   100] loss: 0.724 acc: 79.77 time: 8.17\n",
      "[40,   200] loss: 0.716 acc: 80.13 time: 8.26\n",
      "[40,   300] loss: 0.719 acc: 80.33 time: 8.17\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 79.58 %\n",
      "Average loss on the 10000 test images: 0.720\n",
      "[41,   100] loss: 0.721 acc: 79.86 time: 8.05\n",
      "[41,   200] loss: 0.721 acc: 80.08 time: 8.17\n",
      "[41,   300] loss: 0.713 acc: 80.47 time: 8.78\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 79.59 %\n",
      "Average loss on the 10000 test images: 0.721\n",
      "[42,   100] loss: 0.720 acc: 80.00 time: 8.08\n",
      "[42,   200] loss: 0.720 acc: 80.06 time: 8.22\n",
      "[42,   300] loss: 0.719 acc: 79.96 time: 8.14\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 79.56 %\n",
      "Average loss on the 10000 test images: 0.722\n",
      "[43,   100] loss: 0.721 acc: 79.92 time: 8.08\n",
      "[43,   200] loss: 0.720 acc: 79.92 time: 8.23\n",
      "[43,   300] loss: 0.723 acc: 79.83 time: 8.18\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 79.57 %\n",
      "Average loss on the 10000 test images: 0.724\n",
      "[44,   100] loss: 0.723 acc: 79.66 time: 8.11\n",
      "[44,   200] loss: 0.719 acc: 79.90 time: 8.30\n",
      "[44,   300] loss: 0.725 acc: 79.68 time: 8.40\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 79.88 %\n",
      "Average loss on the 10000 test images: 0.719\n",
      "[45,   100] loss: 0.720 acc: 80.29 time: 8.22\n",
      "[45,   200] loss: 0.720 acc: 80.16 time: 8.05\n",
      "[45,   300] loss: 0.715 acc: 80.27 time: 8.01\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 79.84 %\n",
      "Average loss on the 10000 test images: 0.719\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "train(net, criterion, optimizer, num_epochs=45, decay_epochs=15, init_lr=0.01, task='rotation')\n",
    "################################\n",
    "#     TODO: Save the model     #  \n",
    "################################\n",
    "# Get current date and time\n",
    "current_time = datetime.now().strftime(\"%Y-%m-%d-%H-%M-%S\")\n",
    "\n",
    "# Save the model\n",
    "model_path = f\"model_{current_time}.pth\"\n",
    "torch.save(net.state_dict(), model_path)\n",
    "################################\n",
    "#      End of your code        #  \n",
    "################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PLLMRTS9rTnk"
   },
   "source": [
    "## Fine-tuning on the pre-trained model (9 points)\n",
    "\n",
    "In this section, we will load the ResNet18 model pre-trained on the rotation task and fine-tune on the classification task. We will freeze all previous layers except for the 'layer4' block and 'fc' layer.\n",
    "\n",
    "**Then we will use the trained model from rotation task as the pretrained weights. Notice, you should not use the pretrained weights from ImageNet.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-02T15:50:10.479475300Z",
     "start_time": "2023-11-02T15:50:10.389467200Z"
    },
    "id": "S4nX4ExlrymI"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torchvision.models import resnet18\n",
    "\n",
    "#####################################################\n",
    "#     TODO: Load the pre-trained ResNet18 model     #  \n",
    "#####################################################\n",
    "# load the trained classifier weights\n",
    "ckpt = torch.load('model_2023-11-02-23-22-09.pth')\n",
    "net.load_state_dict(ckpt)\n",
    "####################################################\n",
    "#                End of your code                  #   \n",
    "####################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-02T15:50:38.398084Z",
     "start_time": "2023-11-02T15:50:38.373096900Z"
    },
    "id": "kD44g-TxwYdU"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=512, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#################################################################################################\n",
    "#   TODO: Freeze all previous layers; only keep the 'layer4' block and 'fc' layer trainable     #\n",
    "#################################################################################################\n",
    "# Freeze all parameters\n",
    "net.requires_grad_(False)\n",
    "\n",
    "# Adjusting the fully connected layer to have 10 outputs for 10 classes\n",
    "net.fc = nn.Linear(net.fc.in_features, 10)  # Re-define the fc layer\n",
    "\n",
    "# Unfreeze the last block (layer4) and the fully connected (fc) layer\n",
    "net.layer4.requires_grad_(True)\n",
    "net.fc.requires_grad_(True)\n",
    "\n",
    "# Make sure to move the model to the device after modifying it\n",
    "net.to(device)\n",
    "#################################################################################################\n",
    "#                                          End of your code                                     #\n",
    "#################################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-02T15:50:48.900289800Z",
     "start_time": "2023-11-02T15:50:48.894658Z"
    },
    "id": "9T5DX0efr4fh"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Params to learn:\n",
      "\t layer4.0.conv1.weight\n",
      "\t layer4.0.bn1.weight\n",
      "\t layer4.0.bn1.bias\n",
      "\t layer4.0.conv2.weight\n",
      "\t layer4.0.bn2.weight\n",
      "\t layer4.0.bn2.bias\n",
      "\t layer4.0.downsample.0.weight\n",
      "\t layer4.0.downsample.1.weight\n",
      "\t layer4.0.downsample.1.bias\n",
      "\t layer4.1.conv1.weight\n",
      "\t layer4.1.bn1.weight\n",
      "\t layer4.1.bn1.bias\n",
      "\t layer4.1.conv2.weight\n",
      "\t layer4.1.bn2.weight\n",
      "\t layer4.1.bn2.bias\n",
      "\t fc.weight\n",
      "\t fc.bias\n"
     ]
    }
   ],
   "source": [
    "# Print all the trainable parameters\n",
    "params_to_update = net.parameters()\n",
    "print(\"Params to learn:\")\n",
    "params_to_update = []\n",
    "for name,param in net.named_parameters():\n",
    "    if param.requires_grad == True:\n",
    "        params_to_update.append(param)\n",
    "        print(\"\\t\",name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-02T15:50:53.794832200Z",
     "start_time": "2023-11-02T15:50:53.783320300Z"
    },
    "id": "xb032dG700ph"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CrossEntropyLoss()"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO: Define criterion and optimizer\n",
    "# Note that your optimizer only needs to update the parameters that are trainable.\n",
    "criterion = nn.CrossEntropyLoss(label_smoothing=0.1)\n",
    "\n",
    "# Optimizer: Update only the parameters of layer4 and fc\n",
    "optimizer = optim.Adam([\n",
    "    {'params': net.layer4.parameters()},\n",
    "    {'params': net.fc.parameters()}\n",
    "], lr=0.001)\n",
    "\n",
    "criterion.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-02T16:03:04.822862700Z",
     "start_time": "2023-11-02T15:50:56.058694300Z"
    },
    "id": "3vLSwOo6sBjl"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,   100] loss: 1.947 acc: 30.89 time: 14.61\n",
      "[1,   200] loss: 1.740 acc: 41.41 time: 7.58\n",
      "[1,   300] loss: 1.666 acc: 45.16 time: 8.46\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 48.69 %\n",
      "Average loss on the 10000 test images: 1.585\n",
      "[2,   100] loss: 1.620 acc: 47.46 time: 7.00\n",
      "[2,   200] loss: 1.605 acc: 48.37 time: 7.58\n",
      "[2,   300] loss: 1.604 acc: 48.34 time: 7.67\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 51.22 %\n",
      "Average loss on the 10000 test images: 1.550\n",
      "[3,   100] loss: 1.574 acc: 49.66 time: 6.99\n",
      "[3,   200] loss: 1.573 acc: 50.33 time: 7.82\n",
      "[3,   300] loss: 1.577 acc: 49.33 time: 7.76\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 54.14 %\n",
      "Average loss on the 10000 test images: 1.492\n",
      "[4,   100] loss: 1.553 acc: 51.19 time: 7.00\n",
      "[4,   200] loss: 1.556 acc: 50.28 time: 7.93\n",
      "[4,   300] loss: 1.556 acc: 51.55 time: 8.04\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 53.24 %\n",
      "Average loss on the 10000 test images: 1.518\n",
      "[5,   100] loss: 1.537 acc: 52.16 time: 7.05\n",
      "[5,   200] loss: 1.527 acc: 52.45 time: 7.75\n",
      "[5,   300] loss: 1.527 acc: 52.12 time: 7.70\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 54.44 %\n",
      "Average loss on the 10000 test images: 1.483\n",
      "[6,   100] loss: 1.526 acc: 52.34 time: 7.22\n",
      "[6,   200] loss: 1.516 acc: 53.16 time: 7.87\n",
      "[6,   300] loss: 1.516 acc: 53.31 time: 8.06\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 53.39 %\n",
      "Average loss on the 10000 test images: 1.516\n",
      "[7,   100] loss: 1.504 acc: 53.49 time: 7.82\n",
      "[7,   200] loss: 1.520 acc: 52.48 time: 8.23\n",
      "[7,   300] loss: 1.501 acc: 53.55 time: 8.25\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 54.38 %\n",
      "Average loss on the 10000 test images: 1.483\n",
      "[8,   100] loss: 1.504 acc: 53.05 time: 9.29\n",
      "[8,   200] loss: 1.507 acc: 53.16 time: 8.55\n",
      "[8,   300] loss: 1.497 acc: 53.72 time: 10.86\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 56.63 %\n",
      "Average loss on the 10000 test images: 1.440\n",
      "[9,   100] loss: 1.479 acc: 54.67 time: 8.11\n",
      "[9,   200] loss: 1.488 acc: 54.11 time: 8.95\n",
      "[9,   300] loss: 1.500 acc: 53.65 time: 7.79\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 56.25 %\n",
      "Average loss on the 10000 test images: 1.438\n",
      "[10,   100] loss: 1.486 acc: 54.24 time: 8.56\n",
      "[10,   200] loss: 1.482 acc: 54.03 time: 8.98\n",
      "[10,   300] loss: 1.486 acc: 54.40 time: 6.93\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 55.55 %\n",
      "Average loss on the 10000 test images: 1.456\n",
      "[11,   100] loss: 1.460 acc: 55.43 time: 7.94\n",
      "[11,   200] loss: 1.441 acc: 56.09 time: 7.76\n",
      "[11,   300] loss: 1.441 acc: 56.46 time: 7.82\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 58.33 %\n",
      "Average loss on the 10000 test images: 1.393\n",
      "[12,   100] loss: 1.434 acc: 56.48 time: 7.30\n",
      "[12,   200] loss: 1.444 acc: 56.28 time: 7.83\n",
      "[12,   300] loss: 1.428 acc: 57.27 time: 7.85\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 58.66 %\n",
      "Average loss on the 10000 test images: 1.388\n",
      "[13,   100] loss: 1.428 acc: 56.78 time: 7.25\n",
      "[13,   200] loss: 1.444 acc: 55.75 time: 7.76\n",
      "[13,   300] loss: 1.424 acc: 56.97 time: 7.80\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 58.46 %\n",
      "Average loss on the 10000 test images: 1.390\n",
      "[14,   100] loss: 1.425 acc: 57.17 time: 7.12\n",
      "[14,   200] loss: 1.428 acc: 57.02 time: 7.76\n",
      "[14,   300] loss: 1.411 acc: 57.80 time: 7.81\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 58.86 %\n",
      "Average loss on the 10000 test images: 1.385\n",
      "[15,   100] loss: 1.415 acc: 57.66 time: 7.13\n",
      "[15,   200] loss: 1.428 acc: 56.70 time: 7.65\n",
      "[15,   300] loss: 1.420 acc: 57.39 time: 7.71\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 58.88 %\n",
      "Average loss on the 10000 test images: 1.385\n",
      "[16,   100] loss: 1.422 acc: 57.05 time: 7.64\n",
      "[16,   200] loss: 1.426 acc: 57.29 time: 7.70\n",
      "[16,   300] loss: 1.418 acc: 57.74 time: 7.81\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 59.11 %\n",
      "Average loss on the 10000 test images: 1.382\n",
      "[17,   100] loss: 1.420 acc: 57.20 time: 7.16\n",
      "[17,   200] loss: 1.415 acc: 57.72 time: 7.97\n",
      "[17,   300] loss: 1.429 acc: 56.94 time: 7.79\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 59.43 %\n",
      "Average loss on the 10000 test images: 1.373\n",
      "[18,   100] loss: 1.412 acc: 57.62 time: 7.28\n",
      "[18,   200] loss: 1.414 acc: 57.68 time: 8.19\n",
      "[18,   300] loss: 1.421 acc: 57.41 time: 8.01\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 59.39 %\n",
      "Average loss on the 10000 test images: 1.375\n",
      "[19,   100] loss: 1.414 acc: 57.75 time: 8.21\n",
      "[19,   200] loss: 1.415 acc: 57.42 time: 9.97\n",
      "[19,   300] loss: 1.421 acc: 57.52 time: 8.69\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 59.22 %\n",
      "Average loss on the 10000 test images: 1.375\n",
      "[20,   100] loss: 1.413 acc: 57.92 time: 7.90\n",
      "[20,   200] loss: 1.417 acc: 57.38 time: 8.14\n",
      "[20,   300] loss: 1.411 acc: 57.85 time: 9.00\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 59.25 %\n",
      "Average loss on the 10000 test images: 1.376\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "train(net, criterion, optimizer, num_epochs=20, decay_epochs=10, init_lr=0.01, task='classification')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ghPNhcJBrcNj"
   },
   "source": [
    "## Fine-tuning on the randomly initialized model (9 points)\n",
    "In this section, we will randomly initialize a ResNet18 model and fine-tune on the classification task. We will freeze all previous layers except for the 'layer4' block and 'fc' layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-02T16:05:53.239744400Z",
     "start_time": "2023-11-02T16:05:53.097885700Z"
    },
    "id": "2RfXAh9vxXRB"
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torchvision.models import resnet18\n",
    "#################################################\n",
    "# TODO: Randomly initialize a ResNet18 model    #\n",
    "#################################################\n",
    "# Randomly initialize a ResNet18 model\n",
    "net = resnet18(pretrained=False)\n",
    "#################################################\n",
    "#              End of your code                 #\n",
    "#################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-02T16:05:58.891487100Z",
     "start_time": "2023-11-02T16:05:58.805346400Z"
    },
    "id": "fpx-SYAizt4p"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=512, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#################################################################################################\n",
    "# TODO: Freeze all previous layers; only keep the 'layer4' block and 'fc' layer trainable       #\n",
    "# To do this, you should set requires_grad=False for the frozen layers.                         #\n",
    "#################################################################################################\n",
    "# Adjusting the fully connected layer for 10 classes\n",
    "net.fc = nn.Linear(net.fc.in_features, 10)\n",
    "\n",
    "# Freeze all layers in the randomly initialized model\n",
    "net.requires_grad_(False)\n",
    "\n",
    "# Unfreeze the last block (layer4) and the fully connected (fc) layer\n",
    "net.layer4.requires_grad_(True)\n",
    "net.fc.requires_grad_(True)\n",
    "\n",
    "# Move the model to the device\n",
    "net.to(device)\n",
    "#################################################################################################\n",
    "#                                          End of your code                                     #\n",
    "#################################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-02T16:06:12.468191Z",
     "start_time": "2023-11-02T16:06:12.454161400Z"
    },
    "id": "BUFWizbHxgm2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Params to learn:\n",
      "\t layer4.0.conv1.weight\n",
      "\t layer4.0.bn1.weight\n",
      "\t layer4.0.bn1.bias\n",
      "\t layer4.0.conv2.weight\n",
      "\t layer4.0.bn2.weight\n",
      "\t layer4.0.bn2.bias\n",
      "\t layer4.0.downsample.0.weight\n",
      "\t layer4.0.downsample.1.weight\n",
      "\t layer4.0.downsample.1.bias\n",
      "\t layer4.1.conv1.weight\n",
      "\t layer4.1.bn1.weight\n",
      "\t layer4.1.bn1.bias\n",
      "\t layer4.1.conv2.weight\n",
      "\t layer4.1.bn2.weight\n",
      "\t layer4.1.bn2.bias\n",
      "\t fc.weight\n",
      "\t fc.bias\n"
     ]
    }
   ],
   "source": [
    "# Print all the trainable parameters\n",
    "params_to_update = net.parameters()\n",
    "print(\"Params to learn:\")\n",
    "params_to_update = []\n",
    "for name,param in net.named_parameters():\n",
    "    if param.requires_grad == True:\n",
    "        params_to_update.append(param)\n",
    "        print(\"\\t\",name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-02T16:06:16.180960800Z",
     "start_time": "2023-11-02T16:06:16.169398500Z"
    },
    "id": "BxFrGj091AN_"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CrossEntropyLoss()"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO: Define criterion and optimizer\n",
    "# Note that your optimizer only needs to update the parameters that are trainable.\n",
    "criterion = nn.CrossEntropyLoss(label_smoothing=0.1)\n",
    "\n",
    "# Optimizer: Update only the parameters of layer4 and fc\n",
    "optimizer = optim.Adam([\n",
    "    {'params': net.layer4.parameters()},\n",
    "    {'params': net.fc.parameters()}\n",
    "], lr=0.001)\n",
    "\n",
    "criterion.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-02T16:18:06.594381500Z",
     "start_time": "2023-11-02T16:06:19.136104700Z"
    },
    "id": "GzRVy0MZxpoL"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,   100] loss: 2.282 acc: 25.20 time: 7.40\n",
      "[1,   200] loss: 1.988 acc: 31.16 time: 7.51\n",
      "[1,   300] loss: 1.942 acc: 32.67 time: 7.67\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 37.95 %\n",
      "Average loss on the 10000 test images: 1.835\n",
      "[2,   100] loss: 1.895 acc: 34.92 time: 7.55\n",
      "[2,   200] loss: 1.874 acc: 36.98 time: 8.13\n",
      "[2,   300] loss: 1.874 acc: 35.99 time: 8.20\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 39.88 %\n",
      "Average loss on the 10000 test images: 1.788\n",
      "[3,   100] loss: 1.852 acc: 37.55 time: 7.88\n",
      "[3,   200] loss: 1.846 acc: 37.82 time: 7.68\n",
      "[3,   300] loss: 1.847 acc: 37.66 time: 7.74\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 40.81 %\n",
      "Average loss on the 10000 test images: 1.765\n",
      "[4,   100] loss: 1.825 acc: 38.74 time: 7.42\n",
      "[4,   200] loss: 1.815 acc: 39.22 time: 8.04\n",
      "[4,   300] loss: 1.824 acc: 39.10 time: 7.72\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 40.99 %\n",
      "Average loss on the 10000 test images: 1.765\n",
      "[5,   100] loss: 1.811 acc: 39.53 time: 7.12\n",
      "[5,   200] loss: 1.823 acc: 38.97 time: 7.70\n",
      "[5,   300] loss: 1.797 acc: 39.94 time: 8.47\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 41.21 %\n",
      "Average loss on the 10000 test images: 1.744\n",
      "[6,   100] loss: 1.792 acc: 41.10 time: 7.04\n",
      "[6,   200] loss: 1.808 acc: 39.98 time: 7.74\n",
      "[6,   300] loss: 1.803 acc: 40.49 time: 7.94\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 41.72 %\n",
      "Average loss on the 10000 test images: 1.749\n",
      "[7,   100] loss: 1.799 acc: 40.00 time: 7.10\n",
      "[7,   200] loss: 1.772 acc: 41.05 time: 7.74\n",
      "[7,   300] loss: 1.792 acc: 40.24 time: 8.02\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 43.15 %\n",
      "Average loss on the 10000 test images: 1.729\n",
      "[8,   100] loss: 1.781 acc: 40.20 time: 7.11\n",
      "[8,   200] loss: 1.780 acc: 41.35 time: 7.79\n",
      "[8,   300] loss: 1.775 acc: 41.02 time: 8.91\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 43.29 %\n",
      "Average loss on the 10000 test images: 1.728\n",
      "[9,   100] loss: 1.778 acc: 40.71 time: 7.14\n",
      "[9,   200] loss: 1.770 acc: 41.29 time: 7.76\n",
      "[9,   300] loss: 1.759 acc: 41.98 time: 7.94\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 43.73 %\n",
      "Average loss on the 10000 test images: 1.716\n",
      "[10,   100] loss: 1.766 acc: 41.66 time: 7.20\n",
      "[10,   200] loss: 1.767 acc: 41.77 time: 7.80\n",
      "[10,   300] loss: 1.768 acc: 41.40 time: 7.88\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 43.29 %\n",
      "Average loss on the 10000 test images: 1.728\n",
      "[11,   100] loss: 1.739 acc: 42.60 time: 7.90\n",
      "[11,   200] loss: 1.736 acc: 43.12 time: 8.48\n",
      "[11,   300] loss: 1.737 acc: 43.23 time: 8.33\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 45.17 %\n",
      "Average loss on the 10000 test images: 1.686\n",
      "[12,   100] loss: 1.725 acc: 43.73 time: 7.13\n",
      "[12,   200] loss: 1.722 acc: 43.89 time: 9.57\n",
      "[12,   300] loss: 1.711 acc: 43.90 time: 7.46\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 45.28 %\n",
      "Average loss on the 10000 test images: 1.679\n",
      "[13,   100] loss: 1.711 acc: 44.57 time: 7.26\n",
      "[13,   200] loss: 1.700 acc: 44.51 time: 7.88\n",
      "[13,   300] loss: 1.714 acc: 44.75 time: 7.85\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 45.29 %\n",
      "Average loss on the 10000 test images: 1.677\n",
      "[14,   100] loss: 1.701 acc: 44.95 time: 7.48\n",
      "[14,   200] loss: 1.703 acc: 44.66 time: 7.63\n",
      "[14,   300] loss: 1.706 acc: 44.55 time: 7.77\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 46.14 %\n",
      "Average loss on the 10000 test images: 1.669\n",
      "[15,   100] loss: 1.706 acc: 44.20 time: 7.12\n",
      "[15,   200] loss: 1.703 acc: 44.68 time: 7.64\n",
      "[15,   300] loss: 1.697 acc: 45.16 time: 7.76\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 46.44 %\n",
      "Average loss on the 10000 test images: 1.663\n",
      "[16,   100] loss: 1.694 acc: 44.93 time: 7.15\n",
      "[16,   200] loss: 1.697 acc: 44.81 time: 7.72\n",
      "[16,   300] loss: 1.710 acc: 44.45 time: 7.92\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 46.57 %\n",
      "Average loss on the 10000 test images: 1.657\n",
      "[17,   100] loss: 1.707 acc: 44.99 time: 7.23\n",
      "[17,   200] loss: 1.696 acc: 44.84 time: 7.87\n",
      "[17,   300] loss: 1.690 acc: 44.80 time: 8.02\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 46.64 %\n",
      "Average loss on the 10000 test images: 1.659\n",
      "[18,   100] loss: 1.686 acc: 45.45 time: 7.29\n",
      "[18,   200] loss: 1.696 acc: 44.56 time: 7.86\n",
      "[18,   300] loss: 1.691 acc: 44.98 time: 7.93\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 47.04 %\n",
      "Average loss on the 10000 test images: 1.653\n",
      "[19,   100] loss: 1.684 acc: 45.07 time: 7.11\n",
      "[19,   200] loss: 1.689 acc: 45.66 time: 7.81\n",
      "[19,   300] loss: 1.680 acc: 45.85 time: 7.89\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 46.29 %\n",
      "Average loss on the 10000 test images: 1.660\n",
      "[20,   100] loss: 1.692 acc: 44.95 time: 7.12\n",
      "[20,   200] loss: 1.681 acc: 46.22 time: 7.78\n",
      "[20,   300] loss: 1.674 acc: 46.52 time: 7.85\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 46.79 %\n",
      "Average loss on the 10000 test images: 1.652\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "train(net, criterion, optimizer, num_epochs=20, decay_epochs=10, init_lr=0.01, task='classification')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WcN54tcNN15U"
   },
   "source": [
    "## Supervised training on the pre-trained model (9 points)\n",
    "In this section, we will load the ResNet18 model pre-trained on the rotation task and re-train the whole model on the classification task.\n",
    "\n",
    "**Then we will use the trained model from rotation task as the pretrained weights. Notice, you should not use the pretrained weights from ImageNet.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-02T16:18:51.610621100Z",
     "start_time": "2023-11-02T16:18:51.319450600Z"
    },
    "id": "9xR9h_S1N6Xi"
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torchvision.models import resnet18\n",
    "\n",
    "#####################################################\n",
    "#     TODO: Load the pre-trained ResNet18 model     #  \n",
    "#####################################################\n",
    "# load the trained classifier weights\n",
    "net = resnet18(weights=None, num_classes=4)\n",
    "ckpt = torch.load('model_2023-11-02-23-22-09.pth')\n",
    "net.load_state_dict(ckpt)\n",
    "\n",
    "# Adjusting the fully connected layer for 10 classes\n",
    "net.fc = nn.Linear(net.fc.in_features, 10)\n",
    "net = net.to(device)\n",
    "#####################################################\n",
    "#                End of your code                   #   \n",
    "#####################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-02T16:18:53.538111900Z",
     "start_time": "2023-11-02T16:18:53.532369700Z"
    },
    "id": "gGozc2cM0ADw"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CrossEntropyLoss()"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO: Define criterion and optimizer\n",
    "criterion = nn.CrossEntropyLoss(label_smoothing=0.1)\n",
    "\n",
    "# Optimizer: Update only the parameters of layer4 and fc\n",
    "optimizer = optim.Adam(lr=0.001, params=net.parameters())\n",
    "\n",
    "criterion.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-02T16:30:56.620142100Z",
     "start_time": "2023-11-02T16:18:55.294163100Z"
    },
    "id": "JGWW7gzCz_Bu"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,   100] loss: 1.646 acc: 46.39 time: 7.61\n",
      "[1,   200] loss: 1.375 acc: 60.07 time: 7.79\n",
      "[1,   300] loss: 1.312 acc: 63.84 time: 7.80\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 69.11 %\n",
      "Average loss on the 10000 test images: 1.207\n",
      "[2,   100] loss: 1.215 acc: 68.43 time: 8.12\n",
      "[2,   200] loss: 1.188 acc: 69.86 time: 8.22\n",
      "[2,   300] loss: 1.166 acc: 70.59 time: 9.13\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 72.63 %\n",
      "Average loss on the 10000 test images: 1.115\n",
      "[3,   100] loss: 1.105 acc: 73.33 time: 7.78\n",
      "[3,   200] loss: 1.092 acc: 73.92 time: 8.04\n",
      "[3,   300] loss: 1.092 acc: 74.15 time: 7.97\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 74.88 %\n",
      "Average loss on the 10000 test images: 1.065\n",
      "[4,   100] loss: 1.055 acc: 75.40 time: 7.89\n",
      "[4,   200] loss: 1.057 acc: 75.47 time: 7.93\n",
      "[4,   300] loss: 1.035 acc: 76.24 time: 8.07\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 76.23 %\n",
      "Average loss on the 10000 test images: 1.041\n",
      "[5,   100] loss: 1.019 acc: 77.13 time: 7.83\n",
      "[5,   200] loss: 1.001 acc: 78.05 time: 8.19\n",
      "[5,   300] loss: 1.005 acc: 77.79 time: 8.07\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 78.46 %\n",
      "Average loss on the 10000 test images: 0.998\n",
      "[6,   100] loss: 0.986 acc: 78.36 time: 7.69\n",
      "[6,   200] loss: 0.991 acc: 78.52 time: 7.89\n",
      "[6,   300] loss: 0.979 acc: 79.15 time: 7.92\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 78.74 %\n",
      "Average loss on the 10000 test images: 0.984\n",
      "[7,   100] loss: 0.961 acc: 79.95 time: 8.02\n",
      "[7,   200] loss: 0.974 acc: 79.57 time: 8.05\n",
      "[7,   300] loss: 0.954 acc: 79.80 time: 8.17\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 75.45 %\n",
      "Average loss on the 10000 test images: 1.053\n",
      "[8,   100] loss: 0.943 acc: 80.33 time: 7.94\n",
      "[8,   200] loss: 0.927 acc: 81.20 time: 8.04\n",
      "[8,   300] loss: 0.938 acc: 80.91 time: 8.09\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 78.73 %\n",
      "Average loss on the 10000 test images: 0.983\n",
      "[9,   100] loss: 0.918 acc: 81.75 time: 7.99\n",
      "[9,   200] loss: 0.921 acc: 81.27 time: 8.02\n",
      "[9,   300] loss: 0.925 acc: 81.48 time: 8.04\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 79.68 %\n",
      "Average loss on the 10000 test images: 0.961\n",
      "[10,   100] loss: 0.903 acc: 82.06 time: 7.97\n",
      "[10,   200] loss: 0.898 acc: 82.38 time: 8.33\n",
      "[10,   300] loss: 0.914 acc: 81.95 time: 7.99\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 80.45 %\n",
      "Average loss on the 10000 test images: 0.938\n",
      "[11,   100] loss: 0.851 acc: 84.52 time: 8.08\n",
      "[11,   200] loss: 0.833 acc: 85.45 time: 8.13\n",
      "[11,   300] loss: 0.823 acc: 85.74 time: 8.16\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 83.06 %\n",
      "Average loss on the 10000 test images: 0.874\n",
      "[12,   100] loss: 0.810 acc: 86.34 time: 7.97\n",
      "[12,   200] loss: 0.806 acc: 86.43 time: 7.94\n",
      "[12,   300] loss: 0.820 acc: 85.88 time: 7.81\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 83.37 %\n",
      "Average loss on the 10000 test images: 0.873\n",
      "[13,   100] loss: 0.802 acc: 86.67 time: 16.57\n",
      "[13,   200] loss: 0.792 acc: 87.09 time: 8.06\n",
      "[13,   300] loss: 0.795 acc: 87.09 time: 7.99\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 83.55 %\n",
      "Average loss on the 10000 test images: 0.867\n",
      "[14,   100] loss: 0.795 acc: 86.86 time: 7.96\n",
      "[14,   200] loss: 0.794 acc: 86.93 time: 8.01\n",
      "[14,   300] loss: 0.792 acc: 87.16 time: 7.97\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 83.63 %\n",
      "Average loss on the 10000 test images: 0.868\n",
      "[15,   100] loss: 0.777 acc: 87.65 time: 7.80\n",
      "[15,   200] loss: 0.793 acc: 86.74 time: 7.94\n",
      "[15,   300] loss: 0.785 acc: 87.54 time: 7.97\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 83.79 %\n",
      "Average loss on the 10000 test images: 0.865\n",
      "[16,   100] loss: 0.781 acc: 87.52 time: 9.15\n",
      "[16,   200] loss: 0.777 acc: 87.83 time: 8.38\n",
      "[16,   300] loss: 0.782 acc: 87.64 time: 8.62\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 83.83 %\n",
      "Average loss on the 10000 test images: 0.869\n",
      "[17,   100] loss: 0.757 acc: 88.63 time: 7.66\n",
      "[17,   200] loss: 0.780 acc: 87.65 time: 7.87\n",
      "[17,   300] loss: 0.773 acc: 87.92 time: 7.92\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 84.16 %\n",
      "Average loss on the 10000 test images: 0.864\n",
      "[18,   100] loss: 0.768 acc: 88.30 time: 7.71\n",
      "[18,   200] loss: 0.779 acc: 87.57 time: 7.90\n",
      "[18,   300] loss: 0.775 acc: 87.68 time: 8.05\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 84.23 %\n",
      "Average loss on the 10000 test images: 0.860\n",
      "[19,   100] loss: 0.768 acc: 88.24 time: 7.75\n",
      "[19,   200] loss: 0.759 acc: 88.63 time: 8.09\n",
      "[19,   300] loss: 0.768 acc: 88.20 time: 7.91\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 83.99 %\n",
      "Average loss on the 10000 test images: 0.861\n",
      "[20,   100] loss: 0.748 acc: 89.05 time: 7.75\n",
      "[20,   200] loss: 0.769 acc: 88.41 time: 7.87\n",
      "[20,   300] loss: 0.756 acc: 88.68 time: 8.00\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 84.23 %\n",
      "Average loss on the 10000 test images: 0.860\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "train(net, criterion, optimizer, num_epochs=20, decay_epochs=10, init_lr=0.01, task='classification')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xjVTp9jhefTi"
   },
   "source": [
    "## Supervised training on the randomly initialized model (9 points)\n",
    "In this section, we will randomly initialize a ResNet18 model and re-train the whole model on the classification task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-02T16:30:56.774655300Z",
     "start_time": "2023-11-02T16:30:56.621142800Z"
    },
    "id": "uEjy8TBieeLK"
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torchvision.models import resnet18\n",
    "\n",
    "#################################################\n",
    "# TODO: Randomly initialize a ResNet18 model    #\n",
    "#################################################\n",
    "net = resnet18(weights=None, num_classes=10)\n",
    "net = net.to(device)\n",
    "#################################################\n",
    "#              End of your code                 #\n",
    "#################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-02T16:30:56.780670300Z",
     "start_time": "2023-11-02T16:30:56.775670200Z"
    },
    "id": "jEY90pK_0ZAm"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CrossEntropyLoss()"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO: Define criterion and optimizer\n",
    "criterion = nn.CrossEntropyLoss(label_smoothing=0.1)\n",
    "\n",
    "# Optimizer: Update only the parameters of layer4 and fc\n",
    "optimizer = optim.Adam(lr=0.001, params=net.parameters())\n",
    "\n",
    "criterion.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-02T16:42:20.022178100Z",
     "start_time": "2023-11-02T16:30:56.782667600Z"
    },
    "id": "lMDwelhY0auO"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,   100] loss: 2.389 acc: 20.36 time: 7.88\n",
      "[1,   200] loss: 2.000 acc: 30.71 time: 8.03\n",
      "[1,   300] loss: 1.916 acc: 35.30 time: 8.44\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 42.55 %\n",
      "Average loss on the 10000 test images: 1.749\n",
      "[2,   100] loss: 1.710 acc: 43.37 time: 8.01\n",
      "[2,   200] loss: 1.671 acc: 45.06 time: 8.00\n",
      "[2,   300] loss: 1.623 acc: 48.02 time: 7.95\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 48.34 %\n",
      "Average loss on the 10000 test images: 1.614\n",
      "[3,   100] loss: 1.520 acc: 52.64 time: 7.91\n",
      "[3,   200] loss: 1.480 acc: 54.75 time: 7.99\n",
      "[3,   300] loss: 1.427 acc: 57.74 time: 8.03\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 59.38 %\n",
      "Average loss on the 10000 test images: 1.404\n",
      "[4,   100] loss: 1.348 acc: 61.86 time: 7.88\n",
      "[4,   200] loss: 1.333 acc: 61.82 time: 8.06\n",
      "[4,   300] loss: 1.316 acc: 62.92 time: 7.98\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 66.15 %\n",
      "Average loss on the 10000 test images: 1.254\n",
      "[5,   100] loss: 1.249 acc: 66.68 time: 7.73\n",
      "[5,   200] loss: 1.244 acc: 66.88 time: 7.66\n",
      "[5,   300] loss: 1.231 acc: 67.12 time: 13.66\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 69.82 %\n",
      "Average loss on the 10000 test images: 1.181\n",
      "[6,   100] loss: 1.181 acc: 69.68 time: 7.43\n",
      "[6,   200] loss: 1.186 acc: 69.55 time: 7.59\n",
      "[6,   300] loss: 1.165 acc: 70.13 time: 7.55\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 73.16 %\n",
      "Average loss on the 10000 test images: 1.105\n",
      "[7,   100] loss: 1.111 acc: 72.62 time: 7.21\n",
      "[7,   200] loss: 1.126 acc: 72.30 time: 7.52\n",
      "[7,   300] loss: 1.133 acc: 71.51 time: 7.56\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 73.47 %\n",
      "Average loss on the 10000 test images: 1.105\n",
      "[8,   100] loss: 1.096 acc: 73.52 time: 7.10\n",
      "[8,   200] loss: 1.071 acc: 74.60 time: 7.53\n",
      "[8,   300] loss: 1.085 acc: 74.37 time: 7.50\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 71.70 %\n",
      "Average loss on the 10000 test images: 1.153\n",
      "[9,   100] loss: 1.049 acc: 75.96 time: 7.40\n",
      "[9,   200] loss: 1.057 acc: 75.30 time: 7.56\n",
      "[9,   300] loss: 1.040 acc: 75.73 time: 7.50\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 75.22 %\n",
      "Average loss on the 10000 test images: 1.058\n",
      "[10,   100] loss: 1.031 acc: 76.74 time: 7.12\n",
      "[10,   200] loss: 1.032 acc: 76.41 time: 7.49\n",
      "[10,   300] loss: 1.014 acc: 77.29 time: 7.54\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 73.01 %\n",
      "Average loss on the 10000 test images: 1.108\n",
      "[11,   100] loss: 0.962 acc: 79.68 time: 7.24\n",
      "[11,   200] loss: 0.945 acc: 80.43 time: 7.55\n",
      "[11,   300] loss: 0.916 acc: 81.79 time: 7.52\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 80.77 %\n",
      "Average loss on the 10000 test images: 0.929\n",
      "[12,   100] loss: 0.901 acc: 82.22 time: 7.34\n",
      "[12,   200] loss: 0.897 acc: 82.45 time: 7.53\n",
      "[12,   300] loss: 0.901 acc: 82.25 time: 7.52\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 81.07 %\n",
      "Average loss on the 10000 test images: 0.919\n",
      "[13,   100] loss: 0.887 acc: 82.58 time: 7.23\n",
      "[13,   200] loss: 0.886 acc: 82.81 time: 7.54\n",
      "[13,   300] loss: 0.879 acc: 83.03 time: 7.52\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 81.52 %\n",
      "Average loss on the 10000 test images: 0.914\n",
      "[14,   100] loss: 0.866 acc: 83.68 time: 7.46\n",
      "[14,   200] loss: 0.862 acc: 83.81 time: 7.51\n",
      "[14,   300] loss: 0.876 acc: 83.14 time: 7.53\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 81.76 %\n",
      "Average loss on the 10000 test images: 0.909\n",
      "[15,   100] loss: 0.860 acc: 84.10 time: 7.42\n",
      "[15,   200] loss: 0.868 acc: 83.38 time: 7.54\n",
      "[15,   300] loss: 0.868 acc: 83.45 time: 7.50\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 81.89 %\n",
      "Average loss on the 10000 test images: 0.906\n",
      "[16,   100] loss: 0.853 acc: 84.28 time: 7.32\n",
      "[16,   200] loss: 0.855 acc: 84.34 time: 7.49\n",
      "[16,   300] loss: 0.855 acc: 84.11 time: 7.50\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 82.21 %\n",
      "Average loss on the 10000 test images: 0.905\n",
      "[17,   100] loss: 0.845 acc: 84.59 time: 7.09\n",
      "[17,   200] loss: 0.836 acc: 85.20 time: 7.56\n",
      "[17,   300] loss: 0.843 acc: 84.78 time: 7.52\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 82.53 %\n",
      "Average loss on the 10000 test images: 0.898\n",
      "[18,   100] loss: 0.840 acc: 84.95 time: 7.28\n",
      "[18,   200] loss: 0.828 acc: 85.36 time: 7.51\n",
      "[18,   300] loss: 0.838 acc: 85.58 time: 7.52\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 82.44 %\n",
      "Average loss on the 10000 test images: 0.897\n",
      "[19,   100] loss: 0.830 acc: 85.48 time: 7.29\n",
      "[19,   200] loss: 0.831 acc: 85.41 time: 7.52\n",
      "[19,   300] loss: 0.836 acc: 85.14 time: 7.54\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 82.39 %\n",
      "Average loss on the 10000 test images: 0.899\n",
      "[20,   100] loss: 0.822 acc: 85.97 time: 7.47\n",
      "[20,   200] loss: 0.811 acc: 86.48 time: 7.59\n",
      "[20,   300] loss: 0.826 acc: 85.52 time: 7.53\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 82.77 %\n",
      "Average loss on the 10000 test images: 0.891\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "train(net, criterion, optimizer, num_epochs=20, decay_epochs=10, init_lr=0.01, task='classification')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Write report (37 points)\n",
    "\n",
    "本次作業主要有3個tasks需要大家完成，在A4.pdf中有希望大家達成的baseline **(不能低於baseline最多2%，沒有達到不會給全部分數)**，report的撰寫就希望大家可以透過去調整不同的訓練方法、損失函數、優化器，或者是調整凍結不同的層來進行這次的實驗，就請大家將嘗試的結果寫在report裡，祝大家順利！\n",
    "\n",
    "- Rotation task (13 points)\n",
    "- Fine-tuning the specified layers of the pre-trained model (12 points)\n",
    "- Fine-tuning the whole pre-trained model (12 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extra Credit (13 points)\n",
    "\n",
    "上面基本的code跟report最高可以拿到87分，這個加分部分並沒有要求同學們一定要做，若同學們想要獲得更高的分數可以根據以下的加分要求來獲得加分。\n",
    "\n",
    "- In Figure 5(b) from the Gidaris et al. paper, the authors show a plot of CIFAR10 classification performance vs. number of training examples per category for a supervised CIFAR10 model vs. a RotNet model with the final layers fine-tuned on CIFAR10. The plot shows that pre-training on the Rotation task can be advantageous when only a small amount of labeled data is available. Using your RotNet fine-tuning code and supervised CIFAR10 training code from the main assignment, try to create a similar plot by performing supervised fine-tuning/training on only a subset of CIFAR10.\n",
    "- Use a more advanced model than ResNet18 to try to get higher accuracy on the rotation prediction task, as well as for transfer to supervised CIFAR10 classification.\n",
    "  \n",
    "- If you have a good amount of compute at your disposal, try to train a rotation prediction model on the larger ImageNette dataset (still smaller than ImageNet, though).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": [
    {
     "file_id": "1qQ3NEaCUln7yDSksrEOnDwrt3u9dYNr4",
     "timestamp": 1677623843954
    }
   ]
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "vscode": {
   "interpreter": {
    "hash": "aaa478f9632825e83f6a2247407c7a2930de96a6810af7910643e423346524f9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
