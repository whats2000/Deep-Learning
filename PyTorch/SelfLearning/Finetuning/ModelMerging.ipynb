{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Model Merging\n",
    "概念上，模型分別是由不同的特徵和不同的訓練資料訓練出來的，所以模型之間的差異性是很大的。但是，如果我們能夠將這些模型合併在一起，那麼我們就可以利用這些模型的優勢，來提高模型的預測能力。這就是模型合併的概念。\n",
    "\n",
    "早期研究室使用直接將模型的參數合併在一起，但是這樣的方法並不是很有效。\n",
    "\n",
    "後來，研究把參數當成向量，然後使用向量的加法和乘法來合併模型。這樣的方法相比於直接合併參數，效果要好很多。像是該方法可應用於\"忘記\"模型，這可以拆解成原本的模型和被需要\"忘記\"的模型，然後將這兩個模型合併在一起(忘記模型要乘上-1)，這樣就可以達到\"忘記\"的效果。\n",
    "\n",
    "到後來，TIES Method提出了一個更好的方法，他們提出了一個新的模型合併方法，這個方法可以將模型的參數合併在一起，並且可以避免模型之間的干擾。這個方法的步驟如下：\n",
    "- 修剪（Trim）：僅保留在微調過程中變化顯著的參數，將變化較小的參數重設為預訓練模型的初始值，以減少冗餘參數的干擾。\n",
    "- 選舉（Elect Sign）：針對不同模型中符號不一致的參數，決定每個參數的最終符號，並確保合併後的參數符號一致。\n",
    "- 合併（Merge）：僅對符號一致的參數進行平均合併，忽略符號不一致的參數，以減少干擾，提升合併模型的效能\n",
    "然而雖然這個方法可大幅提升不同模型合併的效能，但是這個方法也會進一步增長Perplexity。\n",
    "\n",
    "應用:\n",
    "- 控制模型輸出的風格: 像是把說故事的模型減去成人語言模型，就可以讓模型的輸出更加符合兒童故事的風格。\n",
    "- Reward Model: 這個模型可以用來評估模型的輸出，然後根據這個模型的評估來調整模型的參數，這樣可以提高模型的預測能力。但是若是把Reward Model和原本的模型合併在一起，就可以直接提高模型的預測能力。使其具備特定領域的專業知識，這樣就可以提高模型的預測能力。\n",
    "\n",
    "優勢:\n",
    "- 方法簡單: 只需要將模型的參數合併在一起，就可以提高模型的預測能力。\n",
    "- Toolkits: 有很多工具可以幫助我們合併模型。\n",
    "- 已有很多 Checkpoint 可以使用: 可以直接使用已經訓練好的模型，不需要重新訓練模型。\n",
    "\n",
    "挑戰:\n",
    "- 沒有太多理論分析講述為什麼模型合併可以提高模型的預測能力。\n",
    "- 合併後會有不想要的副作用: 例如重複輸出，這樣會影響實際應用的效果。"
   ],
   "id": "ad6fe85fe314bdbb"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": ""
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
